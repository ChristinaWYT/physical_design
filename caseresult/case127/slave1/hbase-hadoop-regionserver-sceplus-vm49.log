Sun Jul 13 23:09:21 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-13 23:09:21,834 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-13 23:09:21,835 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-13 23:09:21,835 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-13 23:09:22,079 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 43438 22
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-13 23:09:22,080 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 43438 9.1.143.59 22
2014-07-13 23:09:22,081 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-13 23:09:22,082 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-13 23:09:22,082 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-13 23:09:22,084 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-13 23:09:22,084 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-13 23:09:22,084 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-13 23:09:22,084 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-13 23:09:22,084 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-13 23:09:22,084 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=917
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-13 23:09:22,085 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-13 23:09:22,087 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-13 23:09:22,088 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-13 23:09:22,321 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-13 23:09:22,806 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-13 23:09:22,916 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-13 23:09:22,928 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-13 23:09:22,994 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-13 23:09:22,995 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-13 23:09:22,995 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-13 23:09:23,000 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-13 23:09:23,005 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-13 23:09:23,095 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-13 23:09:23,095 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-13 23:09:23,100 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-13 23:09:23,102 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-13 23:09:23,179 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-13 23:09:23,237 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-13 23:09:23,247 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-13 23:09:23,251 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-13 23:09:23,251 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-13 23:09:23,251 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-13 23:09:23,561 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-13 23:09:23,607 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-13 23:09:23,608 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-13 23:09:23,608 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-13 23:09:23,608 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-13 23:09:23,608 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-13 23:09:23,608 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-13 23:09:23,608 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-13 23:09:23,610 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-13 23:09:23,610 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-13 23:09:23,634 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-13 23:09:23,637 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-13 23:09:23,641 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-13 23:09:23,651 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x47337d6bec0001, negotiated timeout = 90000
2014-07-13 23:09:55,193 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x1e1c1e6c, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-13 23:09:55,194 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x1e1c1e6c connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-13 23:09:55,195 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-13 23:09:55,195 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-13 23:09:55,200 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147337d6ab70002, negotiated timeout = 90000
2014-07-13 23:09:55,509 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@1d5e71ea
2014-07-13 23:09:55,515 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-13 23:09:55,521 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-13 23:09:55,538 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-13 23:09:55,577 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-13 23:09:55,584 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-13 23:09:55,588 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-13 23:09:55,609 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405318161176 with port=60020, startcode=1405318163017
2014-07-13 23:09:55,909 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-13 23:09:55,909 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-13 23:09:55,909 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-13 23:09:55,934 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-13 23:09:55,943 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017
2014-07-13 23:09:55,985 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-13 23:09:55,997 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-13 23:09:56,102 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318196003
2014-07-13 23:09:56,122 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-13 23:09:56,127 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-13 23:09:56,131 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-13 23:09:56,135 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-13 23:09:56,138 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-13 23:09:56,138 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-13 23:09:56,138 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-13 23:09:56,138 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-13 23:09:56,138 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-13 23:09:56,148 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [slave1,60020,1405318163017, sceplus-vm48.almaden.ibm.com,60020,1405318163037] other RSs: [slave1,60020,1405318163017, sceplus-vm48.almaden.ibm.com,60020,1405318163037]
2014-07-13 23:09:56,171 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-13 23:09:56,173 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x2c84c504, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-13 23:09:56,174 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2c84c504 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-13 23:09:56,175 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-13 23:09:56,176 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-13 23:09:56,181 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147337d6ab70003, negotiated timeout = 90000
2014-07-13 23:09:56,192 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-13 23:09:56,192 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-13 23:09:56,246 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405318163017, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x47337d6bec0001
2014-07-13 23:09:56,246 INFO  [SplitLogWorker-slave1,60020,1405318163017] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405318163017 starting
2014-07-13 23:09:56,246 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-13 23:09:56,247 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405318163017
2014-07-13 23:09:56,247 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405318163017'
2014-07-13 23:09:56,247 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-13 23:09:56,249 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-13 23:09:56,250 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-13 23:10:00,758 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:00,895 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:00,896 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d0fd2bc256fec9223f37609ef6eb966d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:00,897 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:00,904 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 402fc28124d60800e3dff956338e457a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:00,905 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 23:10:00,907 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a710399e7ab1e87d0ba3a999d581a472 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:00,918 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:00,919 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:10:00,943 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a710399e7ab1e87d0ba3a999d581a472 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:00,943 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 402fc28124d60800e3dff956338e457a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:00,944 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d0fd2bc256fec9223f37609ef6eb966d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:00,965 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => d0fd2bc256fec9223f37609ef6eb966d, NAME => 'usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-13 23:10:00,965 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => a710399e7ab1e87d0ba3a999d581a472, NAME => 'usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-13 23:10:00,965 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 402fc28124d60800e3dff956338e457a, NAME => 'usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-13 23:10:00,993 INFO  [RS_OPEN_REGION-slave1:60020-2] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-13 23:10:00,993 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a710399e7ab1e87d0ba3a999d581a472
2014-07-13 23:10:00,993 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 402fc28124d60800e3dff956338e457a
2014-07-13 23:10:00,993 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d0fd2bc256fec9223f37609ef6eb966d
2014-07-13 23:10:00,994 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:00,994 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:00,994 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:01,004 INFO  [RS_OPEN_REGION-slave1:60020-2] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-13 23:10:01,006 INFO  [RS_OPEN_REGION-slave1:60020-2] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-13 23:10:01,008 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-13 23:10:01,009 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-13 23:10:01,009 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-13 23:10:01,087 INFO  [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 23:10:01,087 INFO  [StoreOpener-402fc28124d60800e3dff956338e457a-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 23:10:01,087 INFO  [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 23:10:01,170 INFO  [StoreFileOpenerThread-family-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-13 23:10:01,222 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-13 23:10:01,222 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-13 23:10:01,222 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-13 23:10:01,237 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/10dc0f044d7940269024d07cd1b61b0d, isReference=false, isBulkLoadResult=false, seqid=2991, majorCompaction=false
2014-07-13 23:10:01,237 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/003a546cea6c4575b44789f49a3f06a9, isReference=false, isBulkLoadResult=false, seqid=8834, majorCompaction=false
2014-07-13 23:10:01,237 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/06945e5fb4054a1baa49c53b80185d32, isReference=false, isBulkLoadResult=false, seqid=5492, majorCompaction=false
2014-07-13 23:10:01,279 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/0650acd92d6e4270a91f2bc8f591afbc, isReference=false, isBulkLoadResult=false, seqid=7936, majorCompaction=false
2014-07-13 23:10:01,286 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/15ebfb08ea524d55812fa06ef67f1db6, isReference=false, isBulkLoadResult=false, seqid=2355, majorCompaction=false
2014-07-13 23:10:01,315 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/0c611e14298544c0b580f067515ae520, isReference=false, isBulkLoadResult=false, seqid=3290, majorCompaction=false
2014-07-13 23:10:01,318 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/1bbc84cb7fed468c9fb01acf2674713c, isReference=false, isBulkLoadResult=false, seqid=8297, majorCompaction=false
2014-07-13 23:10:01,322 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/16cf57db59a34046a264253bb7876cb1, isReference=false, isBulkLoadResult=false, seqid=3954, majorCompaction=false
2014-07-13 23:10:01,345 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/0d8e5af5b0ec4e718e11acfd186b275a, isReference=false, isBulkLoadResult=false, seqid=4257, majorCompaction=false
2014-07-13 23:10:01,356 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/20f69e64e3534ddc9cf385f9ac48eb9e, isReference=false, isBulkLoadResult=false, seqid=3398, majorCompaction=false
2014-07-13 23:10:01,367 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/19be196fb218465bb1e19ad78ff0679a, isReference=false, isBulkLoadResult=false, seqid=2418, majorCompaction=false
2014-07-13 23:10:01,373 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/13b289285ad7402b8fed15554e5bc0c2, isReference=false, isBulkLoadResult=false, seqid=2632, majorCompaction=false
2014-07-13 23:10:01,387 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/2461ee35f2c84accbe8ab4b360c99b2c, isReference=false, isBulkLoadResult=false, seqid=9986, majorCompaction=false
2014-07-13 23:10:01,394 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/1fd2e5bba95548e19d5279eda667c547, isReference=false, isBulkLoadResult=false, seqid=9275, majorCompaction=false
2014-07-13 23:10:01,404 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/18a7a228a292408ab2ac71368ec33cca, isReference=false, isBulkLoadResult=false, seqid=1814, majorCompaction=false
2014-07-13 23:10:01,418 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/27d543cda36c44c4a4123c028ede848a, isReference=false, isBulkLoadResult=false, seqid=10695, majorCompaction=false
2014-07-13 23:10:01,424 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/28987d69e83f438ba555849d5369885f, isReference=false, isBulkLoadResult=false, seqid=1575, majorCompaction=false
2014-07-13 23:10:01,433 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/1e6e278c3c954cc485f87fbb3054a3c9, isReference=false, isBulkLoadResult=false, seqid=3848, majorCompaction=false
2014-07-13 23:10:01,446 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/2829c0ea7e9e46999d6d28c8b34dac4c, isReference=false, isBulkLoadResult=false, seqid=4372, majorCompaction=false
2014-07-13 23:10:01,447 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/2f82507338a34dbc90590d4498ca00ad, isReference=false, isBulkLoadResult=false, seqid=3946, majorCompaction=false
2014-07-13 23:10:01,456 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/207f32eca2bb49e1a5e13997984d0324, isReference=false, isBulkLoadResult=false, seqid=4425, majorCompaction=false
2014-07-13 23:10:01,463 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/4bef084577814807a97599c217e82582, isReference=false, isBulkLoadResult=false, seqid=502, majorCompaction=false
2014-07-13 23:10:01,468 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/39cea63074de46b4bb47337f1c81ffa4, isReference=false, isBulkLoadResult=false, seqid=10638, majorCompaction=false
2014-07-13 23:10:01,485 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/2eee9cf870f24582830c31e681065a9e, isReference=false, isBulkLoadResult=false, seqid=7530, majorCompaction=false
2014-07-13 23:10:01,498 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/4ff67661eb4a4945ad05d0f6826e1386, isReference=false, isBulkLoadResult=false, seqid=168, majorCompaction=false
2014-07-13 23:10:01,503 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/3ac147e575424595b63ddaf59d8b10ca, isReference=false, isBulkLoadResult=false, seqid=2618, majorCompaction=false
2014-07-13 23:10:01,519 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/3178186d59bb4248ad50c1ba04509c64, isReference=false, isBulkLoadResult=false, seqid=2272, majorCompaction=false
2014-07-13 23:10:01,525 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/5cd5d02807c5411bbde1263e0aad3b48, isReference=false, isBulkLoadResult=false, seqid=680, majorCompaction=false
2014-07-13 23:10:01,535 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/422ed196e4cd487aa372e3b48233ccbe, isReference=false, isBulkLoadResult=false, seqid=4747, majorCompaction=false
2014-07-13 23:10:01,547 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/5d9cd2de70bb437590a75459500f238d, isReference=false, isBulkLoadResult=false, seqid=3565, majorCompaction=false
2014-07-13 23:10:01,553 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/35d5ba85c70541e986e8ddc6c6f69e55, isReference=false, isBulkLoadResult=false, seqid=3680, majorCompaction=false
2014-07-13 23:10:01,573 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/445b6824eab24517936192c83350c52d, isReference=false, isBulkLoadResult=false, seqid=3068, majorCompaction=false
2014-07-13 23:10:01,579 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/3798e669f9354856a2e2604ad8f917c8, isReference=false, isBulkLoadResult=false, seqid=836, majorCompaction=false
2014-07-13 23:10:01,583 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/6219bb873a804ab4a013855d677f2d06, isReference=false, isBulkLoadResult=false, seqid=994, majorCompaction=false
2014-07-13 23:10:01,594 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/58bb871af00947efab0c9a683e6643ff, isReference=false, isBulkLoadResult=false, seqid=4914, majorCompaction=false
2014-07-13 23:10:01,609 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/48a11fbe99184c76903a407ed9518c8f, isReference=false, isBulkLoadResult=false, seqid=6416, majorCompaction=false
2014-07-13 23:10:01,614 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/6adbf724cf824ea98c709eb1c7426d3c, isReference=false, isBulkLoadResult=false, seqid=5355, majorCompaction=false
2014-07-13 23:10:01,641 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/5d7483a81a84470e9d2f6efef91d03ca, isReference=false, isBulkLoadResult=false, seqid=3402, majorCompaction=false
2014-07-13 23:10:01,654 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/4d97b2b9a0ff4a9b96d923991ad53a4d, isReference=false, isBulkLoadResult=false, seqid=7221, majorCompaction=false
2014-07-13 23:10:01,656 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/744d4083922d4a6e8d701fb87ca992bf, isReference=false, isBulkLoadResult=false, seqid=5747, majorCompaction=false
2014-07-13 23:10:01,669 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/69823034b84e4b10a10c8d2c2de0a103, isReference=false, isBulkLoadResult=false, seqid=3619, majorCompaction=false
2014-07-13 23:10:01,681 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/4f948daebbcf48fbbb023f4e9bc2af7f, isReference=false, isBulkLoadResult=false, seqid=173, majorCompaction=false
2014-07-13 23:10:01,688 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/7519cd4c022b41ebbeaf4d20586137d3, isReference=false, isBulkLoadResult=false, seqid=7936, majorCompaction=false
2014-07-13 23:10:01,696 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/6c5408bd7f1c43ada6b562d760b42804, isReference=false, isBulkLoadResult=false, seqid=2847, majorCompaction=false
2014-07-13 23:10:01,711 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/57bd14d1aa1648a4a5deb9f5db43867a, isReference=false, isBulkLoadResult=false, seqid=4621, majorCompaction=false
2014-07-13 23:10:01,718 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/75d2af1383984692ab9f77873fd80ab3, isReference=false, isBulkLoadResult=false, seqid=4372, majorCompaction=false
2014-07-13 23:10:01,721 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/738d802105444e538b4c397db496f0d3, isReference=false, isBulkLoadResult=false, seqid=837, majorCompaction=false
2014-07-13 23:10:01,737 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/7676db3f1f604f8c80a7061193a8b084, isReference=false, isBulkLoadResult=false, seqid=334, majorCompaction=false
2014-07-13 23:10:01,742 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/5dae465bae614386bf71aa830d615679, isReference=false, isBulkLoadResult=false, seqid=6852, majorCompaction=false
2014-07-13 23:10:01,745 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/8652a23489a24aae9ef43d82fec88978, isReference=false, isBulkLoadResult=false, seqid=670, majorCompaction=false
2014-07-13 23:10:01,770 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/778ddf6c36da4f6591b071df6621dc08, isReference=false, isBulkLoadResult=false, seqid=8834, majorCompaction=false
2014-07-13 23:10:01,773 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/87797fc7fb364fbfb4aa73d7bea09df1, isReference=false, isBulkLoadResult=false, seqid=5355, majorCompaction=false
2014-07-13 23:10:01,773 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/5f9d31c814564c438213317ff20e6104, isReference=false, isBulkLoadResult=false, seqid=8620, majorCompaction=false
2014-07-13 23:10:01,800 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/9a3c945fffa444829bd87936e3535379, isReference=false, isBulkLoadResult=false, seqid=2251, majorCompaction=false
2014-07-13 23:10:01,802 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/81b401ed9ffd48c9b0cac6031fad56af, isReference=false, isBulkLoadResult=false, seqid=6196, majorCompaction=false
2014-07-13 23:10:01,807 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/601717ea500c4dda82cb95c241edb566, isReference=false, isBulkLoadResult=false, seqid=10695, majorCompaction=false
2014-07-13 23:10:01,834 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/8f69d99def704ad7926d23866ba5adf3, isReference=false, isBulkLoadResult=false, seqid=2522, majorCompaction=false
2014-07-13 23:10:01,835 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/9b79c6ac6fee471a9665a8e878c6b2b2, isReference=false, isBulkLoadResult=false, seqid=6196, majorCompaction=false
2014-07-13 23:10:01,838 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/76e398fe410a44708a30de5c4c2e795b, isReference=false, isBulkLoadResult=false, seqid=8045, majorCompaction=false
2014-07-13 23:10:01,859 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/9176c244c63b496993df639a288a8329, isReference=false, isBulkLoadResult=false, seqid=3157, majorCompaction=false
2014-07-13 23:10:01,861 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/7b5a63a87f8b4da8bf349655ab93f43f, isReference=false, isBulkLoadResult=false, seqid=668, majorCompaction=false
2014-07-13 23:10:01,869 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/a0052078ee47469db154aa711f2ed6cb, isReference=false, isBulkLoadResult=false, seqid=6642, majorCompaction=false
2014-07-13 23:10:01,880 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/95ed51b099ed4c54a39b6235fa5fd7ab, isReference=false, isBulkLoadResult=false, seqid=2720, majorCompaction=false
2014-07-13 23:10:01,885 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/8ac8ba3251d94ff78c585e7552aeafca, isReference=false, isBulkLoadResult=false, seqid=2439, majorCompaction=false
2014-07-13 23:10:01,900 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/a6637bfb1f3340f181f46f332d524276, isReference=false, isBulkLoadResult=false, seqid=4205, majorCompaction=false
2014-07-13 23:10:01,907 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/9f31b150291c496ead72aabc2947f8c8, isReference=false, isBulkLoadResult=false, seqid=10016, majorCompaction=false
2014-07-13 23:10:01,908 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/9e1b5841b9014b6dac491e3622b67c61, isReference=false, isBulkLoadResult=false, seqid=2095, majorCompaction=false
2014-07-13 23:10:01,921 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/ae8ce986a1e94dbebfd3cd2df5d37943, isReference=false, isBulkLoadResult=false, seqid=8297, majorCompaction=false
2014-07-13 23:10:01,940 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/a2c04fd71f244514a5692529a980a45b, isReference=false, isBulkLoadResult=false, seqid=9103, majorCompaction=false
2014-07-13 23:10:01,941 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/9f0b0498c4444428951a1be780ef2f7c, isReference=false, isBulkLoadResult=false, seqid=4704, majorCompaction=false
2014-07-13 23:10:01,947 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/bc3109f454e24d06b3945a1ade820644, isReference=false, isBulkLoadResult=false, seqid=5747, majorCompaction=false
2014-07-13 23:10:01,958 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/a7b856612d734053881d4879127f4282, isReference=false, isBulkLoadResult=false, seqid=4825, majorCompaction=false
2014-07-13 23:10:01,977 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/c08f2cc95dc54fe7b6eaa68c3c64db0c, isReference=false, isBulkLoadResult=false, seqid=3786, majorCompaction=false
2014-07-13 23:10:01,995 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/c48466e7fa0d4aa2b02e8eba827c5413, isReference=false, isBulkLoadResult=false, seqid=9984, majorCompaction=false
2014-07-13 23:10:02,007 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/a7f35f6c284d41e9b88d81172debfdea, isReference=false, isBulkLoadResult=false, seqid=2870, majorCompaction=false
2014-07-13 23:10:02,011 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/a8d1308a71d2406b827c952d35d878e2, isReference=false, isBulkLoadResult=false, seqid=6642, majorCompaction=false
2014-07-13 23:10:02,026 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/c4c0fbee51f64d00adb0ec49df1eb9c9, isReference=false, isBulkLoadResult=false, seqid=7048, majorCompaction=false
2014-07-13 23:10:02,034 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/ad0fce23c5ca4b2fbdfe158133c0952d, isReference=false, isBulkLoadResult=false, seqid=9296, majorCompaction=false
2014-07-13 23:10:02,035 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/abcd9a6a5238411c81ea1fc6650b1300, isReference=false, isBulkLoadResult=false, seqid=4091, majorCompaction=false
2014-07-13 23:10:02,044 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/b2bb0700ee664cb892fc5d6fe24c85ee, isReference=false, isBulkLoadResult=false, seqid=10642, majorCompaction=false
2014-07-13 23:10:02,053 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/c555fcdaa5db4685b8eb8d93595363a3, isReference=false, isBulkLoadResult=false, seqid=1819, majorCompaction=false
2014-07-13 23:10:02,060 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/bc8bb11d99764e3facf2a5b52f727260, isReference=false, isBulkLoadResult=false, seqid=9432, majorCompaction=false
2014-07-13 23:10:02,068 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/b3f7ff903a274af9b26bf6772cd7e801, isReference=false, isBulkLoadResult=false, seqid=7472, majorCompaction=false
2014-07-13 23:10:02,076 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/cf735d5ca1ce49d0be8d6f9a74599a6e, isReference=false, isBulkLoadResult=false, seqid=173, majorCompaction=false
2014-07-13 23:10:02,083 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/d0eaef7e46f64881bf1ebfbdf619deb3, isReference=false, isBulkLoadResult=false, seqid=10695, majorCompaction=false
2014-07-13 23:10:02,085 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/c8536e1da48c48159db646bcd22c95ea, isReference=false, isBulkLoadResult=false, seqid=4991, majorCompaction=false
2014-07-13 23:10:02,120 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/d11625f986c444c58cba6cfde0bb0a8b, isReference=false, isBulkLoadResult=false, seqid=1330, majorCompaction=false
2014-07-13 23:10:02,126 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/f08877b9e2de42ada0604c52a88a53fa, isReference=false, isBulkLoadResult=false, seqid=3731, majorCompaction=false
2014-07-13 23:10:02,136 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/d3d44d2238ee48d1aed61780eb86b537, isReference=false, isBulkLoadResult=false, seqid=5980, majorCompaction=false
2014-07-13 23:10:02,140 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/e6b53591a86a4c22835f8b228a673072, isReference=false, isBulkLoadResult=false, seqid=7474, majorCompaction=false
2014-07-13 23:10:02,152 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/f27d20ba9c8a45c795905f93871f4b36, isReference=false, isBulkLoadResult=false, seqid=4539, majorCompaction=false
2014-07-13 23:10:02,161 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/e0e55df5e4da44a0bf63dc0ee808fdd5, isReference=false, isBulkLoadResult=false, seqid=452, majorCompaction=false
2014-07-13 23:10:02,166 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/eaa1ab562c1a49d99017cf058c66014a, isReference=false, isBulkLoadResult=false, seqid=453, majorCompaction=false
2014-07-13 23:10:02,181 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/fb326a501b984059945b6b7c8719b178, isReference=false, isBulkLoadResult=false, seqid=7048, majorCompaction=false
2014-07-13 23:10:02,182 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/e76cde7b4a82446a9563b749abccd19e, isReference=false, isBulkLoadResult=false, seqid=3068, majorCompaction=false
2014-07-13 23:10:02,191 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/ee92d41d184a4d3996b199e8fdb130b8, isReference=false, isBulkLoadResult=false, seqid=3235, majorCompaction=false
2014-07-13 23:10:02,198 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/fc0ea5df9a284d61b3a25625574cae2d, isReference=false, isBulkLoadResult=false, seqid=4871, majorCompaction=false
2014-07-13 23:10:02,213 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/ee127dd9da2140c7a83e7e2770db2e44, isReference=false, isBulkLoadResult=false, seqid=1330, majorCompaction=false
2014-07-13 23:10:02,214 DEBUG [StoreOpener-d0fd2bc256fec9223f37609ef6eb966d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d/family/f1b6e4e7dfa24f6d928b55c32fbe853c, isReference=false, isBulkLoadResult=false, seqid=4581, majorCompaction=false
2014-07-13 23:10:02,224 DEBUG [StoreOpener-a710399e7ab1e87d0ba3a999d581a472-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472/family/fd57e00b9c104e1b9a85f3be3b587e4a, isReference=false, isBulkLoadResult=false, seqid=4205, majorCompaction=false
2014-07-13 23:10:02,244 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/f1f4e595a0d74e5d9251547c782a6c88, isReference=false, isBulkLoadResult=false, seqid=3456, majorCompaction=false
2014-07-13 23:10:02,249 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d0fd2bc256fec9223f37609ef6eb966d
2014-07-13 23:10:02,250 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a710399e7ab1e87d0ba3a999d581a472
2014-07-13 23:10:02,255 DEBUG [StoreOpener-402fc28124d60800e3dff956338e457a-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a/family/fcd1468baed34b8c876dd4f92cc02e7e, isReference=false, isBulkLoadResult=false, seqid=10679, majorCompaction=false
2014-07-13 23:10:02,256 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined d0fd2bc256fec9223f37609ef6eb966d; next sequenceid=10696
2014-07-13 23:10:02,256 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d0fd2bc256fec9223f37609ef6eb966d
2014-07-13 23:10:02,258 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined a710399e7ab1e87d0ba3a999d581a472; next sequenceid=10696
2014-07-13 23:10:02,258 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a710399e7ab1e87d0ba3a999d581a472
2014-07-13 23:10:02,261 INFO  [PostOpenDeployTasks:d0fd2bc256fec9223f37609ef6eb966d] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:02,261 INFO  [PostOpenDeployTasks:a710399e7ab1e87d0ba3a999d581a472] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:02,263 DEBUG [PostOpenDeployTasks:a710399e7ab1e87d0ba3a999d581a472] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 23:10:02,264 DEBUG [PostOpenDeployTasks:d0fd2bc256fec9223f37609ef6eb966d] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-13 23:10:02,265 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:02,265 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:02,267 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:02,267 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:02,269 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472. because compaction request was cancelled
2014-07-13 23:10:02,270 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:02,270 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:02,270 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:02,270 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:02,270 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d. because compaction request was cancelled
2014-07-13 23:10:02,297 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/402fc28124d60800e3dff956338e457a
2014-07-13 23:10:02,301 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 402fc28124d60800e3dff956338e457a; next sequenceid=10696
2014-07-13 23:10:02,301 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 402fc28124d60800e3dff956338e457a
2014-07-13 23:10:02,303 INFO  [PostOpenDeployTasks:402fc28124d60800e3dff956338e457a] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:02,304 DEBUG [PostOpenDeployTasks:402fc28124d60800e3dff956338e457a] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 23:10:02,304 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:02,304 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:02,304 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:02,304 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:02,305 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a. because compaction request was cancelled
2014-07-13 23:10:02,376 INFO  [PostOpenDeployTasks:d0fd2bc256fec9223f37609ef6eb966d] catalog.MetaEditor: Updated row usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d. with server=slave1,60020,1405318163017
2014-07-13 23:10:02,376 INFO  [PostOpenDeployTasks:d0fd2bc256fec9223f37609ef6eb966d] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:02,376 INFO  [PostOpenDeployTasks:a710399e7ab1e87d0ba3a999d581a472] catalog.MetaEditor: Updated row usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472. with server=slave1,60020,1405318163017
2014-07-13 23:10:02,376 INFO  [PostOpenDeployTasks:402fc28124d60800e3dff956338e457a] catalog.MetaEditor: Updated row usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a. with server=slave1,60020,1405318163017
2014-07-13 23:10:02,378 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d0fd2bc256fec9223f37609ef6eb966d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,377 INFO  [PostOpenDeployTasks:a710399e7ab1e87d0ba3a999d581a472] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:02,378 INFO  [PostOpenDeployTasks:402fc28124d60800e3dff956338e457a] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:02,379 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a710399e7ab1e87d0ba3a999d581a472 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,379 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 402fc28124d60800e3dff956338e457a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,384 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d0fd2bc256fec9223f37609ef6eb966d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,384 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned d0fd2bc256fec9223f37609ef6eb966d to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:10:02,384 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d. on slave1,60020,1405318163017
2014-07-13 23:10:02,385 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:02,386 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 402fc28124d60800e3dff956338e457a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,386 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 402fc28124d60800e3dff956338e457a to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:10:02,386 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a. on slave1,60020,1405318163017
2014-07-13 23:10:02,386 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a710399e7ab1e87d0ba3a999d581a472 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,387 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d1255ebfbe8f4bf601727d395c31d79 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:02,387 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned a710399e7ab1e87d0ba3a999d581a472 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:10:02,387 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472. on slave1,60020,1405318163017
2014-07-13 23:10:02,388 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 828e64d198ce9b65df292214161840c4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:02,391 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:02,391 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-13 23:10:02,392 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d1255ebfbe8f4bf601727d395c31d79 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:02,392 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 2d1255ebfbe8f4bf601727d395c31d79, NAME => 'usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-13 23:10:02,392 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-13 23:10:02,393 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 23:10:02,393 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2d1255ebfbe8f4bf601727d395c31d79
2014-07-13 23:10:02,393 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:02,394 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 828e64d198ce9b65df292214161840c4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:10:02,395 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 828e64d198ce9b65df292214161840c4, NAME => 'usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-13 23:10:02,396 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 828e64d198ce9b65df292214161840c4
2014-07-13 23:10:02,396 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:10:02,399 INFO  [StoreOpener-2d1255ebfbe8f4bf601727d395c31d79-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 23:10:02,403 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2d1255ebfbe8f4bf601727d395c31d79
2014-07-13 23:10:02,405 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 23:10:02,405 INFO  [StoreOpener-828e64d198ce9b65df292214161840c4-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 23:10:02,409 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 2d1255ebfbe8f4bf601727d395c31d79; next sequenceid=1
2014-07-13 23:10:02,409 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2d1255ebfbe8f4bf601727d395c31d79
2014-07-13 23:10:02,411 INFO  [PostOpenDeployTasks:2d1255ebfbe8f4bf601727d395c31d79] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:02,420 INFO  [PostOpenDeployTasks:2d1255ebfbe8f4bf601727d395c31d79] catalog.MetaEditor: Updated row usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79. with server=slave1,60020,1405318163017
2014-07-13 23:10:02,420 INFO  [PostOpenDeployTasks:2d1255ebfbe8f4bf601727d395c31d79] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:02,421 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-13 23:10:02,421 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d1255ebfbe8f4bf601727d395c31d79 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,425 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-13 23:10:02,428 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-13 23:10:02,428 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-13 23:10:02,428 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d1255ebfbe8f4bf601727d395c31d79 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,428 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 2d1255ebfbe8f4bf601727d395c31d79 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:10:02,428 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79. on slave1,60020,1405318163017
2014-07-13 23:10:02,431 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 23:10:02,439 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405318163017
2014-07-13 23:10:02,439 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 23:10:02,440 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,443 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/203acb481fd444f6ac004a78f683b89c, isReference=false, isBulkLoadResult=false, seqid=2949, majorCompaction=false
2014-07-13 23:10:02,456 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:02,456 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:10:02,456 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405318163017
2014-07-13 23:10:02,472 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/20f7558b15274107aaa95966040c1ca9, isReference=false, isBulkLoadResult=false, seqid=8042, majorCompaction=false
2014-07-13 23:10:02,498 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/222449b4e41a4b9a9de9b1081e9c3aa9, isReference=false, isBulkLoadResult=false, seqid=1575, majorCompaction=false
2014-07-13 23:10:02,520 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/2641366e12c24deab0dd576e95c043fc, isReference=false, isBulkLoadResult=false, seqid=5355, majorCompaction=false
2014-07-13 23:10:02,542 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/34491839477b443c9415ea98ccd8172c, isReference=false, isBulkLoadResult=false, seqid=6221, majorCompaction=false
2014-07-13 23:10:02,563 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/3d6afd4b80b044aab1fe1b1c12558217, isReference=false, isBulkLoadResult=false, seqid=3116, majorCompaction=false
2014-07-13 23:10:02,592 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/3f486135462743c18ef596bcf966fc6c, isReference=false, isBulkLoadResult=false, seqid=6642, majorCompaction=false
2014-07-13 23:10:02,616 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/4654696c96e5433f9f6a6585806c917e, isReference=false, isBulkLoadResult=false, seqid=680, majorCompaction=false
2014-07-13 23:10:02,631 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/514607b5447e4285a8bb3d3a71430b94, isReference=false, isBulkLoadResult=false, seqid=4440, majorCompaction=false
2014-07-13 23:10:02,639 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/5657afdec89b4b5d99f85534996993f7, isReference=false, isBulkLoadResult=false, seqid=10690, majorCompaction=false
2014-07-13 23:10:02,658 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/5e1437d1158b4f01a9d72ae4ab25ab97, isReference=false, isBulkLoadResult=false, seqid=3327, majorCompaction=false
2014-07-13 23:10:02,690 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/67eb5c3366114a93871e6fd3f89d9956, isReference=false, isBulkLoadResult=false, seqid=3710, majorCompaction=false
2014-07-13 23:10:02,719 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/6b8b53da09f54a628c4c4afa3af965fd, isReference=false, isBulkLoadResult=false, seqid=4107, majorCompaction=false
2014-07-13 23:10:02,744 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/771659d859674d03af71ecdd4cf79898, isReference=false, isBulkLoadResult=false, seqid=3493, majorCompaction=false
2014-07-13 23:10:02,759 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/7c44797ea2ef4357a48d932e7c161e13, isReference=false, isBulkLoadResult=false, seqid=2095, majorCompaction=false
2014-07-13 23:10:02,768 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/7f7cee2b1ccb4b2e9cd52173eeab575b, isReference=false, isBulkLoadResult=false, seqid=10695, majorCompaction=false
2014-07-13 23:10:02,781 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/81af50ef69664522a8bb24b7afab3c50, isReference=false, isBulkLoadResult=false, seqid=10049, majorCompaction=false
2014-07-13 23:10:02,806 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/82e1d6ff72d449cc9f98379db0dd6631, isReference=false, isBulkLoadResult=false, seqid=5747, majorCompaction=false
2014-07-13 23:10:02,829 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/8b318d81770f4a20b456314c21a11da8, isReference=false, isBulkLoadResult=false, seqid=7530, majorCompaction=false
2014-07-13 23:10:02,845 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/980ee6ac1f494949bcf26a13e3cef5aa, isReference=false, isBulkLoadResult=false, seqid=4622, majorCompaction=false
2014-07-13 23:10:02,860 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/9a76af533c03459cb2498966163c9d4c, isReference=false, isBulkLoadResult=false, seqid=167, majorCompaction=false
2014-07-13 23:10:02,883 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/9ea2aaa8a2784be193d9c3919ee0f120, isReference=false, isBulkLoadResult=false, seqid=2502, majorCompaction=false
2014-07-13 23:10:02,906 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/9f4d12c8764c4b2f942cafa846daf6f2, isReference=false, isBulkLoadResult=false, seqid=7130, majorCompaction=false
2014-07-13 23:10:02,927 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/a17a575411884de2bd68e749ad0edf92, isReference=false, isBulkLoadResult=false, seqid=334, majorCompaction=false
2014-07-13 23:10:02,944 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/a2967211143e4ec399d08180ca2e9b81, isReference=false, isBulkLoadResult=false, seqid=2699, majorCompaction=false
2014-07-13 23:10:02,961 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/a8601a067bcb4ef88c02fa0806c1480d, isReference=false, isBulkLoadResult=false, seqid=9432, majorCompaction=false
2014-07-13 23:10:02,989 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/aa530b154b5746fd90b313ec443b0237, isReference=false, isBulkLoadResult=false, seqid=990, majorCompaction=false
2014-07-13 23:10:03,016 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/ac2612014baa49548ec584b4f21dd442, isReference=false, isBulkLoadResult=false, seqid=9097, majorCompaction=false
2014-07-13 23:10:03,035 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/c2679a0f18d64804989579e91b3a22e9, isReference=false, isBulkLoadResult=false, seqid=4274, majorCompaction=false
2014-07-13 23:10:03,080 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/de4b5171d89649be9e1f1a8b10a2539c, isReference=false, isBulkLoadResult=false, seqid=3879, majorCompaction=false
2014-07-13 23:10:03,096 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/ea8cef9a7fc140f9904ccbacacd1fa0e, isReference=false, isBulkLoadResult=false, seqid=501, majorCompaction=false
2014-07-13 23:10:03,122 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/ed4fc4279b9a4dbc9e9c727dcb3238bd, isReference=false, isBulkLoadResult=false, seqid=4808, majorCompaction=false
2014-07-13 23:10:03,152 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/f1f4933cc701476fb508a33a55ec8f23, isReference=false, isBulkLoadResult=false, seqid=2335, majorCompaction=false
2014-07-13 23:10:03,174 DEBUG [StoreOpener-828e64d198ce9b65df292214161840c4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4/family/f930d7bcd53c4b75ad8316dd5d946116, isReference=false, isBulkLoadResult=false, seqid=8620, majorCompaction=false
2014-07-13 23:10:03,177 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/828e64d198ce9b65df292214161840c4
2014-07-13 23:10:03,180 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 828e64d198ce9b65df292214161840c4; next sequenceid=10696
2014-07-13 23:10:03,180 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 828e64d198ce9b65df292214161840c4
2014-07-13 23:10:03,183 INFO  [PostOpenDeployTasks:828e64d198ce9b65df292214161840c4] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:10:03,183 DEBUG [PostOpenDeployTasks:828e64d198ce9b65df292214161840c4] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 23:10:03,183 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:03,184 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:03,184 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:03,184 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:03,184 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4. because compaction request was cancelled
2014-07-13 23:10:03,190 INFO  [PostOpenDeployTasks:828e64d198ce9b65df292214161840c4] catalog.MetaEditor: Updated row usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4. with server=slave1,60020,1405318163017
2014-07-13 23:10:03,190 INFO  [PostOpenDeployTasks:828e64d198ce9b65df292214161840c4] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:10:03,191 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 828e64d198ce9b65df292214161840c4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:03,196 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 828e64d198ce9b65df292214161840c4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:10:03,196 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 828e64d198ce9b65df292214161840c4 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:10:03,196 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4. on slave1,60020,1405318163017
2014-07-13 23:10:06,143 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 23:10:06,143 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:06,143 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-13 23:10:06,143 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:06,143 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:06,143 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:06,143 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4. because compaction request was cancelled
2014-07-13 23:10:06,143 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 23:10:06,143 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:06,143 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 23:10:06,143 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d. because compaction request was cancelled
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472. because compaction request was cancelled
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 23:10:06,144 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Not compacting usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a. because compaction request was cancelled
2014-07-13 23:10:29,844 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close 402fc28124d60800e3dff956338e457a, via zk=yes, znode version=0, on null
2014-07-13 23:10:29,847 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:29,847 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close a710399e7ab1e87d0ba3a999d581a472, via zk=yes, znode version=0, on null
2014-07-13 23:10:29,848 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close d0fd2bc256fec9223f37609ef6eb966d, via zk=yes, znode version=0, on null
2014-07-13 23:10:29,848 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close 2d1255ebfbe8f4bf601727d395c31d79, via zk=yes, znode version=0, on null
2014-07-13 23:10:29,850 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:29,851 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:29,851 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Close 828e64d198ce9b65df292214161840c4, via zk=yes, znode version=0, on null
2014-07-13 23:10:29,852 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.: disabling compactions & flushes
2014-07-13 23:10:29,853 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:29,855 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.: disabling compactions & flushes
2014-07-13 23:10:29,856 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:29,856 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.: disabling compactions & flushes
2014-07-13 23:10:29,856 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:29,903 INFO  [StoreCloserThread-usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.-1] regionserver.HStore: Closed family
2014-07-13 23:10:29,903 INFO  [StoreCloserThread-usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.-1] regionserver.HStore: Closed family
2014-07-13 23:10:29,904 INFO  [StoreCloserThread-usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.-1] regionserver.HStore: Closed family
2014-07-13 23:10:29,908 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:29,908 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:29,908 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d0fd2bc256fec9223f37609ef6eb966d from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,908 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:29,908 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 402fc28124d60800e3dff956338e457a from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,909 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a710399e7ab1e87d0ba3a999d581a472 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,917 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d0fd2bc256fec9223f37609ef6eb966d from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,917 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d. on slave1,60020,1405318163017
2014-07-13 23:10:29,917 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user6,1405315227786.d0fd2bc256fec9223f37609ef6eb966d.
2014-07-13 23:10:29,917 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:29,918 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 402fc28124d60800e3dff956338e457a from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,918 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a. on slave1,60020,1405318163017
2014-07-13 23:10:29,918 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user8,1405315227786.402fc28124d60800e3dff956338e457a.
2014-07-13 23:10:29,918 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:10:29,919 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a710399e7ab1e87d0ba3a999d581a472 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,919 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472. on slave1,60020,1405318163017
2014-07-13 23:10:29,919 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user4,1405315227786.a710399e7ab1e87d0ba3a999d581a472.
2014-07-13 23:10:29,921 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.: disabling compactions & flushes
2014-07-13 23:10:29,921 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:29,922 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.: disabling compactions & flushes
2014-07-13 23:10:29,922 INFO  [StoreCloserThread-usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.-1] regionserver.HStore: Closed family
2014-07-13 23:10:29,922 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:10:29,922 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:29,922 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2d1255ebfbe8f4bf601727d395c31d79 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,928 INFO  [StoreCloserThread-usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.-1] regionserver.HStore: Closed family
2014-07-13 23:10:29,929 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:10:29,929 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2d1255ebfbe8f4bf601727d395c31d79 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,930 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79. on slave1,60020,1405318163017
2014-07-13 23:10:29,930 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 828e64d198ce9b65df292214161840c4 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,930 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,,1405315227785.2d1255ebfbe8f4bf601727d395c31d79.
2014-07-13 23:10:29,935 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 828e64d198ce9b65df292214161840c4 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 23:10:29,935 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4. on slave1,60020,1405318163017
2014-07-13 23:10:29,935 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user1,1405315227786.828e64d198ce9b65df292214161840c4.
2014-07-13 23:14:23,113 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=5, hits=3, hitRatio=60.00%, , cachingAccesses=5, cachingHits=3, cachingHitsRatio=60.00%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-13 23:15:43,600 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:15:43,612 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,,1405318543623.f73361229b464956f560836017506882.
2014-07-13 23:15:43,613 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d679c2853f294b83582eebcd030d1677 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,614 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f73361229b464956f560836017506882 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,613 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:15:43,615 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:15:43,615 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8b827125b32700e6f7c5c34f77be22cb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,615 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:15:43,629 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d679c2853f294b83582eebcd030d1677 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,629 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f73361229b464956f560836017506882 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,629 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => d679c2853f294b83582eebcd030d1677, NAME => 'usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-13 23:15:43,629 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8b827125b32700e6f7c5c34f77be22cb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,629 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => f73361229b464956f560836017506882, NAME => 'usertable,,1405318543623.f73361229b464956f560836017506882.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-13 23:15:43,630 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 8b827125b32700e6f7c5c34f77be22cb, NAME => 'usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-13 23:15:43,630 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d679c2853f294b83582eebcd030d1677
2014-07-13 23:15:43,630 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable f73361229b464956f560836017506882
2014-07-13 23:15:43,630 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:15:43,630 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,,1405318543623.f73361229b464956f560836017506882.
2014-07-13 23:15:43,630 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:15:43,630 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:15:43,638 INFO  [StoreOpener-d679c2853f294b83582eebcd030d1677-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 23:15:43,638 INFO  [StoreOpener-8b827125b32700e6f7c5c34f77be22cb-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 23:15:43,640 INFO  [StoreOpener-f73361229b464956f560836017506882-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 23:15:43,643 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677
2014-07-13 23:15:43,644 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:15:43,645 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/f73361229b464956f560836017506882
2014-07-13 23:15:43,646 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined d679c2853f294b83582eebcd030d1677; next sequenceid=1
2014-07-13 23:15:43,646 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d679c2853f294b83582eebcd030d1677
2014-07-13 23:15:43,647 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 8b827125b32700e6f7c5c34f77be22cb; next sequenceid=1
2014-07-13 23:15:43,647 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:15:43,649 INFO  [PostOpenDeployTasks:d679c2853f294b83582eebcd030d1677] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:15:43,650 INFO  [PostOpenDeployTasks:8b827125b32700e6f7c5c34f77be22cb] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:15:43,664 INFO  [PostOpenDeployTasks:d679c2853f294b83582eebcd030d1677] catalog.MetaEditor: Updated row usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. with server=slave1,60020,1405318163017
2014-07-13 23:15:43,664 INFO  [PostOpenDeployTasks:d679c2853f294b83582eebcd030d1677] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:15:43,665 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d679c2853f294b83582eebcd030d1677 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,666 INFO  [PostOpenDeployTasks:8b827125b32700e6f7c5c34f77be22cb] catalog.MetaEditor: Updated row usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. with server=slave1,60020,1405318163017
2014-07-13 23:15:43,666 INFO  [PostOpenDeployTasks:8b827125b32700e6f7c5c34f77be22cb] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:15:43,667 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8b827125b32700e6f7c5c34f77be22cb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,670 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d679c2853f294b83582eebcd030d1677 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,670 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned d679c2853f294b83582eebcd030d1677 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:15:43,670 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. on slave1,60020,1405318163017
2014-07-13 23:15:43,670 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning baaed08b3b283bc33b53e718e07d0f23 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,671 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8b827125b32700e6f7c5c34f77be22cb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,671 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 8b827125b32700e6f7c5c34f77be22cb to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:15:43,672 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. on slave1,60020,1405318163017
2014-07-13 23:15:43,672 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6935e08926c94c414c50c4e2b2667be2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,676 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node baaed08b3b283bc33b53e718e07d0f23 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,676 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => baaed08b3b283bc33b53e718e07d0f23, NAME => 'usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-13 23:15:43,677 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable baaed08b3b283bc33b53e718e07d0f23
2014-07-13 23:15:43,677 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:15:43,678 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined f73361229b464956f560836017506882; next sequenceid=1
2014-07-13 23:15:43,678 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node f73361229b464956f560836017506882
2014-07-13 23:15:43,679 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6935e08926c94c414c50c4e2b2667be2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 23:15:43,680 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 6935e08926c94c414c50c4e2b2667be2, NAME => 'usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-13 23:15:43,681 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:15:43,681 INFO  [PostOpenDeployTasks:f73361229b464956f560836017506882] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405318543623.f73361229b464956f560836017506882.
2014-07-13 23:15:43,681 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:15:43,688 INFO  [PostOpenDeployTasks:f73361229b464956f560836017506882] catalog.MetaEditor: Updated row usertable,,1405318543623.f73361229b464956f560836017506882. with server=slave1,60020,1405318163017
2014-07-13 23:15:43,688 INFO  [PostOpenDeployTasks:f73361229b464956f560836017506882] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405318543623.f73361229b464956f560836017506882.
2014-07-13 23:15:43,689 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f73361229b464956f560836017506882 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,694 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f73361229b464956f560836017506882 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,694 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned f73361229b464956f560836017506882 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:15:43,694 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,,1405318543623.f73361229b464956f560836017506882. on slave1,60020,1405318163017
2014-07-13 23:15:43,696 INFO  [StoreOpener-baaed08b3b283bc33b53e718e07d0f23-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 23:15:43,699 INFO  [StoreOpener-6935e08926c94c414c50c4e2b2667be2-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 23:15:43,706 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23
2014-07-13 23:15:43,707 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:15:43,711 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined baaed08b3b283bc33b53e718e07d0f23; next sequenceid=1
2014-07-13 23:15:43,711 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node baaed08b3b283bc33b53e718e07d0f23
2014-07-13 23:15:43,715 INFO  [PostOpenDeployTasks:baaed08b3b283bc33b53e718e07d0f23] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:15:43,725 INFO  [PostOpenDeployTasks:baaed08b3b283bc33b53e718e07d0f23] catalog.MetaEditor: Updated row usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. with server=slave1,60020,1405318163017
2014-07-13 23:15:43,725 INFO  [PostOpenDeployTasks:baaed08b3b283bc33b53e718e07d0f23] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:15:43,727 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning baaed08b3b283bc33b53e718e07d0f23 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,733 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node baaed08b3b283bc33b53e718e07d0f23 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,733 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned baaed08b3b283bc33b53e718e07d0f23 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:15:43,733 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. on slave1,60020,1405318163017
2014-07-13 23:15:43,750 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 6935e08926c94c414c50c4e2b2667be2; next sequenceid=1
2014-07-13 23:15:43,750 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:15:43,753 INFO  [PostOpenDeployTasks:6935e08926c94c414c50c4e2b2667be2] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:15:43,764 INFO  [PostOpenDeployTasks:6935e08926c94c414c50c4e2b2667be2] catalog.MetaEditor: Updated row usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. with server=slave1,60020,1405318163017
2014-07-13 23:15:43,764 INFO  [PostOpenDeployTasks:6935e08926c94c414c50c4e2b2667be2] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:15:43,765 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6935e08926c94c414c50c4e2b2667be2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,773 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47337d6bec0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6935e08926c94c414c50c4e2b2667be2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 23:15:43,773 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 6935e08926c94c414c50c4e2b2667be2 to OPENED in zk on slave1,60020,1405318163017
2014-07-13 23:15:43,774 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. on slave1,60020,1405318163017
2014-07-13 23:16:03,327 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:03,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 102 synced till here 79
2014-07-13 23:16:03,876 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318196003 with entries=102, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318563465
2014-07-13 23:16:05,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:05,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 204 synced till here 185
2014-07-13 23:16:06,069 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318563465 with entries=102, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318565541
2014-07-13 23:16:07,853 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:07,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 300 synced till here 284
2014-07-13 23:16:08,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318565541 with entries=96, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318567854
2014-07-13 23:16:11,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:11,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 412 synced till here 398
2014-07-13 23:16:11,954 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318567854 with entries=112, filesize=83.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318571460
2014-07-13 23:16:15,951 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:16,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 517 synced till here 502
2014-07-13 23:16:16,561 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318571460 with entries=105, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318575952
2014-07-13 23:16:18,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:18,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 623 synced till here 599
2014-07-13 23:16:18,721 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:16:18,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318575952 with entries=106, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318578187
2014-07-13 23:16:18,875 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 280.3m
2014-07-13 23:16:20,293 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:16:20,301 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 261.7m
2014-07-13 23:16:20,613 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:20,880 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:21,223 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 749 synced till here 720
2014-07-13 23:16:21,339 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:16:21,655 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318578187 with entries=126, filesize=108.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318580880
2014-07-13 23:16:22,083 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:22,089 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-13 23:16:22,257 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:16:23,170 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:23,194 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 840 synced till here 829
2014-07-13 23:16:23,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318580880 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318583171
2014-07-13 23:16:24,996 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=181, memsize=46.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/e2b107cc6f264f2881af4b2c65e21c29
2014-07-13 23:16:25,018 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/e2b107cc6f264f2881af4b2c65e21c29 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/e2b107cc6f264f2881af4b2c65e21c29
2014-07-13 23:16:25,034 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/e2b107cc6f264f2881af4b2c65e21c29, entries=170230, sequenceid=181, filesize=12.1m
2014-07-13 23:16:25,035 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~278.9m/292491440, currentsize=45.2m/47426160 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 4734ms, sequenceid=181, compaction requested=false
2014-07-13 23:16:25,037 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 322.8m
2014-07-13 23:16:25,264 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:25,388 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=234, memsize=67.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/7f5d3d1cbea340b2914bc09af394e234
2014-07-13 23:16:25,406 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/7f5d3d1cbea340b2914bc09af394e234 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f5d3d1cbea340b2914bc09af394e234
2014-07-13 23:16:25,453 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f5d3d1cbea340b2914bc09af394e234, entries=246230, sequenceid=234, filesize=17.5m
2014-07-13 23:16:25,453 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~300.6m/315154480, currentsize=46.6m/48875440 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 6578ms, sequenceid=234, compaction requested=false
2014-07-13 23:16:25,454 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 323.3m
2014-07-13 23:16:25,961 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:26,556 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:26,698 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 927 synced till here 917
2014-07-13 23:16:26,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318583171 with entries=87, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318586556
2014-07-13 23:16:28,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:28,751 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1019 synced till here 1018
2014-07-13 23:16:28,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318586556 with entries=92, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318588412
2014-07-13 23:16:30,601 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:30,607 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=210, memsize=46.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/4c04ae83f8b84b9d88f9675773456fa7
2014-07-13 23:16:30,625 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/4c04ae83f8b84b9d88f9675773456fa7 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4c04ae83f8b84b9d88f9675773456fa7
2014-07-13 23:16:30,628 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318588412 with entries=61, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318590603
2014-07-13 23:16:30,638 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4c04ae83f8b84b9d88f9675773456fa7, entries=169490, sequenceid=210, filesize=12.1m
2014-07-13 23:16:30,638 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~322.8m/338498800, currentsize=77.0m/80727360 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 5601ms, sequenceid=210, compaction requested=false
2014-07-13 23:16:31,462 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=210, memsize=46.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/ce6be1f29f1642a6bf64b11812e5f7ed
2014-07-13 23:16:31,478 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/ce6be1f29f1642a6bf64b11812e5f7ed as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/ce6be1f29f1642a6bf64b11812e5f7ed
2014-07-13 23:16:31,490 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/ce6be1f29f1642a6bf64b11812e5f7ed, entries=169750, sequenceid=210, filesize=12.1m
2014-07-13 23:16:31,490 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~323.3m/338961760, currentsize=92.7m/97209840 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 6036ms, sequenceid=210, compaction requested=false
2014-07-13 23:16:32,511 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:32,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1140 synced till here 1139
2014-07-13 23:16:32,552 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318590603 with entries=60, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318592512
2014-07-13 23:16:32,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318196003
2014-07-13 23:16:32,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318563465
2014-07-13 23:16:32,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318565541
2014-07-13 23:16:32,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318567854
2014-07-13 23:16:32,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318571460
2014-07-13 23:16:32,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318575952
2014-07-13 23:16:34,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:34,239 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1212 synced till here 1210
2014-07-13 23:16:34,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318592512 with entries=72, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318594125
2014-07-13 23:16:35,949 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:36,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318594125 with entries=64, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318595950
2014-07-13 23:16:38,957 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:39,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1363 synced till here 1340
2014-07-13 23:16:39,348 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:16:39,353 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 267.1m
2014-07-13 23:16:39,391 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318595950 with entries=87, filesize=81.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318598957
2014-07-13 23:16:39,786 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:16:39,882 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 276.1m
2014-07-13 23:16:40,262 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:40,288 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:41,464 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:41,540 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1468 synced till here 1462
2014-07-13 23:16:41,626 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318598957 with entries=105, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318601466
2014-07-13 23:16:43,039 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:16:43,265 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:16:44,316 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:44,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1542 synced till here 1531
2014-07-13 23:16:44,921 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318601466 with entries=74, filesize=73.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318604317
2014-07-13 23:16:47,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:47,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1633 synced till here 1627
2014-07-13 23:16:47,644 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318604317 with entries=91, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318607289
2014-07-13 23:16:50,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:51,382 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=331, memsize=211.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/0c460e2d06fd4dfd86314fee5edf1809
2014-07-13 23:16:51,383 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=458, memsize=210.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/6bb20c225a824a40a6ca1c99cef81006
2014-07-13 23:16:51,433 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/6bb20c225a824a40a6ca1c99cef81006 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6bb20c225a824a40a6ca1c99cef81006
2014-07-13 23:16:51,434 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/0c460e2d06fd4dfd86314fee5edf1809 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c460e2d06fd4dfd86314fee5edf1809
2014-07-13 23:16:51,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1748 synced till here 1729
2014-07-13 23:16:51,985 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c460e2d06fd4dfd86314fee5edf1809, entries=769730, sequenceid=331, filesize=54.9m
2014-07-13 23:16:51,985 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~279.5m/293093840, currentsize=138.9m/145689440 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 12103ms, sequenceid=331, compaction requested=false
2014-07-13 23:16:51,986 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 342.1m
2014-07-13 23:16:52,135 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6bb20c225a824a40a6ca1c99cef81006, entries=767130, sequenceid=458, filesize=54.7m
2014-07-13 23:16:52,135 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~273.1m/286379200, currentsize=115.0m/120619680 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 12782ms, sequenceid=458, compaction requested=false
2014-07-13 23:16:52,136 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 340.3m
2014-07-13 23:16:52,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318607289 with entries=115, filesize=110.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318610279
2014-07-13 23:16:52,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318578187
2014-07-13 23:16:52,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318580880
2014-07-13 23:16:55,025 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:55,057 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:16:56,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:56,926 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1858 synced till here 1843
2014-07-13 23:16:57,084 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318610279 with entries=110, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318616781
2014-07-13 23:16:59,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:16:59,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1942 synced till here 1929
2014-07-13 23:16:59,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318616781 with entries=84, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318619263
2014-07-13 23:17:02,342 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:02,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2009 synced till here 1999
2014-07-13 23:17:03,300 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:17:03,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318619263 with entries=67, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318622343
2014-07-13 23:17:04,926 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:05,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2072 synced till here 2070
2014-07-13 23:17:05,042 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318622343 with entries=63, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318624926
2014-07-13 23:17:09,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:09,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2194 synced till here 2160
2014-07-13 23:17:09,871 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318624926 with entries=122, filesize=102.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318629085
2014-07-13 23:17:10,676 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=379, memsize=286.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/0561c7345dbc4ea59c2d38cb24a56e3c
2014-07-13 23:17:10,690 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/0561c7345dbc4ea59c2d38cb24a56e3c as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/0561c7345dbc4ea59c2d38cb24a56e3c
2014-07-13 23:17:10,702 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/0561c7345dbc4ea59c2d38cb24a56e3c, entries=1041510, sequenceid=379, filesize=74.2m
2014-07-13 23:17:10,702 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~342.5m/359156800, currentsize=188.7m/197902800 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 18567ms, sequenceid=379, compaction requested=false
2014-07-13 23:17:10,702 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 359.7m
2014-07-13 23:17:11,650 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=396, memsize=290.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/de596cd36fea407897d5b7d0a2e0ba4e
2014-07-13 23:17:11,661 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/de596cd36fea407897d5b7d0a2e0ba4e as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/de596cd36fea407897d5b7d0a2e0ba4e
2014-07-13 23:17:11,671 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/de596cd36fea407897d5b7d0a2e0ba4e, entries=1058010, sequenceid=396, filesize=75.4m
2014-07-13 23:17:11,672 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~370.6m/388550400, currentsize=220.2m/230884880 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 19686ms, sequenceid=396, compaction requested=false
2014-07-13 23:17:11,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:11,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2315 synced till here 2294
2014-07-13 23:17:12,044 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:17:12,585 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318629085 with entries=121, filesize=104.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318631848
2014-07-13 23:17:12,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318583171
2014-07-13 23:17:12,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318586556
2014-07-13 23:17:12,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318588412
2014-07-13 23:17:12,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318590603
2014-07-13 23:17:12,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318592512
2014-07-13 23:17:12,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318594125
2014-07-13 23:17:12,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318595950
2014-07-13 23:17:13,135 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:17:13,241 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 262.0m
2014-07-13 23:17:13,241 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:17:13,251 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:17:14,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:14,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2427 synced till here 2400
2014-07-13 23:17:14,114 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:17:14,625 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318631848 with entries=112, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318634073
2014-07-13 23:17:16,871 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:18,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2636 synced till here 2611
2014-07-13 23:17:19,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318634073 with entries=209, filesize=183.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318636872
2014-07-13 23:17:20,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:20,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2739 synced till here 2721
2014-07-13 23:17:21,116 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318636872 with entries=103, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318640817
2014-07-13 23:17:22,728 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:22,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2801 synced till here 2800
2014-07-13 23:17:22,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318640817 with entries=62, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318642728
2014-07-13 23:17:24,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:24,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2881 synced till here 2871
2014-07-13 23:17:25,024 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318642728 with entries=80, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318644583
2014-07-13 23:17:26,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:26,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2976 synced till here 2969
2014-07-13 23:17:26,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318644583 with entries=95, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318646817
2014-07-13 23:17:29,378 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:29,503 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3043 synced till here 3040
2014-07-13 23:17:29,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318646817 with entries=67, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318649379
2014-07-13 23:17:30,008 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=796, memsize=183.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/5e4a09ef1070428d8ffb3691feb2d749
2014-07-13 23:17:30,023 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=516, memsize=200.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/2478f3de166f4f9dae825c857fb41cf3
2014-07-13 23:17:30,028 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/5e4a09ef1070428d8ffb3691feb2d749 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5e4a09ef1070428d8ffb3691feb2d749
2014-07-13 23:17:30,043 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5e4a09ef1070428d8ffb3691feb2d749, entries=668680, sequenceid=796, filesize=47.6m
2014-07-13 23:17:30,044 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~266.2m/279087360, currentsize=172.1m/180456560 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 16803ms, sequenceid=796, compaction requested=true
2014-07-13 23:17:30,046 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 23:17:30,046 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-13 23:17:30,046 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 587.6m
2014-07-13 23:17:30,046 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 125676291 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-13 23:17:30,046 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: baaed08b3b283bc33b53e718e07d0f23 - family: Initiating major compaction
2014-07-13 23:17:30,047 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:17:30,047 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp, totalSize=119.9m
2014-07-13 23:17:30,052 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/2478f3de166f4f9dae825c857fb41cf3 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/2478f3de166f4f9dae825c857fb41cf3
2014-07-13 23:17:30,052 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f5d3d1cbea340b2914bc09af394e234, keycount=24623, bloomtype=ROW, size=17.5m, encoding=NONE, seqNum=234, earliestPutTs=1405318564011
2014-07-13 23:17:30,052 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6bb20c225a824a40a6ca1c99cef81006, keycount=76713, bloomtype=ROW, size=54.7m, encoding=NONE, seqNum=458, earliestPutTs=1405318578916
2014-07-13 23:17:30,052 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5e4a09ef1070428d8ffb3691feb2d749, keycount=66868, bloomtype=ROW, size=47.6m, encoding=NONE, seqNum=796, earliestPutTs=1405318599492
2014-07-13 23:17:30,083 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:17:30,184 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/2478f3de166f4f9dae825c857fb41cf3, entries=728810, sequenceid=516, filesize=51.9m
2014-07-13 23:17:30,184 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~379.6m/397998080, currentsize=333.6m/349835200 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 19482ms, sequenceid=516, compaction requested=true
2014-07-13 23:17:30,185 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-13 23:17:30,186 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 569.5m
2014-07-13 23:17:30,252 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:17:31,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:31,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3134 synced till here 3119
2014-07-13 23:17:31,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318649379 with entries=91, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318651495
2014-07-13 23:17:31,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318598957
2014-07-13 23:17:31,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318601466
2014-07-13 23:17:31,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318604317
2014-07-13 23:17:31,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318607289
2014-07-13 23:17:31,988 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:17:32,348 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:17:32,355 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-13 23:17:32,356 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-13 23:17:33,573 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:33,688 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3220 synced till here 3213
2014-07-13 23:17:33,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318651495 with entries=86, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318653575
2014-07-13 23:17:36,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:38,192 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:17:39,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3380 synced till here 3356
2014-07-13 23:17:39,272 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318653575 with entries=160, filesize=147.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318656027
2014-07-13 23:17:41,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:41,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3468 synced till here 3459
2014-07-13 23:17:41,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318656027 with entries=88, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318661158
2014-07-13 23:17:43,740 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:43,777 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3538 synced till here 3529
2014-07-13 23:17:43,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318661158 with entries=70, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318663741
2014-07-13 23:17:45,609 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:45,640 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318663741 with entries=60, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318665609
2014-07-13 23:17:47,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:47,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3664 synced till here 3660
2014-07-13 23:17:48,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318665609 with entries=66, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318667907
2014-07-13 23:17:50,089 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:50,249 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318667907 with entries=60, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318670090
2014-07-13 23:17:51,522 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=683, memsize=182.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/b33e9a6ec6b54bdd9602745277907f4c
2014-07-13 23:17:51,548 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/b33e9a6ec6b54bdd9602745277907f4c as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b33e9a6ec6b54bdd9602745277907f4c
2014-07-13 23:17:51,571 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b33e9a6ec6b54bdd9602745277907f4c, entries=665260, sequenceid=683, filesize=47.4m
2014-07-13 23:17:51,572 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~598.1m/627196560, currentsize=319.0m/334544160 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 21525ms, sequenceid=683, compaction requested=true
2014-07-13 23:17:51,576 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 23:17:51,576 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 658.1m
2014-07-13 23:17:51,592 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:17:51,905 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=685, memsize=185.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/d88c3480a04643c0a417ded6479f5a58
2014-07-13 23:17:52,034 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/d88c3480a04643c0a417ded6479f5a58 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/d88c3480a04643c0a417ded6479f5a58
2014-07-13 23:17:52,254 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/d88c3480a04643c0a417ded6479f5a58, entries=674270, sequenceid=685, filesize=48.1m
2014-07-13 23:17:52,255 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~574.9m/602862800, currentsize=327.0m/342924880 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 22070ms, sequenceid=685, compaction requested=true
2014-07-13 23:17:52,255 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-13 23:17:52,255 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:17:52,256 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 380.6m
2014-07-13 23:17:52,256 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:18:07,316 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 20669ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:18:07,316 WARN  [regionserver60020] util.Sleeper: We slept 15102ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:18:07,316 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 20669ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:18:07,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3792 synced till here 3785
2014-07-13 23:18:07,332 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14785ms
GC pool 'ParNew' had collection(s): count=2 time=98ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=15030ms
2014-07-13 23:18:07,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318670090 with entries=68, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318672256
2014-07-13 23:18:07,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318610279
2014-07-13 23:18:07,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318616781
2014-07-13 23:18:07,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318619263
2014-07-13 23:18:07,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318622343
2014-07-13 23:18:07,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318624926
2014-07-13 23:18:07,534 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15132,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318672258,"queuetimems":0,"class":"HRegionServer","responsesize":2008,"method":"Multi"}
2014-07-13 23:18:07,534 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3067 service: ClientService methodName: Multi size: 366.0k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,539 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,615 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16255,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318671359,"queuetimems":1,"class":"HRegionServer","responsesize":17445,"method":"Multi"}
2014-07-13 23:18:07,615 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16429,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318671185,"queuetimems":0,"class":"HRegionServer","responsesize":15853,"method":"Multi"}
2014-07-13 23:18:07,616 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2985 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,616 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,616 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2990 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,616 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,621 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3060 service: ClientService methodName: Multi size: 13.8k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,621 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,621 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3048 service: ClientService methodName: Multi size: 16.3k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,621 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,622 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318672032,"queuetimems":0,"class":"HRegionServer","responsesize":9865,"method":"Multi"}
2014-07-13 23:18:07,622 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3023 service: ClientService methodName: Multi size: 1.7m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,622 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,622 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3052 service: ClientService methodName: Multi size: 6.3k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,623 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,623 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3058 service: ClientService methodName: Multi size: 36.3k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,623 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,623 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3054 service: ClientService methodName: Multi size: 107.5k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,623 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,623 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3050 service: ClientService methodName: Multi size: 61.2k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,623 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,678 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318671719,"queuetimems":1,"class":"HRegionServer","responsesize":17255,"method":"Multi"}
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16086,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318671596,"queuetimems":0,"class":"HRegionServer","responsesize":15966,"method":"Multi"}
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3056 service: ClientService methodName: Multi size: 1000.4k connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3003 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3006 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,683 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,732 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15876,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318671856,"queuetimems":1,"class":"HRegionServer","responsesize":14351,"method":"Multi"}
2014-07-13 23:18:07,733 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3037 service: ClientService methodName: Multi size: 2.5m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,733 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,732 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15826,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318671906,"queuetimems":1,"class":"HRegionServer","responsesize":12083,"method":"Multi"}
2014-07-13 23:18:07,733 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3025 service: ClientService methodName: Multi size: 2.1m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:07,733 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:07,758 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:08,026 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15959,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318672067,"queuetimems":0,"class":"HRegionServer","responsesize":17592,"method":"Multi"}
2014-07-13 23:18:08,027 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3021 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:08,027 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:08,152 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15944,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318672207,"queuetimems":2,"class":"HRegionServer","responsesize":17645,"method":"Multi"}
2014-07-13 23:18:08,152 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15900,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47025","starttimems":1405318672252,"queuetimems":0,"class":"HRegionServer","responsesize":15781,"method":"Multi"}
2014-07-13 23:18:08,153 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3020 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:08,153 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:08,153 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3019 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:08,153 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:08,154 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3066 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:08,154 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:08,242 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3065 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47025: output error
2014-07-13 23:18:08,243 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:18:09,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:09,184 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3882 synced till here 3868
2014-07-13 23:18:09,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318672256 with entries=90, filesize=78.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318689162
2014-07-13 23:18:11,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:11,449 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3961 synced till here 3958
2014-07-13 23:18:11,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318689162 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318691429
2014-07-13 23:18:15,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:15,937 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318691429 with entries=88, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318695900
2014-07-13 23:18:17,499 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/0fb07ffa5fef4930afa32da24bdd9131 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/0fb07ffa5fef4930afa32da24bdd9131
2014-07-13 23:18:17,794 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:18:17,810 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f5d3d1cbea340b2914bc09af394e234, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f5d3d1cbea340b2914bc09af394e234
2014-07-13 23:18:17,813 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6bb20c225a824a40a6ca1c99cef81006, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6bb20c225a824a40a6ca1c99cef81006
2014-07-13 23:18:17,815 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5e4a09ef1070428d8ffb3691feb2d749, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5e4a09ef1070428d8ffb3691feb2d749
2014-07-13 23:18:17,815 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into 0fb07ffa5fef4930afa32da24bdd9131(size=102.4m), total size for store is 102.4m. This selection was in queue for 0sec, and took 47sec to execute.
2014-07-13 23:18:17,816 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., storeName=family, fileCount=3, fileSize=119.9m, priority=17, time=272557473637107; duration=47sec
2014-07-13 23:18:17,817 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-13 23:18:17,817 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-13 23:18:17,817 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 124695973 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-13 23:18:17,817 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: d679c2853f294b83582eebcd030d1677 - family: Initiating major compaction
2014-07-13 23:18:17,818 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:18:17,818 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp, totalSize=118.9m
2014-07-13 23:18:17,818 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/e2b107cc6f264f2881af4b2c65e21c29, keycount=17023, bloomtype=ROW, size=12.1m, encoding=NONE, seqNum=181, earliestPutTs=1405318578331
2014-07-13 23:18:17,818 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c460e2d06fd4dfd86314fee5edf1809, keycount=76973, bloomtype=ROW, size=54.9m, encoding=NONE, seqNum=331, earliestPutTs=1405318583376
2014-07-13 23:18:17,818 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/2478f3de166f4f9dae825c857fb41cf3, keycount=72881, bloomtype=ROW, size=51.9m, encoding=NONE, seqNum=516, earliestPutTs=1405318600096
2014-07-13 23:18:17,872 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:18,751 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1270, memsize=278.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/bf9c8320819b49a18643ea0198ab3e5a
2014-07-13 23:18:18,762 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/bf9c8320819b49a18643ea0198ab3e5a as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/bf9c8320819b49a18643ea0198ab3e5a
2014-07-13 23:18:18,782 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/bf9c8320819b49a18643ea0198ab3e5a, entries=1015220, sequenceid=1270, filesize=72.3m
2014-07-13 23:18:18,782 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~385.3m/404021040, currentsize=78.0m/81769600 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 26526ms, sequenceid=1270, compaction requested=false
2014-07-13 23:18:18,783 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 465.1m
2014-07-13 23:18:18,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:18,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4127 synced till here 4122
2014-07-13 23:18:19,045 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318695900 with entries=78, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318698964
2014-07-13 23:18:19,233 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:20,383 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:20,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4200 synced till here 4199
2014-07-13 23:18:20,429 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318698964 with entries=73, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318700384
2014-07-13 23:18:21,199 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=844, memsize=290.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/68083d2bca8245aaa29aeb2d9c0b2646
2014-07-13 23:18:21,215 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/68083d2bca8245aaa29aeb2d9c0b2646 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/68083d2bca8245aaa29aeb2d9c0b2646
2014-07-13 23:18:21,231 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/68083d2bca8245aaa29aeb2d9c0b2646, entries=1056160, sequenceid=844, filesize=75.3m
2014-07-13 23:18:21,232 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~662.0m/694124480, currentsize=194.9m/204344560 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 29656ms, sequenceid=844, compaction requested=false
2014-07-13 23:18:21,233 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 518.8m
2014-07-13 23:18:21,679 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:21,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4264 synced till here 4261
2014-07-13 23:18:21,879 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:21,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318700384 with entries=64, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318701679
2014-07-13 23:18:21,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318629085
2014-07-13 23:18:21,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318631848
2014-07-13 23:18:21,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318634073
2014-07-13 23:18:21,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318636872
2014-07-13 23:18:21,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318640817
2014-07-13 23:18:21,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318642728
2014-07-13 23:18:21,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318644583
2014-07-13 23:18:21,884 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318646817
2014-07-13 23:18:23,269 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:23,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4334 synced till here 4331
2014-07-13 23:18:23,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318701679 with entries=70, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318703269
2014-07-13 23:18:24,521 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:18:24,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:26,821 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318703269 with entries=176, filesize=161.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318704809
2014-07-13 23:18:28,376 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:28,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318704809 with entries=67, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318708377
2014-07-13 23:18:30,315 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:18:30,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:30,865 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4640 synced till here 4639
2014-07-13 23:18:30,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318708377 with entries=63, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318710848
2014-07-13 23:18:32,220 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=909, memsize=284.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/1189320e1cb3414395aff07ec2551ea8
2014-07-13 23:18:32,234 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/1189320e1cb3414395aff07ec2551ea8 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/1189320e1cb3414395aff07ec2551ea8
2014-07-13 23:18:32,247 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/1189320e1cb3414395aff07ec2551ea8, entries=1035780, sequenceid=909, filesize=73.8m
2014-07-13 23:18:32,247 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~467.4m/490150880, currentsize=263.7m/276463600 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 13464ms, sequenceid=909, compaction requested=true
2014-07-13 23:18:32,247 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-13 23:18:32,248 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 396.0m
2014-07-13 23:18:32,280 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:18:32,523 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:32,534 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:32,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318710848 with entries=70, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318712535
2014-07-13 23:18:34,707 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:34,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4783 synced till here 4779
2014-07-13 23:18:35,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318712535 with entries=73, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318714707
2014-07-13 23:18:36,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:36,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4853 synced till here 4851
2014-07-13 23:18:36,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318714707 with entries=70, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318716058
2014-07-13 23:18:36,088 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=944, memsize=312.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/12386f0aa184476b92f7be7872b44ea8
2014-07-13 23:18:36,105 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/12386f0aa184476b92f7be7872b44ea8 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/12386f0aa184476b92f7be7872b44ea8
2014-07-13 23:18:36,605 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/12386f0aa184476b92f7be7872b44ea8, entries=1138380, sequenceid=944, filesize=81.1m
2014-07-13 23:18:36,606 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~526.1m/551638800, currentsize=270.9m/284072800 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 15374ms, sequenceid=944, compaction requested=true
2014-07-13 23:18:36,607 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-13 23:18:36,607 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 353.7m
2014-07-13 23:18:36,638 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:18:37,005 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:37,307 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:38,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4959 synced till here 4956
2014-07-13 23:18:38,960 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318716058 with entries=106, filesize=103.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318717307
2014-07-13 23:18:38,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318649379
2014-07-13 23:18:38,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318651495
2014-07-13 23:18:38,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318653575
2014-07-13 23:18:38,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318656027
2014-07-13 23:18:38,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318661158
2014-07-13 23:18:38,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318663741
2014-07-13 23:18:38,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318665609
2014-07-13 23:18:38,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318667907
2014-07-13 23:18:38,979 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/d7152c689b774e24bc68edacff242f2a as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d7152c689b774e24bc68edacff242f2a
2014-07-13 23:18:39,016 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:18:39,029 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/e2b107cc6f264f2881af4b2c65e21c29, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/e2b107cc6f264f2881af4b2c65e21c29
2014-07-13 23:18:39,033 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c460e2d06fd4dfd86314fee5edf1809, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c460e2d06fd4dfd86314fee5edf1809
2014-07-13 23:18:39,037 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/2478f3de166f4f9dae825c857fb41cf3, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/2478f3de166f4f9dae825c857fb41cf3
2014-07-13 23:18:39,037 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into d7152c689b774e24bc68edacff242f2a(size=97.4m), total size for store is 172.7m. This selection was in queue for 0sec, and took 21sec to execute.
2014-07-13 23:18:39,037 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., storeName=family, fileCount=3, fileSize=118.9m, priority=17, time=272605244663431; duration=21sec
2014-07-13 23:18:39,038 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-13 23:18:39,038 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-13 23:18:39,038 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 217570009 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-13 23:18:39,038 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 6935e08926c94c414c50c4e2b2667be2 - family: Initiating major compaction
2014-07-13 23:18:39,038 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:18:39,039 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp, totalSize=207.5m
2014-07-13 23:18:39,039 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/ce6be1f29f1642a6bf64b11812e5f7ed, keycount=16975, bloomtype=ROW, size=12.1m, encoding=NONE, seqNum=210, earliestPutTs=1405318582229
2014-07-13 23:18:39,039 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/0561c7345dbc4ea59c2d38cb24a56e3c, keycount=104151, bloomtype=ROW, size=74.2m, encoding=NONE, seqNum=379, earliestPutTs=1405318585790
2014-07-13 23:18:39,039 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b33e9a6ec6b54bdd9602745277907f4c, keycount=66526, bloomtype=ROW, size=47.4m, encoding=NONE, seqNum=683, earliestPutTs=1405318617984
2014-07-13 23:18:39,039 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/1189320e1cb3414395aff07ec2551ea8, keycount=103578, bloomtype=ROW, size=73.8m, encoding=NONE, seqNum=909, earliestPutTs=1405318651181
2014-07-13 23:18:39,069 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:40,403 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:40,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5024 synced till here 5017
2014-07-13 23:18:40,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318717307 with entries=65, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318720404
2014-07-13 23:18:41,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:41,652 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5091 synced till here 5089
2014-07-13 23:18:41,715 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318720404 with entries=67, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318721623
2014-07-13 23:18:43,407 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:43,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318721623 with entries=64, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318723407
2014-07-13 23:18:44,683 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:44,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5227 synced till here 5221
2014-07-13 23:18:44,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318723407 with entries=72, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318724685
2014-07-13 23:18:45,805 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:46,333 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5312 synced till here 5308
2014-07-13 23:18:46,379 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318724685 with entries=85, filesize=80.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318725805
2014-07-13 23:18:46,598 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1056, memsize=317.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/3624ae3671c7430892d5ebffbb375c67
2014-07-13 23:18:46,619 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/3624ae3671c7430892d5ebffbb375c67 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3624ae3671c7430892d5ebffbb375c67
2014-07-13 23:18:46,632 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3624ae3671c7430892d5ebffbb375c67, entries=1156660, sequenceid=1056, filesize=82.4m
2014-07-13 23:18:46,632 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~396.0m/415234480, currentsize=292.7m/306902960 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 14384ms, sequenceid=1056, compaction requested=true
2014-07-13 23:18:46,632 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-13 23:18:46,632 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 552.7m
2014-07-13 23:18:46,752 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:18:47,016 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:48,627 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:48,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5379 synced till here 5375
2014-07-13 23:18:48,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318725805 with entries=67, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318728628
2014-07-13 23:18:50,217 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:50,585 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1597, memsize=330.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/46b4c9f82a8c4d7bab8bf8a0d64d9642
2014-07-13 23:18:50,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5466 synced till here 5465
2014-07-13 23:18:50,637 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/46b4c9f82a8c4d7bab8bf8a0d64d9642 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/46b4c9f82a8c4d7bab8bf8a0d64d9642
2014-07-13 23:18:50,638 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318728628 with entries=87, filesize=86.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318730218
2014-07-13 23:18:50,697 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/46b4c9f82a8c4d7bab8bf8a0d64d9642, entries=1203330, sequenceid=1597, filesize=85.7m
2014-07-13 23:18:50,697 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~358.6m/376058560, currentsize=214.3m/224667680 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 14090ms, sequenceid=1597, compaction requested=true
2014-07-13 23:18:50,698 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-13 23:18:50,698 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 554.6m
2014-07-13 23:18:51,475 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:18:51,782 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:51,803 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5529 synced till here 5526
2014-07-13 23:18:51,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318730218 with entries=63, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318731782
2014-07-13 23:18:51,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318670090
2014-07-13 23:18:51,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318672256
2014-07-13 23:18:51,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318689162
2014-07-13 23:18:51,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318691429
2014-07-13 23:18:52,101 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:18:53,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:53,037 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5599 synced till here 5592
2014-07-13 23:18:53,118 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318731782 with entries=70, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318733012
2014-07-13 23:18:54,734 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:54,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5667 synced till here 5666
2014-07-13 23:18:54,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318733012 with entries=68, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318734735
2014-07-13 23:18:56,031 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:56,058 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5734 synced till here 5729
2014-07-13 23:18:56,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318734735 with entries=67, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318736031
2014-07-13 23:18:58,045 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:58,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5808 synced till here 5805
2014-07-13 23:18:58,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318736031 with entries=74, filesize=74.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318738045
2014-07-13 23:18:59,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:18:59,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5879 synced till here 5874
2014-07-13 23:18:59,611 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318738045 with entries=71, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318739484
2014-07-13 23:19:01,111 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:01,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318739484 with entries=61, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318741112
2014-07-13 23:19:04,025 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:04,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6007 synced till here 6004
2014-07-13 23:19:04,339 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1210, memsize=428.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/fe5a8aed256846e18487510bbec7c08b
2014-07-13 23:19:04,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318741112 with entries=67, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318744026
2014-07-13 23:19:04,371 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/fe5a8aed256846e18487510bbec7c08b as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/fe5a8aed256846e18487510bbec7c08b
2014-07-13 23:19:04,383 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/fe5a8aed256846e18487510bbec7c08b, entries=1560610, sequenceid=1210, filesize=111.1m
2014-07-13 23:19:04,384 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~554.6m/581529200, currentsize=308.4m/323342880 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 17752ms, sequenceid=1210, compaction requested=false
2014-07-13 23:19:04,384 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 598.1m
2014-07-13 23:19:05,083 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:19:05,455 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:07,061 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:07,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6095 synced till here 6092
2014-07-13 23:19:07,929 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1245, memsize=410.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/acee400683eb435b9e347acc35892717
2014-07-13 23:19:07,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318744026 with entries=88, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318747062
2014-07-13 23:19:07,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318695900
2014-07-13 23:19:07,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318698964
2014-07-13 23:19:07,956 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/acee400683eb435b9e347acc35892717 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/acee400683eb435b9e347acc35892717
2014-07-13 23:19:07,979 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/acee400683eb435b9e347acc35892717, entries=1496140, sequenceid=1245, filesize=106.6m
2014-07-13 23:19:07,980 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~560.6m/587816240, currentsize=273.7m/287016320 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 17281ms, sequenceid=1245, compaction requested=true
2014-07-13 23:19:07,980 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-13 23:19:07,980 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 493.2m
2014-07-13 23:19:08,004 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:19:08,403 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:10,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:10,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318747062 with entries=81, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318750325
2014-07-13 23:19:10,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318700384
2014-07-13 23:19:10,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318701679
2014-07-13 23:19:10,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318703269
2014-07-13 23:19:10,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318704809
2014-07-13 23:19:10,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318708377
2014-07-13 23:19:11,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:11,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6236 synced till here 6231
2014-07-13 23:19:11,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318750325 with entries=60, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318751730
2014-07-13 23:19:12,892 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:12,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6311 synced till here 6307
2014-07-13 23:19:12,995 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318751730 with entries=75, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318752892
2014-07-13 23:19:13,869 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/329fcbdeb16e47b3b2081afe57c49fb6 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/329fcbdeb16e47b3b2081afe57c49fb6
2014-07-13 23:19:13,893 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:19:13,908 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/ce6be1f29f1642a6bf64b11812e5f7ed, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/ce6be1f29f1642a6bf64b11812e5f7ed
2014-07-13 23:19:13,912 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/0561c7345dbc4ea59c2d38cb24a56e3c, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/0561c7345dbc4ea59c2d38cb24a56e3c
2014-07-13 23:19:13,915 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b33e9a6ec6b54bdd9602745277907f4c, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b33e9a6ec6b54bdd9602745277907f4c
2014-07-13 23:19:13,921 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/1189320e1cb3414395aff07ec2551ea8, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/1189320e1cb3414395aff07ec2551ea8
2014-07-13 23:19:13,922 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into 329fcbdeb16e47b3b2081afe57c49fb6(size=178.0m), total size for store is 289.2m. This selection was in queue for 0sec, and took 34sec to execute.
2014-07-13 23:19:13,922 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., storeName=family, fileCount=4, fileSize=207.5m, priority=16, time=272626465441785; duration=34sec
2014-07-13 23:19:13,922 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-13 23:19:13,922 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-13 23:19:13,922 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 338895835 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-13 23:19:13,922 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 8b827125b32700e6f7c5c34f77be22cb - family: Initiating major compaction
2014-07-13 23:19:13,923 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:19:13,923 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp, totalSize=323.2m
2014-07-13 23:19:13,923 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4c04ae83f8b84b9d88f9675773456fa7, keycount=16949, bloomtype=ROW, size=12.1m, encoding=NONE, seqNum=210, earliestPutTs=1405318581440
2014-07-13 23:19:13,923 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/de596cd36fea407897d5b7d0a2e0ba4e, keycount=105801, bloomtype=ROW, size=75.4m, encoding=NONE, seqNum=396, earliestPutTs=1405318585663
2014-07-13 23:19:13,923 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/d88c3480a04643c0a417ded6479f5a58, keycount=67427, bloomtype=ROW, size=48.1m, encoding=NONE, seqNum=685, earliestPutTs=1405318617647
2014-07-13 23:19:13,923 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/12386f0aa184476b92f7be7872b44ea8, keycount=113838, bloomtype=ROW, size=81.1m, encoding=NONE, seqNum=944, earliestPutTs=1405318650578
2014-07-13 23:19:13,924 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/acee400683eb435b9e347acc35892717, keycount=149614, bloomtype=ROW, size=106.6m, encoding=NONE, seqNum=1245, earliestPutTs=1405318701396
2014-07-13 23:19:13,992 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:16,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:16,142 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318752892 with entries=145, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318756113
2014-07-13 23:19:20,473 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:20,499 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6524 synced till here 6521
2014-07-13 23:19:20,565 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318756113 with entries=68, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318760474
2014-07-13 23:19:21,717 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:21,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6598 synced till here 6595
2014-07-13 23:19:21,779 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318760474 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318761718
2014-07-13 23:19:22,366 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1385, memsize=446.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/7e79b8b3e2ae435eb0e00cd0297cf500
2014-07-13 23:19:22,378 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/7e79b8b3e2ae435eb0e00cd0297cf500 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/7e79b8b3e2ae435eb0e00cd0297cf500
2014-07-13 23:19:22,387 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/7e79b8b3e2ae435eb0e00cd0297cf500, entries=1626090, sequenceid=1385, filesize=115.8m
2014-07-13 23:19:22,387 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~611.0m/640728800, currentsize=214.7m/225100160 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 18003ms, sequenceid=1385, compaction requested=true
2014-07-13 23:19:22,387 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-13 23:19:22,387 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 537.9m
2014-07-13 23:19:22,720 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:23,111 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.41 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=20466, hits=3423, hitRatio=16.72%, , cachingAccesses=3428, cachingHits=3422, cachingHitsRatio=99.82%, evictions=0, evicted=2, evictedPerRun=Infinity
2014-07-13 23:19:24,183 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1936, memsize=422.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/c39b150e820d43d393a57ab98c351f29
2014-07-13 23:19:24,209 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/c39b150e820d43d393a57ab98c351f29 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c39b150e820d43d393a57ab98c351f29
2014-07-13 23:19:24,225 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c39b150e820d43d393a57ab98c351f29, entries=1536420, sequenceid=1936, filesize=109.4m
2014-07-13 23:19:24,225 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~493.8m/517806640, currentsize=161.5m/169333200 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 16245ms, sequenceid=1936, compaction requested=true
2014-07-13 23:19:24,225 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-13 23:19:24,226 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 475.1m
2014-07-13 23:19:24,524 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:25,917 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:26,760 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318761718 with entries=121, filesize=88.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318765918
2014-07-13 23:19:26,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318710848
2014-07-13 23:19:26,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318712535
2014-07-13 23:19:26,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318714707
2014-07-13 23:19:26,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318716058
2014-07-13 23:19:26,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318717307
2014-07-13 23:19:26,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318720404
2014-07-13 23:19:26,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318721623
2014-07-13 23:19:26,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318723407
2014-07-13 23:19:26,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318724685
2014-07-13 23:19:27,457 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:19:28,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:28,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6781 synced till here 6779
2014-07-13 23:19:28,662 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318765918 with entries=62, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318768607
2014-07-13 23:19:29,587 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:19:29,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:29,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6846 synced till here 6840
2014-07-13 23:19:30,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318768607 with entries=65, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318769951
2014-07-13 23:19:32,534 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:32,562 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318769951 with entries=84, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318772535
2014-07-13 23:19:34,640 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:34,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318772535 with entries=74, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318774641
2014-07-13 23:19:36,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:37,209 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7101 synced till here 7098
2014-07-13 23:19:37,245 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318774641 with entries=97, filesize=90.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318776704
2014-07-13 23:19:39,940 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:39,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7178 synced till here 7177
2014-07-13 23:19:39,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318776704 with entries=77, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318779941
2014-07-13 23:19:40,497 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1549, memsize=460.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/a40ffa295c844cb8946ddfd38568ae84
2014-07-13 23:19:40,518 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/a40ffa295c844cb8946ddfd38568ae84 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/a40ffa295c844cb8946ddfd38568ae84
2014-07-13 23:19:40,541 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/a40ffa295c844cb8946ddfd38568ae84, entries=1678040, sequenceid=1549, filesize=119.4m
2014-07-13 23:19:40,541 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~537.9m/564041280, currentsize=218.4m/228978080 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 18154ms, sequenceid=1549, compaction requested=true
2014-07-13 23:19:40,541 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-13 23:19:40,542 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 432.7m
2014-07-13 23:19:40,782 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:41,476 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1553, memsize=434.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/12b4659d9e4543d192f49d01aaf0376f
2014-07-13 23:19:41,492 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/12b4659d9e4543d192f49d01aaf0376f as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/12b4659d9e4543d192f49d01aaf0376f
2014-07-13 23:19:41,516 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/12b4659d9e4543d192f49d01aaf0376f, entries=1580720, sequenceid=1553, filesize=112.5m
2014-07-13 23:19:41,516 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~475.1m/498188160, currentsize=209.4m/219541920 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 17290ms, sequenceid=1553, compaction requested=false
2014-07-13 23:19:41,517 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 386.4m
2014-07-13 23:19:41,782 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:54,840 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1691, memsize=432.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/d4baf2bb98834dc4b5d9f59081ad41cd
2014-07-13 23:19:54,862 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/d4baf2bb98834dc4b5d9f59081ad41cd as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d4baf2bb98834dc4b5d9f59081ad41cd
2014-07-13 23:19:54,882 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d4baf2bb98834dc4b5d9f59081ad41cd, entries=1575450, sequenceid=1691, filesize=112.2m
2014-07-13 23:19:54,882 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~432.7m/453716000, currentsize=0.0/0 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 14340ms, sequenceid=1691, compaction requested=true
2014-07-13 23:19:54,882 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-13 23:19:54,965 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2155, memsize=386.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/ff0d8304060e4410a94debd673aabebb
2014-07-13 23:19:54,990 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/ff0d8304060e4410a94debd673aabebb as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ff0d8304060e4410a94debd673aabebb
2014-07-13 23:19:55,013 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ff0d8304060e4410a94debd673aabebb, entries=1406950, sequenceid=2155, filesize=100.2m
2014-07-13 23:19:55,013 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~386.4m/405189360, currentsize=0.0/0 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 13496ms, sequenceid=2155, compaction requested=true
2014-07-13 23:19:55,014 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-13 23:19:58,021 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:19:58,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7250 synced till here 7246
2014-07-13 23:19:58,105 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318779941 with entries=72, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318798022
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318725805
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318728628
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318730218
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318731782
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318733012
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318734735
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318736031
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318738045
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318739484
2014-07-13 23:19:58,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318741112
2014-07-13 23:19:58,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318744026
2014-07-13 23:19:58,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318747062
2014-07-13 23:19:58,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318750325
2014-07-13 23:19:58,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318751730
2014-07-13 23:19:58,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318752892
2014-07-13 23:19:58,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318756113
2014-07-13 23:19:58,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318760474
2014-07-13 23:19:58,704 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:19:58,704 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 256.1m
2014-07-13 23:19:58,870 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:19:59,574 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:19:59,574 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 257.0m
2014-07-13 23:19:59,768 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:00,431 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:00,714 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318798022 with entries=69, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318800431
2014-07-13 23:20:01,269 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/5b3f39879754462a9453f9c108166e06 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5b3f39879754462a9453f9c108166e06
2014-07-13 23:20:01,290 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:20:01,303 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4c04ae83f8b84b9d88f9675773456fa7, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4c04ae83f8b84b9d88f9675773456fa7
2014-07-13 23:20:01,312 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/de596cd36fea407897d5b7d0a2e0ba4e, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/de596cd36fea407897d5b7d0a2e0ba4e
2014-07-13 23:20:01,321 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/d88c3480a04643c0a417ded6479f5a58, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/d88c3480a04643c0a417ded6479f5a58
2014-07-13 23:20:01,334 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/12386f0aa184476b92f7be7872b44ea8, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/12386f0aa184476b92f7be7872b44ea8
2014-07-13 23:20:01,336 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/acee400683eb435b9e347acc35892717, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/acee400683eb435b9e347acc35892717
2014-07-13 23:20:01,337 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into 5b3f39879754462a9453f9c108166e06(size=287.9m), total size for store is 400.4m. This selection was in queue for 0sec, and took 47sec to execute.
2014-07-13 23:20:01,337 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., storeName=family, fileCount=5, fileSize=323.2m, priority=15, time=272661349842539; duration=47sec
2014-07-13 23:20:01,337 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-13 23:20:01,337 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-13 23:20:01,338 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 506439879 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-13 23:20:01,338 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: d679c2853f294b83582eebcd030d1677 - family: Initiating major compaction
2014-07-13 23:20:01,338 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:20:01,338 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp, totalSize=483.0m
2014-07-13 23:20:01,338 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d7152c689b774e24bc68edacff242f2a, keycount=136733, bloomtype=ROW, size=97.4m, encoding=NONE, seqNum=516, earliestPutTs=1405318583376
2014-07-13 23:20:01,338 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/68083d2bca8245aaa29aeb2d9c0b2646, keycount=105616, bloomtype=ROW, size=75.3m, encoding=NONE, seqNum=844, earliestPutTs=1405318640167
2014-07-13 23:20:01,338 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3624ae3671c7430892d5ebffbb375c67, keycount=115666, bloomtype=ROW, size=82.4m, encoding=NONE, seqNum=1056, earliestPutTs=1405318687602
2014-07-13 23:20:01,339 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/7e79b8b3e2ae435eb0e00cd0297cf500, keycount=162609, bloomtype=ROW, size=115.8m, encoding=NONE, seqNum=1385, earliestPutTs=1405318712267
2014-07-13 23:20:01,339 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d4baf2bb98834dc4b5d9f59081ad41cd, keycount=157545, bloomtype=ROW, size=112.2m, encoding=NONE, seqNum=1691, earliestPutTs=1405318745009
2014-07-13 23:20:01,790 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:04,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:04,269 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7421 synced till here 7419
2014-07-13 23:20:04,362 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318800431 with entries=102, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318804223
2014-07-13 23:20:05,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:05,881 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7486 synced till here 7479
2014-07-13 23:20:06,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318804223 with entries=65, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318805810
2014-07-13 23:20:07,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:07,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7555 synced till here 7550
2014-07-13 23:20:07,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318805810 with entries=69, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318807494
2014-07-13 23:20:09,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:09,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318807494 with entries=69, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318809148
2014-07-13 23:20:11,646 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:11,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7705 synced till here 7691
2014-07-13 23:20:11,733 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1712, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/122a2e4f325248eb9f2e2ffb8f86c879
2014-07-13 23:20:11,748 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/122a2e4f325248eb9f2e2ffb8f86c879 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/122a2e4f325248eb9f2e2ffb8f86c879
2014-07-13 23:20:11,759 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/122a2e4f325248eb9f2e2ffb8f86c879, entries=932450, sequenceid=1712, filesize=66.5m
2014-07-13 23:20:11,759 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.1m/268539680, currentsize=168.3m/176461120 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 13055ms, sequenceid=1712, compaction requested=true
2014-07-13 23:20:11,759 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-13 23:20:12,904 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318809148 with entries=81, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318811647
2014-07-13 23:20:13,050 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1716, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/ac5549187a8c42419c9ea54824354617
2014-07-13 23:20:13,069 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/ac5549187a8c42419c9ea54824354617 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ac5549187a8c42419c9ea54824354617
2014-07-13 23:20:13,103 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ac5549187a8c42419c9ea54824354617, entries=935720, sequenceid=1716, filesize=66.7m
2014-07-13 23:20:13,103 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.0m/269482560, currentsize=168.3m/176526320 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 13529ms, sequenceid=1716, compaction requested=true
2014-07-13 23:20:13,103 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:11), split_queue=0, merge_queue=0
2014-07-13 23:20:13,635 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:13,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7778 synced till here 7773
2014-07-13 23:20:13,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318811647 with entries=73, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318813636
2014-07-13 23:20:13,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318761718
2014-07-13 23:20:13,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318765918
2014-07-13 23:20:13,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318768607
2014-07-13 23:20:13,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318769951
2014-07-13 23:20:13,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318772535
2014-07-13 23:20:13,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318774641
2014-07-13 23:20:13,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318776704
2014-07-13 23:20:13,922 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:20:13,922 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 259.2m
2014-07-13 23:20:14,490 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:20:14,497 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 257.6m
2014-07-13 23:20:14,613 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:14,720 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:15,099 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:16,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7886 synced till here 7873
2014-07-13 23:20:16,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318813636 with entries=108, filesize=99.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318815222
2014-07-13 23:20:16,801 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:20:16,917 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:20:17,290 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:17,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7962 synced till here 7954
2014-07-13 23:20:17,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318815222 with entries=76, filesize=74.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318817291
2014-07-13 23:20:18,592 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:19,282 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8041 synced till here 8032
2014-07-13 23:20:19,489 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318817291 with entries=79, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318818593
2014-07-13 23:20:21,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:21,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8124 synced till here 8118
2014-07-13 23:20:21,149 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318818593 with entries=83, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318821053
2014-07-13 23:20:22,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:22,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8199 synced till here 8193
2014-07-13 23:20:22,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318821053 with entries=75, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318822018
2014-07-13 23:20:25,176 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1849, memsize=206.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/4916d9a4d57b4f80903aa88a1a6b9ee3
2014-07-13 23:20:25,193 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/4916d9a4d57b4f80903aa88a1a6b9ee3 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/4916d9a4d57b4f80903aa88a1a6b9ee3
2014-07-13 23:20:25,203 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/4916d9a4d57b4f80903aa88a1a6b9ee3, entries=753400, sequenceid=1849, filesize=53.6m
2014-07-13 23:20:25,204 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~264.1m/276900960, currentsize=206.3m/216295120 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 10707ms, sequenceid=1849, compaction requested=false
2014-07-13 23:20:25,204 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 438.5m
2014-07-13 23:20:25,279 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2308, memsize=220.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/f0f414826f0a4b7b80b108d11b7fb5e6
2014-07-13 23:20:25,291 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/f0f414826f0a4b7b80b108d11b7fb5e6 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f0f414826f0a4b7b80b108d11b7fb5e6
2014-07-13 23:20:25,305 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f0f414826f0a4b7b80b108d11b7fb5e6, entries=801500, sequenceid=2308, filesize=57.0m
2014-07-13 23:20:25,306 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.9m/272530480, currentsize=90.6m/94973680 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 11383ms, sequenceid=2308, compaction requested=true
2014-07-13 23:20:25,306 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-13 23:20:25,306 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 427.7m
2014-07-13 23:20:25,522 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:25,719 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:33,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:33,387 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8288 synced till here 8287
2014-07-13 23:20:33,421 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318822018 with entries=89, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318833359
2014-07-13 23:20:33,421 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318779941
2014-07-13 23:20:34,187 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1975, memsize=249.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/5ad17e55e2844166b4075f58619b3875
2014-07-13 23:20:34,213 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/5ad17e55e2844166b4075f58619b3875 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5ad17e55e2844166b4075f58619b3875
2014-07-13 23:20:34,312 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5ad17e55e2844166b4075f58619b3875, entries=907610, sequenceid=1975, filesize=64.6m
2014-07-13 23:20:34,313 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~427.7m/448517840, currentsize=1.3m/1327680 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 9007ms, sequenceid=1975, compaction requested=true
2014-07-13 23:20:34,313 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-13 23:20:34,541 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1976, memsize=259.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/e9dff5c0a12c4e00a7303f67c7ed6b45
2014-07-13 23:20:34,554 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/e9dff5c0a12c4e00a7303f67c7ed6b45 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e9dff5c0a12c4e00a7303f67c7ed6b45
2014-07-13 23:20:34,567 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e9dff5c0a12c4e00a7303f67c7ed6b45, entries=944220, sequenceid=1976, filesize=67.2m
2014-07-13 23:20:34,568 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~438.5m/459833520, currentsize=5.2m/5503680 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 9364ms, sequenceid=1976, compaction requested=true
2014-07-13 23:20:34,568 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-13 23:20:36,732 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:36,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8350 synced till here 8349
2014-07-13 23:20:36,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318833359 with entries=62, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318836732
2014-07-13 23:20:36,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318798022
2014-07-13 23:20:36,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318800431
2014-07-13 23:20:36,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318804223
2014-07-13 23:20:36,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318805810
2014-07-13 23:20:36,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318807494
2014-07-13 23:20:36,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318809148
2014-07-13 23:20:36,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318811647
2014-07-13 23:20:37,957 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:20:37,957 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 257.8m
2014-07-13 23:20:38,222 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:38,353 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:38,368 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8408 synced till here 8407
2014-07-13 23:20:38,392 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318836732 with entries=58, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318838353
2014-07-13 23:20:39,788 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:39,828 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8482 synced till here 8481
2014-07-13 23:20:39,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318838353 with entries=74, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318839789
2014-07-13 23:20:41,108 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:41,123 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8558 synced till here 8552
2014-07-13 23:20:41,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318839789 with entries=76, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318841108
2014-07-13 23:20:41,290 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:20:41,290 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 258.1m
2014-07-13 23:20:41,509 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:42,757 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:42,792 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8627 synced till here 8625
2014-07-13 23:20:42,857 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318841108 with entries=69, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318842757
2014-07-13 23:20:44,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:44,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8690 synced till here 8689
2014-07-13 23:20:45,168 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318842757 with entries=63, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318844705
2014-07-13 23:20:45,250 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2006, memsize=169.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/db3a5c3eedc04b1e8ea02f2b1fa3f471
2014-07-13 23:20:45,272 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/db3a5c3eedc04b1e8ea02f2b1fa3f471 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/db3a5c3eedc04b1e8ea02f2b1fa3f471
2014-07-13 23:20:45,294 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/db3a5c3eedc04b1e8ea02f2b1fa3f471, entries=617560, sequenceid=2006, filesize=44.0m
2014-07-13 23:20:45,294 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~262.0m/274677360, currentsize=118.9m/124663920 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 7337ms, sequenceid=2006, compaction requested=false
2014-07-13 23:20:46,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:46,528 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8757 synced till here 8754
2014-07-13 23:20:46,694 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318844705 with entries=67, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318846510
2014-07-13 23:20:47,773 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:48,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8853 synced till here 8844
2014-07-13 23:20:48,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318846510 with entries=96, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318847774
2014-07-13 23:20:48,622 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:20:48,623 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 257.9m
2014-07-13 23:20:48,691 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:20:49,348 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:49,525 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:49,547 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8922 synced till here 8920
2014-07-13 23:20:49,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318847774 with entries=69, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318849525
2014-07-13 23:20:50,318 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2465, memsize=207.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/22961bc814534219bc718ab7b8d7df84
2014-07-13 23:20:50,329 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/22961bc814534219bc718ab7b8d7df84 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/22961bc814534219bc718ab7b8d7df84
2014-07-13 23:20:50,339 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/22961bc814534219bc718ab7b8d7df84, entries=754840, sequenceid=2465, filesize=53.8m
2014-07-13 23:20:50,339 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.0m/272642320, currentsize=164.1m/172066640 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 9049ms, sequenceid=2465, compaction requested=true
2014-07-13 23:20:50,339 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-13 23:20:50,339 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 291.7m
2014-07-13 23:20:50,975 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:51,094 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:51,448 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:20:51,529 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9025 synced till here 9024
2014-07-13 23:20:51,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318849525 with entries=103, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318851094
2014-07-13 23:20:51,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318813636
2014-07-13 23:20:51,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318815222
2014-07-13 23:20:51,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318817291
2014-07-13 23:20:51,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318818593
2014-07-13 23:20:51,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318821053
2014-07-13 23:20:54,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:54,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318851094 with entries=78, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318854165
2014-07-13 23:20:57,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:20:57,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9189 synced till here 9186
2014-07-13 23:20:57,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318854165 with entries=86, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318857253
2014-07-13 23:20:57,872 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2131, memsize=239.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/7ceb363c18704302ba0ada76718c6c89
2014-07-13 23:20:57,894 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/7ceb363c18704302ba0ada76718c6c89 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7ceb363c18704302ba0ada76718c6c89
2014-07-13 23:20:57,918 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7ceb363c18704302ba0ada76718c6c89, entries=870740, sequenceid=2131, filesize=62.0m
2014-07-13 23:20:57,918 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.1m/273781760, currentsize=113.2m/118686480 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 9295ms, sequenceid=2131, compaction requested=true
2014-07-13 23:20:57,919 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:16), split_queue=0, merge_queue=0
2014-07-13 23:20:57,919 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 320.1m
2014-07-13 23:20:58,109 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:20:59,689 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2152, memsize=269.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/7f0f26e1bf1644d7b6f6bbbdc21ba5d6
2014-07-13 23:20:59,702 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/7f0f26e1bf1644d7b6f6bbbdc21ba5d6 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/7f0f26e1bf1644d7b6f6bbbdc21ba5d6
2014-07-13 23:20:59,737 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/7f0f26e1bf1644d7b6f6bbbdc21ba5d6, entries=979980, sequenceid=2152, filesize=69.8m
2014-07-13 23:20:59,737 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~291.7m/305824720, currentsize=83.5m/87552240 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 9398ms, sequenceid=2152, compaction requested=true
2014-07-13 23:20:59,737 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:17), split_queue=0, merge_queue=0
2014-07-13 23:21:06,611 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2212, memsize=298.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/ab775b689f9348019cb0fc4c3d3b99b3
2014-07-13 23:21:06,634 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/ab775b689f9348019cb0fc4c3d3b99b3 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ab775b689f9348019cb0fc4c3d3b99b3
2014-07-13 23:21:06,646 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ab775b689f9348019cb0fc4c3d3b99b3, entries=1085210, sequenceid=2212, filesize=77.3m
2014-07-13 23:21:06,646 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~320.4m/335918560, currentsize=0.0/0 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 8727ms, sequenceid=2212, compaction requested=true
2014-07-13 23:21:06,646 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-13 23:21:09,681 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:21:09,681 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 256.2m
2014-07-13 23:21:09,850 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:11,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:12,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318857253 with entries=100, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318871818
2014-07-13 23:21:12,241 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318822018
2014-07-13 23:21:12,241 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318833359
2014-07-13 23:21:12,241 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318836732
2014-07-13 23:21:12,241 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318838353
2014-07-13 23:21:12,241 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318839789
2014-07-13 23:21:13,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:13,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9352 synced till here 9351
2014-07-13 23:21:13,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318871818 with entries=63, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318873517
2014-07-13 23:21:16,293 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:16,325 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9413 synced till here 9409
2014-07-13 23:21:16,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318873517 with entries=61, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318876294
2014-07-13 23:21:17,984 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:18,023 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9488 synced till here 9484
2014-07-13 23:21:18,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318876294 with entries=75, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318877984
2014-07-13 23:21:19,358 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:21:19,359 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 257.6m
2014-07-13 23:21:19,566 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:19,913 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2622, memsize=250.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/35279e0e28844efba4ed8764ce46c424
2014-07-13 23:21:19,933 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/35279e0e28844efba4ed8764ce46c424 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/35279e0e28844efba4ed8764ce46c424
2014-07-13 23:21:19,946 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/35279e0e28844efba4ed8764ce46c424, entries=912640, sequenceid=2622, filesize=65.0m
2014-07-13 23:21:19,947 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268688160, currentsize=134.6m/141090080 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 10266ms, sequenceid=2622, compaction requested=true
2014-07-13 23:21:19,947 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-13 23:21:20,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:20,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9550 synced till here 9549
2014-07-13 23:21:20,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318877984 with entries=62, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318880281
2014-07-13 23:21:20,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318841108
2014-07-13 23:21:20,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318842757
2014-07-13 23:21:20,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318844705
2014-07-13 23:21:20,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318846510
2014-07-13 23:21:21,493 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:21:21,493 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 256.6m
2014-07-13 23:21:21,558 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:21,756 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:21,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9628 synced till here 9615
2014-07-13 23:21:21,932 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318880281 with entries=78, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318881558
2014-07-13 23:21:23,109 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:23,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9707 synced till here 9705
2014-07-13 23:21:23,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318881558 with entries=79, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318883110
2014-07-13 23:21:24,854 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:24,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9795 synced till here 9781
2014-07-13 23:21:24,945 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:21:25,460 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318883110 with entries=88, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318884854
2014-07-13 23:21:25,533 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/788c62b68b93457fbba85fefa73f19d9 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/788c62b68b93457fbba85fefa73f19d9
2014-07-13 23:21:26,816 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:21:26,821 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:21:26,990 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d7152c689b774e24bc68edacff242f2a, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d7152c689b774e24bc68edacff242f2a
2014-07-13 23:21:27,169 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/68083d2bca8245aaa29aeb2d9c0b2646, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/68083d2bca8245aaa29aeb2d9c0b2646
2014-07-13 23:21:27,223 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3624ae3671c7430892d5ebffbb375c67, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3624ae3671c7430892d5ebffbb375c67
2014-07-13 23:21:27,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:27,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9926 synced till here 9892
2014-07-13 23:21:27,363 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/7e79b8b3e2ae435eb0e00cd0297cf500, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/7e79b8b3e2ae435eb0e00cd0297cf500
2014-07-13 23:21:27,366 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d4baf2bb98834dc4b5d9f59081ad41cd, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d4baf2bb98834dc4b5d9f59081ad41cd
2014-07-13 23:21:27,367 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into 788c62b68b93457fbba85fefa73f19d9(size=452.8m), total size for store is 627.7m. This selection was in queue for 0sec, and took 1mins, 26sec to execute.
2014-07-13 23:21:27,367 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., storeName=family, fileCount=5, fileSize=483.0m, priority=15, time=272708764991443; duration=1mins, 26sec
2014-07-13 23:21:27,367 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-13 23:21:27,368 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-13 23:21:27,368 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 8 files of size 677292865 starting at candidate #0 after considering 21 permutations with 21 in ratio
2014-07-13 23:21:27,369 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: baaed08b3b283bc33b53e718e07d0f23 - family: Initiating major compaction
2014-07-13 23:21:27,369 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:21:27,369 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 8 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp, totalSize=645.9m
2014-07-13 23:21:27,370 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/0fb07ffa5fef4930afa32da24bdd9131, keycount=143813, bloomtype=ROW, size=102.4m, encoding=NONE, seqNum=796, earliestPutTs=1405318564011
2014-07-13 23:21:27,370 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/bf9c8320819b49a18643ea0198ab3e5a, keycount=101522, bloomtype=ROW, size=72.3m, encoding=NONE, seqNum=1270, earliestPutTs=1405318633242
2014-07-13 23:21:27,370 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/46b4c9f82a8c4d7bab8bf8a0d64d9642, keycount=120333, bloomtype=ROW, size=85.7m, encoding=NONE, seqNum=1597, earliestPutTs=1405318687551
2014-07-13 23:21:27,370 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c39b150e820d43d393a57ab98c351f29, keycount=153642, bloomtype=ROW, size=109.4m, encoding=NONE, seqNum=1936, earliestPutTs=1405318716628
2014-07-13 23:21:27,370 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ff0d8304060e4410a94debd673aabebb, keycount=140695, bloomtype=ROW, size=100.2m, encoding=NONE, seqNum=2155, earliestPutTs=1405318747986
2014-07-13 23:21:27,370 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f0f414826f0a4b7b80b108d11b7fb5e6, keycount=80150, bloomtype=ROW, size=57.0m, encoding=NONE, seqNum=2308, earliestPutTs=1405318796638
2014-07-13 23:21:27,371 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/22961bc814534219bc718ab7b8d7df84, keycount=75484, bloomtype=ROW, size=53.8m, encoding=NONE, seqNum=2465, earliestPutTs=1405318814658
2014-07-13 23:21:27,371 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/35279e0e28844efba4ed8764ce46c424, keycount=91264, bloomtype=ROW, size=65.0m, encoding=NONE, seqNum=2622, earliestPutTs=1405318841612
2014-07-13 23:21:27,555 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318884854 with entries=131, filesize=94.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318887225
2014-07-13 23:21:28,568 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:29,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:29,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10026 synced till here 10007
2014-07-13 23:21:29,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318887225 with entries=100, filesize=79.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318889230
2014-07-13 23:21:31,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:32,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10167 synced till here 10131
2014-07-13 23:21:32,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318889230 with entries=141, filesize=106.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318891146
2014-07-13 23:21:34,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:34,208 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10282 synced till here 10269
2014-07-13 23:21:34,244 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2289, memsize=251.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/a45b41143d444337a410cdd2db8af87e
2014-07-13 23:21:34,256 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/a45b41143d444337a410cdd2db8af87e as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a45b41143d444337a410cdd2db8af87e
2014-07-13 23:21:34,269 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a45b41143d444337a410cdd2db8af87e, entries=915530, sequenceid=2289, filesize=65.2m
2014-07-13 23:21:34,269 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.8m/274504080, currentsize=268.2m/281278080 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 14910ms, sequenceid=2289, compaction requested=true
2014-07-13 23:21:34,270 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-13 23:21:34,270 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 428.5m
2014-07-13 23:21:34,297 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:21:34,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318891146 with entries=115, filesize=81.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318894168
2014-07-13 23:21:34,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318847774
2014-07-13 23:21:35,963 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:35,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:36,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10381 synced till here 10372
2014-07-13 23:21:36,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318894168 with entries=99, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318895988
2014-07-13 23:21:36,693 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2306, memsize=238.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/dcd6c20a5ade44748289a292e8ee72cb
2014-07-13 23:21:36,734 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/dcd6c20a5ade44748289a292e8ee72cb as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/dcd6c20a5ade44748289a292e8ee72cb
2014-07-13 23:21:37,329 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/dcd6c20a5ade44748289a292e8ee72cb, entries=866530, sequenceid=2306, filesize=61.8m
2014-07-13 23:21:37,329 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~263.1m/275904720, currentsize=306.7m/321619440 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 15836ms, sequenceid=2306, compaction requested=true
2014-07-13 23:21:37,330 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:20), split_queue=0, merge_queue=0
2014-07-13 23:21:37,330 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 394.4m
2014-07-13 23:21:37,369 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:21:37,524 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:37,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10467 synced till here 10453
2014-07-13 23:21:37,713 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318895988 with entries=86, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318897524
2014-07-13 23:21:37,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318849525
2014-07-13 23:21:37,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318851094
2014-07-13 23:21:37,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318854165
2014-07-13 23:21:37,887 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:38,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:38,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10531 synced till here 10529
2014-07-13 23:21:39,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318897524 with entries=64, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318898965
2014-07-13 23:21:40,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:40,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10594 synced till here 10592
2014-07-13 23:21:40,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318898965 with entries=63, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318900373
2014-07-13 23:21:41,990 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:42,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10672 synced till here 10659
2014-07-13 23:21:42,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318900373 with entries=78, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318901990
2014-07-13 23:21:43,597 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:43,634 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10760 synced till here 10748
2014-07-13 23:21:43,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318901990 with entries=88, filesize=80.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318903597
2014-07-13 23:21:45,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:45,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10877 synced till here 10859
2014-07-13 23:21:45,990 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318903597 with entries=117, filesize=107.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318905591
2014-07-13 23:21:47,378 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:48,409 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2452, memsize=200.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/13dc9c4915784adca639394bb2db59ec
2014-07-13 23:21:48,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10976 synced till here 10963
2014-07-13 23:21:48,430 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/13dc9c4915784adca639394bb2db59ec as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/13dc9c4915784adca639394bb2db59ec
2014-07-13 23:21:48,451 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/13dc9c4915784adca639394bb2db59ec, entries=730970, sequenceid=2452, filesize=52.1m
2014-07-13 23:21:48,453 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~444.9m/466546960, currentsize=304.5m/319294000 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 14183ms, sequenceid=2452, compaction requested=true
2014-07-13 23:21:48,454 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-13 23:21:48,454 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 587.1m
2014-07-13 23:21:48,464 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:21:48,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318905591 with entries=99, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318907379
2014-07-13 23:21:49,095 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:49,368 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:49,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11079 synced till here 11072
2014-07-13 23:21:50,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318907379 with entries=103, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318909369
2014-07-13 23:21:50,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:50,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11151 synced till here 11149
2014-07-13 23:21:50,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318909369 with entries=72, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318910791
2014-07-13 23:21:51,675 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3052, memsize=238.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/b6705ddd5f724c869f6ebf9e77a5dad5
2014-07-13 23:21:51,687 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/b6705ddd5f724c869f6ebf9e77a5dad5 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b6705ddd5f724c869f6ebf9e77a5dad5
2014-07-13 23:21:51,711 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b6705ddd5f724c869f6ebf9e77a5dad5, entries=867730, sequenceid=3052, filesize=61.8m
2014-07-13 23:21:51,711 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~398.5m/417892720, currentsize=182.3m/191174160 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 14381ms, sequenceid=3052, compaction requested=false
2014-07-13 23:21:51,712 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 650.9m
2014-07-13 23:21:52,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:52,406 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:21:52,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11228 synced till here 11227
2014-07-13 23:21:52,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318910791 with entries=77, filesize=82.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318912104
2014-07-13 23:21:52,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318857253
2014-07-13 23:21:52,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318871818
2014-07-13 23:21:52,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318873517
2014-07-13 23:21:52,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318876294
2014-07-13 23:21:53,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:54,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318912104 with entries=62, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318913601
2014-07-13 23:21:55,533 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:55,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11367 synced till here 11356
2014-07-13 23:21:56,035 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318913601 with entries=77, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318915533
2014-07-13 23:21:56,281 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:21:56,710 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:56,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11439 synced till here 11434
2014-07-13 23:21:56,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318915533 with entries=72, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318916710
2014-07-13 23:21:58,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:58,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11520 synced till here 11513
2014-07-13 23:21:58,460 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318916710 with entries=81, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318918125
2014-07-13 23:21:59,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:21:59,639 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11621 synced till here 11599
2014-07-13 23:22:00,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318918125 with entries=101, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318919614
2014-07-13 23:22:01,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:01,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11722 synced till here 11712
2014-07-13 23:22:02,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318919614 with entries=101, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318921273
2014-07-13 23:22:03,051 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2601, memsize=208.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/6af32181696643da8cacecdf1dce6c8a
2014-07-13 23:22:03,097 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/6af32181696643da8cacecdf1dce6c8a as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6af32181696643da8cacecdf1dce6c8a
2014-07-13 23:22:03,988 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6af32181696643da8cacecdf1dce6c8a, entries=759740, sequenceid=2601, filesize=54.1m
2014-07-13 23:22:03,993 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~600.3m/629408880, currentsize=359.9m/377364080 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 15539ms, sequenceid=2601, compaction requested=true
2014-07-13 23:22:03,993 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-13 23:22:03,994 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 678.6m
2014-07-13 23:22:04,069 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:22:04,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:04,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11834 synced till here 11803
2014-07-13 23:22:04,312 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318921273 with entries=112, filesize=87.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318924085
2014-07-13 23:22:04,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318877984
2014-07-13 23:22:04,957 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:22:05,863 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:05,896 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11921 synced till here 11914
2014-07-13 23:22:05,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318924085 with entries=87, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318925863
2014-07-13 23:22:07,512 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:07,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11981 synced till here 11975
2014-07-13 23:22:07,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318925863 with entries=60, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318927512
2014-07-13 23:22:07,837 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2645, memsize=217.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/c50f1376c41e48d0aab8b6efe1e285ab
2014-07-13 23:22:07,861 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/c50f1376c41e48d0aab8b6efe1e285ab as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c50f1376c41e48d0aab8b6efe1e285ab
2014-07-13 23:22:07,889 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c50f1376c41e48d0aab8b6efe1e285ab, entries=792790, sequenceid=2645, filesize=56.5m
2014-07-13 23:22:07,891 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~658.9m/690927760, currentsize=369.6m/387527920 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 16179ms, sequenceid=2645, compaction requested=true
2014-07-13 23:22:07,892 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:23), split_queue=0, merge_queue=0
2014-07-13 23:22:07,892 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 363.2m
2014-07-13 23:22:07,975 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:22:08,335 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:08,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318927512 with entries=56, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318928336
2014-07-13 23:22:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318880281
2014-07-13 23:22:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318881558
2014-07-13 23:22:08,359 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318883110
2014-07-13 23:22:08,359 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318884854
2014-07-13 23:22:08,359 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318887225
2014-07-13 23:22:08,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318889230
2014-07-13 23:22:08,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318891146
2014-07-13 23:22:08,380 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:22:10,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:10,971 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12121 synced till here 12116
2014-07-13 23:22:11,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318928336 with entries=84, filesize=81.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318930131
2014-07-13 23:22:11,899 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:12,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12217 synced till here 12207
2014-07-13 23:22:12,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318930131 with entries=96, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318931900
2014-07-13 23:22:14,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:14,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12320 synced till here 12305
2014-07-13 23:22:14,665 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318931900 with entries=103, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318934279
2014-07-13 23:22:16,548 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:16,572 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12422 synced till here 12404
2014-07-13 23:22:16,751 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318934279 with entries=102, filesize=93.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318936549
2014-07-13 23:22:18,521 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:19,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12565 synced till here 12543
2014-07-13 23:22:19,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318936549 with entries=143, filesize=95.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318938522
2014-07-13 23:22:20,664 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:21,408 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12648 synced till here 12646
2014-07-13 23:22:21,437 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318938522 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318940665
2014-07-13 23:22:22,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:23,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12723 synced till here 12717
2014-07-13 23:22:23,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318940665 with entries=75, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318942322
2014-07-13 23:22:23,962 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:24,422 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12796 synced till here 12793
2014-07-13 23:22:24,469 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318942322 with entries=73, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318943962
2014-07-13 23:22:26,232 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3554, memsize=288.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/81ae3ba2ce0c48e78e80fd3c7a989317
2014-07-13 23:22:26,247 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/81ae3ba2ce0c48e78e80fd3c7a989317 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/81ae3ba2ce0c48e78e80fd3c7a989317
2014-07-13 23:22:26,258 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/81ae3ba2ce0c48e78e80fd3c7a989317, entries=1050570, sequenceid=3554, filesize=74.8m
2014-07-13 23:22:26,259 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~369.6m/387537680, currentsize=221.1m/231830640 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 18367ms, sequenceid=3554, compaction requested=false
2014-07-13 23:22:26,259 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 857.9m
2014-07-13 23:22:26,270 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:26,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12861 synced till here 12860
2014-07-13 23:22:26,312 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318943962 with entries=65, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318946270
2014-07-13 23:22:27,019 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:27,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12939 synced till here 12933
2014-07-13 23:22:27,632 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2796, memsize=326.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/0c71c006a37c4e149cad48f4876e143e
2014-07-13 23:22:27,648 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/0c71c006a37c4e149cad48f4876e143e as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c71c006a37c4e149cad48f4876e143e
2014-07-13 23:22:27,667 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318946270 with entries=78, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318947020
2014-07-13 23:22:27,667 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c71c006a37c4e149cad48f4876e143e, entries=1187950, sequenceid=2796, filesize=84.6m
2014-07-13 23:22:27,668 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~692.4m/726073520, currentsize=516.5m/541625040 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 23674ms, sequenceid=2796, compaction requested=true
2014-07-13 23:22:27,668 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:24), split_queue=0, merge_queue=0
2014-07-13 23:22:27,668 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 797.3m
2014-07-13 23:22:27,716 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:22:27,741 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:22:28,395 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:28,413 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:22:28,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13019 synced till here 13016
2014-07-13 23:22:28,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318947020 with entries=80, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318948396
2014-07-13 23:22:28,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318894168
2014-07-13 23:22:28,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318895988
2014-07-13 23:22:28,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318897524
2014-07-13 23:22:28,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318898965
2014-07-13 23:22:28,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318900373
2014-07-13 23:22:28,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318901990
2014-07-13 23:22:28,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318903597
2014-07-13 23:22:28,474 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318905591
2014-07-13 23:22:28,511 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:22:29,668 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:29,722 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13098 synced till here 13080
2014-07-13 23:22:29,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318948396 with entries=79, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318949669
2014-07-13 23:22:30,982 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:31,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13201 synced till here 13198
2014-07-13 23:22:31,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318949669 with entries=103, filesize=82.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318950983
2014-07-13 23:22:32,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:33,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13293 synced till here 13288
2014-07-13 23:22:33,987 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318950983 with entries=92, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318952747
2014-07-13 23:22:35,832 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:35,906 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13380 synced till here 13363
2014-07-13 23:22:36,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318952747 with entries=87, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318955832
2014-07-13 23:22:37,788 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:37,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13479 synced till here 13461
2014-07-13 23:22:37,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318955832 with entries=99, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318957789
2014-07-13 23:22:39,718 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:39,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13593 synced till here 13574
2014-07-13 23:22:39,897 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318957789 with entries=114, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318959718
2014-07-13 23:22:41,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:42,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13709 synced till here 13703
2014-07-13 23:22:42,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318959718 with entries=116, filesize=92.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318961528
2014-07-13 23:22:43,584 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:44,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13821 synced till here 13809
2014-07-13 23:22:45,023 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318961528 with entries=112, filesize=95.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318963585
2014-07-13 23:22:45,760 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:45,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318963585 with entries=90, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318965760
2014-07-13 23:22:47,601 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:47,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13999 synced till here 13986
2014-07-13 23:22:48,565 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318965760 with entries=88, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318967602
2014-07-13 23:22:48,864 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,865 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,927 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,929 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,929 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,929 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,930 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,932 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,941 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,987 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,988 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,988 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:48,990 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,000 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,001 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,008 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,012 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,013 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,014 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,026 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,085 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,122 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,176 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,176 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,176 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,177 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,178 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,178 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,236 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,282 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,389 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,389 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,440 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,469 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,508 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,514 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,551 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,551 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,553 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,553 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,751 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,805 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,805 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,832 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,858 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:49,999 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:50,005 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:50,068 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:50,109 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:50,142 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:22:50,417 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3029, memsize=319.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/43347ccbade744828f08237846a9b433
2014-07-13 23:22:50,431 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/43347ccbade744828f08237846a9b433 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/43347ccbade744828f08237846a9b433
2014-07-13 23:22:50,442 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/43347ccbade744828f08237846a9b433, entries=1163840, sequenceid=3029, filesize=82.9m
2014-07-13 23:22:50,443 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~802.0m/840906080, currentsize=453.0m/475043760 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 22774ms, sequenceid=3029, compaction requested=true
2014-07-13 23:22:50,443 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:25), split_queue=0, merge_queue=0
2014-07-13 23:22:50,443 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 301ms
2014-07-13 23:22:50,443 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,443 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 983.6m
2014-07-13 23:22:50,443 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 334ms
2014-07-13 23:22:50,443 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,444 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 377ms
2014-07-13 23:22:50,444 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,444 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 439ms
2014-07-13 23:22:50,444 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,444 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 445ms
2014-07-13 23:22:50,444 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,444 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 586ms
2014-07-13 23:22:50,444 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,445 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 613ms
2014-07-13 23:22:50,453 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,453 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 648ms
2014-07-13 23:22:50,453 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,454 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 650ms
2014-07-13 23:22:50,454 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,454 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 703ms
2014-07-13 23:22:50,454 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,455 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 902ms
2014-07-13 23:22:50,455 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,455 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 902ms
2014-07-13 23:22:50,455 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,456 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 905ms
2014-07-13 23:22:50,456 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,456 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 906ms
2014-07-13 23:22:50,456 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,460 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 946ms
2014-07-13 23:22:50,460 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,460 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 952ms
2014-07-13 23:22:50,460 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,460 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 991ms
2014-07-13 23:22:50,461 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,461 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1021ms
2014-07-13 23:22:50,461 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,461 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1072ms
2014-07-13 23:22:50,461 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,462 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1074ms
2014-07-13 23:22:50,462 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,468 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1186ms
2014-07-13 23:22:50,469 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,469 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1233ms
2014-07-13 23:22:50,469 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,477 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1299ms
2014-07-13 23:22:50,477 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,485 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1307ms
2014-07-13 23:22:50,486 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,493 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1317ms
2014-07-13 23:22:50,493 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,493 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1317ms
2014-07-13 23:22:50,493 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,493 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1317ms
2014-07-13 23:22:50,493 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,494 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1318ms
2014-07-13 23:22:50,494 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,494 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1372ms
2014-07-13 23:22:50,494 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,494 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1409ms
2014-07-13 23:22:50,494 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,495 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1469ms
2014-07-13 23:22:50,495 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,501 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1488ms
2014-07-13 23:22:50,501 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,501 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1488ms
2014-07-13 23:22:50,501 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,502 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1489ms
2014-07-13 23:22:50,502 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,502 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1494ms
2014-07-13 23:22:50,502 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,504 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1503ms
2014-07-13 23:22:50,505 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,505 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1505ms
2014-07-13 23:22:50,505 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,505 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1515ms
2014-07-13 23:22:50,505 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,507 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1518ms
2014-07-13 23:22:50,507 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,507 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1519ms
2014-07-13 23:22:50,507 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,517 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1530ms
2014-07-13 23:22:50,517 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,519 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1578ms
2014-07-13 23:22:50,519 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,519 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1587ms
2014-07-13 23:22:50,519 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,525 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1595ms
2014-07-13 23:22:50,525 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,525 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1596ms
2014-07-13 23:22:50,525 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,525 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1596ms
2014-07-13 23:22:50,525 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,533 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1606ms
2014-07-13 23:22:50,533 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,541 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1614ms
2014-07-13 23:22:50,541 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,541 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1677ms
2014-07-13 23:22:50,541 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:50,549 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1685ms
2014-07-13 23:22:50,549 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:22:51,718 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:51,733 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:22:51,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14126 synced till here 14108
2014-07-13 23:22:52,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318967602 with entries=127, filesize=103.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318971719
2014-07-13 23:22:52,217 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:22:53,864 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3013, memsize=377.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/e444f0c359ec479abdded80b02e8768b
2014-07-13 23:22:53,880 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/e444f0c359ec479abdded80b02e8768b as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e444f0c359ec479abdded80b02e8768b
2014-07-13 23:22:53,994 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:54,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14217 synced till here 14199
2014-07-13 23:22:54,089 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e444f0c359ec479abdded80b02e8768b, entries=1375300, sequenceid=3013, filesize=98.0m
2014-07-13 23:22:54,089 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~864.7m/906666240, currentsize=567.7m/595246800 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 27830ms, sequenceid=3013, compaction requested=true
2014-07-13 23:22:54,090 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-13 23:22:54,090 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 516.4m
2014-07-13 23:22:54,205 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:22:55,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318971719 with entries=91, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318973995
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318907379
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318909369
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318910791
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318912104
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318913601
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318915533
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318916710
2014-07-13 23:22:55,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318918125
2014-07-13 23:22:55,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318919614
2014-07-13 23:22:55,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318921273
2014-07-13 23:22:55,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:55,819 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:22:56,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14344 synced till here 14343
2014-07-13 23:22:56,098 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318973995 with entries=127, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318975723
2014-07-13 23:22:57,545 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:58,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14421 synced till here 14419
2014-07-13 23:22:58,085 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318975723 with entries=77, filesize=81.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318977546
2014-07-13 23:22:58,752 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:22:59,245 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14491 synced till here 14490
2014-07-13 23:22:59,265 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318977546 with entries=70, filesize=74.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318978752
2014-07-13 23:23:00,143 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:00,167 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14551 synced till here 14548
2014-07-13 23:23:00,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318978752 with entries=60, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318980143
2014-07-13 23:23:01,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:01,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14621 synced till here 14616
2014-07-13 23:23:01,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318980143 with entries=70, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318981276
2014-07-13 23:23:04,059 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:04,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318981276 with entries=58, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318984060
2014-07-13 23:23:05,657 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:05,670 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14750 synced till here 14740
2014-07-13 23:23:06,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318984060 with entries=71, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318985657
2014-07-13 23:23:07,074 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:07,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14831 synced till here 14827
2014-07-13 23:23:07,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318985657 with entries=81, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318987074
2014-07-13 23:23:08,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:08,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318987074 with entries=61, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318988387
2014-07-13 23:23:09,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:10,337 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14995 synced till here 14992
2014-07-13 23:23:10,380 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318988387 with entries=103, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318989759
2014-07-13 23:23:10,576 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,611 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,613 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,615 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,615 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,625 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,651 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,651 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,652 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,660 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,661 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,677 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,678 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,685 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,700 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,702 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,715 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,716 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,719 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,726 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,726 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,727 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,727 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,730 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,730 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,755 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,756 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,767 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,768 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,782 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,822 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,855 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,856 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,856 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,871 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,874 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,891 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,906 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,907 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,930 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,931 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,960 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:10,986 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,018 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,046 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,047 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,047 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,047 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,047 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,048 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:11,866 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4345, memsize=336.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/ea070eb81c1348a4882337b13d4c6479
2014-07-13 23:23:11,893 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/ea070eb81c1348a4882337b13d4c6479 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ea070eb81c1348a4882337b13d4c6479
2014-07-13 23:23:11,913 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ea070eb81c1348a4882337b13d4c6479, entries=1223780, sequenceid=4345, filesize=87.1m
2014-07-13 23:23:11,913 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~521.1m/546408560, currentsize=267.3m/280307920 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 17823ms, sequenceid=4345, compaction requested=true
2014-07-13 23:23:11,913 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-13 23:23:11,914 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 866ms
2014-07-13 23:23:11,914 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,914 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 910.3m
2014-07-13 23:23:11,914 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 867ms
2014-07-13 23:23:11,914 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,914 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 867ms
2014-07-13 23:23:11,914 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,915 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 868ms
2014-07-13 23:23:11,915 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,915 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 869ms
2014-07-13 23:23:11,915 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,915 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 869ms
2014-07-13 23:23:11,915 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,915 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 897ms
2014-07-13 23:23:11,915 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,916 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 930ms
2014-07-13 23:23:11,916 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,916 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 956ms
2014-07-13 23:23:11,916 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,916 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 985ms
2014-07-13 23:23:11,916 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,917 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 987ms
2014-07-13 23:23:11,917 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,919 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1012ms
2014-07-13 23:23:11,919 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,919 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1013ms
2014-07-13 23:23:11,919 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,919 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1028ms
2014-07-13 23:23:11,919 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,919 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1045ms
2014-07-13 23:23:11,920 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,920 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1049ms
2014-07-13 23:23:11,920 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,925 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1069ms
2014-07-13 23:23:11,925 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,925 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1069ms
2014-07-13 23:23:11,925 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,927 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1072ms
2014-07-13 23:23:11,927 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,927 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1105ms
2014-07-13 23:23:11,927 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,937 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1155ms
2014-07-13 23:23:11,937 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,937 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:23:11,945 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1177ms
2014-07-13 23:23:11,945 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,945 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1178ms
2014-07-13 23:23:11,945 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,945 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1190ms
2014-07-13 23:23:11,945 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,946 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1190ms
2014-07-13 23:23:11,946 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,949 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1219ms
2014-07-13 23:23:11,949 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,949 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1219ms
2014-07-13 23:23:11,949 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,951 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1224ms
2014-07-13 23:23:11,951 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,951 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1225ms
2014-07-13 23:23:11,951 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,952 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1226ms
2014-07-13 23:23:11,952 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,952 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1226ms
2014-07-13 23:23:11,952 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,952 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1233ms
2014-07-13 23:23:11,952 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,961 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1245ms
2014-07-13 23:23:11,961 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,961 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1246ms
2014-07-13 23:23:11,961 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,961 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1259ms
2014-07-13 23:23:11,961 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:11,963 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1263ms
2014-07-13 23:23:11,963 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,879 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2194ms
2014-07-13 23:23:12,879 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,880 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2202ms
2014-07-13 23:23:12,880 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,885 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2208ms
2014-07-13 23:23:12,885 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,885 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2225ms
2014-07-13 23:23:12,885 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,886 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2225ms
2014-07-13 23:23:12,886 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,887 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2234ms
2014-07-13 23:23:12,887 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,889 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2238ms
2014-07-13 23:23:12,889 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,889 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2238ms
2014-07-13 23:23:12,889 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,889 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2264ms
2014-07-13 23:23:12,889 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,889 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2274ms
2014-07-13 23:23:12,890 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,890 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2275ms
2014-07-13 23:23:12,890 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,893 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2280ms
2014-07-13 23:23:12,893 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,897 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2286ms
2014-07-13 23:23:12,897 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:12,897 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2321ms
2014-07-13 23:23:12,897 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:13,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:13,693 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:23:13,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15154 synced till here 15144
2014-07-13 23:23:14,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318989759 with entries=159, filesize=109.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318993424
2014-07-13 23:23:15,854 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:16,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15267 synced till here 15233
2014-07-13 23:23:16,943 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3271, memsize=385.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/a2b662b94683429989ba4f5884afb92e
2014-07-13 23:23:16,969 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/a2b662b94683429989ba4f5884afb92e as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/a2b662b94683429989ba4f5884afb92e
2014-07-13 23:23:17,030 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/a2b662b94683429989ba4f5884afb92e, entries=1404610, sequenceid=3271, filesize=100.0m
2014-07-13 23:23:17,031 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~983.6m/1031340800, currentsize=536.7m/562794240 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 26588ms, sequenceid=3271, compaction requested=true
2014-07-13 23:23:17,032 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:28), split_queue=0, merge_queue=0
2014-07-13 23:23:17,032 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1.0g
2014-07-13 23:23:17,093 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:23:17,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318993424 with entries=113, filesize=100.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318996682
2014-07-13 23:23:17,109 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318924085
2014-07-13 23:23:17,109 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318925863
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318927512
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318928336
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318930131
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318931900
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318934279
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318936549
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318938522
2014-07-13 23:23:17,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318940665
2014-07-13 23:23:17,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318942322
2014-07-13 23:23:17,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318943962
2014-07-13 23:23:18,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:19,189 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15456 synced till here 15424
2014-07-13 23:23:19,191 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:23:20,162 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318996682 with entries=189, filesize=130.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318998802
2014-07-13 23:23:20,972 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:20,997 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15576 synced till here 15565
2014-07-13 23:23:21,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318998802 with entries=120, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319000973
2014-07-13 23:23:22,531 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:22,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15670 synced till here 15663
2014-07-13 23:23:22,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319000973 with entries=94, filesize=80.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319002532
2014-07-13 23:23:24,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:24,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15736 synced till here 15731
2014-07-13 23:23:24,352 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319002532 with entries=66, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319004241
2014-07-13 23:23:25,683 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:25,702 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15807 synced till here 15801
2014-07-13 23:23:25,780 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319004241 with entries=71, filesize=75.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319005684
2014-07-13 23:23:27,213 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:27,659 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319005684 with entries=98, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319007214
2014-07-13 23:23:29,658 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:29,970 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15988 synced till here 15966
2014-07-13 23:23:30,266 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319007214 with entries=83, filesize=80.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319009659
2014-07-13 23:23:31,680 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,680 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,682 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,682 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,683 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,685 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,698 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,700 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,720 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,722 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,722 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,723 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,723 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,724 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,725 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,727 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,727 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,765 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,765 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,765 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,767 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,785 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,807 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,840 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,874 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:31,888 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,888 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,889 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,889 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,890 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,890 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,890 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,890 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,890 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,891 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,892 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16069 synced till here 16065
2014-07-13 23:23:31,912 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,923 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,925 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,946 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,946 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,947 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,955 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,956 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,961 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,966 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,966 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,966 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,966 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,966 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:23:31,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319009659 with entries=81, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319011884
2014-07-13 23:23:34,619 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1051ms
GC pool 'ParNew' had collection(s): count=1 time=1102ms
2014-07-13 23:23:36,680 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,681 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,682 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,682 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,683 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,685 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,698 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,700 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,720 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,722 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,722 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,723 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,723 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,724 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,725 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,727 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,727 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,765 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,766 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,766 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,768 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,785 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,807 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,840 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,875 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,888 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,889 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,889 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,890 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,890 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,890 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,891 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,891 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,891 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,892 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,893 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,912 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,924 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,925 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,946 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:23:36,947 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,948 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,956 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,956 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,962 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,966 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,967 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,967 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:23:36,967 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:23:36,967 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:23:41,081 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3492, memsize=452.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/b906c4f4571b4f67930e3376d120a0db
2014-07-13 23:23:41,106 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/b906c4f4571b4f67930e3376d120a0db as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b906c4f4571b4f67930e3376d120a0db
2014-07-13 23:23:41,124 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b906c4f4571b4f67930e3376d120a0db, entries=1648670, sequenceid=3492, filesize=117.5m
2014-07-13 23:23:41,124 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~910.3m/954528880, currentsize=421.4m/441882320 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 29210ms, sequenceid=3492, compaction requested=true
2014-07-13 23:23:41,125 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:29), split_queue=0, merge_queue=0
2014-07-13 23:23:41,125 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9160ms
2014-07-13 23:23:41,125 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 498.6m
2014-07-13 23:23:41,125 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,126 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9160ms
2014-07-13 23:23:41,126 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,126 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9160ms
2014-07-13 23:23:41,126 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,126 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9161ms
2014-07-13 23:23:41,126 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,129 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9164ms
2014-07-13 23:23:41,129 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,141 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9180ms
2014-07-13 23:23:41,141 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,141 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9186ms
2014-07-13 23:23:41,141 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,141 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9186ms
2014-07-13 23:23:41,141 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,142 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9195ms
2014-07-13 23:23:41,142 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,142 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9196ms
2014-07-13 23:23:41,143 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,147 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9201ms
2014-07-13 23:23:41,147 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,148 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9223ms
2014-07-13 23:23:41,148 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,151 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9228ms
2014-07-13 23:23:41,151 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,152 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9239ms
2014-07-13 23:23:41,152 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,157 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9265ms
2014-07-13 23:23:41,157 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,158 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9266ms
2014-07-13 23:23:41,158 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,166 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9275ms
2014-07-13 23:23:41,166 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,167 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9276ms
2014-07-13 23:23:41,167 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,168 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9277ms
2014-07-13 23:23:41,168 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,168 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9278ms
2014-07-13 23:23:41,168 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,169 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9279ms
2014-07-13 23:23:41,169 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,172 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9283ms
2014-07-13 23:23:41,172 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,173 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9283ms
2014-07-13 23:23:41,173 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,174 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9285ms
2014-07-13 23:23:41,174 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,183 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9295ms
2014-07-13 23:23:41,183 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,184 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9309ms
2014-07-13 23:23:41,184 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,185 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9344ms
2014-07-13 23:23:41,185 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,189 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9382ms
2014-07-13 23:23:41,189 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,190 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9404ms
2014-07-13 23:23:41,190 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,201 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9434ms
2014-07-13 23:23:41,201 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,201 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9436ms
2014-07-13 23:23:41,201 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,209 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9444ms
2014-07-13 23:23:41,210 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,210 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9446ms
2014-07-13 23:23:41,210 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,215 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9488ms
2014-07-13 23:23:41,215 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,215 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9489ms
2014-07-13 23:23:41,216 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,216 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9491ms
2014-07-13 23:23:41,216 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,216 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9492ms
2014-07-13 23:23:41,216 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,216 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9493ms
2014-07-13 23:23:41,216 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,217 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9494ms
2014-07-13 23:23:41,217 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,217 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9495ms
2014-07-13 23:23:41,217 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,217 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9495ms
2014-07-13 23:23:41,217 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,221 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9501ms
2014-07-13 23:23:41,221 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,222 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9521ms
2014-07-13 23:23:41,222 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,222 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9524ms
2014-07-13 23:23:41,222 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,224 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9539ms
2014-07-13 23:23:41,224 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,224 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9542ms
2014-07-13 23:23:41,224 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,231 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9549ms
2014-07-13 23:23:41,231 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,237 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9555ms
2014-07-13 23:23:41,237 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,237 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9557ms
2014-07-13 23:23:41,237 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:41,241 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9561ms
2014-07-13 23:23:41,241 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:23:42,467 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:23:42,525 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:23:42,526 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12207,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010319,"queuetimems":0,"class":"HRegionServer","responsesize":16818,"method":"Multi"}
2014-07-13 23:23:42,526 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12254,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010271,"queuetimems":0,"class":"HRegionServer","responsesize":18215,"method":"Multi"}
2014-07-13 23:23:42,716 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010009,"queuetimems":0,"class":"HRegionServer","responsesize":7058,"method":"Multi"}
2014-07-13 23:23:42,716 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319009901,"queuetimems":0,"class":"HRegionServer","responsesize":15922,"method":"Multi"}
2014-07-13 23:23:42,740 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12489,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010234,"queuetimems":0,"class":"HRegionServer","responsesize":17690,"method":"Multi"}
2014-07-13 23:23:42,740 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12779,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319009937,"queuetimems":0,"class":"HRegionServer","responsesize":17379,"method":"Multi"}
2014-07-13 23:23:42,740 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12735,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319009989,"queuetimems":0,"class":"HRegionServer","responsesize":17473,"method":"Multi"}
2014-07-13 23:23:42,745 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12622,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010095,"queuetimems":0,"class":"HRegionServer","responsesize":10866,"method":"Multi"}
2014-07-13 23:23:42,745 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010075,"queuetimems":0,"class":"HRegionServer","responsesize":10971,"method":"Multi"}
2014-07-13 23:23:42,754 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12599,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010125,"queuetimems":1,"class":"HRegionServer","responsesize":13215,"method":"Multi"}
2014-07-13 23:23:42,758 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12535,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010187,"queuetimems":0,"class":"HRegionServer","responsesize":7110,"method":"Multi"}
2014-07-13 23:23:42,759 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11060,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011657,"queuetimems":1,"class":"HRegionServer","responsesize":18579,"method":"Multi"}
2014-07-13 23:23:42,760 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12543,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010174,"queuetimems":0,"class":"HRegionServer","responsesize":16148,"method":"Multi"}
2014-07-13 23:23:42,759 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12660,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010056,"queuetimems":0,"class":"HRegionServer","responsesize":16594,"method":"Multi"}
2014-07-13 23:23:42,975 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:43,217 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16209 synced till here 16159
2014-07-13 23:23:43,262 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11338,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011923,"queuetimems":0,"class":"HRegionServer","responsesize":8134,"method":"Multi"}
2014-07-13 23:23:43,262 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12870,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010392,"queuetimems":0,"class":"HRegionServer","responsesize":2109,"method":"Multi"}
2014-07-13 23:23:43,450 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12904,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010545,"queuetimems":104,"class":"HRegionServer","responsesize":11801,"method":"Multi"}
2014-07-13 23:23:43,450 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13097,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010352,"queuetimems":0,"class":"HRegionServer","responsesize":15702,"method":"Multi"}
2014-07-13 23:23:43,452 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13036,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010416,"queuetimems":0,"class":"HRegionServer","responsesize":5153,"method":"Multi"}
2014-07-13 23:23:43,453 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010398,"queuetimems":0,"class":"HRegionServer","responsesize":3340,"method":"Multi"}
2014-07-13 23:23:43,454 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12883,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010570,"queuetimems":9,"class":"HRegionServer","responsesize":18637,"method":"Multi"}
2014-07-13 23:23:43,457 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12882,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010562,"queuetimems":44,"class":"HRegionServer","responsesize":18296,"method":"Multi"}
2014-07-13 23:23:43,463 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11887,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011575,"queuetimems":0,"class":"HRegionServer","responsesize":18537,"method":"Multi"}
2014-07-13 23:23:43,463 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13077,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010385,"queuetimems":0,"class":"HRegionServer","responsesize":17806,"method":"Multi"}
2014-07-13 23:23:43,464 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12918,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319010545,"queuetimems":69,"class":"HRegionServer","responsesize":18370,"method":"Multi"}
2014-07-13 23:23:44,242 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011909,"queuetimems":0,"class":"HRegionServer","responsesize":18537,"method":"Multi"}
2014-07-13 23:23:44,263 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319011884 with entries=140, filesize=105.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319022976
2014-07-13 23:23:44,481 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12519,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011961,"queuetimems":0,"class":"HRegionServer","responsesize":3340,"method":"Multi"}
2014-07-13 23:23:44,481 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011681,"queuetimems":0,"class":"HRegionServer","responsesize":8134,"method":"Multi"}
2014-07-13 23:23:44,701 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12981,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011719,"queuetimems":1,"class":"HRegionServer","responsesize":18844,"method":"Multi"}
2014-07-13 23:23:44,701 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12937,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011764,"queuetimems":0,"class":"HRegionServer","responsesize":18579,"method":"Multi"}
2014-07-13 23:23:44,702 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12747,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011955,"queuetimems":1,"class":"HRegionServer","responsesize":5153,"method":"Multi"}
2014-07-13 23:23:44,702 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12902,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011800,"queuetimems":0,"class":"HRegionServer","responsesize":18296,"method":"Multi"}
2014-07-13 23:23:44,703 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12757,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011945,"queuetimems":0,"class":"HRegionServer","responsesize":11801,"method":"Multi"}
2014-07-13 23:23:44,705 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12834,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011871,"queuetimems":0,"class":"HRegionServer","responsesize":18370,"method":"Multi"}
2014-07-13 23:23:44,710 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319011836,"queuetimems":0,"class":"HRegionServer","responsesize":18637,"method":"Multi"}
2014-07-13 23:23:45,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:45,219 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16337 synced till here 16309
2014-07-13 23:23:45,876 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319022976 with entries=128, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319025149
2014-07-13 23:23:47,933 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:48,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16492 synced till here 16464
2014-07-13 23:23:48,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319025149 with entries=155, filesize=123.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319027934
2014-07-13 23:23:49,891 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:50,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16625 synced till here 16613
2014-07-13 23:23:50,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319027934 with entries=133, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319029892
2014-07-13 23:23:50,327 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3548, memsize=495.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/1acffef0cefc42bfb2c29dba0eee9928
2014-07-13 23:23:50,345 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/1acffef0cefc42bfb2c29dba0eee9928 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/1acffef0cefc42bfb2c29dba0eee9928
2014-07-13 23:23:50,371 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/1acffef0cefc42bfb2c29dba0eee9928, entries=1802860, sequenceid=3548, filesize=128.4m
2014-07-13 23:23:50,372 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1090940720, currentsize=549.3m/575982960 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 33340ms, sequenceid=3548, compaction requested=true
2014-07-13 23:23:50,380 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:23:50,381 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-13 23:23:50,381 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.1g
2014-07-13 23:23:51,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:52,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16733 synced till here 16692
2014-07-13 23:23:52,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319029892 with entries=108, filesize=100.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319031980
2014-07-13 23:23:52,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318946270
2014-07-13 23:23:52,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318947020
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318948396
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318949669
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318950983
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318952747
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318955832
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318957789
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318959718
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318961528
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318963585
2014-07-13 23:23:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318965760
2014-07-13 23:23:53,823 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:23:53,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:54,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16863 synced till here 16855
2014-07-13 23:23:54,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319031980 with entries=130, filesize=85.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319033982
2014-07-13 23:23:55,449 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:55,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319033982 with entries=52, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319035484
2014-07-13 23:23:57,187 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:57,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319035484 with entries=92, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319037187
2014-07-13 23:23:58,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:23:58,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17102 synced till here 17101
2014-07-13 23:23:58,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319037187 with entries=95, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319038569
2014-07-13 23:23:59,743 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/06b69600c472428d8e1b08dbf540cc2b as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/06b69600c472428d8e1b08dbf540cc2b
2014-07-13 23:23:59,772 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:23:59,791 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/0fb07ffa5fef4930afa32da24bdd9131, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/0fb07ffa5fef4930afa32da24bdd9131
2014-07-13 23:23:59,794 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/bf9c8320819b49a18643ea0198ab3e5a, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/bf9c8320819b49a18643ea0198ab3e5a
2014-07-13 23:23:59,797 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/46b4c9f82a8c4d7bab8bf8a0d64d9642, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/46b4c9f82a8c4d7bab8bf8a0d64d9642
2014-07-13 23:23:59,800 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c39b150e820d43d393a57ab98c351f29, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c39b150e820d43d393a57ab98c351f29
2014-07-13 23:23:59,804 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ff0d8304060e4410a94debd673aabebb, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ff0d8304060e4410a94debd673aabebb
2014-07-13 23:23:59,807 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f0f414826f0a4b7b80b108d11b7fb5e6, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f0f414826f0a4b7b80b108d11b7fb5e6
2014-07-13 23:23:59,810 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/22961bc814534219bc718ab7b8d7df84, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/22961bc814534219bc718ab7b8d7df84
2014-07-13 23:23:59,816 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/35279e0e28844efba4ed8764ce46c424, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/35279e0e28844efba4ed8764ce46c424
2014-07-13 23:23:59,817 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed major compaction of 8 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into 06b69600c472428d8e1b08dbf540cc2b(size=625.3m), total size for store is 849.1m. This selection was in queue for 0sec, and took 2mins, 32sec to execute.
2014-07-13 23:23:59,817 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., storeName=family, fileCount=8, fileSize=645.9m, priority=12, time=272794795981226; duration=2mins, 32sec
2014-07-13 23:23:59,817 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-13 23:23:59,817 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-13 23:23:59,818 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 975859055 starting at candidate #0 after considering 36 permutations with 36 in ratio
2014-07-13 23:23:59,819 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 6935e08926c94c414c50c4e2b2667be2 - family: Initiating major compaction
2014-07-13 23:23:59,819 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:23:59,819 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp, totalSize=930.7m
2014-07-13 23:23:59,819 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/329fcbdeb16e47b3b2081afe57c49fb6, keycount=249990, bloomtype=ROW, size=178.0m, encoding=NONE, seqNum=909, earliestPutTs=1405318583890
2014-07-13 23:23:59,819 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/fe5a8aed256846e18487510bbec7c08b, keycount=156061, bloomtype=ROW, size=111.1m, encoding=NONE, seqNum=1210, earliestPutTs=1405318698891
2014-07-13 23:23:59,819 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/a40ffa295c844cb8946ddfd38568ae84, keycount=167804, bloomtype=ROW, size=119.4m, encoding=NONE, seqNum=1549, earliestPutTs=1405318726635
2014-07-13 23:23:59,820 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/122a2e4f325248eb9f2e2ffb8f86c879, keycount=93245, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=1712, earliestPutTs=1405318762410
2014-07-13 23:23:59,820 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e9dff5c0a12c4e00a7303f67c7ed6b45, keycount=94422, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=1976, earliestPutTs=1405318798899
2014-07-13 23:23:59,820 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/7f0f26e1bf1644d7b6f6bbbdc21ba5d6, keycount=97998, bloomtype=ROW, size=69.8m, encoding=NONE, seqNum=2152, earliestPutTs=1405318832413
2014-07-13 23:23:59,820 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/dcd6c20a5ade44748289a292e8ee72cb, keycount=86653, bloomtype=ROW, size=61.8m, encoding=NONE, seqNum=2306, earliestPutTs=1405318850354
2014-07-13 23:23:59,820 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c50f1376c41e48d0aab8b6efe1e285ab, keycount=79279, bloomtype=ROW, size=56.5m, encoding=NONE, seqNum=2645, earliestPutTs=1405318882010
2014-07-13 23:23:59,820 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/43347ccbade744828f08237846a9b433, keycount=116384, bloomtype=ROW, size=82.9m, encoding=NONE, seqNum=3029, earliestPutTs=1405318911922
2014-07-13 23:23:59,821 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b906c4f4571b4f67930e3376d120a0db, keycount=164867, bloomtype=ROW, size=117.5m, encoding=NONE, seqNum=3492, earliestPutTs=1405318947960
2014-07-13 23:23:59,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:00,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17175 synced till here 17172
2014-07-13 23:24:00,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319038569 with entries=73, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319039902
2014-07-13 23:24:00,328 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:24:01,233 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:01,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17262 synced till here 17260
2014-07-13 23:24:01,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319039902 with entries=87, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319041233
2014-07-13 23:24:02,683 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:02,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17327 synced till here 17325
2014-07-13 23:24:03,198 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319041233 with entries=65, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319042683
2014-07-13 23:24:03,771 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4944, memsize=392.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/45268bdf292f44118de2666e6bc0966c
2014-07-13 23:24:03,788 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/45268bdf292f44118de2666e6bc0966c as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/45268bdf292f44118de2666e6bc0966c
2014-07-13 23:24:03,850 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/45268bdf292f44118de2666e6bc0966c, entries=1428880, sequenceid=4944, filesize=101.8m
2014-07-13 23:24:03,850 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~498.6m/522824320, currentsize=300.5m/315123440 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 22725ms, sequenceid=4944, compaction requested=true
2014-07-13 23:24:03,850 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-13 23:24:03,851 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 954.3m
2014-07-13 23:24:03,874 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:24:04,059 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:04,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17400 synced till here 17398
2014-07-13 23:24:04,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319042683 with entries=73, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319044059
2014-07-13 23:24:05,149 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:24:05,609 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:06,205 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17479 synced till here 17478
2014-07-13 23:24:06,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319044059 with entries=79, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319045609
2014-07-13 23:24:07,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:07,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17550 synced till here 17543
2014-07-13 23:24:07,638 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319045609 with entries=71, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319047142
2014-07-13 23:24:08,515 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:08,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17668 synced till here 17665
2014-07-13 23:24:08,970 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319047142 with entries=118, filesize=74.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319048515
2014-07-13 23:24:09,503 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,518 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,519 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,520 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,520 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,521 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,552 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,552 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,554 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,555 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,556 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,556 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,556 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,557 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,583 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,624 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,626 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,628 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,672 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,711 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,711 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,712 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,738 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,775 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,787 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,790 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,803 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,830 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,947 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,950 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,955 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,962 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,989 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:09,991 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,007 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,059 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,095 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,765 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,774 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,796 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,816 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,851 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,853 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,859 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,890 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,892 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,898 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,900 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,900 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:10,901 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:14,850 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5020ms
2014-07-13 23:24:14,851 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5140ms
2014-07-13 23:24:14,851 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5268ms
2014-07-13 23:24:14,852 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5299ms
2014-07-13 23:24:14,852 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5141ms
2014-07-13 23:24:14,852 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5141ms
2014-07-13 23:24:14,853 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5115ms
2014-07-13 23:24:14,853 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-13 23:24:14,855 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-13 23:24:14,856 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5052ms
2014-07-13 23:24:14,856 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5069ms
2014-07-13 23:24:14,856 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5338ms
2014-07-13 23:24:14,857 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5354ms
2014-07-13 23:24:14,858 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5338ms
2014-07-13 23:24:14,858 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5337ms
2014-07-13 23:24:14,859 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5339ms
2014-07-13 23:24:14,859 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5339ms
2014-07-13 23:24:14,859 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5307ms
2014-07-13 23:24:14,860 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5305ms
2014-07-13 23:24:14,860 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5306ms
2014-07-13 23:24:14,860 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5304ms
2014-07-13 23:24:14,861 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5304ms
2014-07-13 23:24:14,861 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5305ms
2014-07-13 23:24:14,861 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5304ms
2014-07-13 23:24:14,861 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5238ms
2014-07-13 23:24:14,861 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5235ms
2014-07-13 23:24:14,862 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5189ms
2014-07-13 23:24:14,862 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5234ms
2014-07-13 23:24:14,948 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:14,950 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:14,955 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:14,962 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:14,989 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:14,992 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,007 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,059 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:24:15,096 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,766 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:24:15,775 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:24:15,797 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:24:15,816 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,852 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:24:15,853 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,859 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,890 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,893 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,899 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:24:15,900 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,901 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:15,901 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:24:16,889 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3875, memsize=451.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/40daeef5cbea4d0d8b446fee12020d12
2014-07-13 23:24:16,902 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/40daeef5cbea4d0d8b446fee12020d12 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/40daeef5cbea4d0d8b446fee12020d12
2014-07-13 23:24:16,914 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/40daeef5cbea4d0d8b446fee12020d12, entries=1644080, sequenceid=3875, filesize=117.1m
2014-07-13 23:24:16,915 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1207065040, currentsize=400.4m/419842080 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 26534ms, sequenceid=3875, compaction requested=true
2014-07-13 23:24:16,915 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:31), split_queue=0, merge_queue=0
2014-07-13 23:24:16,916 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6015ms
2014-07-13 23:24:16,916 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,916 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1009.5m
2014-07-13 23:24:16,916 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6016ms
2014-07-13 23:24:16,916 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,916 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6016ms
2014-07-13 23:24:16,916 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,917 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6019ms
2014-07-13 23:24:16,917 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,917 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6025ms
2014-07-13 23:24:16,917 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,917 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6027ms
2014-07-13 23:24:16,917 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,917 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6058ms
2014-07-13 23:24:16,917 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,918 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6065ms
2014-07-13 23:24:16,918 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,921 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6070ms
2014-07-13 23:24:16,921 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,926 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6110ms
2014-07-13 23:24:16,926 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,929 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6133ms
2014-07-13 23:24:16,929 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,931 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6157ms
2014-07-13 23:24:16,931 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,931 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6166ms
2014-07-13 23:24:16,931 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,931 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6836ms
2014-07-13 23:24:16,932 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,932 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6874ms
2014-07-13 23:24:16,932 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,933 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6925ms
2014-07-13 23:24:16,933 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,933 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6942ms
2014-07-13 23:24:16,933 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,934 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6945ms
2014-07-13 23:24:16,934 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,935 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6973ms
2014-07-13 23:24:16,935 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,936 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6980ms
2014-07-13 23:24:16,936 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,936 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6986ms
2014-07-13 23:24:16,936 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,937 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6989ms
2014-07-13 23:24:16,937 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,939 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7310ms
2014-07-13 23:24:16,939 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,939 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7267ms
2014-07-13 23:24:16,939 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,941 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7314ms
2014-07-13 23:24:16,941 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,942 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7318ms
2014-07-13 23:24:16,942 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,945 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7387ms
2014-07-13 23:24:16,945 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,947 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7389ms
2014-07-13 23:24:16,947 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,947 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7391ms
2014-07-13 23:24:16,947 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,952 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7395ms
2014-07-13 23:24:16,952 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,954 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7399ms
2014-07-13 23:24:16,954 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,966 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7411ms
2014-07-13 23:24:16,966 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,969 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7417ms
2014-07-13 23:24:16,969 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,971 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7450ms
2014-07-13 23:24:16,971 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,977 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7458ms
2014-07-13 23:24:16,977 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,978 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7456ms
2014-07-13 23:24:16,978 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,980 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7461ms
2014-07-13 23:24:16,980 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,981 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7477ms
2014-07-13 23:24:16,981 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:16,982 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7463ms
2014-07-13 23:24:16,982 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,037 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7196ms
2014-07-13 23:24:17,037 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,037 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7234ms
2014-07-13 23:24:17,037 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,037 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7262ms
2014-07-13 23:24:17,038 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,046 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7255ms
2014-07-13 23:24:17,046 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,046 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7308ms
2014-07-13 23:24:17,046 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,053 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7342ms
2014-07-13 23:24:17,053 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:24:17,053 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,053 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7342ms
2014-07-13 23:24:17,053 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,053 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7501ms
2014-07-13 23:24:17,053 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,054 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7470ms
2014-07-13 23:24:17,054 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,057 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7347ms
2014-07-13 23:24:17,057 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,065 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7235ms
2014-07-13 23:24:17,065 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:17,255 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:18,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17796 synced till here 17794
2014-07-13 23:24:18,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319048515 with entries=128, filesize=92.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319057255
2014-07-13 23:24:18,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318967602
2014-07-13 23:24:18,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318971719
2014-07-13 23:24:18,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318973995
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318975723
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318977546
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318978752
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318980143
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318981276
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318984060
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318985657
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318987074
2014-07-13 23:24:18,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318988387
2014-07-13 23:24:18,936 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:24:20,000 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:20,003 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10266,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049737,"queuetimems":0,"class":"HRegionServer","responsesize":10107,"method":"Multi"}
2014-07-13 23:24:20,009 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049621,"queuetimems":0,"class":"HRegionServer","responsesize":15571,"method":"Multi"}
2014-07-13 23:24:20,017 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10349,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049668,"queuetimems":0,"class":"HRegionServer","responsesize":18354,"method":"Multi"}
2014-07-13 23:24:20,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17909 synced till here 17871
2014-07-13 23:24:20,265 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10747,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049517,"queuetimems":0,"class":"HRegionServer","responsesize":11867,"method":"Multi"}
2014-07-13 23:24:20,265 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10555,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049709,"queuetimems":1,"class":"HRegionServer","responsesize":18353,"method":"Multi"}
2014-07-13 23:24:20,277 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10330,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049947,"queuetimems":1,"class":"HRegionServer","responsesize":18647,"method":"Multi"}
2014-07-13 23:24:20,277 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10185,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319050092,"queuetimems":0,"class":"HRegionServer","responsesize":15952,"method":"Multi"}
2014-07-13 23:24:20,281 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319050055,"queuetimems":0,"class":"HRegionServer","responsesize":18238,"method":"Multi"}
2014-07-13 23:24:20,301 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049989,"queuetimems":0,"class":"HRegionServer","responsesize":15348,"method":"Multi"}
2014-07-13 23:24:20,309 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10730,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049579,"queuetimems":0,"class":"HRegionServer","responsesize":17648,"method":"Multi"}
2014-07-13 23:24:20,281 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10509,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319049772,"queuetimems":1,"class":"HRegionServer","responsesize":18358,"method":"Multi"}
2014-07-13 23:24:20,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319057255 with entries=113, filesize=99.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319060001
2014-07-13 23:24:20,954 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10181,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319050772,"queuetimems":0,"class":"HRegionServer","responsesize":15849,"method":"Multi"}
2014-07-13 23:24:21,829 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:22,058 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18036 synced till here 17990
2014-07-13 23:24:22,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319060001 with entries=127, filesize=115.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319061829
2014-07-13 23:24:23,525 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.41 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=92199, hits=25159, hitRatio=27.28%, , cachingAccesses=25173, cachingHits=25149, cachingHitsRatio=99.90%, evictions=0, evicted=20, evictedPerRun=Infinity
2014-07-13 23:24:24,248 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:24,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18149 synced till here 18128
2014-07-13 23:24:24,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319061829 with entries=113, filesize=96.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319064248
2014-07-13 23:24:26,037 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4008, memsize=322.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/6a490cbbe6df4a2d99043a4e818dde56
2014-07-13 23:24:26,072 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/6a490cbbe6df4a2d99043a4e818dde56 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6a490cbbe6df4a2d99043a4e818dde56
2014-07-13 23:24:26,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:26,276 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6a490cbbe6df4a2d99043a4e818dde56, entries=1173950, sequenceid=4008, filesize=83.6m
2014-07-13 23:24:26,277 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~965.6m/1012537760, currentsize=336.1m/352441360 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 22426ms, sequenceid=4008, compaction requested=false
2014-07-13 23:24:26,277 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 546.5m
2014-07-13 23:24:26,284 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18265 synced till here 18227
2014-07-13 23:24:26,409 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:24:27,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319064248 with entries=116, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319066162
2014-07-13 23:24:27,444 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318989759
2014-07-13 23:24:27,444 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318993424
2014-07-13 23:24:28,359 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:24:28,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:28,633 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18371 synced till here 18359
2014-07-13 23:24:29,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319066162 with entries=106, filesize=94.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319068618
2014-07-13 23:24:30,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:30,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18471 synced till here 18450
2014-07-13 23:24:30,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319068618 with entries=100, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319070019
2014-07-13 23:24:31,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:32,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18570 synced till here 18567
2014-07-13 23:24:32,139 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319070019 with entries=99, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319071490
2014-07-13 23:24:33,429 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:33,452 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18635 synced till here 18634
2014-07-13 23:24:33,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319071490 with entries=65, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319073429
2014-07-13 23:24:34,898 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:35,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18722 synced till here 18719
2014-07-13 23:24:35,559 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319073429 with entries=87, filesize=82.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319074898
2014-07-13 23:24:36,347 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:36,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18800 synced till here 18796
2014-07-13 23:24:36,406 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319074898 with entries=78, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319076348
2014-07-13 23:24:38,152 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:38,172 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18867 synced till here 18865
2014-07-13 23:24:38,191 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319076348 with entries=67, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319078153
2014-07-13 23:24:39,614 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:39,798 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18939 synced till here 18938
2014-07-13 23:24:39,814 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319078153 with entries=72, filesize=73.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319079615
2014-07-13 23:24:41,238 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:41,259 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19024 synced till here 19016
2014-07-13 23:24:41,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319079615 with entries=85, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319081238
2014-07-13 23:24:42,534 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,536 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,538 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,539 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,564 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,616 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,648 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,673 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,688 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,696 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,707 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,778 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,780 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,845 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:42,969 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,039 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,042 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,059 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,124 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,187 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,195 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,198 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,198 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,242 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5725, memsize=291.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/47c85b5121cf40f48b6e880b2c4bc3b3
2014-07-13 23:24:43,242 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,244 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,260 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/47c85b5121cf40f48b6e880b2c4bc3b3 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/47c85b5121cf40f48b6e880b2c4bc3b3
2014-07-13 23:24:43,295 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,302 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:24:43,340 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/47c85b5121cf40f48b6e880b2c4bc3b3, entries=1059610, sequenceid=5725, filesize=75.5m
2014-07-13 23:24:43,340 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~558.1m/585231360, currentsize=246.8m/258760800 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 17063ms, sequenceid=5725, compaction requested=true
2014-07-13 23:24:43,341 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:32), split_queue=0, merge_queue=0
2014-07-13 23:24:43,341 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 39ms
2014-07-13 23:24:43,341 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,341 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 970.9m
2014-07-13 23:24:43,341 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 46ms
2014-07-13 23:24:43,341 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,342 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 98ms
2014-07-13 23:24:43,342 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,342 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 100ms
2014-07-13 23:24:43,342 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,342 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 144ms
2014-07-13 23:24:43,342 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,342 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 145ms
2014-07-13 23:24:43,342 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,343 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 148ms
2014-07-13 23:24:43,343 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,343 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 157ms
2014-07-13 23:24:43,343 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,343 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 219ms
2014-07-13 23:24:43,343 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,348 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 284ms
2014-07-13 23:24:43,350 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,350 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 308ms
2014-07-13 23:24:43,350 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,351 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 312ms
2014-07-13 23:24:43,351 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,351 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 382ms
2014-07-13 23:24:43,351 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,351 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 506ms
2014-07-13 23:24:43,351 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,351 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 572ms
2014-07-13 23:24:43,351 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,357 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 579ms
2014-07-13 23:24:43,357 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,357 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 650ms
2014-07-13 23:24:43,357 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,357 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 661ms
2014-07-13 23:24:43,358 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,358 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 670ms
2014-07-13 23:24:43,358 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,361 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 689ms
2014-07-13 23:24:43,361 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,361 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 714ms
2014-07-13 23:24:43,361 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,369 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 753ms
2014-07-13 23:24:43,369 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,369 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 805ms
2014-07-13 23:24:43,369 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,377 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 838ms
2014-07-13 23:24:43,377 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,377 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 839ms
2014-07-13 23:24:43,377 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,377 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 841ms
2014-07-13 23:24:43,377 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:43,381 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 847ms
2014-07-13 23:24:43,381 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:24:44,333 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:44,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19149 synced till here 19130
2014-07-13 23:24:44,475 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:24:44,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319081238 with entries=125, filesize=85.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319084334
2014-07-13 23:24:45,097 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:24:46,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:46,419 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4079, memsize=416.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/be5aedfee822485b9c21b35a80e0342c
2014-07-13 23:24:46,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19243 synced till here 19227
2014-07-13 23:24:46,443 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/be5aedfee822485b9c21b35a80e0342c as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/be5aedfee822485b9c21b35a80e0342c
2014-07-13 23:24:46,483 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/be5aedfee822485b9c21b35a80e0342c, entries=1515530, sequenceid=4079, filesize=107.9m
2014-07-13 23:24:46,483 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1009.5m/1058533200, currentsize=629.1m/659703280 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 29567ms, sequenceid=4079, compaction requested=true
2014-07-13 23:24:46,484 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:33), split_queue=0, merge_queue=0
2014-07-13 23:24:46,484 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 755.6m
2014-07-13 23:24:46,514 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:24:46,538 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319084334 with entries=94, filesize=86.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319086364
2014-07-13 23:24:46,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318996682
2014-07-13 23:24:46,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405318998802
2014-07-13 23:24:46,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319000973
2014-07-13 23:24:46,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319002532
2014-07-13 23:24:46,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319004241
2014-07-13 23:24:46,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319005684
2014-07-13 23:24:46,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319007214
2014-07-13 23:24:46,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319009659
2014-07-13 23:24:46,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319011884
2014-07-13 23:24:46,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319022976
2014-07-13 23:24:46,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319025149
2014-07-13 23:24:46,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319027934
2014-07-13 23:24:47,387 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:24:47,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:47,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19301 synced till here 19300
2014-07-13 23:24:47,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319086364 with entries=58, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319087883
2014-07-13 23:24:48,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:49,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319087883 with entries=67, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319088798
2014-07-13 23:24:50,012 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:50,042 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319088798 with entries=61, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319090012
2014-07-13 23:24:51,632 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:51,655 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19490 synced till here 19489
2014-07-13 23:24:51,664 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319090012 with entries=61, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319091632
2014-07-13 23:24:52,899 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:53,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19579 synced till here 19577
2014-07-13 23:24:53,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319091632 with entries=89, filesize=80.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319092900
2014-07-13 23:24:54,507 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:54,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19651 synced till here 19650
2014-07-13 23:24:55,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319092900 with entries=72, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319094508
2014-07-13 23:24:56,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:56,311 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19745 synced till here 19730
2014-07-13 23:24:56,396 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319094508 with entries=94, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319096222
2014-07-13 23:24:57,777 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:24:58,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19861 synced till here 19857
2014-07-13 23:24:59,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319096222 with entries=116, filesize=106.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319097778
2014-07-13 23:25:00,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:01,167 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19951 synced till here 19946
2014-07-13 23:25:01,281 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319097778 with entries=90, filesize=92.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319100848
2014-07-13 23:25:02,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:02,685 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,685 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20039 synced till here 20034
2014-07-13 23:25:02,748 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,751 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319100848 with entries=88, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319102676
2014-07-13 23:25:02,767 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,767 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,772 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,773 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,773 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,838 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,846 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,850 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,850 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,874 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,876 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,883 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,890 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,901 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,913 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,914 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,997 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:02,999 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,002 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,006 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,007 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,056 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,083 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,084 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,086 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,088 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,122 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,158 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,158 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,159 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,159 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,160 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,163 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,164 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,164 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,164 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,168 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,169 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,169 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,170 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,172 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,173 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,173 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,920 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,920 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:03,921 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:06,424 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4403, memsize=364.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4cef371056b847b996708d6bbbd17ccb
2014-07-13 23:25:06,441 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4cef371056b847b996708d6bbbd17ccb as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4cef371056b847b996708d6bbbd17ccb
2014-07-13 23:25:06,453 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4cef371056b847b996708d6bbbd17ccb, entries=1326280, sequenceid=4403, filesize=94.5m
2014-07-13 23:25:06,453 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~776.4m/814080720, currentsize=358.7m/376174560 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 19969ms, sequenceid=4403, compaction requested=false
2014-07-13 23:25:06,454 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2533ms
2014-07-13 23:25:06,454 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,454 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2534ms
2014-07-13 23:25:06,454 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 549.7m
2014-07-13 23:25:06,454 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,455 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2535ms
2014-07-13 23:25:06,455 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,455 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3282ms
2014-07-13 23:25:06,455 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,456 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3282ms
2014-07-13 23:25:06,456 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,456 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3284ms
2014-07-13 23:25:06,456 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,456 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3287ms
2014-07-13 23:25:06,456 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,461 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3291ms
2014-07-13 23:25:06,461 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,461 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3292ms
2014-07-13 23:25:06,461 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,461 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3293ms
2014-07-13 23:25:06,461 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,462 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3298ms
2014-07-13 23:25:06,462 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,463 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3299ms
2014-07-13 23:25:06,463 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,463 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3299ms
2014-07-13 23:25:06,463 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,464 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3300ms
2014-07-13 23:25:06,464 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,465 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3304ms
2014-07-13 23:25:06,465 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,465 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3307ms
2014-07-13 23:25:06,465 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,465 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3307ms
2014-07-13 23:25:06,465 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,466 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3307ms
2014-07-13 23:25:06,466 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,467 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3309ms
2014-07-13 23:25:06,467 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,468 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3345ms
2014-07-13 23:25:06,468 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,468 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3380ms
2014-07-13 23:25:06,468 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,469 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3382ms
2014-07-13 23:25:06,469 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,469 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3385ms
2014-07-13 23:25:06,469 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,471 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3387ms
2014-07-13 23:25:06,471 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,471 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3416ms
2014-07-13 23:25:06,471 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,471 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3464ms
2014-07-13 23:25:06,471 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,478 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3472ms
2014-07-13 23:25:06,479 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,480 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3477ms
2014-07-13 23:25:06,480 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,480 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3481ms
2014-07-13 23:25:06,480 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,481 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3483ms
2014-07-13 23:25:06,481 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,481 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3567ms
2014-07-13 23:25:06,481 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,482 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3569ms
2014-07-13 23:25:06,482 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,482 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3581ms
2014-07-13 23:25:06,482 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,485 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3595ms
2014-07-13 23:25:06,485 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,485 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3602ms
2014-07-13 23:25:06,485 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,486 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3610ms
2014-07-13 23:25:06,486 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,492 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3618ms
2014-07-13 23:25:06,492 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,492 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3642ms
2014-07-13 23:25:06,492 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,493 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3643ms
2014-07-13 23:25:06,493 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,498 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3652ms
2014-07-13 23:25:06,498 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,505 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3667ms
2014-07-13 23:25:06,505 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,513 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3740ms
2014-07-13 23:25:06,513 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,513 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3741ms
2014-07-13 23:25:06,513 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,514 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3742ms
2014-07-13 23:25:06,514 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,514 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3747ms
2014-07-13 23:25:06,514 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,514 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3748ms
2014-07-13 23:25:06,514 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,514 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3763ms
2014-07-13 23:25:06,515 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,517 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3769ms
2014-07-13 23:25:06,517 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,517 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3832ms
2014-07-13 23:25:06,517 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:06,524 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3839ms
2014-07-13 23:25:06,524 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:07,665 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:25:08,000 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:25:08,254 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:08,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20156 synced till here 20133
2014-07-13 23:25:09,533 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319102676 with entries=117, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319108255
2014-07-13 23:25:11,700 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:11,787 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20266 synced till here 20222
2014-07-13 23:25:12,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319108255 with entries=110, filesize=105.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319111700
2014-07-13 23:25:14,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:14,150 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20364 synced till here 20346
2014-07-13 23:25:14,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319111700 with entries=98, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319114063
2014-07-13 23:25:16,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:16,730 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20483 synced till here 20461
2014-07-13 23:25:18,070 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319114063 with entries=119, filesize=122.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319116488
2014-07-13 23:25:18,514 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,515 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,516 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,517 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,517 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,517 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,519 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,519 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,520 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,520 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4377, memsize=511.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/1e3e400cda0d4b609c99d9737c1177c6
2014-07-13 23:25:18,520 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,521 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,521 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,521 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,522 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,522 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,522 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,523 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,524 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,525 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,526 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,527 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,527 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,527 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,529 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,529 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,530 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,530 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,530 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,530 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,532 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,532 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,533 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,534 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,535 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,535 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,536 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,536 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,536 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,536 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,537 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,541 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,541 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/1e3e400cda0d4b609c99d9737c1177c6 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1e3e400cda0d4b609c99d9737c1177c6
2014-07-13 23:25:18,542 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,542 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,545 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:18,557 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1e3e400cda0d4b609c99d9737c1177c6, entries=1862190, sequenceid=4377, filesize=132.7m
2014-07-13 23:25:18,557 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~970.9m/1018044240, currentsize=673.3m/705957200 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 35216ms, sequenceid=4377, compaction requested=true
2014-07-13 23:25:18,558 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:34), split_queue=0, merge_queue=0
2014-07-13 23:25:18,558 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13ms
2014-07-13 23:25:18,558 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,558 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16ms
2014-07-13 23:25:18,558 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,558 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1.2g
2014-07-13 23:25:18,558 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16ms
2014-07-13 23:25:18,558 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,558 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17ms
2014-07-13 23:25:18,558 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,559 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22ms
2014-07-13 23:25:18,559 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,559 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23ms
2014-07-13 23:25:18,559 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,559 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 29ms
2014-07-13 23:25:18,559 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,559 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23ms
2014-07-13 23:25:18,559 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,559 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 29ms
2014-07-13 23:25:18,559 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,559 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27ms
2014-07-13 23:25:18,560 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,561 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36ms
2014-07-13 23:25:18,561 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,561 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27ms
2014-07-13 23:25:18,562 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,563 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30ms
2014-07-13 23:25:18,563 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,563 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31ms
2014-07-13 23:25:18,563 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,565 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 33ms
2014-07-13 23:25:18,565 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,565 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 35ms
2014-07-13 23:25:18,565 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,566 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36ms
2014-07-13 23:25:18,566 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,566 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36ms
2014-07-13 23:25:18,567 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,567 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 37ms
2014-07-13 23:25:18,567 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,567 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38ms
2014-07-13 23:25:18,567 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,569 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 40ms
2014-07-13 23:25:18,569 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,577 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 50ms
2014-07-13 23:25:18,577 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,577 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 50ms
2014-07-13 23:25:18,577 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,585 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 59ms
2014-07-13 23:25:18,585 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,585 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 59ms
2014-07-13 23:25:18,585 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,585 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 60ms
2014-07-13 23:25:18,585 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,585 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 61ms
2014-07-13 23:25:18,585 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,585 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 62ms
2014-07-13 23:25:18,585 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,586 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 64ms
2014-07-13 23:25:18,586 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,586 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 64ms
2014-07-13 23:25:18,586 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,586 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 64ms
2014-07-13 23:25:18,586 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,586 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 65ms
2014-07-13 23:25:18,586 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,586 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 65ms
2014-07-13 23:25:18,586 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,589 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 69ms
2014-07-13 23:25:18,589 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,591 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 71ms
2014-07-13 23:25:18,591 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,597 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 77ms
2014-07-13 23:25:18,597 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,597 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 78ms
2014-07-13 23:25:18,597 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,597 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 79ms
2014-07-13 23:25:18,597 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,600 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 84ms
2014-07-13 23:25:18,600 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,602 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 85ms
2014-07-13 23:25:18,602 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,602 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 85ms
2014-07-13 23:25:18,602 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,602 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 86ms
2014-07-13 23:25:18,602 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,602 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 87ms
2014-07-13 23:25:18,602 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:18,613 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 99ms
2014-07-13 23:25:18,613 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:19,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:19,079 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:25:19,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20605 synced till here 20594
2014-07-13 23:25:19,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319116488 with entries=122, filesize=92.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319119079
2014-07-13 23:25:19,971 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319029892
2014-07-13 23:25:19,971 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319031980
2014-07-13 23:25:20,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319033982
2014-07-13 23:25:20,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319035484
2014-07-13 23:25:20,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319037187
2014-07-13 23:25:20,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319038569
2014-07-13 23:25:20,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319039902
2014-07-13 23:25:20,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319041233
2014-07-13 23:25:20,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319042683
2014-07-13 23:25:20,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319044059
2014-07-13 23:25:20,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319045609
2014-07-13 23:25:20,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319047142
2014-07-13 23:25:20,748 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:20,830 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:25:20,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20700 synced till here 20673
2014-07-13 23:25:21,050 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319119079 with entries=95, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319120748
2014-07-13 23:25:22,456 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:22,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20801 synced till here 20799
2014-07-13 23:25:22,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319120748 with entries=101, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319122457
2014-07-13 23:25:24,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:24,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20891 synced till here 20890
2014-07-13 23:25:24,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319122457 with entries=90, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319124161
2014-07-13 23:25:26,048 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:26,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20968 synced till here 20958
2014-07-13 23:25:26,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319124161 with entries=77, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319126048
2014-07-13 23:25:28,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:28,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21058 synced till here 21050
2014-07-13 23:25:28,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319126048 with entries=90, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319128561
2014-07-13 23:25:30,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:30,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21150 synced till here 21135
2014-07-13 23:25:30,509 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319128561 with entries=92, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319130288
2014-07-13 23:25:30,669 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,672 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,689 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,689 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,689 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,691 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,691 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,699 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,699 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,699 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,699 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,702 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,778 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,778 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,784 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,785 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,786 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,786 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,786 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,787 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,787 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,790 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,790 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,790 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,791 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,795 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,797 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,797 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,797 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,798 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,798 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,801 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,804 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,805 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,814 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,825 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,907 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,907 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,913 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,937 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,953 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,954 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:30,954 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:31,073 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:31,113 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:31,188 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:31,188 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:31,221 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:31,254 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:31,266 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:35,670 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,672 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,689 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,690 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,690 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,691 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,692 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-13 23:25:35,699 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,699 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,700 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,700 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,702 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,778 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,779 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,784 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,786 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,786 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,786 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,787 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,788 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,788 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,790 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,790 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,791 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,791 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,795 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,797 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,797 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,798 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,798 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,799 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,802 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,805 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,805 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,815 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,825 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,907 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,907 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,913 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,937 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:35,954 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,955 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:35,955 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:36,073 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:36,113 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:36,189 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:36,189 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:36,221 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:36,254 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:36,266 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:36,735 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6379, memsize=501.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/5cebceae75314960948b68aeafc83097
2014-07-13 23:25:36,761 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/5cebceae75314960948b68aeafc83097 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5cebceae75314960948b68aeafc83097
2014-07-13 23:25:36,783 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5cebceae75314960948b68aeafc83097, entries=1825620, sequenceid=6379, filesize=130.0m
2014-07-13 23:25:36,784 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~549.7m/576409360, currentsize=252.4m/264646160 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 30330ms, sequenceid=6379, compaction requested=true
2014-07-13 23:25:36,784 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:35), split_queue=0, merge_queue=0
2014-07-13 23:25:36,784 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5518ms
2014-07-13 23:25:36,784 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,784 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5530ms
2014-07-13 23:25:36,784 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 852.0m
2014-07-13 23:25:36,784 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,785 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5564ms
2014-07-13 23:25:36,785 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,789 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5601ms
2014-07-13 23:25:36,789 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,789 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5601ms
2014-07-13 23:25:36,789 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,789 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5676ms
2014-07-13 23:25:36,789 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,789 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5717ms
2014-07-13 23:25:36,789 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,790 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5836ms
2014-07-13 23:25:36,790 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,792 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5838ms
2014-07-13 23:25:36,792 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,792 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5839ms
2014-07-13 23:25:36,792 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,795 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5859ms
2014-07-13 23:25:36,795 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,798 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5885ms
2014-07-13 23:25:36,798 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,798 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5891ms
2014-07-13 23:25:36,798 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,798 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5891ms
2014-07-13 23:25:36,798 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,799 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5973ms
2014-07-13 23:25:36,799 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,799 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5985ms
2014-07-13 23:25:36,799 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,809 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6004ms
2014-07-13 23:25:36,809 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,810 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6006ms
2014-07-13 23:25:36,810 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,810 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6009ms
2014-07-13 23:25:36,810 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,810 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6012ms
2014-07-13 23:25:36,810 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,810 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6012ms
2014-07-13 23:25:36,810 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,810 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6013ms
2014-07-13 23:25:36,810 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,811 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6014ms
2014-07-13 23:25:36,811 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,811 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6014ms
2014-07-13 23:25:36,811 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,813 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6018ms
2014-07-13 23:25:36,813 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,813 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6022ms
2014-07-13 23:25:36,813 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,820 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6030ms
2014-07-13 23:25:36,820 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,820 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6030ms
2014-07-13 23:25:36,821 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,827 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6037ms
2014-07-13 23:25:36,827 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,827 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6040ms
2014-07-13 23:25:36,827 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,830 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6043ms
2014-07-13 23:25:36,861 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,869 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6083ms
2014-07-13 23:25:36,869 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,869 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6083ms
2014-07-13 23:25:36,869 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,869 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6083ms
2014-07-13 23:25:36,869 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,869 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6084ms
2014-07-13 23:25:36,869 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,871 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6087ms
2014-07-13 23:25:36,871 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,877 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6099ms
2014-07-13 23:25:36,877 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,877 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6099ms
2014-07-13 23:25:36,877 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,877 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6175ms
2014-07-13 23:25:36,877 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,877 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6178ms
2014-07-13 23:25:36,877 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,883 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6184ms
2014-07-13 23:25:36,883 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,883 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6184ms
2014-07-13 23:25:36,883 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,883 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6184ms
2014-07-13 23:25:36,883 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,883 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6194ms
2014-07-13 23:25:36,883 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,889 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6198ms
2014-07-13 23:25:36,889 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,889 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6200ms
2014-07-13 23:25:36,889 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,889 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6200ms
2014-07-13 23:25:36,889 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,894 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6205ms
2014-07-13 23:25:36,894 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,894 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6222ms
2014-07-13 23:25:36,894 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,894 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6225ms
2014-07-13 23:25:36,894 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:36,925 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:25:38,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:38,209 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:25:38,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21303 synced till here 21270
2014-07-13 23:25:38,587 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319130288 with entries=153, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319138206
2014-07-13 23:25:39,896 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319129083,"queuetimems":0,"class":"HRegionServer","responsesize":18783,"method":"Multi"}
2014-07-13 23:25:40,495 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:40,550 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21425 synced till here 21406
2014-07-13 23:25:41,679 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319138206 with entries=122, filesize=98.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319140496
2014-07-13 23:25:43,477 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:43,645 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21570 synced till here 21522
2014-07-13 23:25:43,923 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,925 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,926 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,928 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,931 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,931 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,932 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,932 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,933 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,933 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,934 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,934 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,934 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,934 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,934 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,937 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,937 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,938 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,940 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,942 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,945 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:43,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319140496 with entries=145, filesize=111.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319143478
2014-07-13 23:25:44,099 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,100 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,102 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,102 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,104 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,108 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,109 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,109 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,110 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,111 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,111 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,115 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,116 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,116 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,116 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,118 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,123 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,123 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,123 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,124 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,126 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,126 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,127 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,127 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,129 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,129 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,186 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:44,927 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:45,537 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:25:48,924 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:48,926 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:48,926 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-13 23:25:48,928 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,931 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,931 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,932 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,932 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,933 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,933 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,934 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:48,934 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5011ms
2014-07-13 23:25:48,935 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:48,935 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-13 23:25:48,935 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:48,938 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-13 23:25:48,938 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:48,938 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,940 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,942 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:48,946 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,099 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,100 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,102 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,102 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,105 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,108 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,109 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,110 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,111 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,111 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,112 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,115 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,116 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,116 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,117 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,119 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,123 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,124 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,124 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,125 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,126 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,127 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,127 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,127 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,129 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:49,130 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:49,245 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5058ms
2014-07-13 23:25:49,927 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:25:50,537 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:25:51,486 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4682, memsize=542.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/a1ee5f4bfb134f67b53b077785eff35a
2014-07-13 23:25:51,508 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/a1ee5f4bfb134f67b53b077785eff35a as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a1ee5f4bfb134f67b53b077785eff35a
2014-07-13 23:25:51,528 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a1ee5f4bfb134f67b53b077785eff35a, entries=1976630, sequenceid=4682, filesize=140.7m
2014-07-13 23:25:51,529 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1283583680, currentsize=427.2m/447900480 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 32971ms, sequenceid=4682, compaction requested=true
2014-07-13 23:25:51,535 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:36), split_queue=0, merge_queue=0
2014-07-13 23:25:51,535 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5999ms
2014-07-13 23:25:51,535 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,535 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6608ms
2014-07-13 23:25:51,535 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.1g
2014-07-13 23:25:51,535 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,536 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7349ms
2014-07-13 23:25:51,536 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,536 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7407ms
2014-07-13 23:25:51,536 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,536 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7407ms
2014-07-13 23:25:51,536 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,536 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7409ms
2014-07-13 23:25:51,537 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,537 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7410ms
2014-07-13 23:25:51,537 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,537 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7411ms
2014-07-13 23:25:51,537 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,539 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7413ms
2014-07-13 23:25:51,539 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,548 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7423ms
2014-07-13 23:25:51,548 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,549 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7425ms
2014-07-13 23:25:51,549 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,549 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7426ms
2014-07-13 23:25:51,549 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,550 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7427ms
2014-07-13 23:25:51,551 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,551 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7433ms
2014-07-13 23:25:51,551 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,552 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7435ms
2014-07-13 23:25:51,552 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,937 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7820ms
2014-07-13 23:25:51,937 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,939 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7823ms
2014-07-13 23:25:51,939 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,940 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7825ms
2014-07-13 23:25:51,940 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,941 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7829ms
2014-07-13 23:25:51,941 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,942 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7830ms
2014-07-13 23:25:51,942 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,942 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7833ms
2014-07-13 23:25:51,942 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,945 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7836ms
2014-07-13 23:25:51,945 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,945 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7836ms
2014-07-13 23:25:51,945 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,945 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7837ms
2014-07-13 23:25:51,945 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,946 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7842ms
2014-07-13 23:25:51,946 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,946 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7844ms
2014-07-13 23:25:51,946 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,947 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7844ms
2014-07-13 23:25:51,947 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,948 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7847ms
2014-07-13 23:25:51,948 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,948 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7849ms
2014-07-13 23:25:51,948 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,949 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8004ms
2014-07-13 23:25:51,949 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,949 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8007ms
2014-07-13 23:25:51,949 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,952 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8011ms
2014-07-13 23:25:51,952 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,953 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8014ms
2014-07-13 23:25:51,953 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,954 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8016ms
2014-07-13 23:25:51,954 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,955 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8020ms
2014-07-13 23:25:51,955 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,956 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8021ms
2014-07-13 23:25:51,956 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,957 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8025ms
2014-07-13 23:25:51,957 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,965 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8031ms
2014-07-13 23:25:51,965 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,965 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8042ms
2014-07-13 23:25:51,965 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,966 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8033ms
2014-07-13 23:25:51,967 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,967 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8034ms
2014-07-13 23:25:51,968 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,968 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8035ms
2014-07-13 23:25:51,968 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,971 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8038ms
2014-07-13 23:25:51,971 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,972 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8039ms
2014-07-13 23:25:51,972 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,973 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8041ms
2014-07-13 23:25:51,973 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,976 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8045ms
2014-07-13 23:25:51,977 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,985 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8057ms
2014-07-13 23:25:51,985 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,985 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8062ms
2014-07-13 23:25:51,985 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,985 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8060ms
2014-07-13 23:25:51,985 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:51,986 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8063ms
2014-07-13 23:25:51,986 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:25:52,429 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10016,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142413,"queuetimems":1898,"class":"HRegionServer","responsesize":9991,"method":"Multi"}
2014-07-13 23:25:52,429 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10028,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142401,"queuetimems":2083,"class":"HRegionServer","responsesize":18595,"method":"Multi"}
2014-07-13 23:25:52,429 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10028,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142401,"queuetimems":2041,"class":"HRegionServer","responsesize":17859,"method":"Multi"}
2014-07-13 23:25:52,429 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10028,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142401,"queuetimems":2120,"class":"HRegionServer","responsesize":17537,"method":"Multi"}
2014-07-13 23:25:52,437 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10032,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142405,"queuetimems":2003,"class":"HRegionServer","responsesize":18454,"method":"Multi"}
2014-07-13 23:25:52,755 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10330,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142425,"queuetimems":1837,"class":"HRegionServer","responsesize":11429,"method":"Multi"}
2014-07-13 23:25:52,755 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10330,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142425,"queuetimems":1824,"class":"HRegionServer","responsesize":11342,"method":"Multi"}
2014-07-13 23:25:52,755 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142413,"queuetimems":1926,"class":"HRegionServer","responsesize":3541,"method":"Multi"}
2014-07-13 23:25:52,755 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10360,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142395,"queuetimems":2157,"class":"HRegionServer","responsesize":7315,"method":"Multi"}
2014-07-13 23:25:52,756 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10350,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142405,"queuetimems":1924,"class":"HRegionServer","responsesize":15323,"method":"Multi"}
2014-07-13 23:25:52,756 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:25:52,773 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:52,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21685 synced till here 21655
2014-07-13 23:25:53,158 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10688,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142469,"queuetimems":481,"class":"HRegionServer","responsesize":11616,"method":"Multi"}
2014-07-13 23:25:53,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319143478 with entries=115, filesize=94.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319152773
2014-07-13 23:25:53,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319048515
2014-07-13 23:25:53,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319057255
2014-07-13 23:25:53,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319060001
2014-07-13 23:25:53,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319061829
2014-07-13 23:25:53,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319064248
2014-07-13 23:25:53,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319066162
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319068618
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319070019
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319071490
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319073429
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319074898
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319076348
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319078153
2014-07-13 23:25:53,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319079615
2014-07-13 23:25:54,154 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:25:54,228 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11822,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142405,"queuetimems":1959,"class":"HRegionServer","responsesize":18783,"method":"Multi"}
2014-07-13 23:25:54,228 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10749,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143479,"queuetimems":1408,"class":"HRegionServer","responsesize":18478,"method":"Multi"}
2014-07-13 23:25:54,228 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10743,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143484,"queuetimems":1354,"class":"HRegionServer","responsesize":9320,"method":"Multi"}
2014-07-13 23:25:54,233 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11780,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142453,"queuetimems":708,"class":"HRegionServer","responsesize":18452,"method":"Multi"}
2014-07-13 23:25:54,233 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11768,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142465,"queuetimems":536,"class":"HRegionServer","responsesize":14665,"method":"Multi"}
2014-07-13 23:25:54,241 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10320,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143921,"queuetimems":385,"class":"HRegionServer","responsesize":3541,"method":"Multi"}
2014-07-13 23:25:54,241 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142433,"queuetimems":842,"class":"HRegionServer","responsesize":11831,"method":"Multi"}
2014-07-13 23:25:54,241 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142441,"queuetimems":814,"class":"HRegionServer","responsesize":18779,"method":"Multi"}
2014-07-13 23:25:54,244 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11783,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142461,"queuetimems":586,"class":"HRegionServer","responsesize":11788,"method":"Multi"}
2014-07-13 23:25:54,249 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10770,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143479,"queuetimems":1370,"class":"HRegionServer","responsesize":15800,"method":"Multi"}
2014-07-13 23:25:54,249 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142449,"queuetimems":781,"class":"HRegionServer","responsesize":18448,"method":"Multi"}
2014-07-13 23:25:54,254 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11797,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142457,"queuetimems":623,"class":"HRegionServer","responsesize":18008,"method":"Multi"}
2014-07-13 23:25:54,256 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11789,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319142466,"queuetimems":504,"class":"HRegionServer","responsesize":15566,"method":"Multi"}
2014-07-13 23:25:54,477 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10552,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143924,"queuetimems":256,"class":"HRegionServer","responsesize":18454,"method":"Multi"}
2014-07-13 23:25:54,484 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10567,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143917,"queuetimems":394,"class":"HRegionServer","responsesize":18595,"method":"Multi"}
2014-07-13 23:25:54,485 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10384,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319144101,"queuetimems":266,"class":"HRegionServer","responsesize":18779,"method":"Multi"}
2014-07-13 23:25:54,486 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10561,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143924,"queuetimems":214,"class":"HRegionServer","responsesize":15323,"method":"Multi"}
2014-07-13 23:25:54,489 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10381,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319144108,"queuetimems":181,"class":"HRegionServer","responsesize":17537,"method":"Multi"}
2014-07-13 23:25:54,490 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10382,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319144108,"queuetimems":225,"class":"HRegionServer","responsesize":17859,"method":"Multi"}
2014-07-13 23:25:54,509 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10409,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319144100,"queuetimems":324,"class":"HRegionServer","responsesize":11342,"method":"Multi"}
2014-07-13 23:25:54,517 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10593,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143924,"queuetimems":321,"class":"HRegionServer","responsesize":11429,"method":"Multi"}
2014-07-13 23:25:54,526 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10601,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143924,"queuetimems":369,"class":"HRegionServer","responsesize":9991,"method":"Multi"}
2014-07-13 23:25:54,533 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10616,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143917,"queuetimems":454,"class":"HRegionServer","responsesize":7315,"method":"Multi"}
2014-07-13 23:25:54,541 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10443,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319144098,"queuetimems":357,"class":"HRegionServer","responsesize":11831,"method":"Multi"}
2014-07-13 23:25:54,698 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:54,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21793 synced till here 21756
2014-07-13 23:25:55,024 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11545,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319143479,"queuetimems":1470,"class":"HRegionServer","responsesize":11534,"method":"Multi"}
2014-07-13 23:25:55,045 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319152773 with entries=108, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319154698
2014-07-13 23:25:56,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:56,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21880 synced till here 21879
2014-07-13 23:25:56,352 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319154698 with entries=87, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319156188
2014-07-13 23:25:57,628 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:57,643 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21944 synced till here 21942
2014-07-13 23:25:57,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319156188 with entries=64, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319157628
2014-07-13 23:25:58,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:25:58,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22021 synced till here 22016
2014-07-13 23:25:58,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319157628 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319158866
2014-07-13 23:26:00,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:00,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22088 synced till here 22086
2014-07-13 23:26:00,220 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319158866 with entries=67, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319160176
2014-07-13 23:26:00,768 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4808, memsize=416.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/36222186b3c940f2a9e5a52c194e48bf
2014-07-13 23:26:00,779 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/36222186b3c940f2a9e5a52c194e48bf as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/36222186b3c940f2a9e5a52c194e48bf
2014-07-13 23:26:00,794 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/36222186b3c940f2a9e5a52c194e48bf, entries=1515300, sequenceid=4808, filesize=107.9m
2014-07-13 23:26:00,795 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~852.0m/893386800, currentsize=412.7m/432741600 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 24011ms, sequenceid=4808, compaction requested=true
2014-07-13 23:26:00,795 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:37), split_queue=0, merge_queue=0
2014-07-13 23:26:00,795 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 452.5m
2014-07-13 23:26:00,852 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:26:01,356 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:26:01,515 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:01,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22147 synced till here 22146
2014-07-13 23:26:01,561 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319160176 with entries=59, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319161515
2014-07-13 23:26:02,698 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:02,712 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22205 synced till here 22203
2014-07-13 23:26:02,756 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319161515 with entries=58, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319162698
2014-07-13 23:26:03,827 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:04,205 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319162698 with entries=76, filesize=81.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319163827
2014-07-13 23:26:05,487 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:05,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22345 synced till here 22339
2014-07-13 23:26:05,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319163827 with entries=64, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319165488
2014-07-13 23:26:07,217 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:07,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22432 synced till here 22427
2014-07-13 23:26:07,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319165488 with entries=87, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319167217
2014-07-13 23:26:09,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:10,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22543 synced till here 22541
2014-07-13 23:26:10,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319167217 with entries=111, filesize=99.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319169222
2014-07-13 23:26:10,641 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7090, memsize=211.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1c219b4b18b24e8ea638b3357bcb3f2c
2014-07-13 23:26:10,669 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1c219b4b18b24e8ea638b3357bcb3f2c as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1c219b4b18b24e8ea638b3357bcb3f2c
2014-07-13 23:26:10,693 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1c219b4b18b24e8ea638b3357bcb3f2c, entries=770820, sequenceid=7090, filesize=54.9m
2014-07-13 23:26:10,694 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~452.5m/474467920, currentsize=155.7m/163250400 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 9899ms, sequenceid=7090, compaction requested=true
2014-07-13 23:26:10,695 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:38), split_queue=0, merge_queue=0
2014-07-13 23:26:10,696 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 912.6m
2014-07-13 23:26:10,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:10,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22626 synced till here 22613
2014-07-13 23:26:11,621 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319169222 with entries=83, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319170835
2014-07-13 23:26:12,302 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:26:13,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:13,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22745 synced till here 22711
2014-07-13 23:26:13,433 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319170835 with entries=119, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319173188
2014-07-13 23:26:14,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:14,918 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22831 synced till here 22827
2014-07-13 23:26:14,976 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319173188 with entries=86, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319174544
2014-07-13 23:26:16,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:16,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22903 synced till here 22894
2014-07-13 23:26:16,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319174544 with entries=72, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319176320
2014-07-13 23:26:16,672 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:26:17,174 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4913, memsize=428.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/5f1c7bb75e9341ae9aa648260d5d757a
2014-07-13 23:26:17,188 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/5f1c7bb75e9341ae9aa648260d5d757a as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5f1c7bb75e9341ae9aa648260d5d757a
2014-07-13 23:26:17,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:18,147 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5f1c7bb75e9341ae9aa648260d5d757a, entries=1560840, sequenceid=4913, filesize=111.2m
2014-07-13 23:26:18,147 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1163231440, currentsize=610.3m/639917840 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 26612ms, sequenceid=4913, compaction requested=true
2014-07-13 23:26:18,147 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22986 synced till here 22984
2014-07-13 23:26:18,148 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:39), split_queue=0, merge_queue=0
2014-07-13 23:26:18,148 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 800.9m
2014-07-13 23:26:18,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319176320 with entries=83, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319177317
2014-07-13 23:26:18,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319081238
2014-07-13 23:26:18,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319084334
2014-07-13 23:26:18,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319086364
2014-07-13 23:26:18,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319087883
2014-07-13 23:26:18,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319088798
2014-07-13 23:26:18,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319090012
2014-07-13 23:26:18,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319091632
2014-07-13 23:26:18,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319092900
2014-07-13 23:26:18,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319094508
2014-07-13 23:26:18,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319096222
2014-07-13 23:26:18,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319097778
2014-07-13 23:26:18,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319100848
2014-07-13 23:26:18,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319102676
2014-07-13 23:26:18,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319108255
2014-07-13 23:26:18,171 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319111700
2014-07-13 23:26:18,172 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319114063
2014-07-13 23:26:18,195 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:26:18,973 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:18,991 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:26:19,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23056 synced till here 23049
2014-07-13 23:26:19,568 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319177317 with entries=70, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319178973
2014-07-13 23:26:20,496 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:21,258 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23157 synced till here 23125
2014-07-13 23:26:21,474 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319178973 with entries=101, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319180496
2014-07-13 23:26:23,477 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:23,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23281 synced till here 23260
2014-07-13 23:26:23,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319180496 with entries=124, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319183477
2014-07-13 23:26:25,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:25,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23417 synced till here 23395
2014-07-13 23:26:25,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319183477 with entries=136, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319185481
2014-07-13 23:26:26,968 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:27,269 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23529 synced till here 23520
2014-07-13 23:26:27,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319185481 with entries=112, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319186969
2014-07-13 23:26:28,763 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:28,785 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23602 synced till here 23595
2014-07-13 23:26:28,962 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319186969 with entries=73, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319188765
2014-07-13 23:26:30,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:30,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23670 synced till here 23664
2014-07-13 23:26:30,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319188765 with entries=68, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319190102
2014-07-13 23:26:31,730 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:31,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23769 synced till here 23755
2014-07-13 23:26:31,875 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319190102 with entries=99, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319191730
2014-07-13 23:26:33,392 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:33,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23871 synced till here 23840
2014-07-13 23:26:33,735 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319191730 with entries=102, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319193392
2014-07-13 23:26:35,005 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,009 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,010 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,014 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,015 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,018 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,020 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,023 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,023 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,023 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,025 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,026 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,038 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,091 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,092 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,108 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,109 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,114 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,151 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,179 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,181 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,183 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,209 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,217 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,291 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,318 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,339 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,372 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,412 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,437 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,439 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,494 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,497 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,498 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,498 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,498 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,498 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,515 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,520 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,569 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,631 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,632 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,632 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,635 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,676 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,677 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,681 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,708 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,709 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:35,709 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:38,690 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5148, memsize=412.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/3162f70bf10049bf9dee927e21b9d16d
2014-07-13 23:26:38,707 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/3162f70bf10049bf9dee927e21b9d16d as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/3162f70bf10049bf9dee927e21b9d16d
2014-07-13 23:26:38,721 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/3162f70bf10049bf9dee927e21b9d16d, entries=1502950, sequenceid=5148, filesize=107.0m
2014-07-13 23:26:38,722 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~920.6m/965304720, currentsize=509.7m/534495600 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 28026ms, sequenceid=5148, compaction requested=true
2014-07-13 23:26:38,722 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:40), split_queue=0, merge_queue=0
2014-07-13 23:26:38,723 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3013ms
2014-07-13 23:26:38,723 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,723 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 528.6m
2014-07-13 23:26:38,723 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3014ms
2014-07-13 23:26:38,723 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,724 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3016ms
2014-07-13 23:26:38,724 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,724 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3043ms
2014-07-13 23:26:38,724 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,730 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3053ms
2014-07-13 23:26:38,730 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,730 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3054ms
2014-07-13 23:26:38,730 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,730 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3095ms
2014-07-13 23:26:38,730 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,731 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3099ms
2014-07-13 23:26:38,731 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,731 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3100ms
2014-07-13 23:26:38,731 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,731 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3100ms
2014-07-13 23:26:38,731 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,731 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3162ms
2014-07-13 23:26:38,731 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,732 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3212ms
2014-07-13 23:26:38,732 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,732 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3217ms
2014-07-13 23:26:38,732 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,732 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3234ms
2014-07-13 23:26:38,732 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,733 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3234ms
2014-07-13 23:26:38,733 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,737 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3237ms
2014-07-13 23:26:38,737 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,738 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3239ms
2014-07-13 23:26:38,738 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,738 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3241ms
2014-07-13 23:26:38,738 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,739 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3245ms
2014-07-13 23:26:38,739 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,739 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3301ms
2014-07-13 23:26:38,740 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,740 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3303ms
2014-07-13 23:26:38,740 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,749 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3337ms
2014-07-13 23:26:38,749 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,750 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3377ms
2014-07-13 23:26:38,750 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,757 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3419ms
2014-07-13 23:26:38,757 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,759 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3442ms
2014-07-13 23:26:38,759 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,759 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3468ms
2014-07-13 23:26:38,760 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,760 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3543ms
2014-07-13 23:26:38,760 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,764 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3554ms
2014-07-13 23:26:38,764 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,764 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3581ms
2014-07-13 23:26:38,764 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,764 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3583ms
2014-07-13 23:26:38,764 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,764 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3585ms
2014-07-13 23:26:38,764 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,773 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3622ms
2014-07-13 23:26:38,773 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,776 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3662ms
2014-07-13 23:26:38,776 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,777 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3668ms
2014-07-13 23:26:38,778 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,782 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3673ms
2014-07-13 23:26:38,782 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,783 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3690ms
2014-07-13 23:26:38,783 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,783 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3692ms
2014-07-13 23:26:38,783 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,784 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3746ms
2014-07-13 23:26:38,784 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,784 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3758ms
2014-07-13 23:26:38,784 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,784 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3759ms
2014-07-13 23:26:38,785 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,789 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3766ms
2014-07-13 23:26:38,789 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,789 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3780ms
2014-07-13 23:26:38,789 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,797 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3774ms
2014-07-13 23:26:38,797 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,797 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3777ms
2014-07-13 23:26:38,797 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,801 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3783ms
2014-07-13 23:26:38,801 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,801 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3787ms
2014-07-13 23:26:38,801 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,801 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3787ms
2014-07-13 23:26:38,802 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,805 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3795ms
2014-07-13 23:26:38,805 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,809 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3800ms
2014-07-13 23:26:38,809 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,810 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3804ms
2014-07-13 23:26:38,810 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:26:38,816 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:26:39,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:39,233 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24008 synced till here 23972
2014-07-13 23:26:39,253 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:26:39,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319193392 with entries=137, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319199206
2014-07-13 23:26:39,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319116488
2014-07-13 23:26:39,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319119079
2014-07-13 23:26:39,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319120748
2014-07-13 23:26:39,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319122457
2014-07-13 23:26:39,648 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319124161
2014-07-13 23:26:39,648 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319126048
2014-07-13 23:26:39,648 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319128561
2014-07-13 23:26:41,643 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:41,710 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24115 synced till here 24085
2014-07-13 23:26:42,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319199206 with entries=107, filesize=97.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319201644
2014-07-13 23:26:43,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:44,637 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24232 synced till here 24209
2014-07-13 23:26:44,819 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319201644 with entries=117, filesize=88.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319203867
2014-07-13 23:26:45,703 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5228, memsize=406.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/5f13fd98fa1e478fa50ea4de5b9cd958
2014-07-13 23:26:45,718 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/5f13fd98fa1e478fa50ea4de5b9cd958 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/5f13fd98fa1e478fa50ea4de5b9cd958
2014-07-13 23:26:45,729 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/5f13fd98fa1e478fa50ea4de5b9cd958, entries=1478210, sequenceid=5228, filesize=105.3m
2014-07-13 23:26:45,730 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~803.9m/842956640, currentsize=484.5m/508084080 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 27582ms, sequenceid=5228, compaction requested=true
2014-07-13 23:26:45,730 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-13 23:26:45,730 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.1g
2014-07-13 23:26:45,738 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:45,739 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:26:46,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24372 synced till here 24344
2014-07-13 23:26:46,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319203867 with entries=140, filesize=86.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319205738
2014-07-13 23:26:46,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319130288
2014-07-13 23:26:46,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319138206
2014-07-13 23:26:46,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319140496
2014-07-13 23:26:47,640 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:26:47,958 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:47,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24433 synced till here 24432
2014-07-13 23:26:48,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319205738 with entries=61, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319207958
2014-07-13 23:26:49,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:49,727 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319207958 with entries=65, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319209433
2014-07-13 23:26:50,939 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:50,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24580 synced till here 24578
2014-07-13 23:26:50,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319209433 with entries=82, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319210939
2014-07-13 23:26:52,067 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:52,896 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24673 synced till here 24661
2014-07-13 23:26:53,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319210939 with entries=93, filesize=85.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319212068
2014-07-13 23:26:53,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:54,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24745 synced till here 24742
2014-07-13 23:26:54,347 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319212068 with entries=72, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319213768
2014-07-13 23:26:55,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:55,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24824 synced till here 24821
2014-07-13 23:26:55,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319213768 with entries=79, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319215147
2014-07-13 23:26:56,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:57,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24917 synced till here 24901
2014-07-13 23:26:57,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319215147 with entries=93, filesize=75.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319216514
2014-07-13 23:26:58,160 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:26:58,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25000 synced till here 24994
2014-07-13 23:26:58,812 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319216514 with entries=83, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319218160
2014-07-13 23:26:59,330 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,345 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,347 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,349 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,403 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,404 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,407 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,413 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,417 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,420 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,425 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,465 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,478 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,478 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,524 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,530 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,532 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,533 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,534 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,535 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,545 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,547 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,595 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,598 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,601 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,613 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,668 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,673 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,718 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,751 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,755 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,755 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,755 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,757 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,792 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,829 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,857 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,879 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,890 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,893 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,908 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,915 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,931 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,934 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,940 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,940 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,943 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,979 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,979 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:26:59,983 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:01,569 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7721, memsize=399.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/957055a7bf5f4f67beed61bd502511df
2014-07-13 23:27:01,580 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/957055a7bf5f4f67beed61bd502511df as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/957055a7bf5f4f67beed61bd502511df
2014-07-13 23:27:01,589 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/957055a7bf5f4f67beed61bd502511df, entries=1455400, sequenceid=7721, filesize=103.7m
2014-07-13 23:27:01,590 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~528.6m/554308720, currentsize=286.1m/300009120 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 22867ms, sequenceid=7721, compaction requested=true
2014-07-13 23:27:01,590 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:42), split_queue=0, merge_queue=0
2014-07-13 23:27:01,590 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1607ms
2014-07-13 23:27:01,590 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,590 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 981.0m
2014-07-13 23:27:01,590 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1611ms
2014-07-13 23:27:01,590 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,590 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1611ms
2014-07-13 23:27:01,591 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,591 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1648ms
2014-07-13 23:27:01,591 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,594 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1654ms
2014-07-13 23:27:01,594 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,594 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1654ms
2014-07-13 23:27:01,594 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,594 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1660ms
2014-07-13 23:27:01,595 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,597 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1666ms
2014-07-13 23:27:01,597 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,597 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:27:01,601 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1686ms
2014-07-13 23:27:01,602 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,602 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1694ms
2014-07-13 23:27:01,602 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,602 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1709ms
2014-07-13 23:27:01,602 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,603 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1713ms
2014-07-13 23:27:01,603 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,613 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1734ms
2014-07-13 23:27:01,613 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,613 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1756ms
2014-07-13 23:27:01,613 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,613 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1784ms
2014-07-13 23:27:01,613 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,613 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1821ms
2014-07-13 23:27:01,613 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,621 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1864ms
2014-07-13 23:27:01,621 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,621 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1866ms
2014-07-13 23:27:01,621 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,621 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1866ms
2014-07-13 23:27:01,621 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,621 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1866ms
2014-07-13 23:27:01,621 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,621 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1870ms
2014-07-13 23:27:01,622 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,622 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1904ms
2014-07-13 23:27:01,622 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,622 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1949ms
2014-07-13 23:27:01,622 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,623 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1954ms
2014-07-13 23:27:01,623 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,623 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2010ms
2014-07-13 23:27:01,624 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,624 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2024ms
2014-07-13 23:27:01,624 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,624 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2026ms
2014-07-13 23:27:01,624 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,624 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2029ms
2014-07-13 23:27:01,624 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,624 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2077ms
2014-07-13 23:27:01,624 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,626 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2081ms
2014-07-13 23:27:01,626 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,626 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2091ms
2014-07-13 23:27:01,626 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,626 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2092ms
2014-07-13 23:27:01,626 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,627 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2093ms
2014-07-13 23:27:01,627 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,658 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2126ms
2014-07-13 23:27:01,658 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,658 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2129ms
2014-07-13 23:27:01,658 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,658 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2134ms
2014-07-13 23:27:01,658 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,659 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2181ms
2014-07-13 23:27:01,659 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,659 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2181ms
2014-07-13 23:27:01,659 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,660 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2195ms
2014-07-13 23:27:01,660 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,661 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2236ms
2014-07-13 23:27:01,661 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,661 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2241ms
2014-07-13 23:27:01,661 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,661 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2244ms
2014-07-13 23:27:01,661 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,669 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2256ms
2014-07-13 23:27:01,669 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,669 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2262ms
2014-07-13 23:27:01,669 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,671 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2267ms
2014-07-13 23:27:01,671 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,672 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2269ms
2014-07-13 23:27:01,672 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,672 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2323ms
2014-07-13 23:27:01,672 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,681 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2334ms
2014-07-13 23:27:01,681 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,685 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2340ms
2014-07-13 23:27:01,685 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:01,688 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2358ms
2014-07-13 23:27:01,688 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:02,030 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:02,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25121 synced till here 25090
2014-07-13 23:27:02,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319218160 with entries=121, filesize=97.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319222030
2014-07-13 23:27:03,773 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:27:04,260 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:04,394 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319222030 with entries=98, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319224261
2014-07-13 23:27:06,540 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:07,318 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25344 synced till here 25334
2014-07-13 23:27:07,366 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319224261 with entries=125, filesize=97.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319226541
2014-07-13 23:27:08,070 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,074 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,075 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,093 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,100 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,132 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,132 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,132 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,132 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,133 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,133 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,133 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,133 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,134 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,134 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,134 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,170 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,171 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,173 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,174 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,177 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,178 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,179 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,187 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:08,200 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,209 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25414 synced till here 25412
2014-07-13 23:27:08,211 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319226541 with entries=70, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319228187
2014-07-13 23:27:08,281 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,281 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,281 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,325 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:08,378 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:09,446 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,312 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,376 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,376 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,377 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,377 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,377 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,379 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,379 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,380 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,380 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,727 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,767 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,815 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,864 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,886 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,928 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:10,970 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:11,007 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:11,056 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:13,070 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,074 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,075 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,093 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,100 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,132 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,132 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,133 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,133 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,133 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,134 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,134 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:27:13,134 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,134 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,135 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,135 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,171 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,171 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,173 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,174 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,177 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,178 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,179 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,201 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,211 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:13,282 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,282 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,282 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,326 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:13,378 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:14,602 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5156ms
2014-07-13 23:27:15,376 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5064ms
2014-07-13 23:27:15,376 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5059ms
2014-07-13 23:27:15,377 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-13 23:27:15,377 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-13 23:27:15,378 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-13 23:27:15,378 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5065ms
2014-07-13 23:27:15,379 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5066ms
2014-07-13 23:27:15,380 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5068ms
2014-07-13 23:27:15,380 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5068ms
2014-07-13 23:27:15,380 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5068ms
2014-07-13 23:27:15,727 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:15,767 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:15,815 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:15,865 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:15,887 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:15,928 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:15,970 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:27:16,007 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:16,057 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:27:18,071 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,075 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,076 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:27:18,094 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,100 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:27:18,133 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,134 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,134 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:27:18,134 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,135 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,135 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 23:27:18,135 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,136 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-13 23:27:18,136 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 23:27:18,136 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:27:18,136 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:27:18,172 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:27:18,172 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:27:18,173 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,174 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:27:18,178 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:27:18,178 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:27:18,180 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,202 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,212 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,288 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10006ms
2014-07-13 23:27:18,288 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-13 23:27:18,288 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10007ms
2014-07-13 23:27:18,293 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5523, memsize=565.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/1a71dee0da7f47dbb034cc67c7b2907a
2014-07-13 23:27:18,313 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/1a71dee0da7f47dbb034cc67c7b2907a as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1a71dee0da7f47dbb034cc67c7b2907a
2014-07-13 23:27:18,327 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:27:18,350 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1a71dee0da7f47dbb034cc67c7b2907a, entries=2060230, sequenceid=5523, filesize=146.8m
2014-07-13 23:27:18,351 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1203605360, currentsize=461.1m/483477120 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 32621ms, sequenceid=5523, compaction requested=true
2014-07-13 23:27:18,352 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-13 23:27:18,352 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10027ms
2014-07-13 23:27:18,352 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,353 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10072ms
2014-07-13 23:27:18,353 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,353 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 971.2m
2014-07-13 23:27:18,353 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10073ms
2014-07-13 23:27:18,353 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,353 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10072ms
2014-07-13 23:27:18,353 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,353 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10142ms
2014-07-13 23:27:18,354 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,354 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10154ms
2014-07-13 23:27:18,354 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,354 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10175ms
2014-07-13 23:27:18,354 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,357 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10179ms
2014-07-13 23:27:18,357 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,361 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10184ms
2014-07-13 23:27:18,361 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,361 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10187ms
2014-07-13 23:27:18,361 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,361 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10189ms
2014-07-13 23:27:18,361 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,361 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10191ms
2014-07-13 23:27:18,361 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,361 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10191ms
2014-07-13 23:27:18,361 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,375 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10241ms
2014-07-13 23:27:18,375 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,375 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10241ms
2014-07-13 23:27:18,375 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,375 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10242ms
2014-07-13 23:27:18,375 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,377 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10245ms
2014-07-13 23:27:18,377 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,378 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10244ms
2014-07-13 23:27:18,378 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,378 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10246ms
2014-07-13 23:27:18,378 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,381 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 23:27:18,381 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,383 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10250ms
2014-07-13 23:27:18,383 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,383 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10250ms
2014-07-13 23:27:18,383 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,384 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10252ms
2014-07-13 23:27:18,384 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,384 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10252ms
2014-07-13 23:27:18,384 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,384 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10252ms
2014-07-13 23:27:18,384 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,384 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10284ms
2014-07-13 23:27:18,385 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,386 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10253,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228133,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:27:18,389 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10296ms
2014-07-13 23:27:18,389 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,389 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10314ms
2014-07-13 23:27:18,389 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,389 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10315ms
2014-07-13 23:27:18,390 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,391 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10321ms
2014-07-13 23:27:18,391 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,392 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7335ms
2014-07-13 23:27:18,392 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,393 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7387ms
2014-07-13 23:27:18,394 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,395 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7424ms
2014-07-13 23:27:18,395 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,396 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7467ms
2014-07-13 23:27:18,396 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,397 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7510ms
2014-07-13 23:27:18,397 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,397 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7533ms
2014-07-13 23:27:18,397 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,397 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7582ms
2014-07-13 23:27:18,397 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,399 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7631ms
2014-07-13 23:27:18,399 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,399 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7673ms
2014-07-13 23:27:18,399 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,402 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8089ms
2014-07-13 23:27:18,402 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,402 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8090ms
2014-07-13 23:27:18,402 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,403 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8091ms
2014-07-13 23:27:18,403 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,404 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8090ms
2014-07-13 23:27:18,404 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,405 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8091ms
2014-07-13 23:27:18,406 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,407 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8092ms
2014-07-13 23:27:18,407 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,408 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8093ms
2014-07-13 23:27:18,408 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,408 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8094ms
2014-07-13 23:27:18,408 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,409 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8092ms
2014-07-13 23:27:18,409 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,410 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8097ms
2014-07-13 23:27:18,410 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,410 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8964ms
2014-07-13 23:27:18,410 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:18,471 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10877,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227593,"queuetimems":1,"class":"HRegionServer","responsesize":13475,"method":"Multi"}
2014-07-13 23:27:18,530 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10396,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228134,"queuetimems":0,"class":"HRegionServer","responsesize":799,"method":"Multi"}
2014-07-13 23:27:18,558 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10426,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228132,"queuetimems":0,"class":"HRegionServer","responsesize":38,"method":"Multi"}
2014-07-13 23:27:18,565 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10432,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228132,"queuetimems":0,"class":"HRegionServer","responsesize":20,"method":"Multi"}
2014-07-13 23:27:18,569 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228132,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:27:18,569 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228133,"queuetimems":1,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:27:18,570 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228133,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:27:18,570 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10438,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228132,"queuetimems":0,"class":"HRegionServer","responsesize":68,"method":"Multi"}
2014-07-13 23:27:18,570 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228134,"queuetimems":0,"class":"HRegionServer","responsesize":32,"method":"Multi"}
2014-07-13 23:27:18,572 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228132,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:27:19,131 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11579,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227551,"queuetimems":0,"class":"HRegionServer","responsesize":11752,"method":"Multi"}
2014-07-13 23:27:19,131 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11439,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227692,"queuetimems":0,"class":"HRegionServer","responsesize":18591,"method":"Multi"}
2014-07-13 23:27:19,136 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11779,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227357,"queuetimems":1,"class":"HRegionServer","responsesize":10232,"method":"Multi"}
2014-07-13 23:27:19,136 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11489,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227647,"queuetimems":0,"class":"HRegionServer","responsesize":18133,"method":"Multi"}
2014-07-13 23:27:19,274 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11944,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227330,"queuetimems":0,"class":"HRegionServer","responsesize":18352,"method":"Multi"}
2014-07-13 23:27:19,277 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13224,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319226053,"queuetimems":76,"class":"HRegionServer","responsesize":18243,"method":"Multi"}
2014-07-13 23:27:19,503 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:27:19,511 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11488,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228022,"queuetimems":1,"class":"HRegionServer","responsesize":17342,"method":"Multi"}
2014-07-13 23:27:19,512 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11535,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227974,"queuetimems":1,"class":"HRegionServer","responsesize":14314,"method":"Multi"}
2014-07-13 23:27:19,793 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:19,810 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227936,"queuetimems":0,"class":"HRegionServer","responsesize":17610,"method":"Multi"}
2014-07-13 23:27:19,813 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11754,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228058,"queuetimems":0,"class":"HRegionServer","responsesize":18248,"method":"Multi"}
2014-07-13 23:27:19,814 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11936,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227878,"queuetimems":0,"class":"HRegionServer","responsesize":16771,"method":"Multi"}
2014-07-13 23:27:19,815 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11983,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227832,"queuetimems":0,"class":"HRegionServer","responsesize":18383,"method":"Multi"}
2014-07-13 23:27:19,815 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12043,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227772,"queuetimems":3,"class":"HRegionServer","responsesize":18517,"method":"Multi"}
2014-07-13 23:27:19,816 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12086,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319227729,"queuetimems":0,"class":"HRegionServer","responsesize":18381,"method":"Multi"}
2014-07-13 23:27:19,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25538 synced till here 25505
2014-07-13 23:27:19,903 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:27:20,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319228187 with entries=124, filesize=93.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319239794
2014-07-13 23:27:20,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319143478
2014-07-13 23:27:20,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319152773
2014-07-13 23:27:20,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319154698
2014-07-13 23:27:20,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319156188
2014-07-13 23:27:20,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319157628
2014-07-13 23:27:20,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319158866
2014-07-13 23:27:20,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319160176
2014-07-13 23:27:20,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319161515
2014-07-13 23:27:20,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319162698
2014-07-13 23:27:20,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319163827
2014-07-13 23:27:20,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319165488
2014-07-13 23:27:20,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319167217
2014-07-13 23:27:21,363 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13263,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228099,"queuetimems":0,"class":"HRegionServer","responsesize":4589,"method":"Multi"}
2014-07-13 23:27:21,363 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10638,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319230724,"queuetimems":0,"class":"HRegionServer","responsesize":10232,"method":"Multi"}
2014-07-13 23:27:21,363 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319230883,"queuetimems":0,"class":"HRegionServer","responsesize":11752,"method":"Multi"}
2014-07-13 23:27:21,363 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13273,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228090,"queuetimems":0,"class":"HRegionServer","responsesize":15978,"method":"Multi"}
2014-07-13 23:27:21,373 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11930,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319229443,"queuetimems":0,"class":"HRegionServer","responsesize":17330,"method":"Multi"}
2014-07-13 23:27:21,374 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10610,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319230763,"queuetimems":1,"class":"HRegionServer","responsesize":13475,"method":"Multi"}
2014-07-13 23:27:21,373 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10369,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319231004,"queuetimems":0,"class":"HRegionServer","responsesize":17342,"method":"Multi"}
2014-07-13 23:27:21,382 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13249,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228132,"queuetimems":1,"class":"HRegionServer","responsesize":15976,"method":"Multi"}
2014-07-13 23:27:21,386 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13013,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228372,"queuetimems":1,"class":"HRegionServer","responsesize":18632,"method":"Multi"}
2014-07-13 23:27:21,386 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10423,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319230963,"queuetimems":0,"class":"HRegionServer","responsesize":17610,"method":"Multi"}
2014-07-13 23:27:21,386 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10526,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319230860,"queuetimems":0,"class":"HRegionServer","responsesize":18248,"method":"Multi"}
2014-07-13 23:27:21,387 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10579,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319230808,"queuetimems":1,"class":"HRegionServer","responsesize":18352,"method":"Multi"}
2014-07-13 23:27:21,386 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13060,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319228325,"queuetimems":1,"class":"HRegionServer","responsesize":18243,"method":"Multi"}
2014-07-13 23:27:21,620 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:21,660 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10737,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319230923,"queuetimems":0,"class":"HRegionServer","responsesize":15978,"method":"Multi"}
2014-07-13 23:27:21,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25631 synced till here 25607
2014-07-13 23:27:21,937 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10891,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319231045,"queuetimems":0,"class":"HRegionServer","responsesize":15976,"method":"Multi"}
2014-07-13 23:27:22,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319239794 with entries=93, filesize=92.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319241620
2014-07-13 23:27:23,414 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:23,445 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319241620 with entries=61, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319243414
2014-07-13 23:27:24,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:24,989 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25769 synced till here 25760
2014-07-13 23:27:25,060 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319243414 with entries=77, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319244893
2014-07-13 23:27:26,182 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/77948be437e340ea869369a95ac0fb32 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/77948be437e340ea869369a95ac0fb32
2014-07-13 23:27:26,322 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:27:26,338 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/329fcbdeb16e47b3b2081afe57c49fb6, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/329fcbdeb16e47b3b2081afe57c49fb6
2014-07-13 23:27:26,341 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/fe5a8aed256846e18487510bbec7c08b, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/fe5a8aed256846e18487510bbec7c08b
2014-07-13 23:27:26,344 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/a40ffa295c844cb8946ddfd38568ae84, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/a40ffa295c844cb8946ddfd38568ae84
2014-07-13 23:27:26,346 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/122a2e4f325248eb9f2e2ffb8f86c879, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/122a2e4f325248eb9f2e2ffb8f86c879
2014-07-13 23:27:26,348 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e9dff5c0a12c4e00a7303f67c7ed6b45, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e9dff5c0a12c4e00a7303f67c7ed6b45
2014-07-13 23:27:26,350 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/7f0f26e1bf1644d7b6f6bbbdc21ba5d6, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/7f0f26e1bf1644d7b6f6bbbdc21ba5d6
2014-07-13 23:27:26,353 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/dcd6c20a5ade44748289a292e8ee72cb, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/dcd6c20a5ade44748289a292e8ee72cb
2014-07-13 23:27:26,356 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c50f1376c41e48d0aab8b6efe1e285ab, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c50f1376c41e48d0aab8b6efe1e285ab
2014-07-13 23:27:26,359 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/43347ccbade744828f08237846a9b433, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/43347ccbade744828f08237846a9b433
2014-07-13 23:27:26,362 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b906c4f4571b4f67930e3376d120a0db, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b906c4f4571b4f67930e3376d120a0db
2014-07-13 23:27:26,362 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed major compaction of 10 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into 77948be437e340ea869369a95ac0fb32(size=900.4m), total size for store is 1.3g. This selection was in queue for 0sec, and took 3mins, 26sec to execute.
2014-07-13 23:27:26,362 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., storeName=family, fileCount=10, fileSize=930.7m, priority=10, time=272947245878362; duration=3mins, 26sec
2014-07-13 23:27:26,362 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-13 23:27:26,363 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 12 store files, 0 compacting, 12 eligible, 20 blocking
2014-07-13 23:27:26,364 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 938201150 starting at candidate #2 after considering 52 permutations with 51 in ratio
2014-07-13 23:27:26,364 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 8b827125b32700e6f7c5c34f77be22cb - family: Initiating minor compaction
2014-07-13 23:27:26,365 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:27:26,365 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp, totalSize=894.7m
2014-07-13 23:27:26,365 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ac5549187a8c42419c9ea54824354617, keycount=93572, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=1716
2014-07-13 23:27:26,365 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5ad17e55e2844166b4075f58619b3875, keycount=90761, bloomtype=ROW, size=64.6m, encoding=NONE, seqNum=1975
2014-07-13 23:27:26,365 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7ceb363c18704302ba0ada76718c6c89, keycount=87074, bloomtype=ROW, size=62.0m, encoding=NONE, seqNum=2131
2014-07-13 23:27:26,365 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a45b41143d444337a410cdd2db8af87e, keycount=91553, bloomtype=ROW, size=65.2m, encoding=NONE, seqNum=2289
2014-07-13 23:27:26,366 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6af32181696643da8cacecdf1dce6c8a, keycount=75974, bloomtype=ROW, size=54.1m, encoding=NONE, seqNum=2601
2014-07-13 23:27:26,366 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e444f0c359ec479abdded80b02e8768b, keycount=137530, bloomtype=ROW, size=98.0m, encoding=NONE, seqNum=3013
2014-07-13 23:27:26,366 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/1acffef0cefc42bfb2c29dba0eee9928, keycount=180286, bloomtype=ROW, size=128.4m, encoding=NONE, seqNum=3548
2014-07-13 23:27:26,366 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/be5aedfee822485b9c21b35a80e0342c, keycount=151553, bloomtype=ROW, size=107.9m, encoding=NONE, seqNum=4079
2014-07-13 23:27:26,366 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a1ee5f4bfb134f67b53b077785eff35a, keycount=197663, bloomtype=ROW, size=140.7m, encoding=NONE, seqNum=4682
2014-07-13 23:27:26,366 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/3162f70bf10049bf9dee927e21b9d16d, keycount=150295, bloomtype=ROW, size=107.0m, encoding=NONE, seqNum=5148
2014-07-13 23:27:26,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:26,925 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:27:27,061 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25868 synced till here 25863
2014-07-13 23:27:27,135 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319244893 with entries=99, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319246876
2014-07-13 23:27:28,455 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5672, memsize=473.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/41e7d6616c634f078bdfd6c9b8aa631a
2014-07-13 23:27:28,469 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/41e7d6616c634f078bdfd6c9b8aa631a as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/41e7d6616c634f078bdfd6c9b8aa631a
2014-07-13 23:27:28,487 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/41e7d6616c634f078bdfd6c9b8aa631a, entries=1722830, sequenceid=5672, filesize=122.8m
2014-07-13 23:27:28,487 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~981.0m/1028622400, currentsize=398.3m/417656080 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 26897ms, sequenceid=5672, compaction requested=true
2014-07-13 23:27:28,487 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-13 23:27:28,488 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 470.7m
2014-07-13 23:27:28,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:28,683 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:27:28,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25969 synced till here 25964
2014-07-13 23:27:28,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319246876 with entries=101, filesize=89.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319248490
2014-07-13 23:27:28,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319169222
2014-07-13 23:27:28,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319170835
2014-07-13 23:27:28,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319173188
2014-07-13 23:27:28,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319174544
2014-07-13 23:27:28,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319176320
2014-07-13 23:27:29,186 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:27:30,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:30,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26041 synced till here 26035
2014-07-13 23:27:30,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319248490 with entries=72, filesize=76.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319250054
2014-07-13 23:27:31,556 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:31,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26108 synced till here 26105
2014-07-13 23:27:31,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319250054 with entries=67, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319251557
2014-07-13 23:27:33,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:33,337 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26182 synced till here 26180
2014-07-13 23:27:33,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319251557 with entries=74, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319253079
2014-07-13 23:27:34,644 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:34,664 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26249 synced till here 26246
2014-07-13 23:27:35,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319253079 with entries=67, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319254645
2014-07-13 23:27:36,689 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:36,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26345 synced till here 26323
2014-07-13 23:27:36,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319254645 with entries=96, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319256689
2014-07-13 23:27:38,404 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:38,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26456 synced till here 26441
2014-07-13 23:27:38,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319256689 with entries=111, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319258405
2014-07-13 23:27:40,941 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:41,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26593 synced till here 26567
2014-07-13 23:27:42,268 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319258405 with entries=137, filesize=95.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319260941
2014-07-13 23:27:43,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:44,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26704 synced till here 26669
2014-07-13 23:27:44,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319260941 with entries=111, filesize=90.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319263200
2014-07-13 23:27:44,711 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,711 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,713 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,716 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,717 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,718 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,719 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,721 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,725 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,729 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,729 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,741 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,746 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,836 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,837 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,838 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,838 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,838 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,839 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,839 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,840 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,842 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,887 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,921 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,923 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,929 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,930 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,930 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,931 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,931 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,941 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,958 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:44,989 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,009 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,046 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,074 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,105 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,108 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,466 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,498 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,529 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,534 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,575 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,607 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,748 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:45,779 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:46,626 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:46,644 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:46,658 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:46,684 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:27:46,832 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8403, memsize=308.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/91432a61750e4002b21398aebec9af4a
2014-07-13 23:27:46,847 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/91432a61750e4002b21398aebec9af4a as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/91432a61750e4002b21398aebec9af4a
2014-07-13 23:27:46,859 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/91432a61750e4002b21398aebec9af4a, entries=1122050, sequenceid=8403, filesize=79.9m
2014-07-13 23:27:46,860 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~471.9m/494771600, currentsize=239.7m/251336800 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 18372ms, sequenceid=8403, compaction requested=true
2014-07-13 23:27:46,860 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:44), split_queue=0, merge_queue=0
2014-07-13 23:27:46,861 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 177ms
2014-07-13 23:27:46,861 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,861 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 203ms
2014-07-13 23:27:46,861 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.0g
2014-07-13 23:27:46,861 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,861 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 217ms
2014-07-13 23:27:46,861 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,861 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 235ms
2014-07-13 23:27:46,861 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,865 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1086ms
2014-07-13 23:27:46,865 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,865 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5743, memsize=388.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/87d8f0459c6640f79bc6b9422203b12c
2014-07-13 23:27:46,865 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1117ms
2014-07-13 23:27:46,866 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,866 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1260ms
2014-07-13 23:27:46,866 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,866 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1292ms
2014-07-13 23:27:46,867 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,867 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1333ms
2014-07-13 23:27:46,867 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,867 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1338ms
2014-07-13 23:27:46,867 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,867 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1369ms
2014-07-13 23:27:46,867 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,870 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1404ms
2014-07-13 23:27:46,870 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,870 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1762ms
2014-07-13 23:27:46,870 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,871 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1766ms
2014-07-13 23:27:46,871 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,871 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1797ms
2014-07-13 23:27:46,871 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,871 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1825ms
2014-07-13 23:27:46,871 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,873 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1863ms
2014-07-13 23:27:46,873 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,873 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1884ms
2014-07-13 23:27:46,873 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,874 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1916ms
2014-07-13 23:27:46,874 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,875 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1933ms
2014-07-13 23:27:46,875 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,877 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1946ms
2014-07-13 23:27:46,877 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,878 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1946ms
2014-07-13 23:27:46,878 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,878 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1948ms
2014-07-13 23:27:46,878 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,878 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1948ms
2014-07-13 23:27:46,878 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,879 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1950ms
2014-07-13 23:27:46,879 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,879 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1956ms
2014-07-13 23:27:46,879 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,879 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1958ms
2014-07-13 23:27:46,879 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,879 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1992ms
2014-07-13 23:27:46,879 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,880 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2038ms
2014-07-13 23:27:46,880 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,885 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2045ms
2014-07-13 23:27:46,885 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,885 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2046ms
2014-07-13 23:27:46,885 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,885 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2046ms
2014-07-13 23:27:46,885 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,893 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2056ms
2014-07-13 23:27:46,893 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,893 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2056ms
2014-07-13 23:27:46,893 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,899 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2063ms
2014-07-13 23:27:46,899 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,899 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2063ms
2014-07-13 23:27:46,900 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,901 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2064ms
2014-07-13 23:27:46,901 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,901 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2155ms
2014-07-13 23:27:46,901 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,902 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2160ms
2014-07-13 23:27:46,902 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,903 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2174ms
2014-07-13 23:27:46,903 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,903 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2174ms
2014-07-13 23:27:46,903 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,903 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2178ms
2014-07-13 23:27:46,903 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,904 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2183ms
2014-07-13 23:27:46,904 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,905 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/87d8f0459c6640f79bc6b9422203b12c as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/87d8f0459c6640f79bc6b9422203b12c
2014-07-13 23:27:46,906 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2187ms
2014-07-13 23:27:46,906 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,906 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2188ms
2014-07-13 23:27:46,906 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,917 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2200ms
2014-07-13 23:27:46,917 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,918 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2201ms
2014-07-13 23:27:46,918 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,918 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2205ms
2014-07-13 23:27:46,919 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,919 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2208ms
2014-07-13 23:27:46,919 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,921 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2210ms
2014-07-13 23:27:46,921 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:27:46,935 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/87d8f0459c6640f79bc6b9422203b12c, entries=1414390, sequenceid=5743, filesize=100.8m
2014-07-13 23:27:46,942 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~971.2m/1018328480, currentsize=604.4m/633789600 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 28589ms, sequenceid=5743, compaction requested=true
2014-07-13 23:27:46,942 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:45), split_queue=0, merge_queue=0
2014-07-13 23:27:46,942 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 750.6m
2014-07-13 23:27:47,262 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:47,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26825 synced till here 26796
2014-07-13 23:27:47,427 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:27:47,546 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319263200 with entries=121, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319267262
2014-07-13 23:27:47,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319177317
2014-07-13 23:27:47,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319178973
2014-07-13 23:27:47,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319180496
2014-07-13 23:27:47,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319183477
2014-07-13 23:27:47,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319185481
2014-07-13 23:27:47,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319186969
2014-07-13 23:27:47,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319188765
2014-07-13 23:27:47,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319190102
2014-07-13 23:27:47,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319191730
2014-07-13 23:27:47,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319193392
2014-07-13 23:27:47,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319199206
2014-07-13 23:27:47,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319201644
2014-07-13 23:27:47,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319203867
2014-07-13 23:27:48,660 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:27:48,685 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:27:48,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26905 synced till here 26899
2014-07-13 23:27:48,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319267262 with entries=80, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319268920
2014-07-13 23:27:49,173 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:27:50,448 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:50,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26991 synced till here 26986
2014-07-13 23:27:50,615 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319268920 with entries=86, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319270449
2014-07-13 23:27:52,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:52,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27065 synced till here 27053
2014-07-13 23:27:52,406 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319270449 with entries=74, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319272259
2014-07-13 23:27:53,533 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27185 synced till here 27183
2014-07-13 23:27:53,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319272259 with entries=120, filesize=96.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319273533
2014-07-13 23:27:55,190 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:55,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27264 synced till here 27263
2014-07-13 23:27:55,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319273533 with entries=79, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319275190
2014-07-13 23:27:57,295 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:57,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27323 synced till here 27322
2014-07-13 23:27:57,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319275190 with entries=59, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319277295
2014-07-13 23:27:58,680 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:58,713 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27389 synced till here 27383
2014-07-13 23:27:58,765 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319277295 with entries=66, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319278680
2014-07-13 23:27:59,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:27:59,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27459 synced till here 27454
2014-07-13 23:28:00,069 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319278680 with entries=70, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319279882
2014-07-13 23:28:03,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:03,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27588 synced till here 27542
2014-07-13 23:28:03,574 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,575 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,576 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,577 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,577 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,578 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,585 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319279882 with entries=129, filesize=106.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319283151
2014-07-13 23:28:03,614 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,632 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,647 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,648 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,652 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,689 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,721 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,739 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,747 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,781 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,781 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,781 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,782 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,782 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,783 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,783 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,783 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,785 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,785 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,785 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,787 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,790 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,791 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,792 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,794 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,798 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,798 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,807 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,829 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,843 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,845 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,865 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,868 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,897 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:03,953 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:04,010 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:04,051 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:04,053 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:04,131 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:04,131 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:04,185 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:06,001 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:06,031 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:06,635 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6066, memsize=309.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/b7c30eebc1264c4c8b9a515c5d1c4ff6
2014-07-13 23:28:06,666 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/b7c30eebc1264c4c8b9a515c5d1c4ff6 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/b7c30eebc1264c4c8b9a515c5d1c4ff6
2014-07-13 23:28:06,681 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/b7c30eebc1264c4c8b9a515c5d1c4ff6, entries=1125400, sequenceid=6066, filesize=80.2m
2014-07-13 23:28:06,681 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~773.3m/810852480, currentsize=372.7m/390847520 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 19739ms, sequenceid=6066, compaction requested=true
2014-07-13 23:28:06,681 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:46), split_queue=0, merge_queue=0
2014-07-13 23:28:06,682 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 652ms
2014-07-13 23:28:06,682 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,682 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 997.0m
2014-07-13 23:28:06,682 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 682ms
2014-07-13 23:28:06,682 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,682 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2498ms
2014-07-13 23:28:06,682 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,683 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2551ms
2014-07-13 23:28:06,683 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,685 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2554ms
2014-07-13 23:28:06,685 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,685 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2632ms
2014-07-13 23:28:06,685 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,685 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2634ms
2014-07-13 23:28:06,685 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,686 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2676ms
2014-07-13 23:28:06,686 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,689 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2736ms
2014-07-13 23:28:06,689 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,689 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2793ms
2014-07-13 23:28:06,690 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,691 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2822ms
2014-07-13 23:28:06,691 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,691 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2826ms
2014-07-13 23:28:06,691 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,694 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2849ms
2014-07-13 23:28:06,694 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,694 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2851ms
2014-07-13 23:28:06,694 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,695 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2865ms
2014-07-13 23:28:06,695 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,697 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2890ms
2014-07-13 23:28:06,697 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,697 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2899ms
2014-07-13 23:28:06,697 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,701 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2903ms
2014-07-13 23:28:06,701 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,705 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2911ms
2014-07-13 23:28:06,705 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,705 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2913ms
2014-07-13 23:28:06,705 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,705 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2914ms
2014-07-13 23:28:06,705 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,705 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2915ms
2014-07-13 23:28:06,705 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,709 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2922ms
2014-07-13 23:28:06,709 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,709 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2924ms
2014-07-13 23:28:06,709 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,710 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2925ms
2014-07-13 23:28:06,710 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,713 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2928ms
2014-07-13 23:28:06,713 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,714 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2930ms
2014-07-13 23:28:06,714 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,714 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2931ms
2014-07-13 23:28:06,714 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,714 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2932ms
2014-07-13 23:28:06,714 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,714 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2932ms
2014-07-13 23:28:06,714 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,717 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2935ms
2014-07-13 23:28:06,717 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,718 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2937ms
2014-07-13 23:28:06,718 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,718 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2937ms
2014-07-13 23:28:06,718 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,719 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2938ms
2014-07-13 23:28:06,719 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,719 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2972ms
2014-07-13 23:28:06,719 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,719 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2980ms
2014-07-13 23:28:06,719 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,719 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2998ms
2014-07-13 23:28:06,719 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,721 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3032ms
2014-07-13 23:28:06,721 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,725 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3073ms
2014-07-13 23:28:06,725 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,725 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3077ms
2014-07-13 23:28:06,725 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,725 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3078ms
2014-07-13 23:28:06,725 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,726 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3094ms
2014-07-13 23:28:06,726 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,726 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3113ms
2014-07-13 23:28:06,726 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,727 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3142ms
2014-07-13 23:28:06,727 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,729 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3151ms
2014-07-13 23:28:06,729 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,730 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3153ms
2014-07-13 23:28:06,730 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,730 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3153ms
2014-07-13 23:28:06,730 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,730 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3154ms
2014-07-13 23:28:06,730 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,731 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3155ms
2014-07-13 23:28:06,731 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:06,731 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3157ms
2014-07-13 23:28:06,731 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:07,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:07,434 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:28:08,678 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27693 synced till here 27683
2014-07-13 23:28:08,780 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319283151 with entries=105, filesize=89.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319287434
2014-07-13 23:28:08,932 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:28:10,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:10,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27797 synced till here 27768
2014-07-13 23:28:11,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319287434 with entries=104, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319290748
2014-07-13 23:28:12,573 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:12,605 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27896 synced till here 27870
2014-07-13 23:28:13,110 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319290748 with entries=99, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319292573
2014-07-13 23:28:14,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:14,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319292573 with entries=101, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319294356
2014-07-13 23:28:15,814 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:15,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28070 synced till here 28066
2014-07-13 23:28:15,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319294356 with entries=73, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319295814
2014-07-13 23:28:16,060 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,088 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,110 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,122 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,159 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,187 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,190 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,206 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,207 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,248 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,266 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,316 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,367 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,367 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,375 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,376 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,376 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,415 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,418 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,529 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,569 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,587 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,621 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,637 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,671 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,682 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,714 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,743 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,776 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,807 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,811 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,812 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,827 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,827 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,827 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,849 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,850 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,850 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:16,851 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,430 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,431 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,431 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,437 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,474 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,483 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,523 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,561 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,602 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,636 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:18,676 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:19,069 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6065, memsize=498.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/df840584b3194a97a6b0e2d0d6dc2d31
2014-07-13 23:28:19,082 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/df840584b3194a97a6b0e2d0d6dc2d31 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/df840584b3194a97a6b0e2d0d6dc2d31
2014-07-13 23:28:19,107 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/df840584b3194a97a6b0e2d0d6dc2d31, entries=1816300, sequenceid=6065, filesize=129.4m
2014-07-13 23:28:19,108 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1124598000, currentsize=584.6m/613015200 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 32247ms, sequenceid=6065, compaction requested=true
2014-07-13 23:28:19,108 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:47), split_queue=0, merge_queue=0
2014-07-13 23:28:19,109 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 433ms
2014-07-13 23:28:19,109 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,109 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 473ms
2014-07-13 23:28:19,109 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 608.1m
2014-07-13 23:28:19,109 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,110 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 508ms
2014-07-13 23:28:19,110 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,110 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 549ms
2014-07-13 23:28:19,110 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,110 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 587ms
2014-07-13 23:28:19,110 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,113 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 630ms
2014-07-13 23:28:19,113 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,113 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 639ms
2014-07-13 23:28:19,113 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,114 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 677ms
2014-07-13 23:28:19,114 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,114 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 683ms
2014-07-13 23:28:19,114 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,114 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 683ms
2014-07-13 23:28:19,114 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,115 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 685ms
2014-07-13 23:28:19,115 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,115 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2264ms
2014-07-13 23:28:19,115 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,121 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2271ms
2014-07-13 23:28:19,121 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,121 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2271ms
2014-07-13 23:28:19,121 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,121 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2272ms
2014-07-13 23:28:19,121 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,121 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2294ms
2014-07-13 23:28:19,122 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,124 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2297ms
2014-07-13 23:28:19,130 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,130 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2303ms
2014-07-13 23:28:19,130 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,130 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2319ms
2014-07-13 23:28:19,131 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,134 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2322ms
2014-07-13 23:28:19,134 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,134 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2327ms
2014-07-13 23:28:19,134 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,134 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2358ms
2014-07-13 23:28:19,134 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,134 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2391ms
2014-07-13 23:28:19,134 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,135 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2420ms
2014-07-13 23:28:19,135 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,135 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2453ms
2014-07-13 23:28:19,135 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,136 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2465ms
2014-07-13 23:28:19,136 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,138 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2499ms
2014-07-13 23:28:19,138 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,143 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2521ms
2014-07-13 23:28:19,143 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,143 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2556ms
2014-07-13 23:28:19,143 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,153 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2584ms
2014-07-13 23:28:19,154 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,154 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2625ms
2014-07-13 23:28:19,154 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,156 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2737ms
2014-07-13 23:28:19,156 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,156 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2742ms
2014-07-13 23:28:19,156 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,157 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2781ms
2014-07-13 23:28:19,157 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,157 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2782ms
2014-07-13 23:28:19,157 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,158 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2782ms
2014-07-13 23:28:19,158 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,160 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2792ms
2014-07-13 23:28:19,160 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,169 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2802ms
2014-07-13 23:28:19,170 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,177 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2861ms
2014-07-13 23:28:19,177 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,178 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2911ms
2014-07-13 23:28:19,178 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,178 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2930ms
2014-07-13 23:28:19,178 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,178 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2971ms
2014-07-13 23:28:19,178 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,179 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2973ms
2014-07-13 23:28:19,180 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,180 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2990ms
2014-07-13 23:28:19,180 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,182 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2995ms
2014-07-13 23:28:19,182 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,182 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3023ms
2014-07-13 23:28:19,183 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,183 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3062ms
2014-07-13 23:28:19,183 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,184 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3074ms
2014-07-13 23:28:19,184 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,184 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3096ms
2014-07-13 23:28:19,184 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,184 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3124ms
2014-07-13 23:28:19,184 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:19,356 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:28:19,754 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:28:19,783 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:20,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28230 synced till here 28206
2014-07-13 23:28:20,911 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319295814 with entries=160, filesize=101.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319299783
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319205738
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319207958
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319209433
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319210939
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319212068
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319213768
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319215147
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319216514
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319218160
2014-07-13 23:28:20,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319222030
2014-07-13 23:28:20,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319224261
2014-07-13 23:28:20,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319226541
2014-07-13 23:28:22,283 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:22,304 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28307 synced till here 28294
2014-07-13 23:28:22,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319299783 with entries=77, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319302283
2014-07-13 23:28:23,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:23,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319302283 with entries=64, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319303325
2014-07-13 23:28:24,751 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:24,788 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319303325 with entries=63, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319304752
2014-07-13 23:28:25,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:25,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28496 synced till here 28494
2014-07-13 23:28:26,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319304752 with entries=62, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319305879
2014-07-13 23:28:26,988 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:27,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319305879 with entries=84, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319306988
2014-07-13 23:28:28,679 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:28,701 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28649 synced till here 28646
2014-07-13 23:28:28,733 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319306988 with entries=69, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319308680
2014-07-13 23:28:29,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:29,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28728 synced till here 28726
2014-07-13 23:28:29,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319308680 with entries=79, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319309801
2014-07-13 23:28:30,386 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,389 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,389 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,391 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,431 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,451 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,474 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,486 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,497 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,497 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,526 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,559 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,562 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,584 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,586 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,633 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,634 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,669 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,679 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,844 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,845 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,848 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,848 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,865 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,922 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:30,952 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,019 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,066 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,069 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,107 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,108 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,113 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,155 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,156 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,159 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,160 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,161 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,199 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,199 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,211 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,219 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,221 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,226 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,249 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,259 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,263 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,276 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,288 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,300 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:31,303 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:35,387 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,389 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,390 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,391 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,432 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,451 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,474 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,486 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,497 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,498 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,526 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,553 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6251, memsize=515.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/c5936faaf1e54fce81e4c7998ad18b73
2014-07-13 23:28:35,559 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,562 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,571 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/c5936faaf1e54fce81e4c7998ad18b73 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c5936faaf1e54fce81e4c7998ad18b73
2014-07-13 23:28:35,584 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,587 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,589 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c5936faaf1e54fce81e4c7998ad18b73, entries=1876990, sequenceid=6251, filesize=133.7m
2014-07-13 23:28:35,589 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~997.0m/1045432720, currentsize=517.5m/542682960 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 28907ms, sequenceid=6251, compaction requested=true
2014-07-13 23:28:35,589 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:48), split_queue=0, merge_queue=0
2014-07-13 23:28:35,590 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-13 23:28:35,590 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,590 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5007ms
2014-07-13 23:28:35,590 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 872.4m
2014-07-13 23:28:35,590 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,590 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5028ms
2014-07-13 23:28:35,590 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,590 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5031ms
2014-07-13 23:28:35,590 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,590 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5064ms
2014-07-13 23:28:35,591 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,591 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5094ms
2014-07-13 23:28:35,591 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,597 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5101ms
2014-07-13 23:28:35,597 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,597 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5111ms
2014-07-13 23:28:35,597 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,597 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5123ms
2014-07-13 23:28:35,597 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,609 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5158ms
2014-07-13 23:28:35,609 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,609 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5178ms
2014-07-13 23:28:35,609 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,609 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5218ms
2014-07-13 23:28:35,609 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,609 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5220ms
2014-07-13 23:28:35,609 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,609 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5221ms
2014-07-13 23:28:35,610 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,610 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5224ms
2014-07-13 23:28:35,610 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,611 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4308ms
2014-07-13 23:28:35,611 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,614 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4313ms
2014-07-13 23:28:35,614 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,614 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4326ms
2014-07-13 23:28:35,614 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,615 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4338ms
2014-07-13 23:28:35,615 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,616 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4352ms
2014-07-13 23:28:35,633 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,633 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4374ms
2014-07-13 23:28:35,633 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,633 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4385ms
2014-07-13 23:28:35,633 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,634 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4408ms
2014-07-13 23:28:35,634 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,635 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:28:35,635 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,645 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4424ms
2014-07-13 23:28:35,645 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,645 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4427ms
2014-07-13 23:28:35,646 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,648 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4437ms
2014-07-13 23:28:35,648 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,649 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4449ms
2014-07-13 23:28:35,649 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,650 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4450ms
2014-07-13 23:28:35,650 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,661 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4500ms
2014-07-13 23:28:35,661 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,661 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4501ms
2014-07-13 23:28:35,661 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,662 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4502ms
2014-07-13 23:28:35,662 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,663 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4506ms
2014-07-13 23:28:35,663 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,664 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4508ms
2014-07-13 23:28:35,664 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,664 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4551ms
2014-07-13 23:28:35,664 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,668 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4560ms
2014-07-13 23:28:35,669 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,669 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4562ms
2014-07-13 23:28:35,669 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,670 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4600ms
2014-07-13 23:28:35,670 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,671 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4604ms
2014-07-13 23:28:35,671 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,672 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4652ms
2014-07-13 23:28:35,672 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,679 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:28:35,679 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,680 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4728ms
2014-07-13 23:28:35,680 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,682 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4760ms
2014-07-13 23:28:35,682 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,682 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4817ms
2014-07-13 23:28:35,682 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,682 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4834ms
2014-07-13 23:28:35,682 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,682 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4834ms
2014-07-13 23:28:35,682 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,689 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4844ms
2014-07-13 23:28:35,689 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,689 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4845ms
2014-07-13 23:28:35,689 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,690 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5020ms
2014-07-13 23:28:35,690 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,690 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5057ms
2014-07-13 23:28:35,690 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:28:35,771 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:28:37,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:37,369 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28839 synced till here 28813
2014-07-13 23:28:37,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319309801 with entries=111, filesize=78.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319317278
2014-07-13 23:28:37,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319228187
2014-07-13 23:28:37,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319239794
2014-07-13 23:28:37,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319241620
2014-07-13 23:28:37,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319243414
2014-07-13 23:28:37,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319244893
2014-07-13 23:28:37,600 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:28:39,210 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:39,271 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28942 synced till here 28914
2014-07-13 23:28:39,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319317278 with entries=103, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319319211
2014-07-13 23:28:41,225 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9052, memsize=406.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/adaab50c6c3e4cd79b9b46ed056f5f0c
2014-07-13 23:28:41,250 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/adaab50c6c3e4cd79b9b46ed056f5f0c as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/adaab50c6c3e4cd79b9b46ed056f5f0c
2014-07-13 23:28:41,275 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/adaab50c6c3e4cd79b9b46ed056f5f0c, entries=1478530, sequenceid=9052, filesize=105.3m
2014-07-13 23:28:41,275 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~608.1m/637624960, currentsize=288.3m/302274080 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 22166ms, sequenceid=9052, compaction requested=true
2014-07-13 23:28:41,276 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:49), split_queue=0, merge_queue=0
2014-07-13 23:28:41,276 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 983.4m
2014-07-13 23:28:41,375 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:41,376 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:28:41,387 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29053 synced till here 29030
2014-07-13 23:28:41,719 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319319211 with entries=111, filesize=89.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319321375
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319246876
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319248490
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319250054
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319251557
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319253079
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319254645
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319256689
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319258405
2014-07-13 23:28:41,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319260941
2014-07-13 23:28:44,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:44,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29180 synced till here 29133
2014-07-13 23:28:45,056 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:28:45,098 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319321375 with entries=127, filesize=118.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319324651
2014-07-13 23:28:46,731 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:46,768 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29289 synced till here 29264
2014-07-13 23:28:47,064 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319324651 with entries=109, filesize=89.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319326731
2014-07-13 23:28:48,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:48,772 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29415 synced till here 29392
2014-07-13 23:28:49,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319326731 with entries=126, filesize=102.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319328724
2014-07-13 23:28:50,527 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:50,633 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29537 synced till here 29513
2014-07-13 23:28:51,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319328724 with entries=122, filesize=96.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319330528
2014-07-13 23:28:52,305 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:52,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29638 synced till here 29619
2014-07-13 23:28:53,245 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319330528 with entries=101, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319332305
2014-07-13 23:28:55,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:55,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29739 synced till here 29708
2014-07-13 23:28:55,696 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319332305 with entries=101, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319335187
2014-07-13 23:28:57,417 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:28:57,423 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,425 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,426 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,438 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29832 synced till here 29811
2014-07-13 23:28:57,496 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,497 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,498 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,499 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,512 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,532 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,534 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:57,536 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,329 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,330 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,331 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,332 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,333 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,333 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,335 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,335 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,336 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,337 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,338 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,339 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,339 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,340 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,340 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,340 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,340 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,341 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,341 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,341 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319335187 with entries=93, filesize=84.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319337417
2014-07-13 23:28:58,408 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,430 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,430 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,431 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,437 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,438 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,438 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,439 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,440 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,829 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,835 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,835 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,839 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,842 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,842 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,869 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,887 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:28:58,888 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:02,423 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,426 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,426 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,439 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:02,496 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,497 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,498 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,499 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,512 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,532 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:02,535 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:02,536 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,407 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5067ms
2014-07-13 23:29:03,408 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5072ms
2014-07-13 23:29:03,408 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,409 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5081ms
2014-07-13 23:29:03,409 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-13 23:29:03,409 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5078ms
2014-07-13 23:29:03,409 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5077ms
2014-07-13 23:29:03,409 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5076ms
2014-07-13 23:29:03,410 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5075ms
2014-07-13 23:29:03,410 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5077ms
2014-07-13 23:29:03,410 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5074ms
2014-07-13 23:29:03,410 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5073ms
2014-07-13 23:29:03,410 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5072ms
2014-07-13 23:29:03,411 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5072ms
2014-07-13 23:29:03,411 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5071ms
2014-07-13 23:29:03,411 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5071ms
2014-07-13 23:29:03,411 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5071ms
2014-07-13 23:29:03,411 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5073ms
2014-07-13 23:29:03,412 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5072ms
2014-07-13 23:29:03,412 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5072ms
2014-07-13 23:29:03,412 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5071ms
2014-07-13 23:29:03,430 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,431 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:03,431 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,437 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,438 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:03,439 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:03,440 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:03,440 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,830 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,835 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,835 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,840 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:03,842 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,843 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:03,870 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:03,888 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:29:03,888 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:29:06,086 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6523, memsize=463.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/7160da18b8234eb5a0917e001b769e55
2014-07-13 23:29:06,101 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/7160da18b8234eb5a0917e001b769e55 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7160da18b8234eb5a0917e001b769e55
2014-07-13 23:29:06,114 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7160da18b8234eb5a0917e001b769e55, entries=1688240, sequenceid=6523, filesize=120.2m
2014-07-13 23:29:06,114 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~872.4m/914756800, currentsize=416.1m/436349200 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 30524ms, sequenceid=6523, compaction requested=true
2014-07-13 23:29:06,114 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:50), split_queue=0, merge_queue=0
2014-07-13 23:29:06,115 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7227ms
2014-07-13 23:29:06,115 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,115 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 918.6m
2014-07-13 23:29:06,118 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7231ms
2014-07-13 23:29:06,118 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,118 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7249ms
2014-07-13 23:29:06,119 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,119 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7277ms
2014-07-13 23:29:06,119 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,119 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7277ms
2014-07-13 23:29:06,119 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,119 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7280ms
2014-07-13 23:29:06,119 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,121 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7286ms
2014-07-13 23:29:06,121 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,121 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7286ms
2014-07-13 23:29:06,121 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,121 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7292ms
2014-07-13 23:29:06,121 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,122 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7681ms
2014-07-13 23:29:06,122 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,122 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7683ms
2014-07-13 23:29:06,122 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,122 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7684ms
2014-07-13 23:29:06,122 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,125 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7688ms
2014-07-13 23:29:06,125 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,125 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7688ms
2014-07-13 23:29:06,125 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,125 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7694ms
2014-07-13 23:29:06,125 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,127 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7697ms
2014-07-13 23:29:06,127 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,127 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7697ms
2014-07-13 23:29:06,127 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,127 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7786ms
2014-07-13 23:29:06,128 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,128 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7788ms
2014-07-13 23:29:06,128 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,128 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7788ms
2014-07-13 23:29:06,128 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,128 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7790ms
2014-07-13 23:29:06,128 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,128 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7788ms
2014-07-13 23:29:06,128 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,128 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7788ms
2014-07-13 23:29:06,129 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,129 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7789ms
2014-07-13 23:29:06,129 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,130 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7791ms
2014-07-13 23:29:06,131 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,132 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7794ms
2014-07-13 23:29:06,132 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,132 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7795ms
2014-07-13 23:29:06,133 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,133 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7797ms
2014-07-13 23:29:06,133 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,136 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7803ms
2014-07-13 23:29:06,136 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,140 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7805ms
2014-07-13 23:29:06,140 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,140 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7807ms
2014-07-13 23:29:06,140 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,140 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7808ms
2014-07-13 23:29:06,140 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,140 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7809ms
2014-07-13 23:29:06,140 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,140 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7810ms
2014-07-13 23:29:06,140 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,140 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7812ms
2014-07-13 23:29:06,173 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,185 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7777ms
2014-07-13 23:29:06,185 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,185 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7850ms
2014-07-13 23:29:06,185 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,186 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7846ms
2014-07-13 23:29:06,186 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,186 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8650ms
2014-07-13 23:29:06,187 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,187 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8653ms
2014-07-13 23:29:06,187 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,197 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8665ms
2014-07-13 23:29:06,198 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,198 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8686ms
2014-07-13 23:29:06,198 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,199 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8699ms
2014-07-13 23:29:06,199 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,199 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8701ms
2014-07-13 23:29:06,200 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,201 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8704ms
2014-07-13 23:29:06,201 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,205 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8709ms
2014-07-13 23:29:06,205 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,208 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8770ms
2014-07-13 23:29:06,208 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,213 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8787ms
2014-07-13 23:29:06,213 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,213 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8788ms
2014-07-13 23:29:06,213 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,215 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8792ms
2014-07-13 23:29:06,215 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:06,365 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:29:07,421 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337374,"queuetimems":0,"class":"HRegionServer","responsesize":17570,"method":"Multi"}
2014-07-13 23:29:07,422 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10035,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337387,"queuetimems":0,"class":"HRegionServer","responsesize":7197,"method":"Multi"}
2014-07-13 23:29:07,421 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10152,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337269,"queuetimems":0,"class":"HRegionServer","responsesize":15857,"method":"Multi"}
2014-07-13 23:29:07,575 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:07,576 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10242,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337334,"queuetimems":1,"class":"HRegionServer","responsesize":18050,"method":"Multi"}
2014-07-13 23:29:07,576 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10450,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337126,"queuetimems":0,"class":"HRegionServer","responsesize":18525,"method":"Multi"}
2014-07-13 23:29:07,576 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10389,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337187,"queuetimems":0,"class":"HRegionServer","responsesize":17582,"method":"Multi"}
2014-07-13 23:29:07,578 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337029,"queuetimems":0,"class":"HRegionServer","responsesize":14641,"method":"Multi"}
2014-07-13 23:29:07,616 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:29:07,682 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29992 synced till here 29964
2014-07-13 23:29:07,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319337417 with entries=160, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319347575
2014-07-13 23:29:08,006 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10510,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319337495,"queuetimems":0,"class":"HRegionServer","responsesize":17929,"method":"Multi"}
2014-07-13 23:29:10,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:10,155 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30081 synced till here 30073
2014-07-13 23:29:10,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319347575 with entries=89, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319350139
2014-07-13 23:29:11,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:11,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30189 synced till here 30188
2014-07-13 23:29:11,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319350139 with entries=108, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319351790
2014-07-13 23:29:13,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:13,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319351790 with entries=139, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319353670
2014-07-13 23:29:15,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:15,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30402 synced till here 30398
2014-07-13 23:29:15,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319353670 with entries=74, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319355129
2014-07-13 23:29:15,604 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6589, memsize=508.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/bbd2de78a262414b997bc994c1dfb322
2014-07-13 23:29:15,615 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/bbd2de78a262414b997bc994c1dfb322 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/bbd2de78a262414b997bc994c1dfb322
2014-07-13 23:29:15,625 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/bbd2de78a262414b997bc994c1dfb322, entries=1850790, sequenceid=6589, filesize=131.8m
2014-07-13 23:29:15,625 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1008.4m/1057424240, currentsize=466.1m/488782240 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 34349ms, sequenceid=6589, compaction requested=true
2014-07-13 23:29:15,626 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:51), split_queue=0, merge_queue=0
2014-07-13 23:29:15,626 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 741.0m
2014-07-13 23:29:15,743 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:29:16,020 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:16,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30473 synced till here 30469
2014-07-13 23:29:16,863 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319355129 with entries=71, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319356021
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319263200
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319267262
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319268920
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319270449
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319272259
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319273533
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319275190
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319277295
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319278680
2014-07-13 23:29:16,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319279882
2014-07-13 23:29:16,940 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:29:17,779 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:18,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30546 synced till here 30545
2014-07-13 23:29:18,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319356021 with entries=73, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319357780
2014-07-13 23:29:19,298 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:19,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319357780 with entries=59, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319359298
2014-07-13 23:29:20,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:21,284 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30685 synced till here 30683
2014-07-13 23:29:21,311 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319359298 with entries=80, filesize=79.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319360527
2014-07-13 23:29:23,121 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:23,133 DEBUG [LruStats #0] hfile.LruBlockCache: Total=5.03 MB, free=3.95 GB, max=3.96 GB, blocks=9, accesses=155144, hits=43046, hitRatio=27.74%, , cachingAccesses=43065, cachingHits=43031, cachingHitsRatio=99.92%, evictions=0, evicted=25, evictedPerRun=Infinity
2014-07-13 23:29:23,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30784 synced till here 30768
2014-07-13 23:29:23,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319360527 with entries=99, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319363122
2014-07-13 23:29:24,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:24,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30902 synced till here 30878
2014-07-13 23:29:25,039 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319363122 with entries=118, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319364840
2014-07-13 23:29:26,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:26,541 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30983 synced till here 30975
2014-07-13 23:29:26,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319364840 with entries=81, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319366340
2014-07-13 23:29:26,834 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6743, memsize=290.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4d127bb2abac4b0da42605efe8af252f
2014-07-13 23:29:26,858 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4d127bb2abac4b0da42605efe8af252f as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4d127bb2abac4b0da42605efe8af252f
2014-07-13 23:29:27,118 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4d127bb2abac4b0da42605efe8af252f, entries=1055710, sequenceid=6743, filesize=75.2m
2014-07-13 23:29:27,118 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~918.6m/963173520, currentsize=439.4m/460792080 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 21003ms, sequenceid=6743, compaction requested=true
2014-07-13 23:29:27,119 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:52), split_queue=0, merge_queue=0
2014-07-13 23:29:27,119 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 844.3m
2014-07-13 23:29:27,121 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:29:27,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:27,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31040 synced till here 31038
2014-07-13 23:29:27,815 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319366340 with entries=57, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319367338
2014-07-13 23:29:27,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319283151
2014-07-13 23:29:27,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319287434
2014-07-13 23:29:27,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319290748
2014-07-13 23:29:27,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319292573
2014-07-13 23:29:27,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319294356
2014-07-13 23:29:28,362 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:29:29,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:29,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31107 synced till here 31106
2014-07-13 23:29:29,884 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319367338 with entries=67, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319369242
2014-07-13 23:29:30,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:30,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31172 synced till here 31169
2014-07-13 23:29:30,718 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319369242 with entries=65, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319370654
2014-07-13 23:29:31,837 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:31,859 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31245 synced till here 31243
2014-07-13 23:29:31,897 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319370654 with entries=73, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319371838
2014-07-13 23:29:33,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:33,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31328 synced till here 31315
2014-07-13 23:29:33,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319371838 with entries=83, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319373606
2014-07-13 23:29:35,022 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1108ms
GC pool 'ParNew' had collection(s): count=1 time=1115ms
2014-07-13 23:29:35,696 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9916, memsize=285.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/0d2a032c60944df982467dd6a1aff28b
2014-07-13 23:29:35,711 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/0d2a032c60944df982467dd6a1aff28b as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/0d2a032c60944df982467dd6a1aff28b
2014-07-13 23:29:35,721 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/0d2a032c60944df982467dd6a1aff28b, entries=1041050, sequenceid=9916, filesize=74.2m
2014-07-13 23:29:35,722 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~748.0m/784353120, currentsize=323.6m/339282000 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 20096ms, sequenceid=9916, compaction requested=true
2014-07-13 23:29:35,722 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:53), split_queue=0, merge_queue=0
2014-07-13 23:29:35,722 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 872.4m
2014-07-13 23:29:35,761 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:29:37,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:37,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31454 synced till here 31442
2014-07-13 23:29:37,589 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319373606 with entries=126, filesize=101.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319377401
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319295814
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319299783
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319302283
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319303325
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319304752
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319305879
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319306988
2014-07-13 23:29:37,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319308680
2014-07-13 23:29:39,029 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:29:39,173 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:39,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31557 synced till here 31525
2014-07-13 23:29:39,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319377401 with entries=103, filesize=93.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319379173
2014-07-13 23:29:41,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:41,319 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31655 synced till here 31629
2014-07-13 23:29:41,514 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319379173 with entries=98, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319381253
2014-07-13 23:29:42,970 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1088ms
GC pool 'ParNew' had collection(s): count=1 time=1136ms
2014-07-13 23:29:43,496 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:43,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31758 synced till here 31737
2014-07-13 23:29:43,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319381253 with entries=103, filesize=78.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319383496
2014-07-13 23:29:45,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:46,015 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319383496 with entries=122, filesize=105.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319385516
2014-07-13 23:29:47,630 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:47,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31963 synced till here 31956
2014-07-13 23:29:47,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319385516 with entries=83, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319387631
2014-07-13 23:29:49,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:49,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32041 synced till here 32039
2014-07-13 23:29:49,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319387631 with entries=78, filesize=74.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319389768
2014-07-13 23:29:51,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:51,222 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32114 synced till here 32108
2014-07-13 23:29:51,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319389768 with entries=73, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319391058
2014-07-13 23:29:52,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:52,533 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:52,535 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:52,536 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:52,537 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:52,537 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:52,537 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:52,538 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:52,539 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,111 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,113 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,113 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,130 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,130 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,130 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,131 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32187 synced till here 32178
2014-07-13 23:29:53,132 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,146 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,147 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,154 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,156 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,165 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,165 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,165 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,175 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,176 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,182 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,184 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,184 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,222 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,257 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,278 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319391058 with entries=73, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319392528
2014-07-13 23:29:53,287 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,304 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,327 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,328 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,335 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,353 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,386 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,388 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,406 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,407 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,414 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,416 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,432 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6992, memsize=313.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/ba8202c46afc4c7493fb2ee4082558ec
2014-07-13 23:29:53,448 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/ba8202c46afc4c7493fb2ee4082558ec as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ba8202c46afc4c7493fb2ee4082558ec
2014-07-13 23:29:53,450 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,450 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,451 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,452 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,468 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,471 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:29:53,479 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ba8202c46afc4c7493fb2ee4082558ec, entries=1142000, sequenceid=6992, filesize=81.3m
2014-07-13 23:29:53,480 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~846.7m/887779360, currentsize=520.8m/546063840 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 26361ms, sequenceid=6992, compaction requested=true
2014-07-13 23:29:53,480 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:54), split_queue=0, merge_queue=0
2014-07-13 23:29:53,480 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9ms
2014-07-13 23:29:53,480 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,481 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13ms
2014-07-13 23:29:53,481 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,481 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 955.4m
2014-07-13 23:29:53,481 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 29ms
2014-07-13 23:29:53,481 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,481 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 30ms
2014-07-13 23:29:53,481 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,481 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31ms
2014-07-13 23:29:53,481 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,481 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31ms
2014-07-13 23:29:53,481 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,481 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 65ms
2014-07-13 23:29:53,481 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,481 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 67ms
2014-07-13 23:29:53,481 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,482 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 75ms
2014-07-13 23:29:53,482 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,482 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 76ms
2014-07-13 23:29:53,482 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,482 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 94ms
2014-07-13 23:29:53,483 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,483 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 97ms
2014-07-13 23:29:53,483 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,483 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 130ms
2014-07-13 23:29:53,483 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,484 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 149ms
2014-07-13 23:29:53,484 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,484 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 156ms
2014-07-13 23:29:53,485 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,485 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 158ms
2014-07-13 23:29:53,485 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,486 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 182ms
2014-07-13 23:29:53,486 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,486 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 199ms
2014-07-13 23:29:53,486 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,486 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 229ms
2014-07-13 23:29:53,487 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,493 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 271ms
2014-07-13 23:29:53,493 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,493 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 309ms
2014-07-13 23:29:53,493 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,495 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 312ms
2014-07-13 23:29:53,495 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,495 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 313ms
2014-07-13 23:29:53,495 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,496 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 320ms
2014-07-13 23:29:53,496 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,496 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 321ms
2014-07-13 23:29:53,496 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,497 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 332ms
2014-07-13 23:29:53,497 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,500 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 335ms
2014-07-13 23:29:53,501 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,501 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 336ms
2014-07-13 23:29:53,501 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,501 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 345ms
2014-07-13 23:29:53,501 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,501 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 347ms
2014-07-13 23:29:53,501 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,501 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 354ms
2014-07-13 23:29:53,501 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,509 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 363ms
2014-07-13 23:29:53,509 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,509 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 377ms
2014-07-13 23:29:53,509 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,509 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 379ms
2014-07-13 23:29:53,509 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,509 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 380ms
2014-07-13 23:29:53,509 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,512 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 383ms
2014-07-13 23:29:53,512 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,513 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 400ms
2014-07-13 23:29:53,513 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,517 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 404ms
2014-07-13 23:29:53,517 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,517 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 406ms
2014-07-13 23:29:53,517 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,517 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 978ms
2014-07-13 23:29:53,517 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,517 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 979ms
2014-07-13 23:29:53,517 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,517 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 980ms
2014-07-13 23:29:53,518 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,554 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1017ms
2014-07-13 23:29:53,554 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,557 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1021ms
2014-07-13 23:29:53,557 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,560 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1024ms
2014-07-13 23:29:53,560 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,561 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1026ms
2014-07-13 23:29:53,561 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,561 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1028ms
2014-07-13 23:29:53,561 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:29:53,940 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:29:55,172 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:29:55,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:55,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32313 synced till here 32277
2014-07-13 23:29:55,576 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319392528 with entries=126, filesize=95.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319395182
2014-07-13 23:29:55,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319309801
2014-07-13 23:29:55,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319317278
2014-07-13 23:29:55,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319319211
2014-07-13 23:29:56,776 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:56,820 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32410 synced till here 32404
2014-07-13 23:29:56,886 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319395182 with entries=97, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319396777
2014-07-13 23:29:58,040 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:29:58,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32488 synced till here 32483
2014-07-13 23:29:58,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319396777 with entries=78, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319398040
2014-07-13 23:29:59,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:01,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32588 synced till here 32584
2014-07-13 23:30:01,103 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319398040 with entries=100, filesize=107.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319399674
2014-07-13 23:30:02,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:02,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32663 synced till here 32651
2014-07-13 23:30:03,511 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319399674 with entries=75, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319402871
2014-07-13 23:30:03,972 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:03,975 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:03,981 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:03,986 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:03,987 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:03,990 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,000 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,001 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,003 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,057 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,077 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,078 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,078 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,079 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,080 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,091 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,097 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,103 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,105 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,155 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,158 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,158 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,159 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,161 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,164 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,167 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,169 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,173 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,238 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,238 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,242 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,266 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,274 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,277 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,277 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,282 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,352 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,369 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,383 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,440 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,450 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,451 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,453 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:04,503 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:05,318 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:05,332 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:05,349 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:05,380 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:05,380 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:05,382 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:06,607 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7073, memsize=426.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/1c9e56e057834d75a9ee429a0a1490ba
2014-07-13 23:30:06,699 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/1c9e56e057834d75a9ee429a0a1490ba as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1c9e56e057834d75a9ee429a0a1490ba
2014-07-13 23:30:06,710 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1c9e56e057834d75a9ee429a0a1490ba, entries=1552300, sequenceid=7073, filesize=110.5m
2014-07-13 23:30:06,710 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~895.7m/939179360, currentsize=581.3m/609564800 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 30988ms, sequenceid=7073, compaction requested=true
2014-07-13 23:30:06,710 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:55), split_queue=0, merge_queue=0
2014-07-13 23:30:06,710 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1328ms
2014-07-13 23:30:06,711 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,711 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1331ms
2014-07-13 23:30:06,711 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 710.4m
2014-07-13 23:30:06,711 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,711 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1332ms
2014-07-13 23:30:06,711 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,711 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1362ms
2014-07-13 23:30:06,711 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,712 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1380ms
2014-07-13 23:30:06,712 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,714 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1396ms
2014-07-13 23:30:06,714 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,714 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2212ms
2014-07-13 23:30:06,714 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,714 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2261ms
2014-07-13 23:30:06,714 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,715 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2263ms
2014-07-13 23:30:06,715 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,716 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2266ms
2014-07-13 23:30:06,716 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,717 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2277ms
2014-07-13 23:30:06,717 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,717 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2334ms
2014-07-13 23:30:06,717 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,718 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2350ms
2014-07-13 23:30:06,718 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,718 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2366ms
2014-07-13 23:30:06,718 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,721 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2439ms
2014-07-13 23:30:06,722 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,722 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2446ms
2014-07-13 23:30:06,722 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,722 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2446ms
2014-07-13 23:30:06,722 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,722 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2448ms
2014-07-13 23:30:06,722 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,722 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2457ms
2014-07-13 23:30:06,722 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,722 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2480ms
2014-07-13 23:30:06,723 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,723 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2485ms
2014-07-13 23:30:06,723 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,723 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2486ms
2014-07-13 23:30:06,723 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,724 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2551ms
2014-07-13 23:30:06,724 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,724 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2555ms
2014-07-13 23:30:06,724 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,724 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2557ms
2014-07-13 23:30:06,724 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,725 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2561ms
2014-07-13 23:30:06,725 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,725 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2564ms
2014-07-13 23:30:06,725 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,725 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2566ms
2014-07-13 23:30:06,725 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,728 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2570ms
2014-07-13 23:30:06,728 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,728 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2570ms
2014-07-13 23:30:06,728 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,728 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2573ms
2014-07-13 23:30:06,728 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,735 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2631ms
2014-07-13 23:30:06,735 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,735 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2632ms
2014-07-13 23:30:06,735 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,737 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2640ms
2014-07-13 23:30:06,737 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,737 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2646ms
2014-07-13 23:30:06,737 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,737 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2657ms
2014-07-13 23:30:06,737 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,737 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2658ms
2014-07-13 23:30:06,737 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,738 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2660ms
2014-07-13 23:30:06,738 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,738 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2660ms
2014-07-13 23:30:06,738 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,738 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2661ms
2014-07-13 23:30:06,738 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,738 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2681ms
2014-07-13 23:30:06,738 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,738 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2735ms
2014-07-13 23:30:06,738 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,738 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2737ms
2014-07-13 23:30:06,739 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,739 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2739ms
2014-07-13 23:30:06,739 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,745 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2755ms
2014-07-13 23:30:06,745 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,745 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2759ms
2014-07-13 23:30:06,745 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,745 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2759ms
2014-07-13 23:30:06,745 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,753 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2772ms
2014-07-13 23:30:06,753 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,753 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2778ms
2014-07-13 23:30:06,753 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,753 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2781ms
2014-07-13 23:30:06,753 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:06,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:07,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32772 synced till here 32744
2014-07-13 23:30:08,328 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:30:08,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319402871 with entries=109, filesize=90.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319406936
2014-07-13 23:30:08,357 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319321375
2014-07-13 23:30:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319324651
2014-07-13 23:30:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319326731
2014-07-13 23:30:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319328724
2014-07-13 23:30:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319330528
2014-07-13 23:30:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319332305
2014-07-13 23:30:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319335187
2014-07-13 23:30:08,446 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:30:10,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:10,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32893 synced till here 32891
2014-07-13 23:30:10,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319406936 with entries=121, filesize=99.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319410265
2014-07-13 23:30:12,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:12,265 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33000 synced till here 32968
2014-07-13 23:30:12,610 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319410265 with entries=107, filesize=102.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319412158
2014-07-13 23:30:14,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:14,697 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33117 synced till here 33088
2014-07-13 23:30:14,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319412158 with entries=117, filesize=98.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319414595
2014-07-13 23:30:16,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:16,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33219 synced till here 33201
2014-07-13 23:30:16,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319414595 with entries=102, filesize=88.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319416521
2014-07-13 23:30:17,867 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,873 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,874 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,874 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,874 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,874 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,883 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,883 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,883 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,883 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,883 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,891 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,892 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,893 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,898 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,904 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,906 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,953 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,956 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,957 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,961 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:17,984 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,017 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,076 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,123 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,136 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,148 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,163 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,317 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,372 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,406 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,436 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,472 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,507 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,538 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:18,558 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:19,508 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:19,547 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,244 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,259 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,291 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,312 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,331 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,353 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,393 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,441 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,492 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,533 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,533 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:20,537 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:22,867 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:22,874 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:22,874 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,874 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,874 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,874 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,883 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,883 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,883 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,884 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:22,884 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:22,891 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,893 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:22,893 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,898 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,904 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,906 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:22,953 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,956 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,957 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,961 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:22,984 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:23,018 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:23,076 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,124 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:23,137 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,148 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,163 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,317 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,372 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,406 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,437 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:23,473 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,507 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:23,539 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:30:23,558 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:30:24,736 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5189ms
2014-07-13 23:30:24,736 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5228ms
2014-07-13 23:30:24,754 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7259, memsize=512.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/6b0d5830c1314c91930b9f979d3f1be4
2014-07-13 23:30:24,772 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/6b0d5830c1314c91930b9f979d3f1be4 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6b0d5830c1314c91930b9f979d3f1be4
2014-07-13 23:30:24,788 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6b0d5830c1314c91930b9f979d3f1be4, entries=1867320, sequenceid=7259, filesize=133.0m
2014-07-13 23:30:24,788 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~955.4m/1001773760, currentsize=466.3m/488993680 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 31307ms, sequenceid=7259, compaction requested=true
2014-07-13 23:30:24,789 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:56), split_queue=0, merge_queue=0
2014-07-13 23:30:24,789 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5281ms
2014-07-13 23:30:24,789 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,789 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5242ms
2014-07-13 23:30:24,789 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,789 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 977.8m
2014-07-13 23:30:24,790 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6232ms
2014-07-13 23:30:24,790 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,790 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6252ms
2014-07-13 23:30:24,790 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,790 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6283ms
2014-07-13 23:30:24,790 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,790 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6318ms
2014-07-13 23:30:24,791 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,793 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6357ms
2014-07-13 23:30:24,793 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,793 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6387ms
2014-07-13 23:30:24,793 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,797 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6425ms
2014-07-13 23:30:24,797 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,797 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6480ms
2014-07-13 23:30:24,797 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,809 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6646ms
2014-07-13 23:30:24,809 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,809 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6661ms
2014-07-13 23:30:24,809 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,809 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6673ms
2014-07-13 23:30:24,809 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,810 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6687ms
2014-07-13 23:30:24,810 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,810 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6734ms
2014-07-13 23:30:24,811 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,811 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6794ms
2014-07-13 23:30:24,811 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,811 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6828ms
2014-07-13 23:30:24,811 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,821 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6860ms
2014-07-13 23:30:24,821 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,825 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6868ms
2014-07-13 23:30:24,841 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,841 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6885ms
2014-07-13 23:30:24,841 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,842 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6889ms
2014-07-13 23:30:24,842 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,842 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6937ms
2014-07-13 23:30:24,842 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,842 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6938ms
2014-07-13 23:30:24,842 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,842 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6944ms
2014-07-13 23:30:24,843 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,845 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6952ms
2014-07-13 23:30:24,845 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,845 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6953ms
2014-07-13 23:30:24,845 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,846 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6955ms
2014-07-13 23:30:24,846 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,846 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6963ms
2014-07-13 23:30:24,846 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,857 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6974ms
2014-07-13 23:30:24,857 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,857 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6974ms
2014-07-13 23:30:24,857 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,857 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6974ms
2014-07-13 23:30:24,857 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,858 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6975ms
2014-07-13 23:30:24,858 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,859 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6985ms
2014-07-13 23:30:24,859 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,861 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6987ms
2014-07-13 23:30:24,861 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,861 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6987ms
2014-07-13 23:30:24,861 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,861 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6987ms
2014-07-13 23:30:24,861 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,861 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6988ms
2014-07-13 23:30:24,861 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,863 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6997ms
2014-07-13 23:30:24,863 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,865 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4328ms
2014-07-13 23:30:24,865 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,865 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4332ms
2014-07-13 23:30:24,865 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,865 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4332ms
2014-07-13 23:30:24,865 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,866 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4374ms
2014-07-13 23:30:24,866 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,866 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4426ms
2014-07-13 23:30:24,866 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,866 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4473ms
2014-07-13 23:30:24,866 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,867 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4513ms
2014-07-13 23:30:24,867 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,871 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4540ms
2014-07-13 23:30:24,871 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,871 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4559ms
2014-07-13 23:30:24,871 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,872 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4580ms
2014-07-13 23:30:24,872 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,873 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4614ms
2014-07-13 23:30:24,873 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:24,873 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4629ms
2014-07-13 23:30:24,873 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:25,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:25,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33348 synced till here 33314
2014-07-13 23:30:25,339 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:30:25,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319416521 with entries=129, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319425128
2014-07-13 23:30:25,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319337417
2014-07-13 23:30:25,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319347575
2014-07-13 23:30:25,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319350139
2014-07-13 23:30:25,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319351790
2014-07-13 23:30:25,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319353670
2014-07-13 23:30:25,818 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:30:26,661 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:26,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33443 synced till here 33419
2014-07-13 23:30:26,980 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319425128 with entries=95, filesize=88.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319426661
2014-07-13 23:30:28,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:28,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33547 synced till here 33532
2014-07-13 23:30:28,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319426661 with entries=104, filesize=81.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319428327
2014-07-13 23:30:30,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:30,439 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33651 synced till here 33646
2014-07-13 23:30:30,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319428327 with entries=104, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319430102
2014-07-13 23:30:31,572 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:31,860 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33730 synced till here 33728
2014-07-13 23:30:31,887 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319430102 with entries=79, filesize=81.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319431573
2014-07-13 23:30:33,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:33,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33797 synced till here 33796
2014-07-13 23:30:33,742 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319431573 with entries=67, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319433590
2014-07-13 23:30:34,852 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10704, memsize=535.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/e836bfdbe76d4b908f30af252ae96afd
2014-07-13 23:30:34,867 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/e836bfdbe76d4b908f30af252ae96afd as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/e836bfdbe76d4b908f30af252ae96afd
2014-07-13 23:30:34,882 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/e836bfdbe76d4b908f30af252ae96afd, entries=1949760, sequenceid=10704, filesize=138.9m
2014-07-13 23:30:34,882 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~710.4m/744943360, currentsize=279.4m/292995600 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 28171ms, sequenceid=10704, compaction requested=true
2014-07-13 23:30:34,883 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:57), split_queue=0, merge_queue=0
2014-07-13 23:30:34,883 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.0g
2014-07-13 23:30:34,897 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:30:35,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:35,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33908 synced till here 33907
2014-07-13 23:30:35,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319433590 with entries=111, filesize=95.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319435147
2014-07-13 23:30:35,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319355129
2014-07-13 23:30:35,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319356021
2014-07-13 23:30:35,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319357780
2014-07-13 23:30:35,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319359298
2014-07-13 23:30:35,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319360527
2014-07-13 23:30:35,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319363122
2014-07-13 23:30:35,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319364840
2014-07-13 23:30:36,306 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:30:36,938 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:37,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33988 synced till here 33984
2014-07-13 23:30:37,422 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319435147 with entries=80, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319436938
2014-07-13 23:30:38,599 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:38,618 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34061 synced till here 34059
2014-07-13 23:30:38,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319436938 with entries=73, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319438599
2014-07-13 23:30:39,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:40,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34133 synced till here 34125
2014-07-13 23:30:40,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319438599 with entries=72, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319439694
2014-07-13 23:30:42,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:42,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34218 synced till here 34200
2014-07-13 23:30:42,321 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319439694 with entries=85, filesize=80.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319442102
2014-07-13 23:30:44,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:44,153 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,156 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,157 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,157 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,159 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,161 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,162 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,163 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,164 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,164 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,165 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,166 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,168 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,173 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,175 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,175 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,177 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,177 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,178 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34327 synced till here 34310
2014-07-13 23:30:44,179 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,179 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,180 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,181 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,181 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,186 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,195 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,196 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,201 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,238 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,241 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,263 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,292 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,313 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,314 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319442102 with entries=109, filesize=93.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319444151
2014-07-13 23:30:44,315 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,315 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,316 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,317 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,322 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,324 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,340 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,345 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,372 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,381 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,392 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,405 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,427 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,462 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,497 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,498 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:44,545 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:30:45,284 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/ae2e7da6b7804b759955699158464142 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ae2e7da6b7804b759955699158464142
2014-07-13 23:30:45,325 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:30:45,362 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ac5549187a8c42419c9ea54824354617, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ac5549187a8c42419c9ea54824354617
2014-07-13 23:30:45,381 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5ad17e55e2844166b4075f58619b3875, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5ad17e55e2844166b4075f58619b3875
2014-07-13 23:30:45,388 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7ceb363c18704302ba0ada76718c6c89, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7ceb363c18704302ba0ada76718c6c89
2014-07-13 23:30:45,396 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a45b41143d444337a410cdd2db8af87e, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a45b41143d444337a410cdd2db8af87e
2014-07-13 23:30:45,456 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6af32181696643da8cacecdf1dce6c8a, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6af32181696643da8cacecdf1dce6c8a
2014-07-13 23:30:45,532 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e444f0c359ec479abdded80b02e8768b, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e444f0c359ec479abdded80b02e8768b
2014-07-13 23:30:45,537 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/1acffef0cefc42bfb2c29dba0eee9928, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/1acffef0cefc42bfb2c29dba0eee9928
2014-07-13 23:30:45,544 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/be5aedfee822485b9c21b35a80e0342c, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/be5aedfee822485b9c21b35a80e0342c
2014-07-13 23:30:45,549 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a1ee5f4bfb134f67b53b077785eff35a, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/a1ee5f4bfb134f67b53b077785eff35a
2014-07-13 23:30:45,554 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/3162f70bf10049bf9dee927e21b9d16d, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/3162f70bf10049bf9dee927e21b9d16d
2014-07-13 23:30:45,554 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into ae2e7da6b7804b759955699158464142(size=828.0m), total size for store is 1.6g. This selection was in queue for 0sec, and took 3mins, 19sec to execute.
2014-07-13 23:30:45,554 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., storeName=family, fileCount=10, fileSize=894.7m, priority=8, time=273153791729134; duration=3mins, 19sec
2014-07-13 23:30:45,555 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:57), split_queue=0, merge_queue=0
2014-07-13 23:30:45,555 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 14 store files, 0 compacting, 14 eligible, 20 blocking
2014-07-13 23:30:45,559 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 964124762 starting at candidate #1 after considering 68 permutations with 64 in ratio
2014-07-13 23:30:45,559 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: d679c2853f294b83582eebcd030d1677 - family: Initiating minor compaction
2014-07-13 23:30:45,560 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:30:45,560 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp, totalSize=919.5m
2014-07-13 23:30:45,560 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/4916d9a4d57b4f80903aa88a1a6b9ee3, keycount=75340, bloomtype=ROW, size=53.6m, encoding=NONE, seqNum=1849
2014-07-13 23:30:45,560 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/db3a5c3eedc04b1e8ea02f2b1fa3f471, keycount=61756, bloomtype=ROW, size=44.0m, encoding=NONE, seqNum=2006
2014-07-13 23:30:45,561 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ab775b689f9348019cb0fc4c3d3b99b3, keycount=108521, bloomtype=ROW, size=77.3m, encoding=NONE, seqNum=2212
2014-07-13 23:30:45,561 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/13dc9c4915784adca639394bb2db59ec, keycount=73097, bloomtype=ROW, size=52.1m, encoding=NONE, seqNum=2452
2014-07-13 23:30:45,561 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c71c006a37c4e149cad48f4876e143e, keycount=118795, bloomtype=ROW, size=84.6m, encoding=NONE, seqNum=2796
2014-07-13 23:30:45,561 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/a2b662b94683429989ba4f5884afb92e, keycount=140461, bloomtype=ROW, size=100.0m, encoding=NONE, seqNum=3271
2014-07-13 23:30:45,561 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/40daeef5cbea4d0d8b446fee12020d12, keycount=164408, bloomtype=ROW, size=117.1m, encoding=NONE, seqNum=3875
2014-07-13 23:30:45,562 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1e3e400cda0d4b609c99d9737c1177c6, keycount=186219, bloomtype=ROW, size=132.7m, encoding=NONE, seqNum=4377
2014-07-13 23:30:45,562 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5f1c7bb75e9341ae9aa648260d5d757a, keycount=156084, bloomtype=ROW, size=111.2m, encoding=NONE, seqNum=4913
2014-07-13 23:30:45,562 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1a71dee0da7f47dbb034cc67c7b2907a, keycount=206023, bloomtype=ROW, size=146.8m, encoding=NONE, seqNum=5523
2014-07-13 23:30:45,944 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:30:48,434 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7493, memsize=378.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/8940e542a43a46069c460ef54f1932bb
2014-07-13 23:30:48,448 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/8940e542a43a46069c460ef54f1932bb as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8940e542a43a46069c460ef54f1932bb
2014-07-13 23:30:48,492 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8940e542a43a46069c460ef54f1932bb, entries=1378760, sequenceid=7493, filesize=98.2m
2014-07-13 23:30:48,492 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~977.8m/1025265440, currentsize=472.5m/495500800 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 23703ms, sequenceid=7493, compaction requested=true
2014-07-13 23:30:48,492 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:57), split_queue=0, merge_queue=0
2014-07-13 23:30:48,493 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3948ms
2014-07-13 23:30:48,493 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,493 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 923.4m
2014-07-13 23:30:48,493 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3995ms
2014-07-13 23:30:48,493 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,493 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3996ms
2014-07-13 23:30:48,493 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,493 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4032ms
2014-07-13 23:30:48,494 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,497 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4070ms
2014-07-13 23:30:48,497 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,497 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4092ms
2014-07-13 23:30:48,497 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,497 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4105ms
2014-07-13 23:30:48,497 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,498 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4117ms
2014-07-13 23:30:48,498 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,498 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4126ms
2014-07-13 23:30:48,498 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,499 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4154ms
2014-07-13 23:30:48,499 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,499 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4160ms
2014-07-13 23:30:48,499 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,500 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4177ms
2014-07-13 23:30:48,500 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,501 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4178ms
2014-07-13 23:30:48,501 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,505 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4188ms
2014-07-13 23:30:48,505 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,505 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4190ms
2014-07-13 23:30:48,505 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,505 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4190ms
2014-07-13 23:30:48,505 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,506 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4190ms
2014-07-13 23:30:48,506 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,509 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4194ms
2014-07-13 23:30:48,509 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,509 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4196ms
2014-07-13 23:30:48,509 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,512 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4220ms
2014-07-13 23:30:48,512 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,512 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4250ms
2014-07-13 23:30:48,512 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,521 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4280ms
2014-07-13 23:30:48,521 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,543 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4304ms
2014-07-13 23:30:48,543 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,545 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4343ms
2014-07-13 23:30:48,545 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,545 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4350ms
2014-07-13 23:30:48,546 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,546 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4351ms
2014-07-13 23:30:48,546 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,552 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4365ms
2014-07-13 23:30:48,552 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,552 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4371ms
2014-07-13 23:30:48,552 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,553 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4372ms
2014-07-13 23:30:48,553 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,553 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4373ms
2014-07-13 23:30:48,553 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,553 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4374ms
2014-07-13 23:30:48,553 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,553 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4374ms
2014-07-13 23:30:48,553 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,554 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4377ms
2014-07-13 23:30:48,554 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,554 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4378ms
2014-07-13 23:30:48,554 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,559 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4384ms
2014-07-13 23:30:48,559 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,561 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4386ms
2014-07-13 23:30:48,561 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,561 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4388ms
2014-07-13 23:30:48,561 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,561 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4393ms
2014-07-13 23:30:48,561 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,561 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4395ms
2014-07-13 23:30:48,562 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,565 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4400ms
2014-07-13 23:30:48,565 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,566 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4401ms
2014-07-13 23:30:48,566 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,566 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4402ms
2014-07-13 23:30:48,566 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,566 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4403ms
2014-07-13 23:30:48,566 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,573 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4411ms
2014-07-13 23:30:48,573 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,574 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4413ms
2014-07-13 23:30:48,574 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,575 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4415ms
2014-07-13 23:30:48,575 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,581 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4424ms
2014-07-13 23:30:48,582 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,582 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4425ms
2014-07-13 23:30:48,582 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,588 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4432ms
2014-07-13 23:30:48,589 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,590 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4437ms
2014-07-13 23:30:48,590 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:30:48,909 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:30:50,276 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:30:50,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:50,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34471 synced till here 34428
2014-07-13 23:30:51,809 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319444151 with entries=144, filesize=117.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319450401
2014-07-13 23:30:51,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319366340
2014-07-13 23:30:51,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319367338
2014-07-13 23:30:51,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319369242
2014-07-13 23:30:51,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319370654
2014-07-13 23:30:51,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319371838
2014-07-13 23:30:52,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:52,722 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34577 synced till here 34544
2014-07-13 23:30:53,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319450401 with entries=106, filesize=90.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319452636
2014-07-13 23:30:55,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:55,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34692 synced till here 34665
2014-07-13 23:30:55,795 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319452636 with entries=115, filesize=102.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319455463
2014-07-13 23:30:56,609 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:56,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34789 synced till here 34780
2014-07-13 23:30:57,538 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319455463 with entries=97, filesize=74.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319456610
2014-07-13 23:30:58,461 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:30:58,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34899 synced till here 34898
2014-07-13 23:30:58,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319456610 with entries=110, filesize=73.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319458462
2014-07-13 23:31:00,012 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,015 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,015 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,048 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,051 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,052 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,052 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,057 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,057 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,059 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,065 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,072 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,108 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,111 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,113 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:00,147 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,149 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,157 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,168 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319458462 with entries=82, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319460147
2014-07-13 23:31:00,180 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,253 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,253 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,255 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,256 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,267 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,318 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:00,321 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,043 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,043 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,044 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,047 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,049 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,050 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,050 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,050 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,051 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,052 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,053 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,053 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,053 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,054 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,054 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:01,054 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,335 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,398 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,400 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,455 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,462 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,465 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,467 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:02,467 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:03,621 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7621, memsize=428.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/8e9aa8d1b81541c2b3b39a6e71fa6be0
2014-07-13 23:31:03,647 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/8e9aa8d1b81541c2b3b39a6e71fa6be0 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e9aa8d1b81541c2b3b39a6e71fa6be0
2014-07-13 23:31:03,662 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e9aa8d1b81541c2b3b39a6e71fa6be0, entries=1558890, sequenceid=7621, filesize=110.9m
2014-07-13 23:31:03,662 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1123578240, currentsize=458.3m/480604320 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 28779ms, sequenceid=7621, compaction requested=true
2014-07-13 23:31:03,663 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:58), split_queue=0, merge_queue=0
2014-07-13 23:31:03,663 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1196ms
2014-07-13 23:31:03,663 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 635.8m
2014-07-13 23:31:03,663 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,663 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1197ms
2014-07-13 23:31:03,663 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,664 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1199ms
2014-07-13 23:31:03,664 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,664 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1202ms
2014-07-13 23:31:03,664 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,664 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1209ms
2014-07-13 23:31:03,664 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,664 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1264ms
2014-07-13 23:31:03,665 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,665 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1267ms
2014-07-13 23:31:03,665 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,665 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1330ms
2014-07-13 23:31:03,665 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,665 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2611ms
2014-07-13 23:31:03,665 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,665 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2611ms
2014-07-13 23:31:03,665 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,665 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2611ms
2014-07-13 23:31:03,665 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,666 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2613ms
2014-07-13 23:31:03,666 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,671 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2618ms
2014-07-13 23:31:03,671 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,671 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2618ms
2014-07-13 23:31:03,671 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,672 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2620ms
2014-07-13 23:31:03,672 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,673 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2622ms
2014-07-13 23:31:03,673 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,673 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2623ms
2014-07-13 23:31:03,673 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,678 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2628ms
2014-07-13 23:31:03,678 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,678 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2628ms
2014-07-13 23:31:03,679 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,679 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2630ms
2014-07-13 23:31:03,679 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,680 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2633ms
2014-07-13 23:31:03,681 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,681 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2637ms
2014-07-13 23:31:03,681 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,681 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2638ms
2014-07-13 23:31:03,681 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,681 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2638ms
2014-07-13 23:31:03,681 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,681 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3360ms
2014-07-13 23:31:03,681 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,681 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3363ms
2014-07-13 23:31:03,682 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,688 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3420ms
2014-07-13 23:31:03,688 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,688 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3432ms
2014-07-13 23:31:03,688 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,689 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3434ms
2014-07-13 23:31:03,689 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,690 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3436ms
2014-07-13 23:31:03,690 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,690 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3437ms
2014-07-13 23:31:03,690 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,691 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3510ms
2014-07-13 23:31:03,691 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,693 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3535ms
2014-07-13 23:31:03,693 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,694 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3544ms
2014-07-13 23:31:03,694 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,702 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3555ms
2014-07-13 23:31:03,702 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,703 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3590ms
2014-07-13 23:31:03,703 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,704 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3593ms
2014-07-13 23:31:03,704 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,704 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3596ms
2014-07-13 23:31:03,704 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,704 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3632ms
2014-07-13 23:31:03,704 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,709 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3644ms
2014-07-13 23:31:03,709 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,709 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3650ms
2014-07-13 23:31:03,709 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,709 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3652ms
2014-07-13 23:31:03,709 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,709 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3652ms
2014-07-13 23:31:03,709 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,709 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3657ms
2014-07-13 23:31:03,710 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,716 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3664ms
2014-07-13 23:31:03,716 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,716 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3666ms
2014-07-13 23:31:03,716 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,716 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3668ms
2014-07-13 23:31:03,716 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,717 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3702ms
2014-07-13 23:31:03,717 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,717 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3702ms
2014-07-13 23:31:03,717 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:03,725 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3713ms
2014-07-13 23:31:03,725 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:04,003 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:31:04,969 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:31:05,065 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:05,147 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35093 synced till here 35089
2014-07-13 23:31:05,210 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319460147 with entries=112, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319465066
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319373606
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319377401
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319379173
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319381253
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319383496
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319385516
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319387631
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319389768
2014-07-13 23:31:05,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319391058
2014-07-13 23:31:06,220 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:06,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35170 synced till here 35167
2014-07-13 23:31:06,287 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319465066 with entries=77, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319466220
2014-07-13 23:31:08,086 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:08,472 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319466220 with entries=78, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319468086
2014-07-13 23:31:09,715 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:09,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319468086 with entries=61, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319469716
2014-07-13 23:31:11,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:12,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319469716 with entries=137, filesize=112.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319471225
2014-07-13 23:31:13,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:13,319 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35532 synced till here 35529
2014-07-13 23:31:13,379 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319471225 with entries=86, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319473302
2014-07-13 23:31:14,454 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:15,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35645 synced till here 35636
2014-07-13 23:31:15,414 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319473302 with entries=113, filesize=103.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319474454
2014-07-13 23:31:15,623 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,624 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,625 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,626 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,627 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,646 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,653 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,661 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,678 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,679 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,682 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,689 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,716 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,716 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,749 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,749 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,761 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,772 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,773 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,876 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,889 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,937 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,944 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:15,999 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,052 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,064 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,065 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,078 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,098 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,150 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,203 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,248 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,313 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,315 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:16,329 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,230 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,232 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,239 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,242 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,243 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,248 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,262 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,293 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,294 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,301 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,303 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,335 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,335 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,336 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,337 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:17,947 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7729, memsize=474.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/de4a2630463b450187c6397a117a3fae
2014-07-13 23:31:17,959 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/de4a2630463b450187c6397a117a3fae as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/de4a2630463b450187c6397a117a3fae
2014-07-13 23:31:17,967 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/de4a2630463b450187c6397a117a3fae, entries=1726490, sequenceid=7729, filesize=122.9m
2014-07-13 23:31:17,967 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~923.4m/968247360, currentsize=551.2m/577927280 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 29474ms, sequenceid=7729, compaction requested=true
2014-07-13 23:31:17,968 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:59), split_queue=0, merge_queue=0
2014-07-13 23:31:17,968 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 631ms
2014-07-13 23:31:17,968 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,969 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 634ms
2014-07-13 23:31:17,969 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,969 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 634ms
2014-07-13 23:31:17,969 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,969 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 634ms
2014-07-13 23:31:17,969 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,969 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 667ms
2014-07-13 23:31:17,969 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,969 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 668ms
2014-07-13 23:31:17,969 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,969 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 675ms
2014-07-13 23:31:17,970 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,968 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1019.3m
2014-07-13 23:31:17,973 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 680ms
2014-07-13 23:31:17,973 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,974 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 712ms
2014-07-13 23:31:17,974 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,981 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 733ms
2014-07-13 23:31:17,981 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,981 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 738ms
2014-07-13 23:31:17,981 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,981 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 739ms
2014-07-13 23:31:17,981 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,983 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 744ms
2014-07-13 23:31:17,983 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,983 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 751ms
2014-07-13 23:31:17,983 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,985 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 755ms
2014-07-13 23:31:17,985 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,985 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1656ms
2014-07-13 23:31:17,985 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,989 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1674ms
2014-07-13 23:31:17,989 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,989 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1677ms
2014-07-13 23:31:17,989 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,989 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1741ms
2014-07-13 23:31:17,989 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:17,989 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1786ms
2014-07-13 23:31:17,989 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,001 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1852ms
2014-07-13 23:31:18,001 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,001 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1903ms
2014-07-13 23:31:18,001 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,001 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1923ms
2014-07-13 23:31:18,001 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,001 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1936ms
2014-07-13 23:31:18,001 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,009 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1945ms
2014-07-13 23:31:18,009 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,009 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1957ms
2014-07-13 23:31:18,009 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,015 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2016ms
2014-07-13 23:31:18,015 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,015 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2071ms
2014-07-13 23:31:18,015 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,016 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2079ms
2014-07-13 23:31:18,016 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,021 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-13 23:31:18,021 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,021 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2145ms
2014-07-13 23:31:18,021 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,033 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2260ms
2014-07-13 23:31:18,033 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,039 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2267ms
2014-07-13 23:31:18,039 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,039 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2278ms
2014-07-13 23:31:18,039 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,039 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2290ms
2014-07-13 23:31:18,039 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,040 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2291ms
2014-07-13 23:31:18,040 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,040 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2324ms
2014-07-13 23:31:18,040 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,040 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2324ms
2014-07-13 23:31:18,040 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,101 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2412ms
2014-07-13 23:31:18,101 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,101 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2419ms
2014-07-13 23:31:18,101 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,109 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2430ms
2014-07-13 23:31:18,109 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,109 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2431ms
2014-07-13 23:31:18,109 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,117 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2456ms
2014-07-13 23:31:18,117 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,117 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2464ms
2014-07-13 23:31:18,117 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,117 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2471ms
2014-07-13 23:31:18,117 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,117 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2491ms
2014-07-13 23:31:18,117 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,117 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2491ms
2014-07-13 23:31:18,118 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,118 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2493ms
2014-07-13 23:31:18,118 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,125 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2501ms
2014-07-13 23:31:18,125 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:18,125 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2502ms
2014-07-13 23:31:18,125 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:19,701 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:19,703 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:31:19,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35762 synced till here 35731
2014-07-13 23:31:19,919 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:31:20,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319474454 with entries=117, filesize=101.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319479701
2014-07-13 23:31:20,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319392528
2014-07-13 23:31:20,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319395182
2014-07-13 23:31:20,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319396777
2014-07-13 23:31:20,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319398040
2014-07-13 23:31:20,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319399674
2014-07-13 23:31:21,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:21,807 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35870 synced till here 35839
2014-07-13 23:31:22,134 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319479701 with entries=108, filesize=99.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319481768
2014-07-13 23:31:22,444 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11400, memsize=336.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/510854d7a2f547f5aff1f80c3c87b366
2014-07-13 23:31:22,455 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/510854d7a2f547f5aff1f80c3c87b366 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/510854d7a2f547f5aff1f80c3c87b366
2014-07-13 23:31:22,463 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/510854d7a2f547f5aff1f80c3c87b366, entries=1224660, sequenceid=11400, filesize=87.2m
2014-07-13 23:31:22,464 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~635.8m/666660160, currentsize=256.5m/268953760 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 18801ms, sequenceid=11400, compaction requested=true
2014-07-13 23:31:22,464 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:60), split_queue=0, merge_queue=0
2014-07-13 23:31:22,464 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 857.4m
2014-07-13 23:31:22,518 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:31:23,482 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:23,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35973 synced till here 35953
2014-07-13 23:31:23,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319481768 with entries=103, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319483483
2014-07-13 23:31:23,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319402871
2014-07-13 23:31:23,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319406936
2014-07-13 23:31:23,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319410265
2014-07-13 23:31:23,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319412158
2014-07-13 23:31:23,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319414595
2014-07-13 23:31:24,063 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:31:25,243 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:25,530 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36075 synced till here 36074
2014-07-13 23:31:25,578 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319483483 with entries=102, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319485243
2014-07-13 23:31:27,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:27,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36141 synced till here 36138
2014-07-13 23:31:27,105 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319485243 with entries=66, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319487043
2014-07-13 23:31:28,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:28,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36217 synced till here 36210
2014-07-13 23:31:28,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319487043 with entries=76, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319488606
2014-07-13 23:31:30,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:30,132 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36320 synced till here 36306
2014-07-13 23:31:30,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319488606 with entries=103, filesize=81.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319490023
2014-07-13 23:31:31,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:31,792 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319490023 with entries=81, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319491557
2014-07-13 23:31:33,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:33,984 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319491557 with entries=77, filesize=81.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319493019
2014-07-13 23:31:35,364 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:35,502 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36559 synced till here 36548
2014-07-13 23:31:35,621 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319493019 with entries=81, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319495364
2014-07-13 23:31:36,712 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,757 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,771 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,779 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,781 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,792 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,793 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,793 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,810 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,829 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,899 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,914 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:36,918 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,925 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,926 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,928 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,931 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36637 synced till here 36633
2014-07-13 23:31:36,946 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,952 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,959 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319495364 with entries=78, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319496914
2014-07-13 23:31:36,981 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:36,982 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,031 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,085 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,122 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,845 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,845 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,845 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,848 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,855 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,855 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,856 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,872 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,896 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,901 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,907 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,907 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,907 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,910 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,912 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,943 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,971 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:37,991 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:38,021 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:38,056 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:38,086 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:38,113 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:38,130 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:38,149 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:38,182 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:39,096 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:31:42,427 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5305ms
2014-07-13 23:31:42,428 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5500ms
2014-07-13 23:31:42,428 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5497ms
2014-07-13 23:31:42,428 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5599ms
2014-07-13 23:31:42,428 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5672ms
2014-07-13 23:31:42,429 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5483ms
2014-07-13 23:31:42,429 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5637ms
2014-07-13 23:31:42,429 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5477ms
2014-07-13 23:31:42,429 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5636ms
2014-07-13 23:31:42,429 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5447ms
2014-07-13 23:31:42,430 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5470ms
2014-07-13 23:31:42,430 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5449ms
2014-07-13 23:31:42,431 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5399ms
2014-07-13 23:31:42,432 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5346ms
2014-07-13 23:31:42,432 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5720ms
2014-07-13 23:31:42,432 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5661ms
2014-07-13 23:31:42,432 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5653ms
2014-07-13 23:31:42,432 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5651ms
2014-07-13 23:31:42,432 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5640ms
2014-07-13 23:31:42,433 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5623ms
2014-07-13 23:31:42,433 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5534ms
2014-07-13 23:31:42,434 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5516ms
2014-07-13 23:31:42,434 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5509ms
2014-07-13 23:31:42,434 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5508ms
2014-07-13 23:31:42,845 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,846 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:42,846 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:42,848 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,855 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,856 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:42,856 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,872 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:42,897 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,902 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:42,907 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,907 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,908 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:42,911 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:42,912 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,943 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,971 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:42,991 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:43,021 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:43,056 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:43,087 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:31:43,113 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:43,130 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:43,150 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:43,182 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:44,096 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:31:45,846 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8099, memsize=414.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/31e7f2f1eae14ea19e41a7760de9c560
2014-07-13 23:31:45,862 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/31e7f2f1eae14ea19e41a7760de9c560 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/31e7f2f1eae14ea19e41a7760de9c560
2014-07-13 23:31:45,877 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/31e7f2f1eae14ea19e41a7760de9c560, entries=1507630, sequenceid=8099, filesize=107.4m
2014-07-13 23:31:45,878 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~868.6m/910814720, currentsize=310.2m/325273280 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 23414ms, sequenceid=8099, compaction requested=true
2014-07-13 23:31:45,878 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:61), split_queue=0, merge_queue=0
2014-07-13 23:31:45,879 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6783ms
2014-07-13 23:31:45,879 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,879 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 974.6m
2014-07-13 23:31:45,879 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7697ms
2014-07-13 23:31:45,879 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,879 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7730ms
2014-07-13 23:31:45,879 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,885 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7755ms
2014-07-13 23:31:45,886 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,888 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7774ms
2014-07-13 23:31:45,888 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,889 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7802ms
2014-07-13 23:31:45,889 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,889 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7833ms
2014-07-13 23:31:45,889 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,897 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7876ms
2014-07-13 23:31:45,897 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,897 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7907ms
2014-07-13 23:31:45,897 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,898 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7926ms
2014-07-13 23:31:45,898 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,899 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7955ms
2014-07-13 23:31:45,899 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,900 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7987ms
2014-07-13 23:31:45,900 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,900 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7990ms
2014-07-13 23:31:45,900 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,901 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7993ms
2014-07-13 23:31:45,901 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,904 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7997ms
2014-07-13 23:31:45,904 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,904 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7997ms
2014-07-13 23:31:45,904 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,904 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8003ms
2014-07-13 23:31:45,904 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,906 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8009ms
2014-07-13 23:31:45,906 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,907 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8036ms
2014-07-13 23:31:45,908 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,911 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8055ms
2014-07-13 23:31:45,912 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,912 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8057ms
2014-07-13 23:31:45,912 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,913 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8058ms
2014-07-13 23:31:45,913 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,913 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8065ms
2014-07-13 23:31:45,913 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,914 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8068ms
2014-07-13 23:31:45,914 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,921 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8076ms
2014-07-13 23:31:45,921 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,921 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8076ms
2014-07-13 23:31:45,921 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,921 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8995ms
2014-07-13 23:31:45,923 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,925 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8999ms
2014-07-13 23:31:45,925 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,925 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9007ms
2014-07-13 23:31:45,925 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,925 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9026ms
2014-07-13 23:31:45,925 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,926 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9116ms
2014-07-13 23:31:45,926 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,928 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9135ms
2014-07-13 23:31:45,928 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,943 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9148ms
2014-07-13 23:31:45,943 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,945 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9165ms
2014-07-13 23:31:45,945 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,947 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9175ms
2014-07-13 23:31:45,948 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,954 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9238ms
2014-07-13 23:31:45,954 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,954 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8869ms
2014-07-13 23:31:45,954 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,954 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8923ms
2014-07-13 23:31:45,954 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,956 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8973ms
2014-07-13 23:31:45,956 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,959 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9000ms
2014-07-13 23:31:45,959 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,962 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8980ms
2014-07-13 23:31:45,962 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,962 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9169ms
2014-07-13 23:31:45,962 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,964 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9011ms
2014-07-13 23:31:45,964 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,973 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9181ms
2014-07-13 23:31:45,973 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,973 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9027ms
2014-07-13 23:31:45,973 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,974 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9217ms
2014-07-13 23:31:45,974 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,981 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9152ms
2014-07-13 23:31:45,981 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,981 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9050ms
2014-07-13 23:31:45,981 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,981 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9053ms
2014-07-13 23:31:45,981 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:45,989 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8867ms
2014-07-13 23:31:45,989 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:31:46,854 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:31:47,216 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10804,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496412,"queuetimems":0,"class":"HRegionServer","responsesize":17112,"method":"Multi"}
2014-07-13 23:31:47,216 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10862,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496354,"queuetimems":0,"class":"HRegionServer","responsesize":15527,"method":"Multi"}
2014-07-13 23:31:47,216 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10762,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496454,"queuetimems":0,"class":"HRegionServer","responsesize":18564,"method":"Multi"}
2014-07-13 23:31:47,216 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10937,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496279,"queuetimems":0,"class":"HRegionServer","responsesize":17592,"method":"Multi"}
2014-07-13 23:31:47,216 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10901,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496315,"queuetimems":0,"class":"HRegionServer","responsesize":11625,"method":"Multi"}
2014-07-13 23:31:47,226 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10447,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496779,"queuetimems":0,"class":"HRegionServer","responsesize":1523,"method":"Multi"}
2014-07-13 23:31:47,496 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496947,"queuetimems":0,"class":"HRegionServer","responsesize":6547,"method":"Multi"}
2014-07-13 23:31:47,496 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10672,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496823,"queuetimems":0,"class":"HRegionServer","responsesize":6479,"method":"Multi"}
2014-07-13 23:31:47,497 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10701,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496795,"queuetimems":0,"class":"HRegionServer","responsesize":7576,"method":"Multi"}
2014-07-13 23:31:47,498 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10723,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496775,"queuetimems":0,"class":"HRegionServer","responsesize":5175,"method":"Multi"}
2014-07-13 23:31:47,505 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496761,"queuetimems":0,"class":"HRegionServer","responsesize":5148,"method":"Multi"}
2014-07-13 23:31:47,496 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10538,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496957,"queuetimems":0,"class":"HRegionServer","responsesize":4250,"method":"Multi"}
2014-07-13 23:31:47,596 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:31:48,094 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:48,096 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11592,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496503,"queuetimems":1,"class":"HRegionServer","responsesize":11039,"method":"Multi"}
2014-07-13 23:31:48,096 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11453,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496643,"queuetimems":0,"class":"HRegionServer","responsesize":15562,"method":"Multi"}
2014-07-13 23:31:48,102 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11566,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496536,"queuetimems":0,"class":"HRegionServer","responsesize":16037,"method":"Multi"}
2014-07-13 23:31:48,916 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12344,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496571,"queuetimems":0,"class":"HRegionServer","responsesize":18011,"method":"Multi"}
2014-07-13 23:31:48,934 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10824,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319498110,"queuetimems":0,"class":"HRegionServer","responsesize":15294,"method":"Multi"}
2014-07-13 23:31:48,935 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10882,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319498053,"queuetimems":0,"class":"HRegionServer","responsesize":17337,"method":"Multi"}
2014-07-13 23:31:48,935 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10756,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319498179,"queuetimems":0,"class":"HRegionServer","responsesize":17623,"method":"Multi"}
2014-07-13 23:31:48,934 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10806,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319498128,"queuetimems":0,"class":"HRegionServer","responsesize":9909,"method":"Multi"}
2014-07-13 23:31:48,936 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10788,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319498148,"queuetimems":1,"class":"HRegionServer","responsesize":11363,"method":"Multi"}
2014-07-13 23:31:48,941 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10952,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497989,"queuetimems":1,"class":"HRegionServer","responsesize":11412,"method":"Multi"}
2014-07-13 23:31:48,942 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10857,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319498084,"queuetimems":1,"class":"HRegionServer","responsesize":15747,"method":"Multi"}
2014-07-13 23:31:48,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36756 synced till here 36754
2014-07-13 23:31:48,983 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11129,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497854,"queuetimems":0,"class":"HRegionServer","responsesize":11379,"method":"Multi"}
2014-07-13 23:31:49,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319496914 with entries=119, filesize=109.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319508094
2014-07-13 23:31:49,077 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497894,"queuetimems":0,"class":"HRegionServer","responsesize":15562,"method":"Multi"}
2014-07-13 23:31:49,130 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319498018,"queuetimems":0,"class":"HRegionServer","responsesize":15302,"method":"Multi"}
2014-07-13 23:31:49,251 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11311,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497940,"queuetimems":0,"class":"HRegionServer","responsesize":16194,"method":"Multi"}
2014-07-13 23:31:49,252 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12172,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497079,"queuetimems":0,"class":"HRegionServer","responsesize":18436,"method":"Multi"}
2014-07-13 23:31:49,252 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497868,"queuetimems":0,"class":"HRegionServer","responsesize":18011,"method":"Multi"}
2014-07-13 23:31:49,257 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12320,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496937,"queuetimems":0,"class":"HRegionServer","responsesize":15769,"method":"Multi"}
2014-07-13 23:31:49,258 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497968,"queuetimems":0,"class":"HRegionServer","responsesize":15821,"method":"Multi"}
2014-07-13 23:31:49,267 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12246,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497021,"queuetimems":0,"class":"HRegionServer","responsesize":18524,"method":"Multi"}
2014-07-13 23:31:49,269 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11425,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497844,"queuetimems":0,"class":"HRegionServer","responsesize":18641,"method":"Multi"}
2014-07-13 23:31:49,494 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496749,"queuetimems":1,"class":"HRegionServer","responsesize":17916,"method":"Multi"}
2014-07-13 23:31:50,510 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:50,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36858 synced till here 36819
2014-07-13 23:31:50,607 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8037, memsize=521.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/8093fc6bd66143b0a625f8db92195200
2014-07-13 23:31:50,620 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/8093fc6bd66143b0a625f8db92195200 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8093fc6bd66143b0a625f8db92195200
2014-07-13 23:31:50,634 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8093fc6bd66143b0a625f8db92195200, entries=1898710, sequenceid=8037, filesize=135.3m
2014-07-13 23:31:50,635 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1019.3m/1068780880, currentsize=506.8m/531460400 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 32667ms, sequenceid=8037, compaction requested=true
2014-07-13 23:31:50,635 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:62), split_queue=0, merge_queue=0
2014-07-13 23:31:50,636 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 552.0m
2014-07-13 23:31:50,761 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:31:50,761 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319496886,"queuetimems":0,"class":"HRegionServer","responsesize":18197,"method":"Multi"}
2014-07-13 23:31:50,778 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13661,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319497116,"queuetimems":1,"class":"HRegionServer","responsesize":15555,"method":"Multi"}
2014-07-13 23:31:50,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319508094 with entries=102, filesize=99.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319510511
2014-07-13 23:31:50,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319416521
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319425128
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319426661
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319428327
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319430102
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319431573
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319433590
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319435147
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319436938
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319438599
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319439694
2014-07-13 23:31:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319442102
2014-07-13 23:31:51,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:52,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36947 synced till here 36924
2014-07-13 23:31:52,589 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319510511 with entries=89, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319512328
2014-07-13 23:31:52,734 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:31:53,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:54,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37054 synced till here 37013
2014-07-13 23:31:54,486 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319512328 with entries=107, filesize=95.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319513480
2014-07-13 23:31:55,179 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:55,377 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37140 synced till here 37138
2014-07-13 23:31:55,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319513480 with entries=86, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319515180
2014-07-13 23:31:57,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:57,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37218 synced till here 37217
2014-07-13 23:31:57,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319515180 with entries=78, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319517400
2014-07-13 23:31:58,779 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:31:59,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37287 synced till here 37283
2014-07-13 23:31:59,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319517400 with entries=69, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319518779
2014-07-13 23:32:00,492 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:00,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37356 synced till here 37352
2014-07-13 23:32:00,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319518779 with entries=69, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319520492
2014-07-13 23:32:01,753 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:02,314 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37436 synced till here 37435
2014-07-13 23:32:02,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319520492 with entries=80, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319521753
2014-07-13 23:32:03,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:03,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37507 synced till here 37505
2014-07-13 23:32:03,794 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319521753 with entries=71, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319523365
2014-07-13 23:32:04,585 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:05,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37586 synced till here 37578
2014-07-13 23:32:05,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319523365 with entries=79, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319524586
2014-07-13 23:32:06,162 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:06,701 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37695 synced till here 37688
2014-07-13 23:32:06,761 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319524586 with entries=109, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319526162
2014-07-13 23:32:07,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:07,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37767 synced till here 37766
2014-07-13 23:32:07,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319526162 with entries=72, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319527681
2014-07-13 23:32:08,529 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,531 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,543 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,557 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,583 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,590 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,594 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,628 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,648 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,683 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,688 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,724 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,729 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,734 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,736 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,775 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,811 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,823 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,829 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,869 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,908 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,941 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,943 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,943 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,943 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,946 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,981 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:08,982 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,022 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,069 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,124 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,138 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,152 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,205 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,206 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,255 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,300 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,302 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,314 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,321 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,337 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,370 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,398 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,437 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,438 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,439 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,451 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,465 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,476 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:09,489 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:11,531 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12040, memsize=390.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/4ace3abab2a54ff3bf581a78f1a5b1e7
2014-07-13 23:32:11,544 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/4ace3abab2a54ff3bf581a78f1a5b1e7 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/4ace3abab2a54ff3bf581a78f1a5b1e7
2014-07-13 23:32:11,553 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/4ace3abab2a54ff3bf581a78f1a5b1e7, entries=1422250, sequenceid=12040, filesize=101.3m
2014-07-13 23:32:11,553 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~558.4m/585499920, currentsize=262.7m/275438480 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 20917ms, sequenceid=12040, compaction requested=true
2014-07-13 23:32:11,554 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:63), split_queue=0, merge_queue=0
2014-07-13 23:32:11,554 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2065ms
2014-07-13 23:32:11,554 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 819.8m
2014-07-13 23:32:11,554 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,554 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2078ms
2014-07-13 23:32:11,555 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,557 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2091ms
2014-07-13 23:32:11,557 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,557 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2106ms
2014-07-13 23:32:11,557 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,564 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2126ms
2014-07-13 23:32:11,564 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,564 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2126ms
2014-07-13 23:32:11,564 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,565 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2128ms
2014-07-13 23:32:11,565 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,574 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2175ms
2014-07-13 23:32:11,574 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,574 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2204ms
2014-07-13 23:32:11,574 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,575 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2237ms
2014-07-13 23:32:11,575 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,577 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2256ms
2014-07-13 23:32:11,577 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,577 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2263ms
2014-07-13 23:32:11,577 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,577 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2275ms
2014-07-13 23:32:11,577 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,578 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2278ms
2014-07-13 23:32:11,578 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,580 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2324ms
2014-07-13 23:32:11,580 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,581 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2375ms
2014-07-13 23:32:11,581 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,581 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2376ms
2014-07-13 23:32:11,581 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,583 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2431ms
2014-07-13 23:32:11,584 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,598 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2460ms
2014-07-13 23:32:11,598 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,608 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2484ms
2014-07-13 23:32:11,608 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,608 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2539ms
2014-07-13 23:32:11,608 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,617 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2595ms
2014-07-13 23:32:11,617 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,617 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2635ms
2014-07-13 23:32:11,617 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,618 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2637ms
2014-07-13 23:32:11,618 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,618 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2672ms
2014-07-13 23:32:11,618 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,619 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2676ms
2014-07-13 23:32:11,619 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,623 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2680ms
2014-07-13 23:32:11,623 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,624 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2681ms
2014-07-13 23:32:11,624 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,626 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2684ms
2014-07-13 23:32:11,626 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,626 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2718ms
2014-07-13 23:32:11,626 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,626 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2757ms
2014-07-13 23:32:11,626 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,633 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2804ms
2014-07-13 23:32:11,633 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,634 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2810ms
2014-07-13 23:32:11,634 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,637 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2824ms
2014-07-13 23:32:11,637 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,641 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2866ms
2014-07-13 23:32:11,641 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,645 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2909ms
2014-07-13 23:32:11,645 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,647 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2913ms
2014-07-13 23:32:11,647 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,647 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2918ms
2014-07-13 23:32:11,647 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,648 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2924ms
2014-07-13 23:32:11,648 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,649 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2960ms
2014-07-13 23:32:11,649 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,649 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2966ms
2014-07-13 23:32:11,650 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,651 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3002ms
2014-07-13 23:32:11,651 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,653 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3025ms
2014-07-13 23:32:11,653 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,653 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3059ms
2014-07-13 23:32:11,653 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,654 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3063ms
2014-07-13 23:32:11,654 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,657 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3074ms
2014-07-13 23:32:11,657 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,661 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3104ms
2014-07-13 23:32:11,661 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,662 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3118ms
2014-07-13 23:32:11,662 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,663 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3133ms
2014-07-13 23:32:11,663 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:11,664 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3134ms
2014-07-13 23:32:11,664 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:32:12,332 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:12,332 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:32:13,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37884 synced till here 37876
2014-07-13 23:32:13,904 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:32:13,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319527681 with entries=117, filesize=94.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319532333
2014-07-13 23:32:15,955 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:16,030 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37975 synced till here 37952
2014-07-13 23:32:16,078 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8250, memsize=472.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/3b1052cfc90f4858b7c64ab91e966d22
2014-07-13 23:32:16,103 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/3b1052cfc90f4858b7c64ab91e966d22 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/3b1052cfc90f4858b7c64ab91e966d22
2014-07-13 23:32:16,126 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/3b1052cfc90f4858b7c64ab91e966d22, entries=1719170, sequenceid=8250, filesize=122.4m
2014-07-13 23:32:16,127 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~974.6m/1021928080, currentsize=548.4m/575025520 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 30248ms, sequenceid=8250, compaction requested=true
2014-07-13 23:32:16,127 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:64), split_queue=0, merge_queue=0
2014-07-13 23:32:16,127 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 984.4m
2014-07-13 23:32:16,253 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:32:16,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319532333 with entries=91, filesize=101.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319535956
2014-07-13 23:32:16,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319444151
2014-07-13 23:32:16,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319450401
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319452636
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319455463
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319456610
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319458462
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319460147
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319465066
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319466220
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319468086
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319469716
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319471225
2014-07-13 23:32:16,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319473302
2014-07-13 23:32:18,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:18,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38080 synced till here 38058
2014-07-13 23:32:18,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319535956 with entries=105, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319538086
2014-07-13 23:32:18,563 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:32:19,772 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1013ms
GC pool 'ParNew' had collection(s): count=1 time=1142ms
2014-07-13 23:32:20,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:20,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38170 synced till here 38140
2014-07-13 23:32:20,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319538086 with entries=90, filesize=97.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319540111
2014-07-13 23:32:22,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:22,171 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38267 synced till here 38238
2014-07-13 23:32:23,391 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319540111 with entries=97, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319542096
2014-07-13 23:32:25,256 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:25,353 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38376 synced till here 38332
2014-07-13 23:32:25,651 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319542096 with entries=109, filesize=104.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319545257
2014-07-13 23:32:48,397 WARN  [regionserver60020] util.Sleeper: We slept 23146ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:32:48,397 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 31615ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:32:48,398 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21651ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=21984ms
2014-07-13 23:32:48,397 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 31615ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:32:48,490 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319542366,"queuetimems":1980,"class":"HRegionServer","responsesize":18372,"method":"Multi"}
2014-07-13 23:32:48,490 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35260 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,491 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,492 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545864,"queuetimems":2409,"class":"HRegionServer","responsesize":505,"method":"Multi"}
2014-07-13 23:32:48,492 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35280 service: ClientService methodName: Multi size: 96.2k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,492 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,501 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22632,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545869,"queuetimems":2405,"class":"HRegionServer","responsesize":460,"method":"Multi"}
2014-07-13 23:32:48,501 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545864,"queuetimems":2400,"class":"HRegionServer","responsesize":1776,"method":"Multi"}
2014-07-13 23:32:48,501 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35278 service: ClientService methodName: Multi size: 90.0k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,501 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22620,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545881,"queuetimems":2415,"class":"HRegionServer","responsesize":165,"method":"Multi"}
2014-07-13 23:32:48,501 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35279 service: ClientService methodName: Multi size: 324.8k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,501 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22620,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545881,"queuetimems":2395,"class":"HRegionServer","responsesize":1542,"method":"Multi"}
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35275 service: ClientService methodName: Multi size: 33.8k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,501 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545873,"queuetimems":2408,"class":"HRegionServer","responsesize":1142,"method":"Multi"}
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545873,"queuetimems":2408,"class":"HRegionServer","responsesize":630,"method":"Multi"}
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35274 service: ClientService methodName: Multi size: 281.0k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35277 service: ClientService methodName: Multi size: 119.9k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,502 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25033,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543469,"queuetimems":1836,"class":"HRegionServer","responsesize":18456,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25012,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543490,"queuetimems":1683,"class":"HRegionServer","responsesize":18243,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26141,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319542361,"queuetimems":2142,"class":"HRegionServer","responsesize":18159,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25033,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543470,"queuetimems":1801,"class":"HRegionServer","responsesize":18698,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35249 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26142,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319542361,"queuetimems":2097,"class":"HRegionServer","responsesize":18399,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26137,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319542366,"queuetimems":2014,"class":"HRegionServer","responsesize":17482,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35265 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35264 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22607,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545897,"queuetimems":2371,"class":"HRegionServer","responsesize":1492,"method":"Multi"}
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35276 service: ClientService methodName: Multi size: 209.9k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35271 service: ClientService methodName: Multi size: 274.8k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22568,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545936,"queuetimems":2315,"class":"HRegionServer","responsesize":460,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25041,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543462,"queuetimems":1870,"class":"HRegionServer","responsesize":16118,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24940,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543563,"queuetimems":1647,"class":"HRegionServer","responsesize":15531,"method":"Multi"}
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22571,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545933,"queuetimems":2313,"class":"HRegionServer","responsesize":165,"method":"Multi"}
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545913,"queuetimems":2296,"class":"HRegionServer","responsesize":630,"method":"Multi"}
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35261 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,505 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,505 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35398 service: ClientService methodName: Multi size: 119.9k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,505 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22582,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545922,"queuetimems":2302,"class":"HRegionServer","responsesize":1776,"method":"Multi"}
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22587,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545917,"queuetimems":2299,"class":"HRegionServer","responsesize":1142,"method":"Multi"}
2014-07-13 23:32:48,505 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35396 service: ClientService methodName: Multi size: 324.8k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,504 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545893,"queuetimems":2406,"class":"HRegionServer","responsesize":1464,"method":"Multi"}
2014-07-13 23:32:48,503 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,505 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35247 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,505 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,505 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22578,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545929,"queuetimems":2309,"class":"HRegionServer","responsesize":909,"method":"Multi"}
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35395 service: ClientService methodName: Multi size: 169.9k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35334 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35273 service: ClientService methodName: Multi size: 268.6k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35397 service: ClientService methodName: Multi size: 209.9k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35327 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,508 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,509 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35394 service: ClientService methodName: Multi size: 33.8k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,509 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,509 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35250 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,509 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,509 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35393 service: ClientService methodName: Multi size: 90.0k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,509 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,509 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24945,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543564,"queuetimems":1620,"class":"HRegionServer","responsesize":16048,"method":"Multi"}
2014-07-13 23:32:48,510 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35326 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,510 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,510 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25025,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543485,"queuetimems":1712,"class":"HRegionServer","responsesize":18667,"method":"Multi"}
2014-07-13 23:32:48,510 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35337 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,510 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,510 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24944,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543566,"queuetimems":1510,"class":"HRegionServer","responsesize":18603,"method":"Multi"}
2014-07-13 23:32:48,510 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24944,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543566,"queuetimems":1584,"class":"HRegionServer","responsesize":18413,"method":"Multi"}
2014-07-13 23:32:48,511 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35323 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,511 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,511 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35325 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,511 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,511 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24945,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543566,"queuetimems":1536,"class":"HRegionServer","responsesize":18730,"method":"Multi"}
2014-07-13 23:32:48,511 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25030,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543481,"queuetimems":1743,"class":"HRegionServer","responsesize":18430,"method":"Multi"}
2014-07-13 23:32:48,512 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35324 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,512 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,512 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35338 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,512 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:48,678 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22661,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319546017,"queuetimems":2396,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:32:48,678 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22660,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319546018,"queuetimems":2397,"class":"HRegionServer","responsesize":233,"method":"Multi"}
2014-07-13 23:32:48,679 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35392 service: ClientService methodName: Multi size: 1.3k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,679 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,679 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35391 service: ClientService methodName: Multi size: 47.5k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,679 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,681 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23424,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545257,"queuetimems":2946,"class":"HRegionServer","responsesize":11147,"method":"Multi"}
2014-07-13 23:32:48,682 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35300 service: ClientService methodName: Multi size: 2.0m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,682 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,689 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319546021,"queuetimems":2399,"class":"HRegionServer","responsesize":505,"method":"Multi"}
2014-07-13 23:32:48,690 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25134,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543555,"queuetimems":1695,"class":"HRegionServer","responsesize":18368,"method":"Multi"}
2014-07-13 23:32:48,690 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35390 service: ClientService methodName: Multi size: 96.2k connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,690 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,690 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35331 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,690 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,690 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26324,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319542366,"queuetimems":2057,"class":"HRegionServer","responsesize":17130,"method":"Multi"}
2014-07-13 23:32:48,691 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26324,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319542366,"queuetimems":882,"class":"HRegionServer","responsesize":17538,"method":"Multi"}
2014-07-13 23:32:48,691 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24701,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543989,"queuetimems":1746,"class":"HRegionServer","responsesize":9266,"method":"Multi"}
2014-07-13 23:32:48,691 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543477,"queuetimems":1772,"class":"HRegionServer","responsesize":18643,"method":"Multi"}
2014-07-13 23:32:48,691 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35263 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,692 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,692 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35340 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,692 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,692 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35310 service: ClientService methodName: Multi size: 1.6m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,692 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,692 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24719,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543973,"queuetimems":1807,"class":"HRegionServer","responsesize":14168,"method":"Multi"}
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24720,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543972,"queuetimems":1845,"class":"HRegionServer","responsesize":18334,"method":"Multi"}
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35320 service: ClientService methodName: Multi size: 2.5m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24720,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543972,"queuetimems":1882,"class":"HRegionServer","responsesize":17594,"method":"Multi"}
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35321 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35259 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,693 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35322 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,694 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38476 synced till here 38459
2014-07-13 23:32:48,757 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24770,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319543986,"queuetimems":1769,"class":"HRegionServer","responsesize":16382,"method":"Multi"}
2014-07-13 23:32:48,757 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35314 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,757 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23356,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545400,"queuetimems":1969,"class":"HRegionServer","responsesize":15192,"method":"Multi"}
2014-07-13 23:32:48,758 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35293 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,757 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,758 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:48,783 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319545257 with entries=100, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319568674
2014-07-13 23:32:48,889 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23267,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545621,"queuetimems":2167,"class":"HRegionServer","responsesize":15307,"method":"Multi"}
2014-07-13 23:32:48,889 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35284 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:48,889 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:49,057 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23026,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319546031,"queuetimems":2351,"class":"HRegionServer","responsesize":11147,"method":"Multi"}
2014-07-13 23:32:49,058 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35388 service: ClientService methodName: Multi size: 2.0m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:49,058 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:49,110 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23216,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545893,"queuetimems":2371,"class":"HRegionServer","responsesize":15816,"method":"Multi"}
2014-07-13 23:32:49,110 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35272 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:49,110 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:49,111 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23205,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545905,"queuetimems":2289,"class":"HRegionServer","responsesize":15307,"method":"Multi"}
2014-07-13 23:32:49,111 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35399 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:49,111 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:49,111 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23496,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319545615,"queuetimems":2171,"class":"HRegionServer","responsesize":15665,"method":"Multi"}
2014-07-13 23:32:49,112 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35285 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:49,112 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:49,263 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23234,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47030","starttimems":1405319546028,"queuetimems":2381,"class":"HRegionServer","responsesize":15665,"method":"Multi"}
2014-07-13 23:32:49,263 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 35389 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47030: output error
2014-07-13 23:32:49,263 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:32:50,009 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:50,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38561 synced till here 38548
2014-07-13 23:32:50,246 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319568674 with entries=85, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319570009
2014-07-13 23:32:51,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:51,522 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38652 synced till here 38631
2014-07-13 23:32:51,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319570009 with entries=91, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319571499
2014-07-13 23:32:52,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:32:52,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38766 synced till here 38765
2014-07-13 23:32:52,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319571499 with entries=114, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319572880
2014-07-13 23:32:53,162 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,170 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,179 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,184 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,408 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,419 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,430 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,497 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,511 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,569 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,573 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:53,750 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:55,116 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:55,159 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:55,207 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:55,321 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:55,322 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:55,385 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:55,436 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,336 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,336 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,409 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,429 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,430 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,430 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,431 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:57,431 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:58,163 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:32:58,170 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,179 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,185 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,409 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:32:58,419 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,430 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,498 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,511 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,570 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,573 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:58,750 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:32:59,423 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:59,425 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:59,486 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:32:59,544 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:00,116 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:33:00,160 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:33:00,207 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:33:00,322 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:33:00,323 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:33:00,386 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:33:00,390 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:00,398 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:00,415 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8505, memsize=440.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/5164cd8747a74d64b3b0f2bd64d2c65c
2014-07-13 23:33:00,433 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/5164cd8747a74d64b3b0f2bd64d2c65c as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5164cd8747a74d64b3b0f2bd64d2c65c
2014-07-13 23:33:00,436 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:33:00,452 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5164cd8747a74d64b3b0f2bd64d2c65c, entries=1602730, sequenceid=8505, filesize=114.1m
2014-07-13 23:33:00,453 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~819.8m/859660880, currentsize=409.6m/429484640 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 48899ms, sequenceid=8505, compaction requested=true
2014-07-13 23:33:00,453 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:65), split_queue=0, merge_queue=0
2014-07-13 23:33:00,454 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5018ms
2014-07-13 23:33:00,454 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,454 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 537.0m
2014-07-13 23:33:00,454 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 56ms
2014-07-13 23:33:00,454 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,454 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 64ms
2014-07-13 23:33:00,454 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,454 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5069ms
2014-07-13 23:33:00,455 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,460 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5138ms
2014-07-13 23:33:00,460 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,460 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5139ms
2014-07-13 23:33:00,460 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,461 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5254ms
2014-07-13 23:33:00,461 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,461 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5302ms
2014-07-13 23:33:00,462 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,464 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5348ms
2014-07-13 23:33:00,464 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,466 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 922ms
2014-07-13 23:33:00,467 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,467 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 981ms
2014-07-13 23:33:00,467 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,467 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1042ms
2014-07-13 23:33:00,467 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,467 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1044ms
2014-07-13 23:33:00,467 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,468 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6717ms
2014-07-13 23:33:00,469 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,470 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6896ms
2014-07-13 23:33:00,470 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,471 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6901ms
2014-07-13 23:33:00,471 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,476 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6965ms
2014-07-13 23:33:00,477 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,477 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6980ms
2014-07-13 23:33:00,477 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,477 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7047ms
2014-07-13 23:33:00,478 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,478 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7059ms
2014-07-13 23:33:00,478 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,480 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7072ms
2014-07-13 23:33:00,481 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,484 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7300ms
2014-07-13 23:33:00,484 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,485 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7306ms
2014-07-13 23:33:00,485 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,489 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7319ms
2014-07-13 23:33:00,489 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,489 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7327ms
2014-07-13 23:33:00,490 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,490 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3059ms
2014-07-13 23:33:00,491 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,491 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3060ms
2014-07-13 23:33:00,491 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,491 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3061ms
2014-07-13 23:33:00,491 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,492 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3062ms
2014-07-13 23:33:00,493 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,494 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3064ms
2014-07-13 23:33:00,494 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,495 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3085ms
2014-07-13 23:33:00,495 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,498 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3161ms
2014-07-13 23:33:00,498 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,499 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3163ms
2014-07-13 23:33:00,499 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:00,657 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:33:01,357 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:33:01,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:01,680 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38900 synced till here 38871
2014-07-13 23:33:01,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319572880 with entries=134, filesize=79.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319581636
2014-07-13 23:33:03,418 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:03,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39017 synced till here 38998
2014-07-13 23:33:03,483 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319581636 with entries=117, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319583419
2014-07-13 23:33:04,975 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:05,002 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319583419 with entries=81, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319584976
2014-07-13 23:33:06,608 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:06,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39176 synced till here 39175
2014-07-13 23:33:06,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319584976 with entries=78, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319586608
2014-07-13 23:33:07,301 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8556, memsize=488.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/6b7fa8b576094f499adfe2db74c7dd27
2014-07-13 23:33:07,319 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/6b7fa8b576094f499adfe2db74c7dd27 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6b7fa8b576094f499adfe2db74c7dd27
2014-07-13 23:33:07,330 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6b7fa8b576094f499adfe2db74c7dd27, entries=1778570, sequenceid=8556, filesize=126.7m
2014-07-13 23:33:07,330 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1090410960, currentsize=459.3m/481656480 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 51203ms, sequenceid=8556, compaction requested=true
2014-07-13 23:33:07,331 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:66), split_queue=0, merge_queue=0
2014-07-13 23:33:07,331 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 1.1g
2014-07-13 23:33:07,799 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:33:07,958 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:08,306 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39277 synced till here 39276
2014-07-13 23:33:08,320 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319586608 with entries=101, filesize=83.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319587958
2014-07-13 23:33:08,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319474454
2014-07-13 23:33:08,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319479701
2014-07-13 23:33:08,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319481768
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319483483
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319485243
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319487043
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319488606
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319490023
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319491557
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319493019
2014-07-13 23:33:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319495364
2014-07-13 23:33:08,531 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:33:09,676 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:10,639 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39371 synced till here 39369
2014-07-13 23:33:10,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319587958 with entries=94, filesize=101.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319589677
2014-07-13 23:33:11,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:11,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39433 synced till here 39432
2014-07-13 23:33:11,596 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319589677 with entries=62, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319591517
2014-07-13 23:33:12,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:13,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39512 synced till here 39510
2014-07-13 23:33:13,500 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319591517 with entries=79, filesize=79.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319592914
2014-07-13 23:33:14,364 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12740, memsize=285.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/5b74449f3f5b4ce787f72cb82e473fd0
2014-07-13 23:33:14,387 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/5b74449f3f5b4ce787f72cb82e473fd0 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5b74449f3f5b4ce787f72cb82e473fd0
2014-07-13 23:33:14,401 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5b74449f3f5b4ce787f72cb82e473fd0, entries=1039250, sequenceid=12740, filesize=73.9m
2014-07-13 23:33:14,402 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~537.0m/563096560, currentsize=234.4m/245746800 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 13948ms, sequenceid=12740, compaction requested=true
2014-07-13 23:33:14,402 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:67), split_queue=0, merge_queue=0
2014-07-13 23:33:14,402 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 729.9m
2014-07-13 23:33:14,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:14,502 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39574 synced till here 39569
2014-07-13 23:33:15,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319592914 with entries=62, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319594488
2014-07-13 23:33:15,618 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:33:15,804 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:33:15,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:15,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39647 synced till here 39644
2014-07-13 23:33:15,876 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319594488 with entries=73, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319595833
2014-07-13 23:33:17,103 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:17,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39738 synced till here 39725
2014-07-13 23:33:17,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319595833 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319597103
2014-07-13 23:33:18,719 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:18,784 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39844 synced till here 39820
2014-07-13 23:33:18,869 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319597103 with entries=106, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319598719
2014-07-13 23:33:20,134 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:20,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39924 synced till here 39915
2014-07-13 23:33:21,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319598719 with entries=80, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319600134
2014-07-13 23:33:21,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:21,698 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39992 synced till here 39986
2014-07-13 23:33:21,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319600134 with entries=68, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319601681
2014-07-13 23:33:23,198 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:23,233 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40075 synced till here 40074
2014-07-13 23:33:23,325 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319601681 with entries=83, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319603198
2014-07-13 23:33:24,536 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:24,580 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319603198 with entries=64, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319604536
2014-07-13 23:33:26,416 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:26,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40208 synced till here 40196
2014-07-13 23:33:26,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319604536 with entries=69, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319606417
2014-07-13 23:33:28,064 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:28,951 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40298 synced till here 40272
2014-07-13 23:33:29,142 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319606417 with entries=90, filesize=85.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319608065
2014-07-13 23:33:29,439 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,440 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,442 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,443 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,444 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,444 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,449 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,449 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,450 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,450 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,451 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,452 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,453 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,455 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,455 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,459 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,460 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,462 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,479 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,479 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,487 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,487 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,499 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,501 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,506 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,532 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,541 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,561 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,666 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,695 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,708 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,718 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,733 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,747 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,763 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,778 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,787 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,818 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,859 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,895 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,925 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,944 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,963 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,964 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,965 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,965 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,965 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,965 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,966 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:29,968 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:31,573 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8808, memsize=399.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/ca9753c1deed4b449ff9bc6ea8f02ad8
2014-07-13 23:33:31,590 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/ca9753c1deed4b449ff9bc6ea8f02ad8 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/ca9753c1deed4b449ff9bc6ea8f02ad8
2014-07-13 23:33:31,601 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/ca9753c1deed4b449ff9bc6ea8f02ad8, entries=1453080, sequenceid=8808, filesize=103.5m
2014-07-13 23:33:31,601 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1144512960, currentsize=482.1m/505512720 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 24270ms, sequenceid=8808, compaction requested=true
2014-07-13 23:33:31,602 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:68), split_queue=0, merge_queue=0
2014-07-13 23:33:31,602 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1634ms
2014-07-13 23:33:31,602 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,602 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 959.0m
2014-07-13 23:33:31,602 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1636ms
2014-07-13 23:33:31,602 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,602 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1637ms
2014-07-13 23:33:31,602 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,603 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1638ms
2014-07-13 23:33:31,603 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,603 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1638ms
2014-07-13 23:33:31,603 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,603 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1638ms
2014-07-13 23:33:31,603 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,608 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1643ms
2014-07-13 23:33:31,608 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,608 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1645ms
2014-07-13 23:33:31,608 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,609 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1664ms
2014-07-13 23:33:31,609 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,613 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1688ms
2014-07-13 23:33:31,613 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,613 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1718ms
2014-07-13 23:33:31,613 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,613 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1755ms
2014-07-13 23:33:31,613 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,614 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1795ms
2014-07-13 23:33:31,614 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,614 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1827ms
2014-07-13 23:33:31,614 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,616 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1838ms
2014-07-13 23:33:31,616 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,617 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1853ms
2014-07-13 23:33:31,617 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,618 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1870ms
2014-07-13 23:33:31,618 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,618 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1885ms
2014-07-13 23:33:31,618 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,630 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1911ms
2014-07-13 23:33:31,630 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,630 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1922ms
2014-07-13 23:33:31,630 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,633 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1938ms
2014-07-13 23:33:31,633 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,634 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1969ms
2014-07-13 23:33:31,634 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,635 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2073ms
2014-07-13 23:33:31,635 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,635 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2094ms
2014-07-13 23:33:31,635 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,635 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2103ms
2014-07-13 23:33:31,636 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,636 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2130ms
2014-07-13 23:33:31,636 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,637 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2136ms
2014-07-13 23:33:31,637 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,641 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2142ms
2014-07-13 23:33:31,641 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,641 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2154ms
2014-07-13 23:33:31,641 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,641 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2154ms
2014-07-13 23:33:31,641 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,676 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2197ms
2014-07-13 23:33:31,677 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,677 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2198ms
2014-07-13 23:33:31,677 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,680 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2218ms
2014-07-13 23:33:31,680 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,681 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2221ms
2014-07-13 23:33:31,681 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,684 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2224ms
2014-07-13 23:33:31,684 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,684 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2229ms
2014-07-13 23:33:31,684 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,685 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2230ms
2014-07-13 23:33:31,685 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,685 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2232ms
2014-07-13 23:33:31,685 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,686 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2233ms
2014-07-13 23:33:31,686 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,686 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2235ms
2014-07-13 23:33:31,686 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,687 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2237ms
2014-07-13 23:33:31,687 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,687 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2237ms
2014-07-13 23:33:31,687 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,687 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2238ms
2014-07-13 23:33:31,687 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,689 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2240ms
2014-07-13 23:33:31,689 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,690 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2246ms
2014-07-13 23:33:31,690 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,690 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2247ms
2014-07-13 23:33:31,690 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,693 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2250ms
2014-07-13 23:33:31,693 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,694 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2251ms
2014-07-13 23:33:31,694 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,695 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2255ms
2014-07-13 23:33:31,695 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,697 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2258ms
2014-07-13 23:33:31,697 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:31,809 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:33:32,245 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:32,316 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40425 synced till here 40404
2014-07-13 23:33:32,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319608065 with entries=127, filesize=93.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319612246
2014-07-13 23:33:32,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319496914
2014-07-13 23:33:32,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319508094
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319510511
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319512328
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319513480
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319515180
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319517400
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319518779
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319520492
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319521753
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319523365
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319524586
2014-07-13 23:33:32,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319526162
2014-07-13 23:33:32,534 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:33:33,766 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8884, memsize=310.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/87ddb1e9470b4b5eba82fda01e02ae5c
2014-07-13 23:33:33,797 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/87ddb1e9470b4b5eba82fda01e02ae5c as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/87ddb1e9470b4b5eba82fda01e02ae5c
2014-07-13 23:33:33,807 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/87ddb1e9470b4b5eba82fda01e02ae5c, entries=1131870, sequenceid=8884, filesize=80.5m
2014-07-13 23:33:33,808 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~734.7m/770419600, currentsize=389.4m/408324000 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 19406ms, sequenceid=8884, compaction requested=true
2014-07-13 23:33:33,808 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:69), split_queue=0, merge_queue=0
2014-07-13 23:33:33,808 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 530.8m
2014-07-13 23:33:33,834 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:33:34,080 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:34,975 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40554 synced till here 40506
2014-07-13 23:33:35,422 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319612246 with entries=129, filesize=110.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319614080
2014-07-13 23:33:35,422 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319527681
2014-07-13 23:33:35,422 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319532333
2014-07-13 23:33:35,470 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:33:36,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:36,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40680 synced till here 40647
2014-07-13 23:33:37,308 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319614080 with entries=126, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319616875
2014-07-13 23:33:38,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:38,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40796 synced till here 40765
2014-07-13 23:33:39,005 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319616875 with entries=116, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319618636
2014-07-13 23:33:40,439 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:40,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40900 synced till here 40884
2014-07-13 23:33:40,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319618636 with entries=104, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319620440
2014-07-13 23:33:42,114 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:42,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40977 synced till here 40974
2014-07-13 23:33:42,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319620440 with entries=77, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319622114
2014-07-13 23:33:43,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:43,768 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41050 synced till here 41049
2014-07-13 23:33:43,793 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319622114 with entries=73, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319623746
2014-07-13 23:33:45,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:45,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41133 synced till here 41132
2014-07-13 23:33:45,083 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319623746 with entries=83, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319625039
2014-07-13 23:33:46,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:46,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41267 synced till here 41255
2014-07-13 23:33:46,656 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319625039 with entries=134, filesize=92.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319626206
2014-07-13 23:33:47,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:48,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41383 synced till here 41376
2014-07-13 23:33:48,443 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319626206 with entries=116, filesize=101.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319627873
2014-07-13 23:33:49,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:49,990 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319627873 with entries=75, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319629769
2014-07-13 23:33:51,308 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:51,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41536 synced till here 41534
2014-07-13 23:33:51,937 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319629769 with entries=78, filesize=75.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319631308
2014-07-13 23:33:52,244 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,245 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,246 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,261 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,276 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,278 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,286 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,290 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,293 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,302 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,312 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,316 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,317 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,320 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,320 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,325 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,331 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,352 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,388 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,442 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,489 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,639 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,641 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,687 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,689 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,701 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,730 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,749 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,758 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,787 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,822 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,825 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,836 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,836 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,846 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,865 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,868 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,897 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,910 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,926 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,926 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,927 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,938 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,939 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,970 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,991 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,992 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,992 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,992 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:52,993 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:33:55,900 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13359, memsize=442.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1618333d4f844e37b9830c98f0f426a3
2014-07-13 23:33:55,916 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1618333d4f844e37b9830c98f0f426a3 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1618333d4f844e37b9830c98f0f426a3
2014-07-13 23:33:55,937 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1618333d4f844e37b9830c98f0f426a3, entries=1611430, sequenceid=13359, filesize=114.6m
2014-07-13 23:33:55,937 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~542.4m/568779120, currentsize=286.9m/300831600 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 22129ms, sequenceid=13359, compaction requested=true
2014-07-13 23:33:55,937 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:70), split_queue=0, merge_queue=0
2014-07-13 23:33:55,938 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2946ms
2014-07-13 23:33:55,938 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,938 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 986.6m
2014-07-13 23:33:55,938 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2946ms
2014-07-13 23:33:55,939 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,939 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2947ms
2014-07-13 23:33:55,939 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,940 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2947ms
2014-07-13 23:33:55,940 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,940 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2949ms
2014-07-13 23:33:55,940 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,940 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2970ms
2014-07-13 23:33:55,940 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,940 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3001ms
2014-07-13 23:33:55,941 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,941 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3003ms
2014-07-13 23:33:55,941 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,942 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3014ms
2014-07-13 23:33:55,942 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,942 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3016ms
2014-07-13 23:33:55,942 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,943 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3017ms
2014-07-13 23:33:55,943 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,943 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3033ms
2014-07-13 23:33:55,944 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,944 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3047ms
2014-07-13 23:33:55,944 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,944 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3076ms
2014-07-13 23:33:55,944 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,945 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3080ms
2014-07-13 23:33:55,945 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,948 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3101ms
2014-07-13 23:33:55,948 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,948 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3112ms
2014-07-13 23:33:55,949 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,949 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3114ms
2014-07-13 23:33:55,949 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,949 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3124ms
2014-07-13 23:33:55,949 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,949 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:33:55,957 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3135ms
2014-07-13 23:33:55,957 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,957 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3170ms
2014-07-13 23:33:55,957 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,957 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3199ms
2014-07-13 23:33:55,957 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,958 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3208ms
2014-07-13 23:33:55,959 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,962 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3231ms
2014-07-13 23:33:55,962 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,962 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3261ms
2014-07-13 23:33:55,962 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,962 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3273ms
2014-07-13 23:33:55,962 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,963 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3275ms
2014-07-13 23:33:55,963 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,963 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3322ms
2014-07-13 23:33:55,963 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,969 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3331ms
2014-07-13 23:33:55,969 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,969 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3480ms
2014-07-13 23:33:55,969 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,977 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3536ms
2014-07-13 23:33:55,977 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,977 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3589ms
2014-07-13 23:33:55,977 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,985 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3633ms
2014-07-13 23:33:55,985 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,985 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3655ms
2014-07-13 23:33:55,985 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,985 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3660ms
2014-07-13 23:33:55,985 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,986 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3665ms
2014-07-13 23:33:55,986 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,986 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3666ms
2014-07-13 23:33:55,986 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,986 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3669ms
2014-07-13 23:33:55,986 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,991 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3675ms
2014-07-13 23:33:55,991 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,991 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3679ms
2014-07-13 23:33:55,991 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:55,997 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3695ms
2014-07-13 23:33:55,997 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,005 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3712ms
2014-07-13 23:33:56,005 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,005 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3715ms
2014-07-13 23:33:56,005 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,007 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3721ms
2014-07-13 23:33:56,007 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,008 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3730ms
2014-07-13 23:33:56,008 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,009 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3733ms
2014-07-13 23:33:56,009 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,010 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3748ms
2014-07-13 23:33:56,010 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,010 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3765ms
2014-07-13 23:33:56,011 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,011 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3766ms
2014-07-13 23:33:56,011 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:56,011 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3767ms
2014-07-13 23:33:56,011 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:33:57,424 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:57,682 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41699 synced till here 41665
2014-07-13 23:33:57,689 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:33:57,953 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319631308 with entries=163, filesize=124.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319637425
2014-07-13 23:33:59,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:33:59,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41817 synced till here 41785
2014-07-13 23:34:00,681 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319637425 with entries=118, filesize=95.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319639671
2014-07-13 23:34:01,343 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9047, memsize=526.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/98e923fe6bf3426a86df5f7bf131ebae
2014-07-13 23:34:01,354 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/98e923fe6bf3426a86df5f7bf131ebae as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/98e923fe6bf3426a86df5f7bf131ebae
2014-07-13 23:34:01,364 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/98e923fe6bf3426a86df5f7bf131ebae, entries=1916480, sequenceid=9047, filesize=136.4m
2014-07-13 23:34:01,366 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~959.0m/1005550480, currentsize=610.9m/640613520 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 29763ms, sequenceid=9047, compaction requested=true
2014-07-13 23:34:01,366 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:71), split_queue=0, merge_queue=0
2014-07-13 23:34:01,367 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 947.9m
2014-07-13 23:34:01,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:01,454 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:34:01,490 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41927 synced till here 41903
2014-07-13 23:34:02,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319639671 with entries=110, filesize=89.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319641453
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319535956
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319538086
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319540111
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319542096
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319545257
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319568674
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319570009
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319571499
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319572880
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319581636
2014-07-13 23:34:02,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319583419
2014-07-13 23:34:02,459 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319584976
2014-07-13 23:34:03,221 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:34:04,028 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:04,061 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42054 synced till here 42035
2014-07-13 23:34:04,263 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319641453 with entries=127, filesize=102.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319644029
2014-07-13 23:34:05,614 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:05,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42170 synced till here 42146
2014-07-13 23:34:05,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319644029 with entries=116, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319645615
2014-07-13 23:34:06,605 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:07,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319645615 with entries=76, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319646606
2014-07-13 23:34:08,717 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:08,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319646606 with entries=62, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319648717
2014-07-13 23:34:09,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:09,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42369 synced till here 42367
2014-07-13 23:34:10,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319648717 with entries=61, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319649817
2014-07-13 23:34:11,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:11,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42473 synced till here 42455
2014-07-13 23:34:11,885 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319649817 with entries=104, filesize=81.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319651691
2014-07-13 23:34:13,676 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:13,707 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,710 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,713 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,714 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,714 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,715 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42590 synced till here 42557
2014-07-13 23:34:13,773 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,843 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,859 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,904 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,907 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,911 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,912 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,913 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,913 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,914 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,915 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,916 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,918 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,920 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,924 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,939 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319651691 with entries=117, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319653676
2014-07-13 23:34:13,947 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,948 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:13,949 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,002 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,008 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,009 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,009 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,029 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,029 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,029 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,031 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,031 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,032 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,032 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,035 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,037 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,042 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,050 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,059 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,118 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,119 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,149 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,149 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,151 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,206 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,211 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,253 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,258 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:14,307 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:34:18,707 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,710 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,713 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,714 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,714 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,716 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,774 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,843 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,859 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,905 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,907 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,912 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,912 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,913 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,914 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,914 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,915 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,916 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,918 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,920 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,924 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,948 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:18,949 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:18,949 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,002 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,008 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,009 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,010 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,029 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,029 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,030 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,031 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,032 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,032 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,033 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,035 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,037 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,043 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,050 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,059 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,118 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,120 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,149 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,150 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,151 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,207 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,212 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:19,254 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,259 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:34:19,308 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:34:21,093 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/dd62800a8ca14d09bf9264429a7fa417 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/dd62800a8ca14d09bf9264429a7fa417
2014-07-13 23:34:21,118 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:34:21,135 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/4916d9a4d57b4f80903aa88a1a6b9ee3, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/4916d9a4d57b4f80903aa88a1a6b9ee3
2014-07-13 23:34:21,139 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/db3a5c3eedc04b1e8ea02f2b1fa3f471, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/db3a5c3eedc04b1e8ea02f2b1fa3f471
2014-07-13 23:34:21,143 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ab775b689f9348019cb0fc4c3d3b99b3, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ab775b689f9348019cb0fc4c3d3b99b3
2014-07-13 23:34:21,148 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/13dc9c4915784adca639394bb2db59ec, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/13dc9c4915784adca639394bb2db59ec
2014-07-13 23:34:21,153 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c71c006a37c4e149cad48f4876e143e, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/0c71c006a37c4e149cad48f4876e143e
2014-07-13 23:34:21,157 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/a2b662b94683429989ba4f5884afb92e, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/a2b662b94683429989ba4f5884afb92e
2014-07-13 23:34:21,160 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/40daeef5cbea4d0d8b446fee12020d12, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/40daeef5cbea4d0d8b446fee12020d12
2014-07-13 23:34:21,167 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1e3e400cda0d4b609c99d9737c1177c6, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1e3e400cda0d4b609c99d9737c1177c6
2014-07-13 23:34:21,169 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5f1c7bb75e9341ae9aa648260d5d757a, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5f1c7bb75e9341ae9aa648260d5d757a
2014-07-13 23:34:21,174 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1a71dee0da7f47dbb034cc67c7b2907a, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1a71dee0da7f47dbb034cc67c7b2907a
2014-07-13 23:34:21,175 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into dd62800a8ca14d09bf9264429a7fa417(size=837.2m), total size for store is 2.0g. This selection was in queue for 0sec, and took 3mins, 35sec to execute.
2014-07-13 23:34:21,175 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., storeName=family, fileCount=10, fileSize=919.5m, priority=6, time=273352986363822; duration=3mins, 35sec
2014-07-13 23:34:21,175 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:71), split_queue=0, merge_queue=0
2014-07-13 23:34:21,176 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-13 23:34:21,178 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 917275031 starting at candidate #1 after considering 92 permutations with 88 in ratio
2014-07-13 23:34:21,178 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: baaed08b3b283bc33b53e718e07d0f23 - family: Initiating minor compaction
2014-07-13 23:34:21,179 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:34:21,179 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp, totalSize=874.8m
2014-07-13 23:34:21,179 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b6705ddd5f724c869f6ebf9e77a5dad5, keycount=86773, bloomtype=ROW, size=61.8m, encoding=NONE, seqNum=3052
2014-07-13 23:34:21,179 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/81ae3ba2ce0c48e78e80fd3c7a989317, keycount=105057, bloomtype=ROW, size=74.8m, encoding=NONE, seqNum=3554
2014-07-13 23:34:21,179 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ea070eb81c1348a4882337b13d4c6479, keycount=122378, bloomtype=ROW, size=87.1m, encoding=NONE, seqNum=4345
2014-07-13 23:34:21,180 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/45268bdf292f44118de2666e6bc0966c, keycount=142888, bloomtype=ROW, size=101.8m, encoding=NONE, seqNum=4944
2014-07-13 23:34:21,180 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/47c85b5121cf40f48b6e880b2c4bc3b3, keycount=105961, bloomtype=ROW, size=75.5m, encoding=NONE, seqNum=5725
2014-07-13 23:34:21,180 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5cebceae75314960948b68aeafc83097, keycount=182562, bloomtype=ROW, size=130.0m, encoding=NONE, seqNum=6379
2014-07-13 23:34:21,180 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1c219b4b18b24e8ea638b3357bcb3f2c, keycount=77082, bloomtype=ROW, size=54.9m, encoding=NONE, seqNum=7090
2014-07-13 23:34:21,180 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/957055a7bf5f4f67beed61bd502511df, keycount=145540, bloomtype=ROW, size=103.7m, encoding=NONE, seqNum=7721
2014-07-13 23:34:21,180 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/91432a61750e4002b21398aebec9af4a, keycount=112205, bloomtype=ROW, size=79.9m, encoding=NONE, seqNum=8403
2014-07-13 23:34:21,180 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/adaab50c6c3e4cd79b9b46ed056f5f0c, keycount=147853, bloomtype=ROW, size=105.3m, encoding=NONE, seqNum=9052
2014-07-13 23:34:21,444 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:34:23,119 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.91 MB, free=3.95 GB, max=3.96 GB, blocks=8, accesses=223406, hits=68213, hitRatio=30.53%, , cachingAccesses=68243, cachingHits=68188, cachingHitsRatio=99.91%, evictions=0, evicted=47, evictedPerRun=Infinity
2014-07-13 23:34:23,708 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,711 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,714 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:23,715 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:23,715 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,716 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,774 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,844 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,860 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:34:23,906 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:34:23,908 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,913 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,913 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,914 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:23,914 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,915 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,916 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:23,917 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,919 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,921 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:23,925 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,948 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,949 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:23,950 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,002 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,008 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,009 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,010 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,030 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,031 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,031 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:34:24,032 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,032 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,033 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,033 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,035 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,038 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,043 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,050 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,059 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,119 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,120 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,149 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,150 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,151 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:34:24,207 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,212 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,254 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,259 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:34:24,309 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:34:25,198 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9421, memsize=442.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/72de0aaf971e4b0f95501112ae9ebd70
2014-07-13 23:34:25,217 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/72de0aaf971e4b0f95501112ae9ebd70 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/72de0aaf971e4b0f95501112ae9ebd70
2014-07-13 23:34:25,227 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/72de0aaf971e4b0f95501112ae9ebd70, entries=1612330, sequenceid=9421, filesize=114.8m
2014-07-13 23:34:25,227 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~968.0m/1015022480, currentsize=279.5m/293026480 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 23860ms, sequenceid=9421, compaction requested=true
2014-07-13 23:34:25,227 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:71), split_queue=0, merge_queue=0
2014-07-13 23:34:25,227 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10920ms
2014-07-13 23:34:25,228 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,228 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 556.7m
2014-07-13 23:34:25,228 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10970ms
2014-07-13 23:34:25,228 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,228 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10975ms
2014-07-13 23:34:25,229 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,229 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11018ms
2014-07-13 23:34:25,229 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,229 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11023ms
2014-07-13 23:34:25,229 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,230 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11079ms
2014-07-13 23:34:25,230 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,230 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11081ms
2014-07-13 23:34:25,231 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,231 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11082ms
2014-07-13 23:34:25,231 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,235 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11116ms
2014-07-13 23:34:25,235 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,235 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11118ms
2014-07-13 23:34:25,235 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,235 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11176ms
2014-07-13 23:34:25,235 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,236 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11186ms
2014-07-13 23:34:25,236 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,237 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11195ms
2014-07-13 23:34:25,237 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,237 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11200ms
2014-07-13 23:34:25,237 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,241 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10988,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654253,"queuetimems":0,"class":"HRegionServer","responsesize":44,"method":"Multi"}
2014-07-13 23:34:25,249 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11214ms
2014-07-13 23:34:25,249 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,249 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11217ms
2014-07-13 23:34:25,249 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,249 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11217ms
2014-07-13 23:34:25,249 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,250 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11218ms
2014-07-13 23:34:25,250 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,251 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11220ms
2014-07-13 23:34:25,251 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,252 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11223ms
2014-07-13 23:34:25,252 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,252 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11223ms
2014-07-13 23:34:25,252 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,253 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11224ms
2014-07-13 23:34:25,253 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,253 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11244ms
2014-07-13 23:34:25,253 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,253 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11244ms
2014-07-13 23:34:25,253 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,253 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11245ms
2014-07-13 23:34:25,253 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,254 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11252ms
2014-07-13 23:34:25,254 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,258 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11308ms
2014-07-13 23:34:25,258 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,259 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11310ms
2014-07-13 23:34:25,259 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,262 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11315ms
2014-07-13 23:34:25,262 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,266 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654206,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:34:25,267 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11117,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654149,"queuetimems":0,"class":"HRegionServer","responsesize":550,"method":"Multi"}
2014-07-13 23:34:25,269 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11345ms
2014-07-13 23:34:25,269 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,269 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11121,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654148,"queuetimems":0,"class":"HRegionServer","responsesize":62,"method":"Multi"}
2014-07-13 23:34:25,270 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11349ms
2014-07-13 23:34:25,270 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,273 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11355ms
2014-07-13 23:34:25,273 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,273 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11357ms
2014-07-13 23:34:25,273 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,273 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11358ms
2014-07-13 23:34:25,273 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,277 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11160,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654117,"queuetimems":0,"class":"HRegionServer","responsesize":177,"method":"Multi"}
2014-07-13 23:34:25,281 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11231,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654050,"queuetimems":1,"class":"HRegionServer","responsesize":116,"method":"Multi"}
2014-07-13 23:34:25,281 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11223,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654058,"queuetimems":0,"class":"HRegionServer","responsesize":1469,"method":"Multi"}
2014-07-13 23:34:25,285 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11371ms
2014-07-13 23:34:25,285 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,285 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11372ms
2014-07-13 23:34:25,285 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,285 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11372ms
2014-07-13 23:34:25,285 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,293 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11381ms
2014-07-13 23:34:25,293 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,293 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11382ms
2014-07-13 23:34:25,293 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,305 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11399ms
2014-07-13 23:34:25,305 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,306 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11401ms
2014-07-13 23:34:25,306 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,306 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11448ms
2014-07-13 23:34:25,306 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,308 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11464ms
2014-07-13 23:34:25,308 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,308 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11535ms
2014-07-13 23:34:25,308 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,308 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11593ms
2014-07-13 23:34:25,308 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,309 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11595ms
2014-07-13 23:34:25,310 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,310 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11596ms
2014-07-13 23:34:25,310 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,313 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11600ms
2014-07-13 23:34:25,313 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,313 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11603ms
2014-07-13 23:34:25,313 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,313 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11606ms
2014-07-13 23:34:25,313 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:34:25,370 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11341,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654029,"queuetimems":0,"class":"HRegionServer","responsesize":74,"method":"Multi"}
2014-07-13 23:34:25,370 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11253,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654117,"queuetimems":0,"class":"HRegionServer","responsesize":4165,"method":"Multi"}
2014-07-13 23:34:25,377 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654031,"queuetimems":0,"class":"HRegionServer","responsesize":32,"method":"Multi"}
2014-07-13 23:34:25,377 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11430,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653947,"queuetimems":0,"class":"HRegionServer","responsesize":464,"method":"Multi"}
2014-07-13 23:34:25,377 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654031,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:34:25,379 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11349,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654029,"queuetimems":1,"class":"HRegionServer","responsesize":20,"method":"Multi"}
2014-07-13 23:34:25,370 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654028,"queuetimems":0,"class":"HRegionServer","responsesize":50,"method":"Multi"}
2014-07-13 23:34:25,377 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654031,"queuetimems":0,"class":"HRegionServer","responsesize":128,"method":"Multi"}
2014-07-13 23:34:25,402 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11456,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653946,"queuetimems":0,"class":"HRegionServer","responsesize":4023,"method":"Multi"}
2014-07-13 23:34:25,487 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11547,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653938,"queuetimems":0,"class":"HRegionServer","responsesize":8928,"method":"Multi"}
2014-07-13 23:34:25,501 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11583,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653918,"queuetimems":0,"class":"HRegionServer","responsesize":2110,"method":"Multi"}
2014-07-13 23:34:25,502 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11588,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653913,"queuetimems":0,"class":"HRegionServer","responsesize":26,"method":"Multi"}
2014-07-13 23:34:25,503 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653912,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:34:25,501 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11579,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653922,"queuetimems":0,"class":"HRegionServer","responsesize":1761,"method":"Multi"}
2014-07-13 23:34:25,575 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:34:25,700 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12498,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653201,"queuetimems":0,"class":"HRegionServer","responsesize":18380,"method":"Multi"}
2014-07-13 23:34:25,731 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13435,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652296,"queuetimems":0,"class":"HRegionServer","responsesize":15384,"method":"Multi"}
2014-07-13 23:34:25,733 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13368,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652364,"queuetimems":0,"class":"HRegionServer","responsesize":18334,"method":"Multi"}
2014-07-13 23:34:25,949 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13729,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652219,"queuetimems":1,"class":"HRegionServer","responsesize":17467,"method":"Multi"}
2014-07-13 23:34:25,949 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652136,"queuetimems":1,"class":"HRegionServer","responsesize":16030,"method":"Multi"}
2014-07-13 23:34:25,949 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652090,"queuetimems":1,"class":"HRegionServer","responsesize":16219,"method":"Multi"}
2014-07-13 23:34:25,949 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13687,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652262,"queuetimems":0,"class":"HRegionServer","responsesize":16011,"method":"Multi"}
2014-07-13 23:34:25,949 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13770,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652179,"queuetimems":0,"class":"HRegionServer","responsesize":17992,"method":"Multi"}
2014-07-13 23:34:25,955 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13920,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319652035,"queuetimems":1,"class":"HRegionServer","responsesize":9887,"method":"Multi"}
2014-07-13 23:34:25,957 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14046,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319651910,"queuetimems":0,"class":"HRegionServer","responsesize":18630,"method":"Multi"}
2014-07-13 23:34:25,989 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9337, memsize=576.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/42d495aec762451c9e9f44dc6e5c30ef
2014-07-13 23:34:25,993 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:34:26,016 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/42d495aec762451c9e9f44dc6e5c30ef as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/42d495aec762451c9e9f44dc6e5c30ef
2014-07-13 23:34:26,052 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/42d495aec762451c9e9f44dc6e5c30ef, entries=2099660, sequenceid=9337, filesize=149.4m
2014-07-13 23:34:26,052 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~986.6m/1034529760, currentsize=427.0m/447788320 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 30114ms, sequenceid=9337, compaction requested=true
2014-07-13 23:34:26,053 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:72), split_queue=0, merge_queue=0
2014-07-13 23:34:26,053 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 926.5m
2014-07-13 23:34:26,250 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:26,403 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42740 synced till here 42703
2014-07-13 23:34:27,110 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:34:27,111 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13699,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653411,"queuetimems":0,"class":"HRegionServer","responsesize":6188,"method":"Multi"}
2014-07-13 23:34:27,111 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13760,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653350,"queuetimems":0,"class":"HRegionServer","responsesize":14227,"method":"Multi"}
2014-07-13 23:34:27,111 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13432,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653678,"queuetimems":14,"class":"HRegionServer","responsesize":18363,"method":"Multi"}
2014-07-13 23:34:27,111 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13896,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653214,"queuetimems":0,"class":"HRegionServer","responsesize":18322,"method":"Multi"}
2014-07-13 23:34:27,111 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13433,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653678,"queuetimems":85,"class":"HRegionServer","responsesize":18571,"method":"Multi"}
2014-07-13 23:34:27,111 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13711,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653399,"queuetimems":0,"class":"HRegionServer","responsesize":18685,"method":"Multi"}
2014-07-13 23:34:27,111 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13870,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653240,"queuetimems":0,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-13 23:34:27,275 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13247,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654028,"queuetimems":0,"class":"HRegionServer","responsesize":9887,"method":"Multi"}
2014-07-13 23:34:27,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319653676 with entries=150, filesize=106.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319666251
2014-07-13 23:34:27,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319586608
2014-07-13 23:34:27,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319587958
2014-07-13 23:34:27,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319589677
2014-07-13 23:34:27,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319591517
2014-07-13 23:34:27,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319592914
2014-07-13 23:34:27,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319594488
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319595833
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319597103
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319598719
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319600134
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319601681
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319603198
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319604536
2014-07-13 23:34:27,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319606417
2014-07-13 23:34:27,630 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13481,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654148,"queuetimems":0,"class":"HRegionServer","responsesize":14227,"method":"Multi"}
2014-07-13 23:34:27,637 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13634,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654003,"queuetimems":0,"class":"HRegionServer","responsesize":15689,"method":"Multi"}
2014-07-13 23:34:27,638 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13338,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654300,"queuetimems":0,"class":"HRegionServer","responsesize":18380,"method":"Multi"}
2014-07-13 23:34:27,637 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13782,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653855,"queuetimems":0,"class":"HRegionServer","responsesize":6969,"method":"Multi"}
2014-07-13 23:34:27,650 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13396,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654253,"queuetimems":1,"class":"HRegionServer","responsesize":18322,"method":"Multi"}
2014-07-13 23:34:27,650 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13443,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319654206,"queuetimems":0,"class":"HRegionServer","responsesize":17493,"method":"Multi"}
2014-07-13 23:34:27,651 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13811,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653839,"queuetimems":0,"class":"HRegionServer","responsesize":16061,"method":"Multi"}
2014-07-13 23:34:27,652 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13739,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653912,"queuetimems":1,"class":"HRegionServer","responsesize":11847,"method":"Multi"}
2014-07-13 23:34:27,659 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14338,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653320,"queuetimems":0,"class":"HRegionServer","responsesize":17493,"method":"Multi"}
2014-07-13 23:34:27,659 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13892,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653767,"queuetimems":0,"class":"HRegionServer","responsesize":16053,"method":"Multi"}
2014-07-13 23:34:28,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:28,069 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42849 synced till here 42824
2014-07-13 23:34:28,083 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:34:28,898 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319653715,"queuetimems":0,"class":"HRegionServer","responsesize":18630,"method":"Multi"}
2014-07-13 23:34:28,973 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319666251 with entries=109, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319668010
2014-07-13 23:34:29,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:30,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42979 synced till here 42933
2014-07-13 23:34:30,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319668010 with entries=130, filesize=109.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319669787
2014-07-13 23:34:32,464 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:32,500 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43130 synced till here 43095
2014-07-13 23:34:32,606 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319669787 with entries=151, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319672464
2014-07-13 23:34:33,664 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:33,679 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43213 synced till here 43212
2014-07-13 23:34:33,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319672464 with entries=83, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319673664
2014-07-13 23:34:34,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:35,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43306 synced till here 43298
2014-07-13 23:34:35,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319673664 with entries=93, filesize=96.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319674806
2014-07-13 23:34:36,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:36,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43370 synced till here 43363
2014-07-13 23:34:36,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319674806 with entries=64, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319676654
2014-07-13 23:34:37,938 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:38,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43454 synced till here 43441
2014-07-13 23:34:38,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319676654 with entries=84, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319677938
2014-07-13 23:34:39,499 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:39,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319677938 with entries=65, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319679500
2014-07-13 23:34:40,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:41,250 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43606 synced till here 43592
2014-07-13 23:34:41,310 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319679500 with entries=87, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319680790
2014-07-13 23:34:42,420 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:42,553 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14004, memsize=333.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d5adeca2d3ab4173bb1725eb80b9c508
2014-07-13 23:34:42,554 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43680 synced till here 43670
2014-07-13 23:34:42,614 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d5adeca2d3ab4173bb1725eb80b9c508 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d5adeca2d3ab4173bb1725eb80b9c508
2014-07-13 23:34:42,629 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d5adeca2d3ab4173bb1725eb80b9c508, entries=1213210, sequenceid=14004, filesize=86.4m
2014-07-13 23:34:42,629 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~556.7m/583729680, currentsize=268.2m/281277200 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 17401ms, sequenceid=14004, compaction requested=true
2014-07-13 23:34:42,630 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:73), split_queue=0, merge_queue=0
2014-07-13 23:34:42,630 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:34:42,630 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 735.2m
2014-07-13 23:34:42,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319680790 with entries=74, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319682420
2014-07-13 23:34:43,796 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:34:44,518 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:44,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43746 synced till here 43745
2014-07-13 23:34:44,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319682420 with entries=66, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319684519
2014-07-13 23:34:45,648 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:45,688 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43829 synced till here 43817
2014-07-13 23:34:45,771 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319684519 with entries=83, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319685666
2014-07-13 23:34:47,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:47,194 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43905 synced till here 43904
2014-07-13 23:34:47,253 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319685666 with entries=76, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319687118
2014-07-13 23:34:48,584 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9593, memsize=352.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/7e5d3fff04da41988deff0b1a02f6386
2014-07-13 23:34:48,596 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/7e5d3fff04da41988deff0b1a02f6386 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7e5d3fff04da41988deff0b1a02f6386
2014-07-13 23:34:48,680 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:48,860 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7e5d3fff04da41988deff0b1a02f6386, entries=1283510, sequenceid=9593, filesize=91.4m
2014-07-13 23:34:48,860 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~962.6m/1009390560, currentsize=548.5m/575194160 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 22807ms, sequenceid=9593, compaction requested=true
2014-07-13 23:34:48,861 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:74), split_queue=0, merge_queue=0
2014-07-13 23:34:48,861 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 1016.5m
2014-07-13 23:34:49,641 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:34:49,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44018 synced till here 44007
2014-07-13 23:34:49,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319687118 with entries=113, filesize=99.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319688680
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319608065
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319612246
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319614080
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319616875
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319618636
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319620440
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319622114
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319623746
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319625039
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319626206
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319627873
2014-07-13 23:34:49,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319629769
2014-07-13 23:34:50,411 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:50,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44143 synced till here 44120
2014-07-13 23:34:51,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319688680 with entries=125, filesize=78.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319690411
2014-07-13 23:34:51,514 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:34:52,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:52,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44218 synced till here 44208
2014-07-13 23:34:52,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319690411 with entries=75, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319692104
2014-07-13 23:34:53,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:54,206 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44291 synced till here 44272
2014-07-13 23:34:54,281 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319692104 with entries=73, filesize=78.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319693564
2014-07-13 23:34:55,046 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:55,110 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319693564 with entries=64, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319695047
2014-07-13 23:34:56,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:56,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44424 synced till here 44423
2014-07-13 23:34:56,281 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319695047 with entries=69, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319696204
2014-07-13 23:34:57,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:57,407 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44487 synced till here 44486
2014-07-13 23:34:57,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319696204 with entries=63, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319697392
2014-07-13 23:34:58,829 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:34:58,856 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44560 synced till here 44558
2014-07-13 23:34:58,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319697392 with entries=73, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319698829
2014-07-13 23:35:00,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:00,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319698829 with entries=63, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319700141
2014-07-13 23:35:01,657 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9802, memsize=346.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/add8a32c855d49578c4f86588e361db8
2014-07-13 23:35:01,984 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:01,993 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/add8a32c855d49578c4f86588e361db8 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/add8a32c855d49578c4f86588e361db8
2014-07-13 23:35:02,007 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/add8a32c855d49578c4f86588e361db8, entries=1260440, sequenceid=9802, filesize=89.8m
2014-07-13 23:35:02,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319700141 with entries=63, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319701984
2014-07-13 23:35:02,008 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~744.4m/780597440, currentsize=426.1m/446809440 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 19378ms, sequenceid=9802, compaction requested=true
2014-07-13 23:35:02,008 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:75), split_queue=0, merge_queue=0
2014-07-13 23:35:02,008 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 618.2m
2014-07-13 23:35:02,053 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:35:02,484 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:35:03,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:03,878 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44760 synced till here 44759
2014-07-13 23:35:03,904 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319701984 with entries=74, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319703594
2014-07-13 23:35:05,269 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:05,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44845 synced till here 44839
2014-07-13 23:35:05,652 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319703594 with entries=85, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319705269
2014-07-13 23:35:06,770 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:07,321 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319705269 with entries=80, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319706771
2014-07-13 23:35:08,372 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:08,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44996 synced till here 44990
2014-07-13 23:35:08,936 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319706771 with entries=71, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319708373
2014-07-13 23:35:09,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:09,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319708373 with entries=66, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319709623
2014-07-13 23:35:11,113 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:11,134 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45125 synced till here 45123
2014-07-13 23:35:11,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319709623 with entries=63, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319711114
2014-07-13 23:35:11,913 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:11,952 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:11,953 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:11,954 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:11,955 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:11,956 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:11,964 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:11,965 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,002 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,017 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,032 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,042 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,100 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,109 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,110 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,128 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,139 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,153 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,157 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,207 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,245 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,283 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,285 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,348 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,352 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9876, memsize=411.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/d4721d5e74eb4d4b8da5595fafa0d712
2014-07-13 23:35:12,357 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,357 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,360 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,360 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,361 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,362 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:12,367 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/d4721d5e74eb4d4b8da5595fafa0d712 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/d4721d5e74eb4d4b8da5595fafa0d712
2014-07-13 23:35:12,386 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/d4721d5e74eb4d4b8da5595fafa0d712, entries=1497950, sequenceid=9876, filesize=106.7m
2014-07-13 23:35:12,387 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.0g/1078504960, currentsize=516.2m/541326480 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 23526ms, sequenceid=9876, compaction requested=true
2014-07-13 23:35:12,387 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-13 23:35:12,387 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25ms
2014-07-13 23:35:12,387 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,387 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26ms
2014-07-13 23:35:12,387 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,387 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1.1g
2014-07-13 23:35:12,387 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27ms
2014-07-13 23:35:12,387 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,387 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27ms
2014-07-13 23:35:12,388 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,388 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 31ms
2014-07-13 23:35:12,388 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,389 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32ms
2014-07-13 23:35:12,389 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,389 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 41ms
2014-07-13 23:35:12,389 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,389 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 104ms
2014-07-13 23:35:12,389 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,389 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 106ms
2014-07-13 23:35:12,389 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,389 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 145ms
2014-07-13 23:35:12,389 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,393 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 186ms
2014-07-13 23:35:12,393 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,393 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 236ms
2014-07-13 23:35:12,393 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,395 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 242ms
2014-07-13 23:35:12,395 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,397 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 259ms
2014-07-13 23:35:12,397 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,397 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 269ms
2014-07-13 23:35:12,397 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,397 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 287ms
2014-07-13 23:35:12,397 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,399 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 290ms
2014-07-13 23:35:12,399 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,399 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 299ms
2014-07-13 23:35:12,399 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,399 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 357ms
2014-07-13 23:35:12,399 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,399 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 367ms
2014-07-13 23:35:12,399 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,399 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 382ms
2014-07-13 23:35:12,400 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,403 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 402ms
2014-07-13 23:35:12,403 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,403 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 438ms
2014-07-13 23:35:12,403 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,403 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 439ms
2014-07-13 23:35:12,403 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,406 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 450ms
2014-07-13 23:35:12,406 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,406 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 451ms
2014-07-13 23:35:12,406 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,406 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 452ms
2014-07-13 23:35:12,406 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,406 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 454ms
2014-07-13 23:35:12,406 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,406 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 454ms
2014-07-13 23:35:12,407 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,407 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 494ms
2014-07-13 23:35:12,407 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:12,773 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:35:12,914 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:13,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45218 synced till here 45197
2014-07-13 23:35:13,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319711114 with entries=93, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319712914
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319631308
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319637425
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319639671
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319641453
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319644029
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319645615
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319646606
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319648717
2014-07-13 23:35:13,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319649817
2014-07-13 23:35:13,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319651691
2014-07-13 23:35:14,257 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:35:15,515 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:15,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45331 synced till here 45311
2014-07-13 23:35:15,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319712914 with entries=113, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319715516
2014-07-13 23:35:17,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:17,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45440 synced till here 45415
2014-07-13 23:35:17,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319715516 with entries=109, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319717709
2014-07-13 23:35:19,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:19,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45553 synced till here 45523
2014-07-13 23:35:21,317 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1091ms
GC pool 'ParNew' had collection(s): count=1 time=1164ms
2014-07-13 23:35:21,430 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319717709 with entries=113, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319719847
2014-07-13 23:35:22,244 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:22,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45655 synced till here 45624
2014-07-13 23:35:23,441 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319719847 with entries=102, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319722244
2014-07-13 23:35:25,388 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:25,434 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45762 synced till here 45738
2014-07-13 23:35:25,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319722244 with entries=107, filesize=90.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319725389
2014-07-13 23:35:27,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:27,404 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,404 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,405 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,406 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,406 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,407 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,418 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45876 synced till here 45856
2014-07-13 23:35:27,422 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,494 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,494 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,497 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,497 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,497 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,498 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,499 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,502 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,538 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,540 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,564 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319725389 with entries=114, filesize=81.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319727401
2014-07-13 23:35:27,594 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,595 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,596 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:27,598 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,095 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,125 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,169 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,211 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,219 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,254 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,256 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,291 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,305 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,342 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,376 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,415 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,444 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,474 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,475 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,477 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,489 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,500 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,523 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,562 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,590 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,619 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,658 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,676 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,688 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,694 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,698 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:28,698 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:30,168 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14706, memsize=490.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/8dafd496f34245b5a05f6418789592bd
2014-07-13 23:35:30,183 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/8dafd496f34245b5a05f6418789592bd as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/8dafd496f34245b5a05f6418789592bd
2014-07-13 23:35:31,018 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/8dafd496f34245b5a05f6418789592bd, entries=1785280, sequenceid=14706, filesize=127.1m
2014-07-13 23:35:31,019 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~621.2m/651347920, currentsize=366.1m/383886720 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 29010ms, sequenceid=14706, compaction requested=true
2014-07-13 23:35:31,019 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:77), split_queue=0, merge_queue=0
2014-07-13 23:35:31,019 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2321ms
2014-07-13 23:35:31,019 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,019 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 949.5m
2014-07-13 23:35:31,019 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2321ms
2014-07-13 23:35:31,019 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,021 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2327ms
2014-07-13 23:35:31,021 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,023 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2336ms
2014-07-13 23:35:31,023 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,023 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:35:31,029 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2353ms
2014-07-13 23:35:31,029 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,029 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2372ms
2014-07-13 23:35:31,029 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,029 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2410ms
2014-07-13 23:35:31,029 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,029 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2439ms
2014-07-13 23:35:31,029 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,029 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2467ms
2014-07-13 23:35:31,029 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,029 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2506ms
2014-07-13 23:35:31,030 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,032 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2532ms
2014-07-13 23:35:31,032 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,032 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2543ms
2014-07-13 23:35:31,032 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,032 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2555ms
2014-07-13 23:35:31,032 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,033 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2558ms
2014-07-13 23:35:31,033 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,035 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2561ms
2014-07-13 23:35:31,035 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,035 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2591ms
2014-07-13 23:35:31,035 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,036 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2621ms
2014-07-13 23:35:31,036 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,039 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2662ms
2014-07-13 23:35:31,039 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,039 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2697ms
2014-07-13 23:35:31,039 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,039 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2735ms
2014-07-13 23:35:31,039 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,042 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2751ms
2014-07-13 23:35:31,042 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,043 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2787ms
2014-07-13 23:35:31,043 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,043 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2790ms
2014-07-13 23:35:31,043 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,043 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2824ms
2014-07-13 23:35:31,043 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,044 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2833ms
2014-07-13 23:35:31,044 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,044 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2875ms
2014-07-13 23:35:31,044 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,044 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2920ms
2014-07-13 23:35:31,044 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,044 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2949ms
2014-07-13 23:35:31,044 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,044 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3446ms
2014-07-13 23:35:31,045 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,045 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3449ms
2014-07-13 23:35:31,045 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,047 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3452ms
2014-07-13 23:35:31,047 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,048 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3454ms
2014-07-13 23:35:31,048 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,049 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3508ms
2014-07-13 23:35:31,049 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,049 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3511ms
2014-07-13 23:35:31,049 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,057 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3555ms
2014-07-13 23:35:31,057 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,058 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3558ms
2014-07-13 23:35:31,058 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,058 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3560ms
2014-07-13 23:35:31,058 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,058 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3561ms
2014-07-13 23:35:31,058 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,058 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3561ms
2014-07-13 23:35:31,058 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,059 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3563ms
2014-07-13 23:35:31,060 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,063 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3569ms
2014-07-13 23:35:31,063 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,064 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3569ms
2014-07-13 23:35:31,064 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,064 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3642ms
2014-07-13 23:35:31,064 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,070 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3652ms
2014-07-13 23:35:31,070 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,070 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3663ms
2014-07-13 23:35:31,070 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,070 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3664ms
2014-07-13 23:35:31,070 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,070 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3664ms
2014-07-13 23:35:31,071 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,071 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3666ms
2014-07-13 23:35:31,071 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,077 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3673ms
2014-07-13 23:35:31,077 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,077 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3674ms
2014-07-13 23:35:31,077 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:31,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:31,877 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46005 synced till here 45968
2014-07-13 23:35:31,975 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:35:32,976 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319727401 with entries=129, filesize=92.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319731842
2014-07-13 23:35:33,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:34,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46119 synced till here 46110
2014-07-13 23:35:34,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319731842 with entries=114, filesize=82.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319733807
2014-07-13 23:35:35,825 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:36,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46202 synced till here 46186
2014-07-13 23:35:36,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319733807 with entries=83, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319735826
2014-07-13 23:35:37,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:37,398 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,401 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,440 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,448 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,477 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319735826 with entries=67, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319737295
2014-07-13 23:35:37,492 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,494 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,538 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,850 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,884 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,896 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,896 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,903 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,905 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,908 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,935 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:37,990 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,005 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,016 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,053 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,097 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,104 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,112 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,180 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,220 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,221 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,233 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,233 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,235 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,274 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,276 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,304 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,305 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,305 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,308 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,312 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,356 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,393 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,429 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,469 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,515 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,554 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,592 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,615 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,657 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,688 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,726 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,732 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,740 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,764 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:38,789 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:35:42,398 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,402 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:42,440 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,449 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:42,492 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,494 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,538 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,850 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,884 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,896 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,897 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,903 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,906 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:42,908 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,935 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:42,990 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,006 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,016 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,053 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,098 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,104 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,112 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,181 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,220 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,222 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,233 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,234 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,235 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,275 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,277 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,304 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,305 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,305 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,308 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,312 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,357 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,394 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,430 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,470 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,515 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,555 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,592 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,615 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,657 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,688 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,727 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,732 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,741 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:43,764 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:35:43,789 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:35:47,398 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:47,402 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,441 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,449 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,492 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:47,495 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,538 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:47,851 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,884 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:47,897 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,897 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,904 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,906 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,908 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:47,936 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:47,991 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,007 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,016 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,054 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,098 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,105 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,113 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,181 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,221 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,223 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,234 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,234 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,236 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,275 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,277 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,304 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,305 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,305 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,309 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,312 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,357 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,394 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,430 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,470 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,516 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,555 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,593 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,615 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,658 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,689 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,727 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,732 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:35:48,741 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,765 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:48,789 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:35:50,774 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10144, memsize=704.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/cf617cd67d524475972a1c6e0bc38805
2014-07-13 23:35:50,793 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/cf617cd67d524475972a1c6e0bc38805 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/cf617cd67d524475972a1c6e0bc38805
2014-07-13 23:35:50,811 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/cf617cd67d524475972a1c6e0bc38805, entries=2566590, sequenceid=10144, filesize=182.7m
2014-07-13 23:35:50,811 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1130584400, currentsize=450.5m/472352160 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 38424ms, sequenceid=10144, compaction requested=true
2014-07-13 23:35:50,811 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:78), split_queue=0, merge_queue=0
2014-07-13 23:35:50,811 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12023ms
2014-07-13 23:35:50,811 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,812 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12048ms
2014-07-13 23:35:50,812 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 976.1m
2014-07-13 23:35:50,812 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,812 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12072ms
2014-07-13 23:35:50,812 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,812 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12080ms
2014-07-13 23:35:50,812 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,812 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12086ms
2014-07-13 23:35:50,812 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,813 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12125ms
2014-07-13 23:35:50,813 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,813 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12157ms
2014-07-13 23:35:50,813 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,816 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12202ms
2014-07-13 23:35:50,816 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,820 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12228ms
2014-07-13 23:35:50,820 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,820 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12266ms
2014-07-13 23:35:50,820 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,820 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12305ms
2014-07-13 23:35:50,820 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,820 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12351ms
2014-07-13 23:35:50,820 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,820 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12391ms
2014-07-13 23:35:50,820 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,820 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12427ms
2014-07-13 23:35:50,820 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,827 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12471ms
2014-07-13 23:35:50,827 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,828 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12516ms
2014-07-13 23:35:50,828 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,828 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12520ms
2014-07-13 23:35:50,828 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,829 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12524ms
2014-07-13 23:35:50,829 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,829 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12524ms
2014-07-13 23:35:50,829 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,832 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12528ms
2014-07-13 23:35:50,832 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,832 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12556ms
2014-07-13 23:35:50,832 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,837 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12563ms
2014-07-13 23:35:50,837 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,837 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12602ms
2014-07-13 23:35:50,837 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,857 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12624ms
2014-07-13 23:35:50,857 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,857 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12624ms
2014-07-13 23:35:50,857 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,858 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12636ms
2014-07-13 23:35:50,858 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,858 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12638ms
2014-07-13 23:35:50,858 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,858 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12678ms
2014-07-13 23:35:50,858 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,859 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12747ms
2014-07-13 23:35:50,859 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,860 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12756ms
2014-07-13 23:35:50,860 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,862 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12765ms
2014-07-13 23:35:50,862 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,862 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12809ms
2014-07-13 23:35:50,862 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,862 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12847ms
2014-07-13 23:35:50,862 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,862 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12857ms
2014-07-13 23:35:50,862 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,863 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12873ms
2014-07-13 23:35:50,863 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,865 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12930ms
2014-07-13 23:35:50,865 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,865 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12957ms
2014-07-13 23:35:50,865 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,865 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12960ms
2014-07-13 23:35:50,865 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,865 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12962ms
2014-07-13 23:35:50,865 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,866 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12970ms
2014-07-13 23:35:50,866 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,866 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12970ms
2014-07-13 23:35:50,866 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,866 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12982ms
2014-07-13 23:35:50,866 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,869 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13019ms
2014-07-13 23:35:50,869 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,869 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13331ms
2014-07-13 23:35:50,869 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,872 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13378ms
2014-07-13 23:35:50,872 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,872 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13380ms
2014-07-13 23:35:50,872 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,872 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13424ms
2014-07-13 23:35:50,872 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,874 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13434ms
2014-07-13 23:35:50,874 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,874 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13473ms
2014-07-13 23:35:50,875 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:50,877 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13479ms
2014-07-13 23:35:50,877 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:35:51,512 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:35:51,514 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14305,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737207,"queuetimems":0,"class":"HRegionServer","responsesize":18277,"method":"Multi"}
2014-07-13 23:35:51,741 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13434,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738307,"queuetimems":0,"class":"HRegionServer","responsesize":1596,"method":"Multi"}
2014-07-13 23:35:51,748 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738311,"queuetimems":0,"class":"HRegionServer","responsesize":1805,"method":"Multi"}
2014-07-13 23:35:51,905 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13165,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738740,"queuetimems":1,"class":"HRegionServer","responsesize":3222,"method":"Multi"}
2014-07-13 23:35:51,914 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737446,"queuetimems":1,"class":"HRegionServer","responsesize":4361,"method":"Multi"}
2014-07-13 23:35:51,921 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14014,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737907,"queuetimems":0,"class":"HRegionServer","responsesize":1373,"method":"Multi"}
2014-07-13 23:35:51,929 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13696,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738233,"queuetimems":1,"class":"HRegionServer","responsesize":4347,"method":"Multi"}
2014-07-13 23:35:51,933 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14031,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737902,"queuetimems":0,"class":"HRegionServer","responsesize":1485,"method":"Multi"}
2014-07-13 23:35:51,937 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13923,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738014,"queuetimems":1,"class":"HRegionServer","responsesize":3944,"method":"Multi"}
2014-07-13 23:35:51,941 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737896,"queuetimems":0,"class":"HRegionServer","responsesize":645,"method":"Multi"}
2014-07-13 23:35:51,941 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13939,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738002,"queuetimems":0,"class":"HRegionServer","responsesize":5241,"method":"Multi"}
2014-07-13 23:35:51,945 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737905,"queuetimems":1,"class":"HRegionServer","responsesize":1301,"method":"Multi"}
2014-07-13 23:35:51,946 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13713,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738233,"queuetimems":0,"class":"HRegionServer","responsesize":32,"method":"Multi"}
2014-07-13 23:35:51,946 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14454,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737492,"queuetimems":1,"class":"HRegionServer","responsesize":392,"method":"Multi"}
2014-07-13 23:35:51,949 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13716,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738233,"queuetimems":0,"class":"HRegionServer","responsesize":104,"method":"Multi"}
2014-07-13 23:35:51,949 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13675,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738274,"queuetimems":0,"class":"HRegionServer","responsesize":86,"method":"Multi"}
2014-07-13 23:35:51,949 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13645,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738304,"queuetimems":0,"class":"HRegionServer","responsesize":555,"method":"Multi"}
2014-07-13 23:35:51,957 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13654,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738303,"queuetimems":0,"class":"HRegionServer","responsesize":532,"method":"Multi"}
2014-07-13 23:35:51,960 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13739,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738221,"queuetimems":1,"class":"HRegionServer","responsesize":1471,"method":"Multi"}
2014-07-13 23:35:51,960 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13850,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738110,"queuetimems":0,"class":"HRegionServer","responsesize":4030,"method":"Multi"}
2014-07-13 23:35:51,960 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13858,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738102,"queuetimems":0,"class":"HRegionServer","responsesize":4275,"method":"Multi"}
2014-07-13 23:35:51,973 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14078,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737895,"queuetimems":1,"class":"HRegionServer","responsesize":3776,"method":"Multi"}
2014-07-13 23:35:52,113 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13382,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738731,"queuetimems":0,"class":"HRegionServer","responsesize":4848,"method":"Multi"}
2014-07-13 23:35:52,288 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:35:52,417 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:52,418 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738763,"queuetimems":1,"class":"HRegionServer","responsesize":10013,"method":"Multi"}
2014-07-13 23:35:52,418 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13631,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738787,"queuetimems":0,"class":"HRegionServer","responsesize":11889,"method":"Multi"}
2014-07-13 23:35:52,420 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13699,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738721,"queuetimems":0,"class":"HRegionServer","responsesize":16821,"method":"Multi"}
2014-07-13 23:35:52,422 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13770,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738652,"queuetimems":0,"class":"HRegionServer","responsesize":15595,"method":"Multi"}
2014-07-13 23:35:52,422 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738303,"queuetimems":0,"class":"HRegionServer","responsesize":10400,"method":"Multi"}
2014-07-13 23:35:52,430 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13816,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738613,"queuetimems":0,"class":"HRegionServer","responsesize":10315,"method":"Multi"}
2014-07-13 23:35:53,439 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46410 synced till here 46370
2014-07-13 23:35:53,648 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15715,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737933,"queuetimems":0,"class":"HRegionServer","responsesize":11758,"method":"Multi"}
2014-07-13 23:35:53,654 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737846,"queuetimems":1,"class":"HRegionServer","responsesize":17643,"method":"Multi"}
2014-07-13 23:35:53,648 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15374,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738274,"queuetimems":0,"class":"HRegionServer","responsesize":17371,"method":"Multi"}
2014-07-13 23:35:53,665 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16229,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737436,"queuetimems":0,"class":"HRegionServer","responsesize":18482,"method":"Multi"}
2014-07-13 23:35:53,673 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15578,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738095,"queuetimems":1,"class":"HRegionServer","responsesize":16223,"method":"Multi"}
2014-07-13 23:35:53,852 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16317,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737534,"queuetimems":0,"class":"HRegionServer","responsesize":17886,"method":"Multi"}
2014-07-13 23:35:53,855 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15678,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738177,"queuetimems":0,"class":"HRegionServer","responsesize":18357,"method":"Multi"}
2014-07-13 23:35:53,865 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16374,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737491,"queuetimems":0,"class":"HRegionServer","responsesize":18098,"method":"Multi"}
2014-07-13 23:35:53,865 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15878,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737987,"queuetimems":0,"class":"HRegionServer","responsesize":16272,"method":"Multi"}
2014-07-13 23:35:53,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319737295 with entries=141, filesize=115.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319752417
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319653676
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319666251
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319668010
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319669787
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319672464
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319673664
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319674806
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319676654
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319677938
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319679500
2014-07-13 23:35:53,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319680790
2014-07-13 23:35:54,177 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15709,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738467,"queuetimems":0,"class":"HRegionServer","responsesize":15704,"method":"Multi"}
2014-07-13 23:35:54,177 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15750,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738427,"queuetimems":0,"class":"HRegionServer","responsesize":15800,"method":"Multi"}
2014-07-13 23:35:54,177 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15663,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738513,"queuetimems":1,"class":"HRegionServer","responsesize":15965,"method":"Multi"}
2014-07-13 23:35:54,177 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15786,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738390,"queuetimems":0,"class":"HRegionServer","responsesize":14714,"method":"Multi"}
2014-07-13 23:35:54,178 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15626,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738552,"queuetimems":0,"class":"HRegionServer","responsesize":16000,"method":"Multi"}
2014-07-13 23:35:54,177 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15587,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738590,"queuetimems":0,"class":"HRegionServer","responsesize":15730,"method":"Multi"}
2014-07-13 23:35:54,182 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15491,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738685,"queuetimems":0,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-13 23:35:54,378 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16159,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738218,"queuetimems":0,"class":"HRegionServer","responsesize":15583,"method":"Multi"}
2014-07-13 23:35:55,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:55,392 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17038,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738354,"queuetimems":0,"class":"HRegionServer","responsesize":16051,"method":"Multi"}
2014-07-13 23:35:55,392 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737396,"queuetimems":1,"class":"HRegionServer","responsesize":15800,"method":"Multi"}
2014-07-13 23:35:55,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46521 synced till here 46479
2014-07-13 23:35:55,704 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10319, memsize=518.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/8e52eece5fa64a4d83dcd468032f385a
2014-07-13 23:35:55,724 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/8e52eece5fa64a4d83dcd468032f385a as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e52eece5fa64a4d83dcd468032f385a
2014-07-13 23:35:55,733 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e52eece5fa64a4d83dcd468032f385a, entries=1888610, sequenceid=10319, filesize=134.5m
2014-07-13 23:35:55,733 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~949.5m/995638880, currentsize=256.3m/268742080 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 24714ms, sequenceid=10319, compaction requested=true
2014-07-13 23:35:55,734 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:79), split_queue=0, merge_queue=0
2014-07-13 23:35:55,734 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 528.6m
2014-07-13 23:35:55,872 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17820,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319738052,"queuetimems":0,"class":"HRegionServer","responsesize":18141,"method":"Multi"}
2014-07-13 23:35:55,874 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17991,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319737882,"queuetimems":0,"class":"HRegionServer","responsesize":15499,"method":"Multi"}
2014-07-13 23:35:55,877 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:35:56,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319752417 with entries=111, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319755391
2014-07-13 23:35:56,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319682420
2014-07-13 23:35:56,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319684519
2014-07-13 23:35:56,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319685666
2014-07-13 23:35:56,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319687118
2014-07-13 23:35:57,685 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:57,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46627 synced till here 46590
2014-07-13 23:35:57,881 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:35:58,027 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319755391 with entries=106, filesize=94.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319757685
2014-07-13 23:35:59,337 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:35:59,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46742 synced till here 46729
2014-07-13 23:35:59,744 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319757685 with entries=115, filesize=101.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319759337
2014-07-13 23:36:01,287 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:01,450 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46849 synced till here 46845
2014-07-13 23:36:01,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319759337 with entries=107, filesize=84.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319761288
2014-07-13 23:36:02,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:02,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46919 synced till here 46918
2014-07-13 23:36:02,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319761288 with entries=70, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319762810
2014-07-13 23:36:04,160 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:04,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46989 synced till here 46987
2014-07-13 23:36:04,237 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319762810 with entries=70, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319764161
2014-07-13 23:36:05,734 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:05,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47072 synced till here 47062
2014-07-13 23:36:05,972 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319764161 with entries=83, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319765735
2014-07-13 23:36:07,125 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:07,148 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47141 synced till here 47138
2014-07-13 23:36:07,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319765735 with entries=69, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319767125
2014-07-13 23:36:08,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:08,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47204 synced till here 47202
2014-07-13 23:36:08,518 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319767125 with entries=63, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319768458
2014-07-13 23:36:09,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:09,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319768458 with entries=65, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319769819
2014-07-13 23:36:10,634 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:11,189 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47346 synced till here 47345
2014-07-13 23:36:11,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319769819 with entries=77, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319770635
2014-07-13 23:36:12,102 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:12,216 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15259, memsize=268.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/11aa92889cdb4286942fc336b8f3ade9
2014-07-13 23:36:12,219 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47430 synced till here 47428
2014-07-13 23:36:12,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319770635 with entries=84, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319772102
2014-07-13 23:36:12,292 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/11aa92889cdb4286942fc336b8f3ade9 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/11aa92889cdb4286942fc336b8f3ade9
2014-07-13 23:36:12,307 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/11aa92889cdb4286942fc336b8f3ade9, entries=978180, sequenceid=15259, filesize=69.7m
2014-07-13 23:36:12,307 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~541.8m/568168800, currentsize=296.5m/310906480 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 16573ms, sequenceid=15259, compaction requested=true
2014-07-13 23:36:12,307 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:80), split_queue=0, merge_queue=0
2014-07-13 23:36:12,308 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 939.3m
2014-07-13 23:36:12,874 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:36:13,562 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:36:13,725 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:14,053 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47512 synced till here 47511
2014-07-13 23:36:14,474 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319772102 with entries=82, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319773725
2014-07-13 23:36:16,615 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:16,644 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47581 synced till here 47576
2014-07-13 23:36:16,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319773725 with entries=69, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319776615
2014-07-13 23:36:17,478 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:17,495 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47657 synced till here 47653
2014-07-13 23:36:18,160 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319776615 with entries=76, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319777478
2014-07-13 23:36:18,953 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:18,987 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47721 synced till here 47718
2014-07-13 23:36:19,023 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319777478 with entries=64, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319778954
2014-07-13 23:36:20,450 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:20,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47798 synced till here 47792
2014-07-13 23:36:20,682 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319778954 with entries=77, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319780451
2014-07-13 23:36:21,722 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,742 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,761 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,763 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,790 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,792 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,796 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,799 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,800 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,800 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,801 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,815 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10411, memsize=507.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/a2dbcd38011e4ffe876ee03569933935
2014-07-13 23:36:21,820 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,832 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/a2dbcd38011e4ffe876ee03569933935 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/a2dbcd38011e4ffe876ee03569933935
2014-07-13 23:36:21,834 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,841 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/a2dbcd38011e4ffe876ee03569933935, entries=1848590, sequenceid=10411, filesize=131.7m
2014-07-13 23:36:21,841 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:21,841 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~976.1m/1023536880, currentsize=684.7m/717946800 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 31029ms, sequenceid=10411, compaction requested=true
2014-07-13 23:36:21,842 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:81), split_queue=0, merge_queue=0
2014-07-13 23:36:21,842 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1ms
2014-07-13 23:36:21,842 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,842 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8ms
2014-07-13 23:36:21,842 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 842.8m
2014-07-13 23:36:21,842 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,843 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23ms
2014-07-13 23:36:21,843 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,843 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 42ms
2014-07-13 23:36:21,843 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,843 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 43ms
2014-07-13 23:36:21,843 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,843 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 43ms
2014-07-13 23:36:21,843 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,844 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 45ms
2014-07-13 23:36:21,844 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,844 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 48ms
2014-07-13 23:36:21,844 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,859 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 68ms
2014-07-13 23:36:21,860 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,860 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 71ms
2014-07-13 23:36:21,860 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,860 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 97ms
2014-07-13 23:36:21,860 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,860 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 99ms
2014-07-13 23:36:21,860 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,860 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 118ms
2014-07-13 23:36:21,860 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,864 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 142ms
2014-07-13 23:36:21,864 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:21,916 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:21,916 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:36:21,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47885 synced till here 47878
2014-07-13 23:36:22,014 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319780451 with entries=87, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319781916
2014-07-13 23:36:22,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319688680
2014-07-13 23:36:22,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319690411
2014-07-13 23:36:22,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319692104
2014-07-13 23:36:22,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319693564
2014-07-13 23:36:22,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319695047
2014-07-13 23:36:22,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319696204
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319697392
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319698829
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319700141
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319701984
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319703594
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319705269
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319706771
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319708373
2014-07-13 23:36:22,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319709623
2014-07-13 23:36:23,087 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:36:23,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:23,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47956 synced till here 47953
2014-07-13 23:36:23,480 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319781916 with entries=71, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319783397
2014-07-13 23:36:24,661 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:24,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48046 synced till here 48043
2014-07-13 23:36:24,994 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319783397 with entries=90, filesize=84.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319784661
2014-07-13 23:36:26,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:26,333 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48124 synced till here 48115
2014-07-13 23:36:26,414 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319784661 with entries=78, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319786289
2014-07-13 23:36:27,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:27,865 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48222 synced till here 48221
2014-07-13 23:36:28,414 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319786289 with entries=98, filesize=79.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319787690
2014-07-13 23:36:29,220 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:29,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48328 synced till here 48321
2014-07-13 23:36:29,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319787690 with entries=106, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319789221
2014-07-13 23:36:30,742 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:30,837 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10665, memsize=292.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/c9b3498c0ff04d879301e2571d51d952
2014-07-13 23:36:30,849 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/c9b3498c0ff04d879301e2571d51d952 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/c9b3498c0ff04d879301e2571d51d952
2014-07-13 23:36:30,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48412 synced till here 48411
2014-07-13 23:36:30,900 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/c9b3498c0ff04d879301e2571d51d952, entries=1065350, sequenceid=10665, filesize=75.9m
2014-07-13 23:36:30,901 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~943.2m/989058240, currentsize=411.8m/431842400 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 18593ms, sequenceid=10665, compaction requested=true
2014-07-13 23:36:30,901 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:82), split_queue=0, merge_queue=0
2014-07-13 23:36:30,901 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 609.5m
2014-07-13 23:36:30,922 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319789221 with entries=84, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319790742
2014-07-13 23:36:30,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319711114
2014-07-13 23:36:30,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319712914
2014-07-13 23:36:30,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319715516
2014-07-13 23:36:30,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319717709
2014-07-13 23:36:30,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319719847
2014-07-13 23:36:30,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319722244
2014-07-13 23:36:30,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319725389
2014-07-13 23:36:31,352 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:36:31,758 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:36:32,306 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:32,870 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48491 synced till here 48477
2014-07-13 23:36:32,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319790742 with entries=79, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319792306
2014-07-13 23:36:33,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:33,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48565 synced till here 48563
2014-07-13 23:36:33,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319792306 with entries=74, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319793787
2014-07-13 23:36:35,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:35,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48662 synced till here 48661
2014-07-13 23:36:35,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319793787 with entries=97, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319795112
2014-07-13 23:36:37,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:37,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48763 synced till here 48741
2014-07-13 23:36:37,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319795112 with entries=101, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319797397
2014-07-13 23:36:39,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:39,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48852 synced till here 48842
2014-07-13 23:36:39,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319797397 with entries=89, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319799259
2014-07-13 23:36:40,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:40,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48962 synced till here 48944
2014-07-13 23:36:41,081 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319799259 with entries=110, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319800921
2014-07-13 23:36:42,737 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:42,792 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49071 synced till here 49049
2014-07-13 23:36:43,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319800921 with entries=109, filesize=78.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319802737
2014-07-13 23:36:44,569 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,570 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,571 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,572 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,572 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,574 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,574 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,576 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,580 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,581 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,609 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,643 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,643 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,643 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,644 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,646 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,659 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:44,662 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,663 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,663 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49178 synced till here 49172
2014-07-13 23:36:44,684 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,698 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,699 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,699 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,713 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,714 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319802737 with entries=107, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319804659
2014-07-13 23:36:44,719 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,720 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,763 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,769 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,777 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,782 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,796 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,803 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,826 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,876 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,929 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:44,994 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:45,028 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:45,337 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:45,370 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:36:46,550 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10758, memsize=392.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/25b75ced49634ed6954a5f2b307e905f
2014-07-13 23:36:46,565 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/25b75ced49634ed6954a5f2b307e905f as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/25b75ced49634ed6954a5f2b307e905f
2014-07-13 23:36:46,645 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/25b75ced49634ed6954a5f2b307e905f, entries=1427150, sequenceid=10758, filesize=101.7m
2014-07-13 23:36:46,645 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~842.8m/883692080, currentsize=529.2m/554958000 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 24803ms, sequenceid=10758, compaction requested=true
2014-07-13 23:36:46,645 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:83), split_queue=0, merge_queue=0
2014-07-13 23:36:46,646 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1276ms
2014-07-13 23:36:46,646 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,646 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 1.2g
2014-07-13 23:36:46,646 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1309ms
2014-07-13 23:36:46,646 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,646 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1618ms
2014-07-13 23:36:46,646 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,647 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1653ms
2014-07-13 23:36:46,647 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,647 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1718ms
2014-07-13 23:36:46,648 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,648 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1772ms
2014-07-13 23:36:46,648 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,658 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1832ms
2014-07-13 23:36:46,658 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,659 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1855ms
2014-07-13 23:36:46,659 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,660 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1863ms
2014-07-13 23:36:46,660 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,660 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1878ms
2014-07-13 23:36:46,660 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,661 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1884ms
2014-07-13 23:36:46,661 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,661 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1892ms
2014-07-13 23:36:46,661 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,661 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1898ms
2014-07-13 23:36:46,661 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,668 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1948ms
2014-07-13 23:36:46,668 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,668 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1949ms
2014-07-13 23:36:46,668 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,669 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1955ms
2014-07-13 23:36:46,669 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,669 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1970ms
2014-07-13 23:36:46,670 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,677 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1978ms
2014-07-13 23:36:46,677 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,677 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1979ms
2014-07-13 23:36:46,677 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,677 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1993ms
2014-07-13 23:36:46,677 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,678 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2014ms
2014-07-13 23:36:46,678 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,679 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2016ms
2014-07-13 23:36:46,679 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,681 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2019ms
2014-07-13 23:36:46,693 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,701 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2055ms
2014-07-13 23:36:46,702 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,702 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2059ms
2014-07-13 23:36:46,702 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,703 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2059ms
2014-07-13 23:36:46,703 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,704 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2061ms
2014-07-13 23:36:46,704 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,704 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2061ms
2014-07-13 23:36:46,704 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,705 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2096ms
2014-07-13 23:36:46,705 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,705 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2124ms
2014-07-13 23:36:46,705 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,705 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2125ms
2014-07-13 23:36:46,706 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,706 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2130ms
2014-07-13 23:36:46,706 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,706 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-13 23:36:46,706 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,706 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-13 23:36:46,707 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,713 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2141ms
2014-07-13 23:36:46,713 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,714 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2141ms
2014-07-13 23:36:46,714 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,721 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2150ms
2014-07-13 23:36:46,721 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,721 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2151ms
2014-07-13 23:36:46,721 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:46,721 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2152ms
2014-07-13 23:36:46,721 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:36:47,556 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:36:48,080 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:48,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49266 synced till here 49256
2014-07-13 23:36:48,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319804659 with entries=88, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319808081
2014-07-13 23:36:48,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319727401
2014-07-13 23:36:48,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319731842
2014-07-13 23:36:48,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319733807
2014-07-13 23:36:48,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319735826
2014-07-13 23:36:49,211 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:36:49,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:49,974 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49356 synced till here 49355
2014-07-13 23:36:49,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319808081 with entries=90, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319809770
2014-07-13 23:36:51,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:51,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49418 synced till here 49417
2014-07-13 23:36:51,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319809770 with entries=62, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319811531
2014-07-13 23:36:52,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:53,178 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15892, memsize=378.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d33ad8187a3b40d697540269a5146055
2014-07-13 23:36:53,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319811531 with entries=82, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319812923
2014-07-13 23:36:53,196 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d33ad8187a3b40d697540269a5146055 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d33ad8187a3b40d697540269a5146055
2014-07-13 23:36:53,209 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d33ad8187a3b40d697540269a5146055, entries=1379100, sequenceid=15892, filesize=98.2m
2014-07-13 23:36:53,210 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~611.0m/640689440, currentsize=245.0m/256935920 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 22309ms, sequenceid=15892, compaction requested=true
2014-07-13 23:36:53,210 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:84), split_queue=0, merge_queue=0
2014-07-13 23:36:53,210 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 868.8m
2014-07-13 23:36:53,925 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:36:54,207 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:36:54,262 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:54,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49563 synced till here 49562
2014-07-13 23:36:54,325 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319812923 with entries=63, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319814262
2014-07-13 23:36:55,499 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:55,615 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49637 synced till here 49630
2014-07-13 23:36:55,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319814262 with entries=74, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319815499
2014-07-13 23:36:56,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:56,936 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49728 synced till here 49718
2014-07-13 23:36:57,022 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319815499 with entries=91, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319816922
2014-07-13 23:36:58,137 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:36:58,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49803 synced till here 49796
2014-07-13 23:36:58,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319816922 with entries=75, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319818137
2014-07-13 23:36:59,439 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:00,005 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49930 synced till here 49923
2014-07-13 23:37:00,814 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319818137 with entries=127, filesize=104.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319819440
2014-07-13 23:37:02,245 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:02,266 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50021 synced till here 50008
2014-07-13 23:37:02,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319819440 with entries=91, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319822245
2014-07-13 23:37:03,021 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,022 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,024 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,024 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,024 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,024 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,026 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,027 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,029 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,029 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,031 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,031 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,032 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,032 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,033 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,034 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,056 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,064 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,998 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,998 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:03,999 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,014 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:04,053 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,055 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,056 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,057 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,057 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,057 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,060 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,060 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,060 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,062 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,064 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,065 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,066 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,066 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,069 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,069 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,069 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,069 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,070 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,071 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,114 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,164 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,164 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,164 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,165 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,166 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,168 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,171 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:37:04,211 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319822245 with entries=81, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319824050
2014-07-13 23:37:08,021 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:08,023 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:08,024 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:08,024 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:08,024 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,025 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,026 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,027 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,029 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:08,029 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,031 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,032 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,032 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,032 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,033 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,035 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:08,056 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,064 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,998 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:08,999 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:08,999 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,014 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,053 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,055 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,057 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,057 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,057 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,058 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,060 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,060 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,060 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,063 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,064 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,065 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,066 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,069 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-13 23:37:09,069 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,069 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,069 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:37:09,070 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,070 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,071 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,114 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,164 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,165 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:37:09,166 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,166 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,166 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:09,168 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:37:09,172 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:37:13,022 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:37:13,023 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,024 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,025 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,025 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,026 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,026 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:13,028 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:13,029 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,029 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:13,031 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:13,032 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,033 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:13,033 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,034 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,036 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,056 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:13,065 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:37:13,900 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11131, memsize=376.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/e13507f61c604318bd0ee7b7f51e3594
2014-07-13 23:37:13,919 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/e13507f61c604318bd0ee7b7f51e3594 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e13507f61c604318bd0ee7b7f51e3594
2014-07-13 23:37:13,933 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e13507f61c604318bd0ee7b7f51e3594, entries=1370940, sequenceid=11131, filesize=97.6m
2014-07-13 23:37:13,933 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~877.5m/920142400, currentsize=241.2m/252895440 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 20723ms, sequenceid=11131, compaction requested=true
2014-07-13 23:37:13,934 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:85), split_queue=0, merge_queue=0
2014-07-13 23:37:13,934 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10870ms
2014-07-13 23:37:13,934 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,934 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 943.9m
2014-07-13 23:37:13,934 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10878ms
2014-07-13 23:37:13,934 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,934 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10900ms
2014-07-13 23:37:13,934 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,935 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10902ms
2014-07-13 23:37:13,935 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,937 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10905ms
2014-07-13 23:37:13,938 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,938 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10906ms
2014-07-13 23:37:13,938 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,949 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10918ms
2014-07-13 23:37:13,949 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,950 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10919ms
2014-07-13 23:37:13,950 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,955 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10926ms
2014-07-13 23:37:13,955 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,957 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10929ms
2014-07-13 23:37:13,957 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,957 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10930ms
2014-07-13 23:37:13,957 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,957 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10931ms
2014-07-13 23:37:13,957 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,958 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10934ms
2014-07-13 23:37:13,958 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,958 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10934ms
2014-07-13 23:37:13,958 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,958 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10935ms
2014-07-13 23:37:13,958 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,965 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10942ms
2014-07-13 23:37:13,965 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,965 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10943ms
2014-07-13 23:37:13,965 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,965 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10945ms
2014-07-13 23:37:13,965 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,966 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9794ms
2014-07-13 23:37:13,966 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,978 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9809ms
2014-07-13 23:37:13,978 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,978 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9813ms
2014-07-13 23:37:13,978 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,979 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9812ms
2014-07-13 23:37:13,979 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,979 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9815ms
2014-07-13 23:37:13,979 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,980 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9817ms
2014-07-13 23:37:13,980 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,992 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9829ms
2014-07-13 23:37:13,992 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,994 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9880ms
2014-07-13 23:37:13,995 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:13,996 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9924ms
2014-07-13 23:37:13,996 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,012 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10014ms
2014-07-13 23:37:14,013 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,016 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:37:14,016 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,032 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10033ms
2014-07-13 23:37:14,032 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,037 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10039ms
2014-07-13 23:37:14,038 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,038 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9968ms
2014-07-13 23:37:14,038 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,039 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9969ms
2014-07-13 23:37:14,039 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,045 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9978ms
2014-07-13 23:37:14,045 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,046 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9977ms
2014-07-13 23:37:14,046 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,050 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9981ms
2014-07-13 23:37:14,050 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,051 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9985ms
2014-07-13 23:37:14,051 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,052 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9985ms
2014-07-13 23:37:14,052 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,052 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9987ms
2014-07-13 23:37:14,053 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,053 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9989ms
2014-07-13 23:37:14,053 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,054 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9992ms
2014-07-13 23:37:14,054 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,055 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9995ms
2014-07-13 23:37:14,056 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,058 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:14,058 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,060 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:37:14,060 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,061 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-13 23:37:14,061 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,063 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-13 23:37:14,063 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,064 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10006ms
2014-07-13 23:37:14,064 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,064 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-13 23:37:14,064 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,073 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10018ms
2014-07-13 23:37:14,073 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,081 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10029ms
2014-07-13 23:37:14,081 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:37:14,145 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822259,"queuetimems":0,"class":"HRegionServer","responsesize":18894,"method":"Multi"}
2014-07-13 23:37:14,146 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11872,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822273,"queuetimems":1,"class":"HRegionServer","responsesize":18441,"method":"Multi"}
2014-07-13 23:37:14,145 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11793,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822352,"queuetimems":2,"class":"HRegionServer","responsesize":6342,"method":"Multi"}
2014-07-13 23:37:14,145 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11765,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822380,"queuetimems":1,"class":"HRegionServer","responsesize":10168,"method":"Multi"}
2014-07-13 23:37:14,256 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11194,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823061,"queuetimems":0,"class":"HRegionServer","responsesize":4508,"method":"Multi"}
2014-07-13 23:37:14,256 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11233,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823022,"queuetimems":0,"class":"HRegionServer","responsesize":4067,"method":"Multi"}
2014-07-13 23:37:14,256 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10192,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824063,"queuetimems":16,"class":"HRegionServer","responsesize":4946,"method":"Multi"}
2014-07-13 23:37:14,257 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10259,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823998,"queuetimems":1,"class":"HRegionServer","responsesize":44,"method":"Multi"}
2014-07-13 23:37:14,265 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823024,"queuetimems":2,"class":"HRegionServer","responsesize":950,"method":"Multi"}
2014-07-13 23:37:14,265 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823997,"queuetimems":0,"class":"HRegionServer","responsesize":195,"method":"Multi"}
2014-07-13 23:37:14,265 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10101,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824164,"queuetimems":64,"class":"HRegionServer","responsesize":177,"method":"Multi"}
2014-07-13 23:37:14,265 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10102,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824163,"queuetimems":64,"class":"HRegionServer","responsesize":32,"method":"Multi"}
2014-07-13 23:37:14,265 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10100,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824165,"queuetimems":64,"class":"HRegionServer","responsesize":207,"method":"Multi"}
2014-07-13 23:37:14,265 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10102,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824163,"queuetimems":63,"class":"HRegionServer","responsesize":62,"method":"Multi"}
2014-07-13 23:37:14,266 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10101,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824165,"queuetimems":64,"class":"HRegionServer","responsesize":56,"method":"Multi"}
2014-07-13 23:37:14,266 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11240,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823026,"queuetimems":1,"class":"HRegionServer","responsesize":584,"method":"Multi"}
2014-07-13 23:37:14,267 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11243,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823023,"queuetimems":0,"class":"HRegionServer","responsesize":68,"method":"Multi"}
2014-07-13 23:37:14,445 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822324,"queuetimems":0,"class":"HRegionServer","responsesize":15872,"method":"Multi"}
2014-07-13 23:37:14,449 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:37:15,698 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11634,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824063,"queuetimems":7,"class":"HRegionServer","responsesize":4112,"method":"Multi"}
2014-07-13 23:37:15,698 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11639,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824059,"queuetimems":29,"class":"HRegionServer","responsesize":443,"method":"Multi"}
2014-07-13 23:37:15,698 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824061,"queuetimems":24,"class":"HRegionServer","responsesize":2652,"method":"Multi"}
2014-07-13 23:37:15,698 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824061,"queuetimems":23,"class":"HRegionServer","responsesize":774,"method":"Multi"}
2014-07-13 23:37:15,699 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11639,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824059,"queuetimems":29,"class":"HRegionServer","responsesize":195,"method":"Multi"}
2014-07-13 23:37:15,699 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11633,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824065,"queuetimems":9,"class":"HRegionServer","responsesize":456,"method":"Multi"}
2014-07-13 23:37:15,700 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11638,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824061,"queuetimems":29,"class":"HRegionServer","responsesize":1914,"method":"Multi"}
2014-07-13 23:37:15,705 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11642,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824063,"queuetimems":15,"class":"HRegionServer","responsesize":1143,"method":"Multi"}
2014-07-13 23:37:15,706 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11647,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824058,"queuetimems":29,"class":"HRegionServer","responsesize":2044,"method":"Multi"}
2014-07-13 23:37:15,708 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824065,"queuetimems":8,"class":"HRegionServer","responsesize":183,"method":"Multi"}
2014-07-13 23:37:15,710 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13262,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822447,"queuetimems":1,"class":"HRegionServer","responsesize":18566,"method":"Multi"}
2014-07-13 23:37:15,713 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13422,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822290,"queuetimems":1,"class":"HRegionServer","responsesize":15794,"method":"Multi"}
2014-07-13 23:37:15,714 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13207,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822507,"queuetimems":0,"class":"HRegionServer","responsesize":9331,"method":"Multi"}
2014-07-13 23:37:15,710 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13169,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822540,"queuetimems":0,"class":"HRegionServer","responsesize":16410,"method":"Multi"}
2014-07-13 23:37:15,746 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13133,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822612,"queuetimems":0,"class":"HRegionServer","responsesize":18236,"method":"Multi"}
2014-07-13 23:37:15,894 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:37:15,932 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:15,940 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13253,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822686,"queuetimems":0,"class":"HRegionServer","responsesize":11734,"method":"Multi"}
2014-07-13 23:37:15,940 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13208,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822731,"queuetimems":0,"class":"HRegionServer","responsesize":11766,"method":"Multi"}
2014-07-13 23:37:15,940 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822824,"queuetimems":1,"class":"HRegionServer","responsesize":18204,"method":"Multi"}
2014-07-13 23:37:15,940 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13459,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822481,"queuetimems":1,"class":"HRegionServer","responsesize":17840,"method":"Multi"}
2014-07-13 23:37:15,941 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13053,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822887,"queuetimems":1,"class":"HRegionServer","responsesize":14471,"method":"Multi"}
2014-07-13 23:37:15,941 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12997,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822944,"queuetimems":0,"class":"HRegionServer","responsesize":11226,"method":"Multi"}
2014-07-13 23:37:15,941 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13276,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822665,"queuetimems":0,"class":"HRegionServer","responsesize":17792,"method":"Multi"}
2014-07-13 23:37:15,941 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13361,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822579,"queuetimems":1,"class":"HRegionServer","responsesize":18628,"method":"Multi"}
2014-07-13 23:37:15,944 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12932,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823012,"queuetimems":1,"class":"HRegionServer","responsesize":17571,"method":"Multi"}
2014-07-13 23:37:15,946 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13314,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822632,"queuetimems":0,"class":"HRegionServer","responsesize":11652,"method":"Multi"}
2014-07-13 23:37:15,965 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50231 synced till here 50187
2014-07-13 23:37:16,151 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13096,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823054,"queuetimems":0,"class":"HRegionServer","responsesize":15399,"method":"Multi"}
2014-07-13 23:37:16,166 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13308,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822858,"queuetimems":0,"class":"HRegionServer","responsesize":15960,"method":"Multi"}
2014-07-13 23:37:16,166 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13377,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319822789,"queuetimems":1,"class":"HRegionServer","responsesize":18066,"method":"Multi"}
2014-07-13 23:37:16,198 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12099,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824099,"queuetimems":0,"class":"HRegionServer","responsesize":18349,"method":"Multi"}
2014-07-13 23:37:16,206 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12195,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824010,"queuetimems":1,"class":"HRegionServer","responsesize":17263,"method":"Multi"}
2014-07-13 23:37:16,211 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12157,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319824053,"queuetimems":27,"class":"HRegionServer","responsesize":17334,"method":"Multi"}
2014-07-13 23:37:16,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319824050 with entries=129, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319835932
2014-07-13 23:37:17,545 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405319823997,"queuetimems":1,"class":"HRegionServer","responsesize":17428,"method":"Multi"}
2014-07-13 23:37:18,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:18,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50367 synced till here 50340
2014-07-13 23:37:19,198 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319835932 with entries=136, filesize=101.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319838182
2014-07-13 23:37:19,650 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11039, memsize=540.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f23104ecb37b4d298f2c7f050a5a34ae
2014-07-13 23:37:19,662 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f23104ecb37b4d298f2c7f050a5a34ae as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f23104ecb37b4d298f2c7f050a5a34ae
2014-07-13 23:37:19,686 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f23104ecb37b4d298f2c7f050a5a34ae, entries=1967160, sequenceid=11039, filesize=140.1m
2014-07-13 23:37:19,701 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1258311040, currentsize=493.4m/517390800 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 33055ms, sequenceid=11039, compaction requested=true
2014-07-13 23:37:19,701 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:86), split_queue=0, merge_queue=0
2014-07-13 23:37:19,743 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. has too many store files; delaying flush up to 90000ms
2014-07-13 23:37:19,743 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-13 23:37:19,743 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 362.3m
2014-07-13 23:37:21,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:21,259 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50480 synced till here 50449
2014-07-13 23:37:21,372 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:37:21,501 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:37:21,756 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319838182 with entries=113, filesize=105.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319841206
2014-07-13 23:37:21,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319737295
2014-07-13 23:37:21,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319752417
2014-07-13 23:37:21,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319755391
2014-07-13 23:37:21,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319757685
2014-07-13 23:37:21,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319759337
2014-07-13 23:37:21,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319761288
2014-07-13 23:37:21,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319762810
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319764161
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319765735
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319767125
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319768458
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319769819
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319770635
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319772102
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319773725
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319776615
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319777478
2014-07-13 23:37:21,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319778954
2014-07-13 23:37:23,258 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:23,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50598 synced till here 50571
2014-07-13 23:37:23,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319841206 with entries=118, filesize=97.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319843259
2014-07-13 23:37:25,549 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:25,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50751 synced till here 50708
2014-07-13 23:37:26,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319843259 with entries=153, filesize=118.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319845549
2014-07-13 23:37:28,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:28,215 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50871 synced till here 50849
2014-07-13 23:37:28,972 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/428227936817425cbc98e9844205f3dc as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/428227936817425cbc98e9844205f3dc
2014-07-13 23:37:29,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319845549 with entries=120, filesize=99.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319848120
2014-07-13 23:37:29,320 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:37:29,374 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b6705ddd5f724c869f6ebf9e77a5dad5, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b6705ddd5f724c869f6ebf9e77a5dad5
2014-07-13 23:37:29,378 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/81ae3ba2ce0c48e78e80fd3c7a989317, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/81ae3ba2ce0c48e78e80fd3c7a989317
2014-07-13 23:37:29,382 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ea070eb81c1348a4882337b13d4c6479, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/ea070eb81c1348a4882337b13d4c6479
2014-07-13 23:37:29,389 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/45268bdf292f44118de2666e6bc0966c, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/45268bdf292f44118de2666e6bc0966c
2014-07-13 23:37:29,391 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/47c85b5121cf40f48b6e880b2c4bc3b3, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/47c85b5121cf40f48b6e880b2c4bc3b3
2014-07-13 23:37:29,395 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5cebceae75314960948b68aeafc83097, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5cebceae75314960948b68aeafc83097
2014-07-13 23:37:29,398 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1c219b4b18b24e8ea638b3357bcb3f2c, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1c219b4b18b24e8ea638b3357bcb3f2c
2014-07-13 23:37:29,401 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/957055a7bf5f4f67beed61bd502511df, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/957055a7bf5f4f67beed61bd502511df
2014-07-13 23:37:29,404 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/91432a61750e4002b21398aebec9af4a, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/91432a61750e4002b21398aebec9af4a
2014-07-13 23:37:29,407 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/adaab50c6c3e4cd79b9b46ed056f5f0c, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/adaab50c6c3e4cd79b9b46ed056f5f0c
2014-07-13 23:37:29,407 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into 428227936817425cbc98e9844205f3dc(size=855.0m), total size for store is 2.4g. This selection was in queue for 0sec, and took 3mins, 8sec to execute.
2014-07-13 23:37:29,407 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., storeName=family, fileCount=10, fileSize=874.8m, priority=3, time=273568605771799; duration=3mins, 8sec
2014-07-13 23:37:29,407 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-13 23:37:29,408 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-13 23:37:29,410 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1131745677 starting at candidate #1 after considering 84 permutations with 78 in ratio
2014-07-13 23:37:29,410 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 6935e08926c94c414c50c4e2b2667be2 - family: Initiating minor compaction
2014-07-13 23:37:29,411 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:37:29,411 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp, totalSize=1.1g
2014-07-13 23:37:29,411 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6a490cbbe6df4a2d99043a4e818dde56, keycount=117395, bloomtype=ROW, size=83.6m, encoding=NONE, seqNum=4008
2014-07-13 23:37:29,411 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4cef371056b847b996708d6bbbd17ccb, keycount=132628, bloomtype=ROW, size=94.5m, encoding=NONE, seqNum=4403
2014-07-13 23:37:29,411 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/36222186b3c940f2a9e5a52c194e48bf, keycount=151530, bloomtype=ROW, size=107.9m, encoding=NONE, seqNum=4808
2014-07-13 23:37:29,411 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/5f13fd98fa1e478fa50ea4de5b9cd958, keycount=147821, bloomtype=ROW, size=105.3m, encoding=NONE, seqNum=5228
2014-07-13 23:37:29,411 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/87d8f0459c6640f79bc6b9422203b12c, keycount=141439, bloomtype=ROW, size=100.8m, encoding=NONE, seqNum=5743
2014-07-13 23:37:29,411 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c5936faaf1e54fce81e4c7998ad18b73, keycount=187699, bloomtype=ROW, size=133.7m, encoding=NONE, seqNum=6251
2014-07-13 23:37:29,412 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4d127bb2abac4b0da42605efe8af252f, keycount=105571, bloomtype=ROW, size=75.2m, encoding=NONE, seqNum=6743
2014-07-13 23:37:29,412 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6b0d5830c1314c91930b9f979d3f1be4, keycount=186732, bloomtype=ROW, size=133.0m, encoding=NONE, seqNum=7259
2014-07-13 23:37:29,412 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/de4a2630463b450187c6397a117a3fae, keycount=172649, bloomtype=ROW, size=122.9m, encoding=NONE, seqNum=7729
2014-07-13 23:37:29,412 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/3b1052cfc90f4858b7c64ab91e966d22, keycount=171917, bloomtype=ROW, size=122.4m, encoding=NONE, seqNum=8250
2014-07-13 23:37:29,712 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:37:30,077 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:31,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50980 synced till here 50937
2014-07-13 23:37:31,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319848120 with entries=109, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319850077
2014-07-13 23:37:32,135 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:32,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51083 synced till here 51053
2014-07-13 23:37:33,116 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319850077 with entries=103, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319852135
2014-07-13 23:37:33,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:33,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319852135 with entries=79, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319853897
2014-07-13 23:37:34,281 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11326, memsize=193.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/4110885abd8c4d17a5cf8f36ac425330
2014-07-13 23:37:34,300 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/4110885abd8c4d17a5cf8f36ac425330 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4110885abd8c4d17a5cf8f36ac425330
2014-07-13 23:37:34,318 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4110885abd8c4d17a5cf8f36ac425330, entries=705020, sequenceid=11326, filesize=50.3m
2014-07-13 23:37:34,318 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~383.7m/402359280, currentsize=306.6m/321489360 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 14575ms, sequenceid=11326, compaction requested=true
2014-07-13 23:37:34,318 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-13 23:37:34,318 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 654.5m
2014-07-13 23:37:34,838 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:37:37,625 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:37:39,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:39,530 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51230 synced till here 51229
2014-07-13 23:37:39,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319853897 with entries=68, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319859510
2014-07-13 23:37:41,074 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:41,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51307 synced till here 51305
2014-07-13 23:37:41,161 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319859510 with entries=77, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319861074
2014-07-13 23:37:42,578 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:42,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51380 synced till here 51378
2014-07-13 23:37:42,630 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319861074 with entries=73, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319862579
2014-07-13 23:37:43,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:43,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51452 synced till here 51451
2014-07-13 23:37:44,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319862579 with entries=72, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319863905
2014-07-13 23:37:44,460 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11263, memsize=467.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/3e59221dcbe74033bbb6b27e15363255
2014-07-13 23:37:44,482 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/3e59221dcbe74033bbb6b27e15363255 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3e59221dcbe74033bbb6b27e15363255
2014-07-13 23:37:45,394 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3e59221dcbe74033bbb6b27e15363255, entries=1701260, sequenceid=11263, filesize=121.1m
2014-07-13 23:37:45,395 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~943.9m/989763840, currentsize=590.1m/618750000 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 31461ms, sequenceid=11263, compaction requested=true
2014-07-13 23:37:45,395 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:88), split_queue=0, merge_queue=0
2014-07-13 23:37:45,396 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 1004.9m
2014-07-13 23:37:45,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:45,541 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51560 synced till here 51534
2014-07-13 23:37:45,648 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:37:45,666 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319863905 with entries=108, filesize=78.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319865515
2014-07-13 23:37:45,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319780451
2014-07-13 23:37:45,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319781916
2014-07-13 23:37:45,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319783397
2014-07-13 23:37:45,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319784661
2014-07-13 23:37:45,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319786289
2014-07-13 23:37:45,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319787690
2014-07-13 23:37:45,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319789221
2014-07-13 23:37:47,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:47,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51671 synced till here 51653
2014-07-13 23:37:47,308 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319865515 with entries=111, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319867239
2014-07-13 23:37:47,482 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:37:48,627 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:48,654 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51742 synced till here 51738
2014-07-13 23:37:48,710 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319867239 with entries=71, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319868627
2014-07-13 23:37:49,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:49,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51805 synced till here 51801
2014-07-13 23:37:49,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319868627 with entries=63, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319869446
2014-07-13 23:37:50,795 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:51,316 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51871 synced till here 51863
2014-07-13 23:37:51,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319869446 with entries=66, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319870795
2014-07-13 23:37:52,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:52,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51936 synced till here 51932
2014-07-13 23:37:52,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319870795 with entries=65, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319872161
2014-07-13 23:37:52,719 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16851, memsize=381.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/01232ff87b594bc28747b91ff2943f66
2014-07-13 23:37:52,737 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/01232ff87b594bc28747b91ff2943f66 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/01232ff87b594bc28747b91ff2943f66
2014-07-13 23:37:52,763 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/01232ff87b594bc28747b91ff2943f66, entries=1387160, sequenceid=16851, filesize=98.8m
2014-07-13 23:37:52,763 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~654.5m/686294400, currentsize=240.7m/252340480 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 18445ms, sequenceid=16851, compaction requested=true
2014-07-13 23:37:52,764 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:89), split_queue=0, merge_queue=0
2014-07-13 23:37:52,764 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 640.6m
2014-07-13 23:37:53,168 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:37:53,351 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:37:53,368 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:53,416 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319872161 with entries=63, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319873369
2014-07-13 23:37:53,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319790742
2014-07-13 23:37:53,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319792306
2014-07-13 23:37:53,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319793787
2014-07-13 23:37:53,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319795112
2014-07-13 23:37:53,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319797397
2014-07-13 23:37:53,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319799259
2014-07-13 23:37:53,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319800921
2014-07-13 23:37:53,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319802737
2014-07-13 23:37:54,749 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:54,781 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319873369 with entries=57, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319874749
2014-07-13 23:37:56,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:56,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52135 synced till here 52117
2014-07-13 23:37:56,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319874749 with entries=79, filesize=84.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319876521
2014-07-13 23:37:58,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:37:58,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52205 synced till here 52202
2014-07-13 23:37:58,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319876521 with entries=70, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319878589
2014-07-13 23:38:00,093 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:00,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52272 synced till here 52265
2014-07-13 23:38:00,191 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319878589 with entries=67, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319880093
2014-07-13 23:38:01,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:01,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52393 synced till here 52368
2014-07-13 23:38:01,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319880093 with entries=121, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319881565
2014-07-13 23:38:03,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:03,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319881565 with entries=112, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319883317
2014-07-13 23:38:04,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:04,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52574 synced till here 52568
2014-07-13 23:38:04,885 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319883317 with entries=69, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319884781
2014-07-13 23:38:06,844 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:06,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52636 synced till here 52634
2014-07-13 23:38:06,913 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319884781 with entries=62, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319886845
2014-07-13 23:38:08,180 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,182 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,182 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,186 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,187 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,188 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,202 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,221 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,258 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,260 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,260 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,261 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,262 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,273 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,291 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,292 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,293 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,336 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,382 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,513 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,575 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,579 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,583 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,634 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,641 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,690 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,695 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,698 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,734 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,777 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,849 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,850 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,901 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,902 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,910 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:08,964 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,006 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,057 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,057 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,094 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,128 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,179 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,235 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,291 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,341 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,351 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,368 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,401 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,446 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:09,448 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:11,536 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11641, memsize=295.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/eef1a53948634ccba01ecb6fc05625ac
2014-07-13 23:38:11,549 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/eef1a53948634ccba01ecb6fc05625ac as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/eef1a53948634ccba01ecb6fc05625ac
2014-07-13 23:38:11,562 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/eef1a53948634ccba01ecb6fc05625ac, entries=1077200, sequenceid=11641, filesize=76.7m
2014-07-13 23:38:11,563 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~648.5m/680014960, currentsize=329.0m/345016800 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 18799ms, sequenceid=11641, compaction requested=true
2014-07-13 23:38:11,563 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:90), split_queue=0, merge_queue=0
2014-07-13 23:38:11,563 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2115ms
2014-07-13 23:38:11,563 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,563 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.1g
2014-07-13 23:38:11,563 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2117ms
2014-07-13 23:38:11,563 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,564 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2163ms
2014-07-13 23:38:11,564 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,565 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2197ms
2014-07-13 23:38:11,565 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,565 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2214ms
2014-07-13 23:38:11,565 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,565 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2224ms
2014-07-13 23:38:11,565 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,565 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2274ms
2014-07-13 23:38:11,565 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,573 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2338ms
2014-07-13 23:38:11,573 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,573 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2394ms
2014-07-13 23:38:11,573 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,578 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2450ms
2014-07-13 23:38:11,579 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,581 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2487ms
2014-07-13 23:38:11,581 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,581 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2524ms
2014-07-13 23:38:11,581 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,581 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2524ms
2014-07-13 23:38:11,581 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,589 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2583ms
2014-07-13 23:38:11,589 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,590 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2626ms
2014-07-13 23:38:11,590 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,591 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2680ms
2014-07-13 23:38:11,591 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,592 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2689ms
2014-07-13 23:38:11,592 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,592 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2691ms
2014-07-13 23:38:11,592 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,595 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2745ms
2014-07-13 23:38:11,595 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,596 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2746ms
2014-07-13 23:38:11,596 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,601 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2825ms
2014-07-13 23:38:11,601 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,601 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2867ms
2014-07-13 23:38:11,601 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,603 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2905ms
2014-07-13 23:38:11,603 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,603 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2908ms
2014-07-13 23:38:11,604 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,609 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2919ms
2014-07-13 23:38:11,609 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,609 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2969ms
2014-07-13 23:38:11,609 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,609 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2975ms
2014-07-13 23:38:11,609 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,609 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3026ms
2014-07-13 23:38:11,610 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,617 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3038ms
2014-07-13 23:38:11,617 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,618 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3042ms
2014-07-13 23:38:11,618 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,621 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3108ms
2014-07-13 23:38:11,621 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,622 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3239ms
2014-07-13 23:38:11,622 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,622 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3286ms
2014-07-13 23:38:11,623 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,623 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3330ms
2014-07-13 23:38:11,623 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,623 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3331ms
2014-07-13 23:38:11,623 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,623 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3332ms
2014-07-13 23:38:11,623 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,623 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3350ms
2014-07-13 23:38:11,623 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,624 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3361ms
2014-07-13 23:38:11,624 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,633 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3372ms
2014-07-13 23:38:11,633 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,633 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3373ms
2014-07-13 23:38:11,633 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,633 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3373ms
2014-07-13 23:38:11,633 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,645 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3387ms
2014-07-13 23:38:11,646 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,646 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3425ms
2014-07-13 23:38:11,646 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,653 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3451ms
2014-07-13 23:38:11,653 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,653 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3465ms
2014-07-13 23:38:11,653 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,656 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3469ms
2014-07-13 23:38:11,656 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,659 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3473ms
2014-07-13 23:38:11,659 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,659 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3477ms
2014-07-13 23:38:11,659 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,659 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3477ms
2014-07-13 23:38:11,660 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,660 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3480ms
2014-07-13 23:38:11,660 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:11,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:11,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52720 synced till here 52698
2014-07-13 23:38:11,939 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319886845 with entries=84, filesize=82.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319891684
2014-07-13 23:38:12,023 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11555, memsize=366.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/7183660e57e740f1945b91f4a035f43d
2014-07-13 23:38:12,052 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/7183660e57e740f1945b91f4a035f43d as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/7183660e57e740f1945b91f4a035f43d
2014-07-13 23:38:12,079 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/7183660e57e740f1945b91f4a035f43d, entries=1334470, sequenceid=11555, filesize=95.1m
2014-07-13 23:38:12,079 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1019.3m/1068811920, currentsize=505.6m/530190240 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 26683ms, sequenceid=11555, compaction requested=true
2014-07-13 23:38:12,080 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:91), split_queue=0, merge_queue=0
2014-07-13 23:38:12,080 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 466.9m
2014-07-13 23:38:12,180 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:38:13,372 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:38:13,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:13,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52825 synced till here 52788
2014-07-13 23:38:14,018 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:38:14,063 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:38:14,239 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319891684 with entries=105, filesize=106.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319893779
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319804659
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319808081
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319809770
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319811531
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319812923
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319814262
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319815499
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319816922
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319818137
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319819440
2014-07-13 23:38:14,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319822245
2014-07-13 23:38:15,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:15,949 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52931 synced till here 52893
2014-07-13 23:38:17,519 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319893779 with entries=106, filesize=108.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319895922
2014-07-13 23:38:19,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:19,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53036 synced till here 53010
2014-07-13 23:38:20,266 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319895922 with entries=105, filesize=103.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319899866
2014-07-13 23:38:22,256 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:22,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53141 synced till here 53121
2014-07-13 23:38:23,427 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319899866 with entries=105, filesize=105.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319902256
2014-07-13 23:38:25,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:25,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53246 synced till here 53208
2014-07-13 23:38:25,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319902256 with entries=105, filesize=102.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319905359
2014-07-13 23:38:26,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:26,489 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53322 synced till here 53316
2014-07-13 23:38:26,970 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319905359 with entries=76, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319906471
2014-07-13 23:38:28,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:29,012 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53398 synced till here 53394
2014-07-13 23:38:29,057 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319906471 with entries=76, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319908489
2014-07-13 23:38:30,145 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:30,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53480 synced till here 53479
2014-07-13 23:38:30,629 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319908489 with entries=82, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319910145
2014-07-13 23:38:32,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:32,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53553 synced till here 53541
2014-07-13 23:38:32,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319910145 with entries=73, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319912534
2014-07-13 23:38:33,426 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:34,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53647 synced till here 53636
2014-07-13 23:38:34,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319912534 with entries=94, filesize=74.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319913426
2014-07-13 23:38:34,315 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,316 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,316 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,317 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,320 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,320 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,320 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,362 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,363 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,363 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,364 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,364 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,368 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,368 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,368 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,370 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,383 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,385 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,396 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,436 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,480 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,510 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,526 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,527 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,527 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,528 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,538 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,538 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,540 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,549 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,584 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,620 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,620 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,620 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,623 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,628 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,629 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:34,632 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:35,659 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,500 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,507 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,508 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,509 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,511 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,512 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,531 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,533 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,533 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,539 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:36,541 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:39,138 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17460, memsize=433.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/cced37c3e00344e0ae9fbbd4c844b5b9
2014-07-13 23:38:39,157 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/cced37c3e00344e0ae9fbbd4c844b5b9 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/cced37c3e00344e0ae9fbbd4c844b5b9
2014-07-13 23:38:39,190 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/cced37c3e00344e0ae9fbbd4c844b5b9, entries=1576700, sequenceid=17460, filesize=112.3m
2014-07-13 23:38:39,190 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~487.5m/511189600, currentsize=243.1m/254930640 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 27110ms, sequenceid=17460, compaction requested=true
2014-07-13 23:38:39,190 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:92), split_queue=0, merge_queue=0
2014-07-13 23:38:39,191 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2650ms
2014-07-13 23:38:39,191 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,191 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 970.4m
2014-07-13 23:38:39,191 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2652ms
2014-07-13 23:38:39,191 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,191 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2658ms
2014-07-13 23:38:39,191 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,191 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2658ms
2014-07-13 23:38:39,191 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,191 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2660ms
2014-07-13 23:38:39,191 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,191 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2679ms
2014-07-13 23:38:39,192 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,196 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2685ms
2014-07-13 23:38:39,196 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,196 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2687ms
2014-07-13 23:38:39,196 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,196 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2689ms
2014-07-13 23:38:39,196 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,197 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2690ms
2014-07-13 23:38:39,197 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,197 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2697ms
2014-07-13 23:38:39,197 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,198 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3539ms
2014-07-13 23:38:39,198 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,199 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4567ms
2014-07-13 23:38:39,199 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,201 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4572ms
2014-07-13 23:38:39,201 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,201 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4573ms
2014-07-13 23:38:39,201 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,201 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4578ms
2014-07-13 23:38:39,201 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,202 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4582ms
2014-07-13 23:38:39,202 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,202 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4582ms
2014-07-13 23:38:39,202 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,202 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4582ms
2014-07-13 23:38:39,202 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,202 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4619ms
2014-07-13 23:38:39,202 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,203 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4654ms
2014-07-13 23:38:39,203 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,203 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4663ms
2014-07-13 23:38:39,203 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,204 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4666ms
2014-07-13 23:38:39,204 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,208 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4670ms
2014-07-13 23:38:39,208 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,208 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4680ms
2014-07-13 23:38:39,208 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,208 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4681ms
2014-07-13 23:38:39,208 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,208 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4681ms
2014-07-13 23:38:39,209 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,209 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4683ms
2014-07-13 23:38:39,209 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,209 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4699ms
2014-07-13 23:38:39,209 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,211 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4731ms
2014-07-13 23:38:39,211 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,225 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4789ms
2014-07-13 23:38:39,225 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,225 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4830ms
2014-07-13 23:38:39,225 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,226 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4840ms
2014-07-13 23:38:39,226 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,226 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4843ms
2014-07-13 23:38:39,227 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,230 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4859ms
2014-07-13 23:38:39,230 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,230 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4862ms
2014-07-13 23:38:39,230 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,230 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4862ms
2014-07-13 23:38:39,230 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,231 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4862ms
2014-07-13 23:38:39,231 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,232 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4868ms
2014-07-13 23:38:39,232 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,241 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4877ms
2014-07-13 23:38:39,241 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,241 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4878ms
2014-07-13 23:38:39,241 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,242 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4879ms
2014-07-13 23:38:39,242 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,243 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4881ms
2014-07-13 23:38:39,243 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,243 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4923ms
2014-07-13 23:38:39,243 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,244 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4924ms
2014-07-13 23:38:39,244 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,245 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4925ms
2014-07-13 23:38:39,245 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,245 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4928ms
2014-07-13 23:38:39,245 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,245 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4929ms
2014-07-13 23:38:39,245 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,246 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4930ms
2014-07-13 23:38:39,246 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,249 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4935ms
2014-07-13 23:38:39,249 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:39,497 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:38:40,665 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:40,793 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53778 synced till here 53759
2014-07-13 23:38:40,915 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:38:41,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319913426 with entries=131, filesize=91.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319920666
2014-07-13 23:38:42,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:42,254 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53884 synced till here 53861
2014-07-13 23:38:42,476 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319920666 with entries=106, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319922240
2014-07-13 23:38:43,955 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:43,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53959 synced till here 53948
2014-07-13 23:38:44,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319922240 with entries=75, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319923955
2014-07-13 23:38:44,423 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,424 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,425 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,427 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,427 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,430 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,430 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,495 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,513 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,559 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,561 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,582 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,606 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,625 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,635 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,638 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,678 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,682 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,690 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,698 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:44,705 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,013 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,275 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,319 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,351 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,386 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,431 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,480 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,518 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,564 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,611 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,663 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,688 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:45,715 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:47,182 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11792, memsize=491.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/97af7dcaf50942e49f1a7f30316e1c5e
2014-07-13 23:38:47,190 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:47,190 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:47,191 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:47,191 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:47,191 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:38:47,214 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/97af7dcaf50942e49f1a7f30316e1c5e as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/97af7dcaf50942e49f1a7f30316e1c5e
2014-07-13 23:38:47,227 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/97af7dcaf50942e49f1a7f30316e1c5e, entries=1788450, sequenceid=11792, filesize=127.4m
2014-07-13 23:38:47,227 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1162336480, currentsize=603.5m/632833920 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 35664ms, sequenceid=11792, compaction requested=true
2014-07-13 23:38:47,227 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:93), split_queue=0, merge_queue=0
2014-07-13 23:38:47,227 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 36ms
2014-07-13 23:38:47,227 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,228 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 37ms
2014-07-13 23:38:47,228 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 943.6m
2014-07-13 23:38:47,228 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,228 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38ms
2014-07-13 23:38:47,228 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,228 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38ms
2014-07-13 23:38:47,228 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,228 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 38ms
2014-07-13 23:38:47,228 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,228 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1513ms
2014-07-13 23:38:47,228 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,228 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1540ms
2014-07-13 23:38:47,228 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,229 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1566ms
2014-07-13 23:38:47,229 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,229 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1618ms
2014-07-13 23:38:47,229 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,229 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1665ms
2014-07-13 23:38:47,229 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,229 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1711ms
2014-07-13 23:38:47,229 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,230 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1750ms
2014-07-13 23:38:47,230 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,230 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1799ms
2014-07-13 23:38:47,230 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,233 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1847ms
2014-07-13 23:38:47,233 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,236 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1885ms
2014-07-13 23:38:47,236 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,236 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1917ms
2014-07-13 23:38:47,237 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,237 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1962ms
2014-07-13 23:38:47,237 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,237 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2224ms
2014-07-13 23:38:47,237 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,239 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2535ms
2014-07-13 23:38:47,239 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,240 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2542ms
2014-07-13 23:38:47,240 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,241 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2551ms
2014-07-13 23:38:47,241 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,241 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2559ms
2014-07-13 23:38:47,241 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,245 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2567ms
2014-07-13 23:38:47,245 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,246 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2608ms
2014-07-13 23:38:47,246 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,246 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2611ms
2014-07-13 23:38:47,247 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,247 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2622ms
2014-07-13 23:38:47,247 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,247 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2642ms
2014-07-13 23:38:47,247 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,247 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2665ms
2014-07-13 23:38:47,247 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,248 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2687ms
2014-07-13 23:38:47,248 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,255 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2696ms
2014-07-13 23:38:47,255 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,256 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2743ms
2014-07-13 23:38:47,256 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,256 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2761ms
2014-07-13 23:38:47,256 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,265 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2835ms
2014-07-13 23:38:47,265 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,265 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2836ms
2014-07-13 23:38:47,265 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,265 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2838ms
2014-07-13 23:38:47,265 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,268 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2841ms
2014-07-13 23:38:47,268 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,268 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2843ms
2014-07-13 23:38:47,268 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,268 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2844ms
2014-07-13 23:38:47,268 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,268 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2845ms
2014-07-13 23:38:47,268 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:38:47,429 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:38:47,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:47,669 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319923955 with entries=95, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319927603
2014-07-13 23:38:47,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319824050
2014-07-13 23:38:47,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319835932
2014-07-13 23:38:47,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319838182
2014-07-13 23:38:47,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319841206
2014-07-13 23:38:47,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319843259
2014-07-13 23:38:47,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319845549
2014-07-13 23:38:47,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319848120
2014-07-13 23:38:47,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319850077
2014-07-13 23:38:47,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319852135
2014-07-13 23:38:47,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319853897
2014-07-13 23:38:47,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319859510
2014-07-13 23:38:47,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319861074
2014-07-13 23:38:47,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319862579
2014-07-13 23:38:48,110 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:38:49,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:49,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54129 synced till here 54127
2014-07-13 23:38:49,272 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319927603 with entries=75, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319929014
2014-07-13 23:38:50,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:50,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319929014 with entries=62, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319930498
2014-07-13 23:38:52,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:52,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54262 synced till here 54256
2014-07-13 23:38:52,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319930498 with entries=71, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319932019
2014-07-13 23:38:52,790 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:52,833 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319932019 with entries=71, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319932790
2014-07-13 23:38:53,936 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:53,968 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319932790 with entries=65, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319933936
2014-07-13 23:38:55,442 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:55,503 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54465 synced till here 54461
2014-07-13 23:38:55,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319933936 with entries=67, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319935442
2014-07-13 23:38:57,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:38:58,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54564 synced till here 54546
2014-07-13 23:38:58,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319935442 with entries=99, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319937562
2014-07-13 23:39:00,290 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:00,573 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,573 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,573 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,574 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,574 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,575 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,576 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,577 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,578 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,579 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,580 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,580 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,581 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,583 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,606 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,626 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,628 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,628 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,630 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,641 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,666 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319937562 with entries=129, filesize=115.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319940290
2014-07-13 23:39:00,681 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,690 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,691 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,692 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,692 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:00,693 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,304 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,350 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,386 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,418 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,456 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,475 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,510 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,537 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,572 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,590 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,600 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,600 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,601 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,601 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,605 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,607 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,608 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,615 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,616 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:01,616 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:02,458 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:02,467 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:02,484 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:05,224 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12028, memsize=459.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/dd59d39b1c4549299c79d7560a802dc2
2014-07-13 23:39:05,248 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/dd59d39b1c4549299c79d7560a802dc2 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/dd59d39b1c4549299c79d7560a802dc2
2014-07-13 23:39:05,263 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/dd59d39b1c4549299c79d7560a802dc2, entries=1671880, sequenceid=12028, filesize=119.1m
2014-07-13 23:39:05,263 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~970.4m/1017586400, currentsize=445.6m/467294880 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 26072ms, sequenceid=12028, compaction requested=true
2014-07-13 23:39:05,263 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:94), split_queue=0, merge_queue=0
2014-07-13 23:39:05,264 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2780ms
2014-07-13 23:39:05,264 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,264 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 519.4m
2014-07-13 23:39:05,264 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2797ms
2014-07-13 23:39:05,264 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,265 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2807ms
2014-07-13 23:39:05,265 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,267 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3650ms
2014-07-13 23:39:05,267 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,267 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3651ms
2014-07-13 23:39:05,267 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,269 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3654ms
2014-07-13 23:39:05,269 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,269 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3661ms
2014-07-13 23:39:05,269 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,273 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3666ms
2014-07-13 23:39:05,277 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,277 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3672ms
2014-07-13 23:39:05,277 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,277 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3676ms
2014-07-13 23:39:05,277 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,277 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3676ms
2014-07-13 23:39:05,278 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,278 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3678ms
2014-07-13 23:39:05,278 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,278 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3678ms
2014-07-13 23:39:05,278 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,279 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3688ms
2014-07-13 23:39:05,279 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,281 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3709ms
2014-07-13 23:39:05,281 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,282 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3744ms
2014-07-13 23:39:05,282 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,283 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3773ms
2014-07-13 23:39:05,283 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,284 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3808ms
2014-07-13 23:39:05,284 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,284 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3828ms
2014-07-13 23:39:05,284 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,285 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3867ms
2014-07-13 23:39:05,285 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,286 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3900ms
2014-07-13 23:39:05,286 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,286 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3936ms
2014-07-13 23:39:05,286 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,287 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3982ms
2014-07-13 23:39:05,287 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,289 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4596ms
2014-07-13 23:39:05,289 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,289 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4597ms
2014-07-13 23:39:05,289 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,289 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4597ms
2014-07-13 23:39:05,290 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,290 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4599ms
2014-07-13 23:39:05,290 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,291 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4601ms
2014-07-13 23:39:05,291 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,291 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4610ms
2014-07-13 23:39:05,291 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,295 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4629ms
2014-07-13 23:39:05,295 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,299 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4659ms
2014-07-13 23:39:05,299 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,299 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4669ms
2014-07-13 23:39:05,299 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,305 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4677ms
2014-07-13 23:39:05,305 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,305 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4678ms
2014-07-13 23:39:05,305 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,305 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4679ms
2014-07-13 23:39:05,305 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,313 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4707ms
2014-07-13 23:39:05,313 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,313 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4730ms
2014-07-13 23:39:05,313 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,313 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4732ms
2014-07-13 23:39:05,313 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,314 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4733ms
2014-07-13 23:39:05,314 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,314 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4734ms
2014-07-13 23:39:05,314 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,314 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4735ms
2014-07-13 23:39:05,314 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,320 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4742ms
2014-07-13 23:39:05,320 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,321 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4744ms
2014-07-13 23:39:05,321 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,321 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4745ms
2014-07-13 23:39:05,321 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,322 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4746ms
2014-07-13 23:39:05,322 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,323 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4750ms
2014-07-13 23:39:05,324 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,326 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4751ms
2014-07-13 23:39:05,326 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,326 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4753ms
2014-07-13 23:39:05,327 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,329 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4757ms
2014-07-13 23:39:05,329 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:05,329 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4757ms
2014-07-13 23:39:05,329 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:06,631 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:39:06,702 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:39:06,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:06,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54795 synced till here 54792
2014-07-13 23:39:07,035 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319940290 with entries=102, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319946870
2014-07-13 23:39:07,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319863905
2014-07-13 23:39:07,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319865515
2014-07-13 23:39:07,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319867239
2014-07-13 23:39:07,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319868627
2014-07-13 23:39:07,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319869446
2014-07-13 23:39:07,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319870795
2014-07-13 23:39:08,616 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:08,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54893 synced till here 54871
2014-07-13 23:39:08,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319946870 with entries=98, filesize=84.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319948617
2014-07-13 23:39:08,946 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12103, memsize=314.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/55363b75d51341e9ab519b93286288ca
2014-07-13 23:39:08,965 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/55363b75d51341e9ab519b93286288ca as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/55363b75d51341e9ab519b93286288ca
2014-07-13 23:39:09,018 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/55363b75d51341e9ab519b93286288ca, entries=1143960, sequenceid=12103, filesize=81.5m
2014-07-13 23:39:09,019 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~943.6m/989411280, currentsize=391.0m/410031280 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 21792ms, sequenceid=12103, compaction requested=true
2014-07-13 23:39:09,020 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:95), split_queue=0, merge_queue=0
2014-07-13 23:39:09,020 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1012.9m
2014-07-13 23:39:09,123 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:39:10,316 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:10,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54993 synced till here 54973
2014-07-13 23:39:10,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319948617 with entries=100, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319950316
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319872161
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319873369
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319874749
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319876521
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319878589
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319880093
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319881565
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319883317
2014-07-13 23:39:10,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319884781
2014-07-13 23:39:11,029 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:39:11,886 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:11,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55092 synced till here 55081
2014-07-13 23:39:12,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319950316 with entries=99, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319951887
2014-07-13 23:39:14,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:14,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319951887 with entries=75, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319954509
2014-07-13 23:39:15,510 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:16,233 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55250 synced till here 55235
2014-07-13 23:39:16,410 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319954509 with entries=83, filesize=80.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319955511
2014-07-13 23:39:18,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:18,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55348 synced till here 55340
2014-07-13 23:39:18,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319955511 with entries=98, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319958142
2014-07-13 23:39:19,510 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:19,530 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55427 synced till here 55424
2014-07-13 23:39:19,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319958142 with entries=79, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319959511
2014-07-13 23:39:21,179 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:21,258 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55504 synced till here 55500
2014-07-13 23:39:21,319 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319959511 with entries=77, filesize=80.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319961180
2014-07-13 23:39:22,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:23,156 DEBUG [LruStats #0] hfile.LruBlockCache: Total=5.29 MB, free=3.95 GB, max=3.96 GB, blocks=11, accesses=296137, hits=94738, hitRatio=31.99%, , cachingAccesses=94788, cachingHits=94718, cachingHitsRatio=99.92%, evictions=0, evicted=59, evictedPerRun=Infinity
2014-07-13 23:39:23,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55619 synced till here 55614
2014-07-13 23:39:23,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319961180 with entries=115, filesize=114.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319962595
2014-07-13 23:39:24,260 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18062, memsize=296.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/f7a4cc6b7826443aae565c150a69bb2c
2014-07-13 23:39:24,286 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/f7a4cc6b7826443aae565c150a69bb2c as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f7a4cc6b7826443aae565c150a69bb2c
2014-07-13 23:39:24,451 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f7a4cc6b7826443aae565c150a69bb2c, entries=1080910, sequenceid=18062, filesize=77.0m
2014-07-13 23:39:24,453 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~519.4m/544650800, currentsize=187.3m/196446000 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 19188ms, sequenceid=18062, compaction requested=true
2014-07-13 23:39:24,453 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:96), split_queue=0, merge_queue=0
2014-07-13 23:39:24,454 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 881.2m
2014-07-13 23:39:24,834 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:24,909 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55710 synced till here 55695
2014-07-13 23:39:25,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319962595 with entries=91, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319964834
2014-07-13 23:39:26,094 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:39:26,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:27,185 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55805 synced till here 55775
2014-07-13 23:39:27,312 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319964834 with entries=95, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319966326
2014-07-13 23:39:27,434 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:39:28,034 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:28,793 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55907 synced till here 55889
2014-07-13 23:39:29,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319966326 with entries=102, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319968034
2014-07-13 23:39:29,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:29,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55997 synced till here 55990
2014-07-13 23:39:29,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319968034 with entries=90, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319969849
2014-07-13 23:39:31,220 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:31,325 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56072 synced till here 56064
2014-07-13 23:39:31,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319969849 with entries=75, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319971230
2014-07-13 23:39:32,359 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12313, memsize=310.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/be672ff979a64225b4ec805601d46de9
2014-07-13 23:39:32,373 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/be672ff979a64225b4ec805601d46de9 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/be672ff979a64225b4ec805601d46de9
2014-07-13 23:39:32,390 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/be672ff979a64225b4ec805601d46de9, entries=1129660, sequenceid=12313, filesize=80.4m
2014-07-13 23:39:32,391 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1023.5m/1073197600, currentsize=504.5m/528979280 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 23371ms, sequenceid=12313, compaction requested=true
2014-07-13 23:39:32,391 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:97), split_queue=0, merge_queue=0
2014-07-13 23:39:32,391 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 918.6m
2014-07-13 23:39:32,404 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:39:32,567 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:32,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56136 synced till here 56127
2014-07-13 23:39:32,670 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319971230 with entries=64, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319972568
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319886845
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319891684
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319893779
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319895922
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319899866
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319902256
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319905359
2014-07-13 23:39:32,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319906471
2014-07-13 23:39:32,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319908489
2014-07-13 23:39:32,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319910145
2014-07-13 23:39:32,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319912534
2014-07-13 23:39:33,602 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:39:34,362 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:34,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56206 synced till here 56204
2014-07-13 23:39:35,470 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319972568 with entries=70, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319974363
2014-07-13 23:39:36,202 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:37,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56300 synced till here 56277
2014-07-13 23:39:37,216 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319974363 with entries=94, filesize=85.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319976202
2014-07-13 23:39:38,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:38,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56399 synced till here 56371
2014-07-13 23:39:38,997 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319976202 with entries=99, filesize=85.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319978671
2014-07-13 23:39:40,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:40,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56493 synced till here 56483
2014-07-13 23:39:40,319 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319978671 with entries=94, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319980184
2014-07-13 23:39:41,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:41,741 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56601 synced till here 56585
2014-07-13 23:39:42,064 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319980184 with entries=108, filesize=80.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319981638
2014-07-13 23:39:43,592 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:43,643 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56690 synced till here 56672
2014-07-13 23:39:43,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319981638 with entries=89, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319983592
2014-07-13 23:39:45,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:45,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56761 synced till here 56758
2014-07-13 23:39:45,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319983592 with entries=71, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319985273
2014-07-13 23:39:46,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:46,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56841 synced till here 56828
2014-07-13 23:39:46,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319985273 with entries=80, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319986769
2014-07-13 23:39:48,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:48,182 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,182 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,194 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,194 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,195 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,196 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56919 synced till here 56911
2014-07-13 23:39:48,222 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,236 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319986769 with entries=78, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319988177
2014-07-13 23:39:48,288 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,357 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,359 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,363 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,376 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,381 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,389 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,391 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,394 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,395 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,409 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,464 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,464 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,464 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,465 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,480 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,523 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,533 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,542 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,547 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,556 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,623 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,666 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,678 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,688 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,756 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,802 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,804 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,806 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,843 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,883 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,883 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,884 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,893 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,898 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,900 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,944 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:48,947 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:49,000 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:49,032 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:49,035 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:49,041 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:39:49,645 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12472, memsize=384.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/83ab91b4321446f4a291abda1463d7d4
2014-07-13 23:39:49,659 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/83ab91b4321446f4a291abda1463d7d4 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/83ab91b4321446f4a291abda1463d7d4
2014-07-13 23:39:49,672 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/83ab91b4321446f4a291abda1463d7d4, entries=1400290, sequenceid=12472, filesize=99.7m
2014-07-13 23:39:49,672 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~890.1m/933318720, currentsize=525.8m/551293840 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 25218ms, sequenceid=12472, compaction requested=true
2014-07-13 23:39:49,672 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:98), split_queue=0, merge_queue=0
2014-07-13 23:39:49,672 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 632ms
2014-07-13 23:39:49,672 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,673 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 544.9m
2014-07-13 23:39:49,673 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 638ms
2014-07-13 23:39:49,673 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,673 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 641ms
2014-07-13 23:39:49,673 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,674 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 674ms
2014-07-13 23:39:49,674 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,676 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 729ms
2014-07-13 23:39:49,680 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,680 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 736ms
2014-07-13 23:39:49,680 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,681 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 781ms
2014-07-13 23:39:49,681 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,681 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 784ms
2014-07-13 23:39:49,681 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,681 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 788ms
2014-07-13 23:39:49,681 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,681 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 797ms
2014-07-13 23:39:49,681 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,681 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 798ms
2014-07-13 23:39:49,681 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,681 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 798ms
2014-07-13 23:39:49,682 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,682 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 840ms
2014-07-13 23:39:49,682 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,683 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 877ms
2014-07-13 23:39:49,684 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,684 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 880ms
2014-07-13 23:39:49,684 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,684 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 882ms
2014-07-13 23:39:49,684 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,684 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 929ms
2014-07-13 23:39:49,685 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,686 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 998ms
2014-07-13 23:39:49,686 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,686 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1008ms
2014-07-13 23:39:49,686 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,688 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1022ms
2014-07-13 23:39:49,688 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,688 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1065ms
2014-07-13 23:39:49,688 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,688 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1132ms
2014-07-13 23:39:49,688 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,689 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1142ms
2014-07-13 23:39:49,689 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,689 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1147ms
2014-07-13 23:39:49,689 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,689 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1156ms
2014-07-13 23:39:49,689 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,689 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1166ms
2014-07-13 23:39:49,689 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,692 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1212ms
2014-07-13 23:39:49,692 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,692 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1227ms
2014-07-13 23:39:49,692 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,693 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1229ms
2014-07-13 23:39:49,693 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,693 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1229ms
2014-07-13 23:39:49,693 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,693 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1229ms
2014-07-13 23:39:49,693 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,693 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1284ms
2014-07-13 23:39:49,693 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,694 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1299ms
2014-07-13 23:39:49,694 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,694 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1300ms
2014-07-13 23:39:49,694 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,694 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1303ms
2014-07-13 23:39:49,694 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,696 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1307ms
2014-07-13 23:39:49,696 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,700 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1319ms
2014-07-13 23:39:49,700 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,700 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1324ms
2014-07-13 23:39:49,700 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,700 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1337ms
2014-07-13 23:39:49,700 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,700 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1341ms
2014-07-13 23:39:49,701 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,701 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1344ms
2014-07-13 23:39:49,701 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,706 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1418ms
2014-07-13 23:39:49,706 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,706 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1470ms
2014-07-13 23:39:49,706 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,713 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1491ms
2014-07-13 23:39:49,713 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,713 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1517ms
2014-07-13 23:39:49,713 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,713 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1519ms
2014-07-13 23:39:49,713 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,717 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1523ms
2014-07-13 23:39:49,717 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,725 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1531ms
2014-07-13 23:39:49,725 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,725 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1543ms
2014-07-13 23:39:49,725 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:49,733 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1551ms
2014-07-13 23:39:49,733 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:39:51,236 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:39:51,360 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:39:51,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:51,712 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57021 synced till here 57007
2014-07-13 23:39:52,042 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319988177 with entries=102, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319991613
2014-07-13 23:39:52,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319913426
2014-07-13 23:39:52,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319920666
2014-07-13 23:39:52,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319922240
2014-07-13 23:39:53,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:53,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57130 synced till here 57097
2014-07-13 23:39:54,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319991613 with entries=109, filesize=97.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319993936
2014-07-13 23:39:56,629 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:56,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57245 synced till here 57211
2014-07-13 23:39:56,844 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319993936 with entries=115, filesize=93.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319996630
2014-07-13 23:39:58,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:39:58,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57363 synced till here 57339
2014-07-13 23:39:58,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319996630 with entries=118, filesize=89.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319998623
2014-07-13 23:40:00,515 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:00,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57470 synced till here 57457
2014-07-13 23:40:00,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319998623 with entries=107, filesize=92.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320000515
2014-07-13 23:40:02,094 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,097 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,104 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,105 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,107 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,109 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,111 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,112 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,117 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,119 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,122 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,123 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,220 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,271 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:02,279 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,279 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,280 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,280 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,289 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,304 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,308 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,350 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,405 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,438 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,468 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,518 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:02,635 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320000515 with entries=75, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320002273
2014-07-13 23:40:03,673 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:03,931 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,224 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,267 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,276 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,321 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,360 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,408 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,449 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,492 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,548 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,589 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,629 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,669 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:04,702 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:05,210 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:05,229 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:05,993 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:06,010 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:06,031 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:06,031 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:06,032 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:06,034 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:06,049 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12565, memsize=483.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/d57f0d59646343c399f69c1e8b3c4d59
2014-07-13 23:40:06,069 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/d57f0d59646343c399f69c1e8b3c4d59 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/d57f0d59646343c399f69c1e8b3c4d59
2014-07-13 23:40:06,085 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/d57f0d59646343c399f69c1e8b3c4d59, entries=1759850, sequenceid=12565, filesize=125.4m
2014-07-13 23:40:06,085 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~923.3m/968123840, currentsize=599.9m/628998880 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 33694ms, sequenceid=12565, compaction requested=true
2014-07-13 23:40:06,085 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-13 23:40:06,086 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 52ms
2014-07-13 23:40:06,086 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,086 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.1g
2014-07-13 23:40:06,086 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 55ms
2014-07-13 23:40:06,086 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,086 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 55ms
2014-07-13 23:40:06,086 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,088 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 57ms
2014-07-13 23:40:06,090 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,090 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 80ms
2014-07-13 23:40:06,090 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,094 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 101ms
2014-07-13 23:40:06,094 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,094 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 865ms
2014-07-13 23:40:06,094 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,095 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 885ms
2014-07-13 23:40:06,095 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,097 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1395ms
2014-07-13 23:40:06,097 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,105 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1436ms
2014-07-13 23:40:06,105 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,110 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1481ms
2014-07-13 23:40:06,110 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,110 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1522ms
2014-07-13 23:40:06,110 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,113 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1565ms
2014-07-13 23:40:06,113 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,115 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1623ms
2014-07-13 23:40:06,115 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,119 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1670ms
2014-07-13 23:40:06,120 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,121 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1713ms
2014-07-13 23:40:06,121 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,121 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1762ms
2014-07-13 23:40:06,121 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,121 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1800ms
2014-07-13 23:40:06,121 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,122 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1846ms
2014-07-13 23:40:06,122 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,123 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1856ms
2014-07-13 23:40:06,123 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,124 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1899ms
2014-07-13 23:40:06,124 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,125 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2194ms
2014-07-13 23:40:06,125 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,130 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2457ms
2014-07-13 23:40:06,130 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,131 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3613ms
2014-07-13 23:40:06,131 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,137 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3669ms
2014-07-13 23:40:06,138 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,138 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3700ms
2014-07-13 23:40:06,138 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,141 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3736ms
2014-07-13 23:40:06,141 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,141 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3792ms
2014-07-13 23:40:06,141 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,145 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3837ms
2014-07-13 23:40:06,145 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,145 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3841ms
2014-07-13 23:40:06,145 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,145 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3856ms
2014-07-13 23:40:06,145 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,145 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3865ms
2014-07-13 23:40:06,145 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,146 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3867ms
2014-07-13 23:40:06,146 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,146 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3867ms
2014-07-13 23:40:06,146 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,157 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3878ms
2014-07-13 23:40:06,157 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,157 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3887ms
2014-07-13 23:40:06,157 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,157 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3937ms
2014-07-13 23:40:06,157 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,159 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4036ms
2014-07-13 23:40:06,159 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,165 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4043ms
2014-07-13 23:40:06,165 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,165 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4046ms
2014-07-13 23:40:06,165 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,166 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4048ms
2014-07-13 23:40:06,166 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,167 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4055ms
2014-07-13 23:40:06,167 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,168 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4056ms
2014-07-13 23:40:06,168 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,174 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4064ms
2014-07-13 23:40:06,174 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,174 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4067ms
2014-07-13 23:40:06,174 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,174 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4069ms
2014-07-13 23:40:06,174 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,175 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4070ms
2014-07-13 23:40:06,175 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,177 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4081ms
2014-07-13 23:40:06,177 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,181 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4087ms
2014-07-13 23:40:06,181 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:06,923 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:40:07,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:07,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57616 synced till here 57614
2014-07-13 23:40:07,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320002273 with entries=71, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320007015
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319923955
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319927603
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319929014
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319930498
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319932019
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319932790
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319933936
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319935442
2014-07-13 23:40:07,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319937562
2014-07-13 23:40:07,495 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:40:08,555 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:08,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320007015 with entries=65, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320008556
2014-07-13 23:40:10,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:10,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320008556 with entries=64, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320010324
2014-07-13 23:40:11,843 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:11,968 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57833 synced till here 57828
2014-07-13 23:40:12,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320010324 with entries=88, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320011844
2014-07-13 23:40:13,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:14,023 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57942 synced till here 57932
2014-07-13 23:40:14,128 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320011844 with entries=109, filesize=99.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320013747
2014-07-13 23:40:15,424 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:15,498 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58015 synced till here 58004
2014-07-13 23:40:16,000 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18829, memsize=426.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1d0e02bd9ca443b3968422a01650fc64
2014-07-13 23:40:16,022 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1d0e02bd9ca443b3968422a01650fc64 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1d0e02bd9ca443b3968422a01650fc64
2014-07-13 23:40:16,024 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320013747 with entries=73, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320015424
2014-07-13 23:40:16,039 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1d0e02bd9ca443b3968422a01650fc64, entries=1553380, sequenceid=18829, filesize=110.6m
2014-07-13 23:40:16,040 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~544.9m/571401120, currentsize=264.4m/277196640 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 26367ms, sequenceid=18829, compaction requested=true
2014-07-13 23:40:16,040 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-13 23:40:16,040 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 1009.9m
2014-07-13 23:40:16,632 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:40:17,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:17,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58100 synced till here 58088
2014-07-13 23:40:17,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320015424 with entries=85, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320017281
2014-07-13 23:40:17,468 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319940290
2014-07-13 23:40:17,468 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319946870
2014-07-13 23:40:18,047 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:40:19,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:19,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58168 synced till here 58163
2014-07-13 23:40:19,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320017281 with entries=68, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320019118
2014-07-13 23:40:20,314 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:20,342 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58250 synced till here 58245
2014-07-13 23:40:20,412 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320019118 with entries=82, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320020315
2014-07-13 23:40:21,634 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:21,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58363 synced till here 58354
2014-07-13 23:40:22,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320020315 with entries=113, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320021634
2014-07-13 23:40:23,537 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:23,539 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,546 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,546 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,551 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,603 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,603 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,653 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,656 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,657 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,658 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,661 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,661 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,674 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,674 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,675 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,680 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,731 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,794 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,848 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,849 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,857 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,859 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,874 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,889 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,889 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,889 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,897 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:23,953 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,007 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,071 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320021634 with entries=89, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320023538
2014-07-13 23:40:24,108 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,159 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,878 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,880 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,881 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,884 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,905 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,906 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,914 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:24,962 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,767 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,768 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,768 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,820 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,845 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,877 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,885 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,920 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,955 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:25,991 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:40:28,540 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,546 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,546 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,551 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,603 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,604 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,654 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,657 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,658 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,658 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,661 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,661 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,675 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,675 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,675 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,681 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,731 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,794 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,849 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,849 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,857 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,860 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,874 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,889 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,890 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:28,890 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:28,897 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:29,366 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5207ms
2014-07-13 23:40:29,367 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5414ms
2014-07-13 23:40:29,367 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5361ms
2014-07-13 23:40:29,367 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5296ms
2014-07-13 23:40:29,367 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5259ms
2014-07-13 23:40:29,878 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:29,880 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:29,881 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:29,885 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:29,906 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:29,906 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:29,914 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:29,962 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,768 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,768 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:30,768 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,820 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,846 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,877 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,885 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,920 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,955 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:40:30,992 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:40:33,464 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12874, memsize=509.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/d334e3c78247454085bbe92390d364ad
2014-07-13 23:40:33,492 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/d334e3c78247454085bbe92390d364ad as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d334e3c78247454085bbe92390d364ad
2014-07-13 23:40:33,541 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:40:33,546 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:40:33,547 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:40:33,552 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:40:33,594 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/d334e3c78247454085bbe92390d364ad, entries=1856350, sequenceid=12874, filesize=132.2m
2014-07-13 23:40:33,594 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1171002640, currentsize=391.0m/410017520 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 27508ms, sequenceid=12874, compaction requested=true
2014-07-13 23:40:33,595 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:101), split_queue=0, merge_queue=0
2014-07-13 23:40:33,595 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10044ms
2014-07-13 23:40:33,596 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,596 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10050ms
2014-07-13 23:40:33,596 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,596 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 993.9m
2014-07-13 23:40:33,596 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10051ms
2014-07-13 23:40:33,596 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,596 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10057ms
2014-07-13 23:40:33,597 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,597 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7606ms
2014-07-13 23:40:33,597 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,597 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7642ms
2014-07-13 23:40:33,598 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,598 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7678ms
2014-07-13 23:40:33,598 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,599 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7713ms
2014-07-13 23:40:33,599 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,599 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7722ms
2014-07-13 23:40:33,600 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,606 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7760ms
2014-07-13 23:40:33,606 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,609 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7789ms
2014-07-13 23:40:33,609 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,611 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7843ms
2014-07-13 23:40:33,611 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,612 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7845ms
2014-07-13 23:40:33,612 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,612 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7845ms
2014-07-13 23:40:33,612 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,614 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8651ms
2014-07-13 23:40:33,614 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,614 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8700ms
2014-07-13 23:40:33,614 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,616 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8709ms
2014-07-13 23:40:33,616 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,616 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8711ms
2014-07-13 23:40:33,616 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,620 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8736ms
2014-07-13 23:40:33,620 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,625 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8744ms
2014-07-13 23:40:33,625 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,627 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8745ms
2014-07-13 23:40:33,627 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,630 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8752ms
2014-07-13 23:40:33,631 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,631 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9523ms
2014-07-13 23:40:33,631 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,631 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9560ms
2014-07-13 23:40:33,631 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,632 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9625ms
2014-07-13 23:40:33,632 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,632 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9679ms
2014-07-13 23:40:33,633 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,634 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9474ms
2014-07-13 23:40:33,634 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,641 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9744ms
2014-07-13 23:40:33,641 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,645 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9756ms
2014-07-13 23:40:33,645 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,645 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9756ms
2014-07-13 23:40:33,645 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,646 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9756ms
2014-07-13 23:40:33,646 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,647 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9772ms
2014-07-13 23:40:33,647 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,649 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9790ms
2014-07-13 23:40:33,649 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,650 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9792ms
2014-07-13 23:40:33,650 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,650 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9802ms
2014-07-13 23:40:33,650 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,651 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9803ms
2014-07-13 23:40:33,651 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,652 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9858ms
2014-07-13 23:40:33,653 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,654 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9922ms
2014-07-13 23:40:33,654 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,654 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:40:33,654 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,657 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9977ms
2014-07-13 23:40:33,657 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,658 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9983ms
2014-07-13 23:40:33,658 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,659 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9984ms
2014-07-13 23:40:33,659 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,659 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9985ms
2014-07-13 23:40:33,659 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,659 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9998ms
2014-07-13 23:40:33,659 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,659 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9999ms
2014-07-13 23:40:33,659 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,660 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:40:33,660 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,661 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 23:40:33,661 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,665 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10009ms
2014-07-13 23:40:33,665 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,665 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10062ms
2014-07-13 23:40:33,665 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:33,665 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10062ms
2014-07-13 23:40:33,665 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:40:34,231 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:40:34,310 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11387,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320022922,"queuetimems":1,"class":"HRegionServer","responsesize":16116,"method":"Multi"}
2014-07-13 23:40:34,310 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11205,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023104,"queuetimems":1,"class":"HRegionServer","responsesize":11066,"method":"Multi"}
2014-07-13 23:40:34,310 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11413,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320022897,"queuetimems":1,"class":"HRegionServer","responsesize":18313,"method":"Multi"}
2014-07-13 23:40:34,508 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11225,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023282,"queuetimems":0,"class":"HRegionServer","responsesize":11976,"method":"Multi"}
2014-07-13 23:40:34,508 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11151,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023356,"queuetimems":1,"class":"HRegionServer","responsesize":15283,"method":"Multi"}
2014-07-13 23:40:34,508 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11493,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023014,"queuetimems":0,"class":"HRegionServer","responsesize":17600,"method":"Multi"}
2014-07-13 23:40:34,508 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11438,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023069,"queuetimems":1,"class":"HRegionServer","responsesize":15631,"method":"Multi"}
2014-07-13 23:40:34,665 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10809,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023856,"queuetimems":0,"class":"HRegionServer","responsesize":3896,"method":"Multi"}
2014-07-13 23:40:34,666 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11505,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023160,"queuetimems":0,"class":"HRegionServer","responsesize":17839,"method":"Multi"}
2014-07-13 23:40:34,666 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10776,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023889,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:40:34,667 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10810,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023857,"queuetimems":1,"class":"HRegionServer","responsesize":62,"method":"Multi"}
2014-07-13 23:40:34,667 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10796,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023871,"queuetimems":1,"class":"HRegionServer","responsesize":3988,"method":"Multi"}
2014-07-13 23:40:34,665 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10991,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023674,"queuetimems":1,"class":"HRegionServer","responsesize":460,"method":"Multi"}
2014-07-13 23:40:34,666 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023495,"queuetimems":0,"class":"HRegionServer","responsesize":18666,"method":"Multi"}
2014-07-13 23:40:34,666 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023414,"queuetimems":0,"class":"HRegionServer","responsesize":15854,"method":"Multi"}
2014-07-13 23:40:34,669 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10995,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023674,"queuetimems":0,"class":"HRegionServer","responsesize":38,"method":"Multi"}
2014-07-13 23:40:34,669 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10781,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023888,"queuetimems":0,"class":"HRegionServer","responsesize":38,"method":"Multi"}
2014-07-13 23:40:34,673 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10825,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023848,"queuetimems":0,"class":"HRegionServer","responsesize":20,"method":"Multi"}
2014-07-13 23:40:34,681 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023889,"queuetimems":1,"class":"HRegionServer","responsesize":38,"method":"Multi"}
2014-07-13 23:40:34,687 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11013,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023674,"queuetimems":0,"class":"HRegionServer","responsesize":56,"method":"Multi"}
2014-07-13 23:40:34,689 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11086,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023603,"queuetimems":0,"class":"HRegionServer","responsesize":153,"method":"Multi"}
2014-07-13 23:40:34,690 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023888,"queuetimems":0,"class":"HRegionServer","responsesize":6547,"method":"Multi"}
2014-07-13 23:40:34,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:34,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58569 synced till here 58535
2014-07-13 23:40:35,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320023538 with entries=117, filesize=88.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320034868
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319948617
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319950316
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319951887
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319954509
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319955511
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319958142
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319959511
2014-07-13 23:40:35,991 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319961180
2014-07-13 23:40:36,190 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10348,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320025842,"queuetimems":1,"class":"HRegionServer","responsesize":11976,"method":"Multi"}
2014-07-13 23:40:36,190 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10274,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320025916,"queuetimems":0,"class":"HRegionServer","responsesize":18783,"method":"Multi"}
2014-07-13 23:40:36,235 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:40:36,338 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023788,"queuetimems":0,"class":"HRegionServer","responsesize":18205,"method":"Multi"}
2014-07-13 23:40:36,552 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12397,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320024155,"queuetimems":1,"class":"HRegionServer","responsesize":17878,"method":"Multi"}
2014-07-13 23:40:36,556 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11677,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320024877,"queuetimems":0,"class":"HRegionServer","responsesize":17356,"method":"Multi"}
2014-07-13 23:40:36,557 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12448,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320024104,"queuetimems":0,"class":"HRegionServer","responsesize":15803,"method":"Multi"}
2014-07-13 23:40:36,558 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11598,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320024960,"queuetimems":0,"class":"HRegionServer","responsesize":11901,"method":"Multi"}
2014-07-13 23:40:36,559 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320025955,"queuetimems":0,"class":"HRegionServer","responsesize":17839,"method":"Multi"}
2014-07-13 23:40:36,566 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12497,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320024068,"queuetimems":1,"class":"HRegionServer","responsesize":12148,"method":"Multi"}
2014-07-13 23:40:36,570 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023942,"queuetimems":0,"class":"HRegionServer","responsesize":16152,"method":"Multi"}
2014-07-13 23:40:36,570 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320024903,"queuetimems":0,"class":"HRegionServer","responsesize":15417,"method":"Multi"}
2014-07-13 23:40:36,574 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10756,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320025818,"queuetimems":1,"class":"HRegionServer","responsesize":16007,"method":"Multi"}
2014-07-13 23:40:36,959 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:37,004 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58677 synced till here 58639
2014-07-13 23:40:38,062 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12186,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320025876,"queuetimems":0,"class":"HRegionServer","responsesize":11066,"method":"Multi"}
2014-07-13 23:40:38,064 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14215,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023848,"queuetimems":0,"class":"HRegionServer","responsesize":18580,"method":"Multi"}
2014-07-13 23:40:38,073 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14068,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320024005,"queuetimems":0,"class":"HRegionServer","responsesize":17424,"method":"Multi"}
2014-07-13 23:40:38,078 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14350,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023727,"queuetimems":0,"class":"HRegionServer","responsesize":16007,"method":"Multi"}
2014-07-13 23:40:38,083 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14409,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023672,"queuetimems":0,"class":"HRegionServer","responsesize":18783,"method":"Multi"}
2014-07-13 23:40:38,101 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320034868 with entries=108, filesize=101.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320036960
2014-07-13 23:40:38,386 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14784,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47035","starttimems":1405320023602,"queuetimems":0,"class":"HRegionServer","responsesize":18558,"method":"Multi"}
2014-07-13 23:40:39,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:40,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58808 synced till here 58768
2014-07-13 23:40:40,236 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12991, memsize=415.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f2bf8d453dfb4830a4dfbd296728514a
2014-07-13 23:40:40,268 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f2bf8d453dfb4830a4dfbd296728514a as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f2bf8d453dfb4830a4dfbd296728514a
2014-07-13 23:40:40,326 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f2bf8d453dfb4830a4dfbd296728514a, entries=1513230, sequenceid=12991, filesize=107.7m
2014-07-13 23:40:40,329 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1017.6m/1067056240, currentsize=286.2m/300113040 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 24289ms, sequenceid=12991, compaction requested=true
2014-07-13 23:40:40,329 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:102), split_queue=0, merge_queue=0
2014-07-13 23:40:40,330 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 501.6m
2014-07-13 23:40:40,446 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:40:40,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320036960 with entries=131, filesize=117.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320039799
2014-07-13 23:40:40,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319962595
2014-07-13 23:40:40,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319964834
2014-07-13 23:40:40,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319966326
2014-07-13 23:40:40,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319968034
2014-07-13 23:40:40,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319969849
2014-07-13 23:40:41,942 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:40:42,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:42,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58908 synced till here 58907
2014-07-13 23:40:42,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320039799 with entries=100, filesize=80.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320042047
2014-07-13 23:40:43,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:43,881 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59001 synced till here 58998
2014-07-13 23:40:44,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320042047 with entries=93, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320043514
2014-07-13 23:40:45,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:45,652 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59070 synced till here 59068
2014-07-13 23:40:45,681 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320043514 with entries=69, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320045618
2014-07-13 23:40:47,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:47,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59131 synced till here 59130
2014-07-13 23:40:47,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320045618 with entries=61, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320047048
2014-07-13 23:40:48,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:48,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59201 synced till here 59191
2014-07-13 23:40:48,727 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320047048 with entries=70, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320048587
2014-07-13 23:40:50,149 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:50,447 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59282 synced till here 59276
2014-07-13 23:40:50,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320048587 with entries=81, filesize=82.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320050149
2014-07-13 23:40:52,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:52,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59355 synced till here 59352
2014-07-13 23:40:52,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320050149 with entries=73, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320052340
2014-07-13 23:40:53,738 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:53,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59416 synced till here 59414
2014-07-13 23:40:53,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320052340 with entries=61, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320053739
2014-07-13 23:40:54,387 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19467, memsize=253.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d00e04e951c24932b473dbddb32a1953
2014-07-13 23:40:54,399 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d00e04e951c24932b473dbddb32a1953 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d00e04e951c24932b473dbddb32a1953
2014-07-13 23:40:54,412 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d00e04e951c24932b473dbddb32a1953, entries=923230, sequenceid=19467, filesize=65.8m
2014-07-13 23:40:54,412 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~507.9m/532595360, currentsize=215.2m/225690800 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 14082ms, sequenceid=19467, compaction requested=true
2014-07-13 23:40:54,413 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:103), split_queue=0, merge_queue=0
2014-07-13 23:40:54,413 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 836.9m
2014-07-13 23:40:54,990 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:55,367 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59507 synced till here 59501
2014-07-13 23:40:55,450 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320053739 with entries=91, filesize=95.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320054990
2014-07-13 23:40:55,454 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:40:56,749 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:56,756 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:40:56,772 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59574 synced till here 59570
2014-07-13 23:40:56,816 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320054990 with entries=67, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320056749
2014-07-13 23:40:58,429 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:40:58,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59644 synced till here 59642
2014-07-13 23:40:58,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320056749 with entries=70, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320058429
2014-07-13 23:40:59,071 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13083, memsize=401.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/b68278556ff14ef2b6a0ece08f316071
2014-07-13 23:40:59,086 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/b68278556ff14ef2b6a0ece08f316071 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/b68278556ff14ef2b6a0ece08f316071
2014-07-13 23:40:59,097 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/b68278556ff14ef2b6a0ece08f316071, entries=1462950, sequenceid=13083, filesize=104.1m
2014-07-13 23:40:59,097 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~993.9m/1042194240, currentsize=550.3m/577032400 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 25501ms, sequenceid=13083, compaction requested=true
2014-07-13 23:40:59,098 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:104), split_queue=0, merge_queue=0
2014-07-13 23:40:59,098 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 711.6m
2014-07-13 23:40:59,128 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:40:59,683 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:40:59,805 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:00,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320058429 with entries=80, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320059805
2014-07-13 23:41:00,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319971230
2014-07-13 23:41:00,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319972568
2014-07-13 23:41:00,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319974363
2014-07-13 23:41:00,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319976202
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319978671
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319980184
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319981638
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319983592
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319985273
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319986769
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319988177
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319991613
2014-07-13 23:41:00,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319993936
2014-07-13 23:41:00,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319996630
2014-07-13 23:41:00,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405319998623
2014-07-13 23:41:00,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320000515
2014-07-13 23:41:01,519 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:01,564 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320059805 with entries=65, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320061519
2014-07-13 23:41:02,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:03,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59874 synced till here 59870
2014-07-13 23:41:03,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320061519 with entries=85, filesize=80.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320062781
2014-07-13 23:41:04,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:04,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59951 synced till here 59940
2014-07-13 23:41:04,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320062781 with entries=77, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320064297
2014-07-13 23:41:06,395 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:06,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60037 synced till here 60022
2014-07-13 23:41:07,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320064297 with entries=86, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320066396
2014-07-13 23:41:09,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:09,499 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60165 synced till here 60136
2014-07-13 23:41:09,755 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320066396 with entries=128, filesize=90.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320069433
2014-07-13 23:41:11,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:11,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60275 synced till here 60252
2014-07-13 23:41:12,081 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320069433 with entries=110, filesize=84.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320071593
2014-07-13 23:41:14,307 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:14,341 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60383 synced till here 60370
2014-07-13 23:41:14,445 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320071593 with entries=108, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320074307
2014-07-13 23:41:16,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:16,317 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60478 synced till here 60477
2014-07-13 23:41:16,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320074307 with entries=95, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320076272
2014-07-13 23:41:17,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:17,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60548 synced till here 60546
2014-07-13 23:41:17,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320076272 with entries=70, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320077582
2014-07-13 23:41:18,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:18,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60619 synced till here 60615
2014-07-13 23:41:19,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320077582 with entries=71, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320078923
2014-07-13 23:41:20,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:20,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60688 synced till here 60686
2014-07-13 23:41:20,781 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,782 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,792 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,800 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,803 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,809 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320078923 with entries=69, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320080740
2014-07-13 23:41:20,833 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,838 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,851 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,869 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,901 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,904 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,904 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,905 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,919 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,920 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,940 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:20,976 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,007 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,031 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,036 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,037 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,069 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,097 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,097 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:41:21,961 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13309, memsize=474.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/82fea14ff36442259b0283555d30c645
2014-07-13 23:41:21,975 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/82fea14ff36442259b0283555d30c645 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/82fea14ff36442259b0283555d30c645
2014-07-13 23:41:21,989 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/82fea14ff36442259b0283555d30c645, entries=1726320, sequenceid=13309, filesize=122.9m
2014-07-13 23:41:21,989 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~841.0m/881802240, currentsize=533.4m/559279040 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 27576ms, sequenceid=13309, compaction requested=true
2014-07-13 23:41:21,990 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:105), split_queue=0, merge_queue=0
2014-07-13 23:41:21,990 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 893ms
2014-07-13 23:41:21,990 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,990 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 596.2m
2014-07-13 23:41:21,990 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 893ms
2014-07-13 23:41:21,990 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,990 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 921ms
2014-07-13 23:41:21,990 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,990 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 953ms
2014-07-13 23:41:21,990 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,992 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 956ms
2014-07-13 23:41:21,992 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,995 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 964ms
2014-07-13 23:41:21,995 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,995 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 989ms
2014-07-13 23:41:21,995 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,995 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1019ms
2014-07-13 23:41:21,995 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,995 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1056ms
2014-07-13 23:41:21,995 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,997 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1077ms
2014-07-13 23:41:21,997 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,997 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1078ms
2014-07-13 23:41:21,997 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,997 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1092ms
2014-07-13 23:41:21,997 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,997 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1093ms
2014-07-13 23:41:21,997 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,997 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1093ms
2014-07-13 23:41:21,997 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,998 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1098ms
2014-07-13 23:41:21,998 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:21,999 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1130ms
2014-07-13 23:41:21,999 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,003 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1152ms
2014-07-13 23:41:22,004 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,004 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1166ms
2014-07-13 23:41:22,004 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,004 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1171ms
2014-07-13 23:41:22,004 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,006 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1203ms
2014-07-13 23:41:22,006 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,009 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1209ms
2014-07-13 23:41:22,009 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,009 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1218ms
2014-07-13 23:41:22,009 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,009 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1227ms
2014-07-13 23:41:22,009 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,009 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1228ms
2014-07-13 23:41:22,009 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:41:22,150 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:41:23,185 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:41:23,436 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:23,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60771 synced till here 60757
2014-07-13 23:41:23,596 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320080740 with entries=83, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320083437
2014-07-13 23:41:23,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320002273
2014-07-13 23:41:23,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320007015
2014-07-13 23:41:23,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320008556
2014-07-13 23:41:23,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320010324
2014-07-13 23:41:23,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320011844
2014-07-13 23:41:23,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320013747
2014-07-13 23:41:23,974 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13367, memsize=414.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/971dcc1d03bc4b1ba0b183311ddd0dfd
2014-07-13 23:41:23,987 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/971dcc1d03bc4b1ba0b183311ddd0dfd as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/971dcc1d03bc4b1ba0b183311ddd0dfd
2014-07-13 23:41:23,998 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/971dcc1d03bc4b1ba0b183311ddd0dfd, entries=1508810, sequenceid=13367, filesize=107.4m
2014-07-13 23:41:23,998 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~715.1m/749788400, currentsize=473.7m/496752000 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 24900ms, sequenceid=13367, compaction requested=true
2014-07-13 23:41:23,999 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:106), split_queue=0, merge_queue=0
2014-07-13 23:41:23,999 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1.0g
2014-07-13 23:41:23,999 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:41:24,628 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/98f9a2c0ca114349bded9a4a1a7d4125 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/98f9a2c0ca114349bded9a4a1a7d4125
2014-07-13 23:41:24,719 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:24,725 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:41:24,738 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6a490cbbe6df4a2d99043a4e818dde56, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6a490cbbe6df4a2d99043a4e818dde56
2014-07-13 23:41:24,740 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60835 synced till here 60833
2014-07-13 23:41:24,743 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4cef371056b847b996708d6bbbd17ccb, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4cef371056b847b996708d6bbbd17ccb
2014-07-13 23:41:24,749 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/36222186b3c940f2a9e5a52c194e48bf, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/36222186b3c940f2a9e5a52c194e48bf
2014-07-13 23:41:24,759 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/5f13fd98fa1e478fa50ea4de5b9cd958, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/5f13fd98fa1e478fa50ea4de5b9cd958
2014-07-13 23:41:24,768 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/87d8f0459c6640f79bc6b9422203b12c, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/87d8f0459c6640f79bc6b9422203b12c
2014-07-13 23:41:24,768 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320083437 with entries=64, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320084720
2014-07-13 23:41:24,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320015424
2014-07-13 23:41:24,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320017281
2014-07-13 23:41:24,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320019118
2014-07-13 23:41:24,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320020315
2014-07-13 23:41:24,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320021634
2014-07-13 23:41:24,770 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c5936faaf1e54fce81e4c7998ad18b73, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/c5936faaf1e54fce81e4c7998ad18b73
2014-07-13 23:41:24,775 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4d127bb2abac4b0da42605efe8af252f, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4d127bb2abac4b0da42605efe8af252f
2014-07-13 23:41:24,778 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6b0d5830c1314c91930b9f979d3f1be4, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6b0d5830c1314c91930b9f979d3f1be4
2014-07-13 23:41:24,780 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/de4a2630463b450187c6397a117a3fae, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/de4a2630463b450187c6397a117a3fae
2014-07-13 23:41:24,784 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/3b1052cfc90f4858b7c64ab91e966d22, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/3b1052cfc90f4858b7c64ab91e966d22
2014-07-13 23:41:24,784 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into 98f9a2c0ca114349bded9a4a1a7d4125(size=970.7m), total size for store is 3.0g. This selection was in queue for 0sec, and took 3mins, 55sec to execute.
2014-07-13 23:41:24,784 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., storeName=family, fileCount=10, fileSize=1.1g, priority=4, time=273756837709204; duration=3mins, 55sec
2014-07-13 23:41:24,784 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:106), split_queue=0, merge_queue=0
2014-07-13 23:41:24,784 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-13 23:41:24,788 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 218592607 starting at candidate #15 after considering 116 permutations with 103 in ratio
2014-07-13 23:41:24,788 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 8b827125b32700e6f7c5c34f77be22cb - family: Initiating minor compaction
2014-07-13 23:41:24,788 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:41:24,788 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp, totalSize=208.5m
2014-07-13 23:41:24,788 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4110885abd8c4d17a5cf8f36ac425330, keycount=70502, bloomtype=ROW, size=50.3m, encoding=NONE, seqNum=11326
2014-07-13 23:41:24,789 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/eef1a53948634ccba01ecb6fc05625ac, keycount=107720, bloomtype=ROW, size=76.7m, encoding=NONE, seqNum=11641
2014-07-13 23:41:24,789 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/55363b75d51341e9ab519b93286288ca, keycount=114396, bloomtype=ROW, size=81.5m, encoding=NONE, seqNum=12103
2014-07-13 23:41:24,871 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:41:25,493 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:41:26,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:26,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60938 synced till here 60937
2014-07-13 23:41:26,273 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320084720 with entries=103, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320086128
2014-07-13 23:41:32,501 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:32,530 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61010 synced till here 61007
2014-07-13 23:41:32,572 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320086128 with entries=72, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320092502
2014-07-13 23:41:33,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:34,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61079 synced till here 61073
2014-07-13 23:41:34,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320092502 with entries=69, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320093843
2014-07-13 23:41:39,106 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20013, memsize=471.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/adb2d50db6394eb6ba10843f27fea429
2014-07-13 23:41:39,117 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/adb2d50db6394eb6ba10843f27fea429 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/adb2d50db6394eb6ba10843f27fea429
2014-07-13 23:41:39,128 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/adb2d50db6394eb6ba10843f27fea429, entries=1715900, sequenceid=20013, filesize=122.1m
2014-07-13 23:41:39,128 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~596.2m/625155440, currentsize=124.0m/129990320 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 17138ms, sequenceid=20013, compaction requested=true
2014-07-13 23:41:39,128 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:106), split_queue=0, merge_queue=0
2014-07-13 23:41:39,129 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 710.2m
2014-07-13 23:41:39,677 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:41:40,959 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:40,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61157 synced till here 61156
2014-07-13 23:41:40,994 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320093843 with entries=78, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320100959
2014-07-13 23:41:43,782 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:43,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61229 synced till here 61228
2014-07-13 23:41:43,846 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320100959 with entries=72, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320103782
2014-07-13 23:41:45,569 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13641, memsize=516.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/fa2182e839b44420885650737a1585e2
2014-07-13 23:41:45,587 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/fa2182e839b44420885650737a1585e2 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/fa2182e839b44420885650737a1585e2
2014-07-13 23:41:45,599 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/fa2182e839b44420885650737a1585e2, entries=1879250, sequenceid=13641, filesize=133.7m
2014-07-13 23:41:45,599 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.0g/1086357520, currentsize=190.8m/200089680 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 21600ms, sequenceid=13641, compaction requested=true
2014-07-13 23:41:45,599 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:107), split_queue=0, merge_queue=0
2014-07-13 23:41:45,600 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 675.9m
2014-07-13 23:41:45,608 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:45,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61316 synced till here 61310
2014-07-13 23:41:45,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320103782 with entries=87, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320105608
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320023538
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320034868
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320036960
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320039799
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320042047
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320043514
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320045618
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320047048
2014-07-13 23:41:45,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320048587
2014-07-13 23:41:45,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320050149
2014-07-13 23:41:45,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320052340
2014-07-13 23:41:46,322 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:41:46,545 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:46,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320105608 with entries=62, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320106545
2014-07-13 23:41:48,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:48,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320106545 with entries=66, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320108424
2014-07-13 23:41:48,894 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:41:49,688 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:41:50,837 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:50,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61528 synced till here 61517
2014-07-13 23:41:50,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320108424 with entries=84, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320110837
2014-07-13 23:41:52,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:53,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61606 synced till here 61603
2014-07-13 23:41:53,092 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320110837 with entries=78, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320112849
2014-07-13 23:41:54,794 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/ee91bac3350946fdbab4687fada0737f as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ee91bac3350946fdbab4687fada0737f
2014-07-13 23:41:54,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:54,828 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:41:54,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61681 synced till here 61679
2014-07-13 23:41:54,884 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4110885abd8c4d17a5cf8f36ac425330, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4110885abd8c4d17a5cf8f36ac425330
2014-07-13 23:41:54,901 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/eef1a53948634ccba01ecb6fc05625ac, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/eef1a53948634ccba01ecb6fc05625ac
2014-07-13 23:41:54,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320112849 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320114818
2014-07-13 23:41:54,911 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/55363b75d51341e9ab519b93286288ca, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/55363b75d51341e9ab519b93286288ca
2014-07-13 23:41:54,911 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into ee91bac3350946fdbab4687fada0737f(size=185.1m), total size for store is 3.1g. This selection was in queue for 0sec, and took 30sec to execute.
2014-07-13 23:41:54,912 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., storeName=family, fileCount=3, fileSize=208.5m, priority=0, time=273992215129564; duration=30sec
2014-07-13 23:41:54,912 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:107), split_queue=0, merge_queue=0
2014-07-13 23:41:54,912 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-13 23:41:54,915 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1005989410 starting at candidate #5 after considering 100 permutations with 93 in ratio
2014-07-13 23:41:54,915 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: baaed08b3b283bc33b53e718e07d0f23 - family: Initiating minor compaction
2014-07-13 23:41:54,915 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:41:54,916 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp, totalSize=959.4m
2014-07-13 23:41:54,916 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/4ace3abab2a54ff3bf581a78f1a5b1e7, keycount=142225, bloomtype=ROW, size=101.3m, encoding=NONE, seqNum=12040
2014-07-13 23:41:54,916 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5b74449f3f5b4ce787f72cb82e473fd0, keycount=103925, bloomtype=ROW, size=73.9m, encoding=NONE, seqNum=12740
2014-07-13 23:41:54,916 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1618333d4f844e37b9830c98f0f426a3, keycount=161143, bloomtype=ROW, size=114.6m, encoding=NONE, seqNum=13359
2014-07-13 23:41:54,916 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d5adeca2d3ab4173bb1725eb80b9c508, keycount=121321, bloomtype=ROW, size=86.4m, encoding=NONE, seqNum=14004
2014-07-13 23:41:54,916 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/8dafd496f34245b5a05f6418789592bd, keycount=178528, bloomtype=ROW, size=127.1m, encoding=NONE, seqNum=14706
2014-07-13 23:41:54,916 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/11aa92889cdb4286942fc336b8f3ade9, keycount=97818, bloomtype=ROW, size=69.7m, encoding=NONE, seqNum=15259
2014-07-13 23:41:54,916 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d33ad8187a3b40d697540269a5146055, keycount=137910, bloomtype=ROW, size=98.2m, encoding=NONE, seqNum=15892
2014-07-13 23:41:54,917 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/01232ff87b594bc28747b91ff2943f66, keycount=138716, bloomtype=ROW, size=98.8m, encoding=NONE, seqNum=16851
2014-07-13 23:41:54,917 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/cced37c3e00344e0ae9fbbd4c844b5b9, keycount=157670, bloomtype=ROW, size=112.3m, encoding=NONE, seqNum=17460
2014-07-13 23:41:54,917 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f7a4cc6b7826443aae565c150a69bb2c, keycount=108091, bloomtype=ROW, size=77.0m, encoding=NONE, seqNum=18062
2014-07-13 23:41:55,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:55,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61754 synced till here 61751
2014-07-13 23:41:55,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320114818 with entries=73, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320115566
2014-07-13 23:41:55,885 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:41:56,170 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13727, memsize=395.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/ac4fc86e4cdc45d58ebfcc476555455f
2014-07-13 23:41:56,181 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/ac4fc86e4cdc45d58ebfcc476555455f as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ac4fc86e4cdc45d58ebfcc476555455f
2014-07-13 23:41:56,189 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ac4fc86e4cdc45d58ebfcc476555455f, entries=1439490, sequenceid=13727, filesize=102.5m
2014-07-13 23:41:56,189 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~710.2m/744682160, currentsize=259.3m/271870560 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 17061ms, sequenceid=13727, compaction requested=true
2014-07-13 23:41:56,189 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:107), split_queue=0, merge_queue=0
2014-07-13 23:41:56,190 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 372.8m
2014-07-13 23:41:56,259 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:41:56,396 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:41:57,286 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:41:57,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61865 synced till here 61863
2014-07-13 23:41:57,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320115566 with entries=111, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320117287
2014-07-13 23:41:57,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320053739
2014-07-13 23:41:57,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320054990
2014-07-13 23:41:57,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320056749
2014-07-13 23:42:00,235 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:00,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320117287 with entries=82, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320120235
2014-07-13 23:42:02,217 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13782, memsize=387.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f4aa2dfb4403487fa030b3479ed739a1
2014-07-13 23:42:02,235 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f4aa2dfb4403487fa030b3479ed739a1 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f4aa2dfb4403487fa030b3479ed739a1
2014-07-13 23:42:02,249 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f4aa2dfb4403487fa030b3479ed739a1, entries=1410450, sequenceid=13782, filesize=100.5m
2014-07-13 23:42:02,250 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~677.6m/710538960, currentsize=275.9m/289258720 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 16650ms, sequenceid=13782, compaction requested=true
2014-07-13 23:42:02,250 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-13 23:42:02,250 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 467.4m
2014-07-13 23:42:02,393 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:42:02,473 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:02,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62019 synced till here 62018
2014-07-13 23:42:02,536 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320120235 with entries=72, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320122474
2014-07-13 23:42:02,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320058429
2014-07-13 23:42:02,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320059805
2014-07-13 23:42:02,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320061519
2014-07-13 23:42:02,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320062781
2014-07-13 23:42:02,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320064297
2014-07-13 23:42:02,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320066396
2014-07-13 23:42:02,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320069433
2014-07-13 23:42:02,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320071593
2014-07-13 23:42:02,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320074307
2014-07-13 23:42:02,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320076272
2014-07-13 23:42:02,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320077582
2014-07-13 23:42:02,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320078923
2014-07-13 23:42:02,650 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:42:03,993 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:04,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320122474 with entries=90, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320123994
2014-07-13 23:42:07,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:07,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62204 synced till here 62198
2014-07-13 23:42:07,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320123994 with entries=95, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320127141
2014-07-13 23:42:09,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:09,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62268 synced till here 62265
2014-07-13 23:42:09,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320127141 with entries=64, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320129372
2014-07-13 23:42:10,717 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20226, memsize=362.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/fdb6f6dcf615494783b59678c0038869
2014-07-13 23:42:10,729 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/fdb6f6dcf615494783b59678c0038869 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/fdb6f6dcf615494783b59678c0038869
2014-07-13 23:42:10,747 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/fdb6f6dcf615494783b59678c0038869, entries=1320260, sequenceid=20226, filesize=94.0m
2014-07-13 23:42:10,747 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~372.8m/390893760, currentsize=201.9m/211711200 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 14557ms, sequenceid=20226, compaction requested=true
2014-07-13 23:42:10,747 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:109), split_queue=0, merge_queue=0
2014-07-13 23:42:10,748 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 453.6m
2014-07-13 23:42:11,072 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:42:11,100 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:11,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62353 synced till here 62349
2014-07-13 23:42:11,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320129372 with entries=85, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320131100
2014-07-13 23:42:11,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320080740
2014-07-13 23:42:13,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:13,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320131100 with entries=65, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320133206
2014-07-13 23:42:14,639 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:42:15,267 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:15,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62505 synced till here 62504
2014-07-13 23:42:15,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320133206 with entries=87, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320135268
2014-07-13 23:42:18,962 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:19,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62577 synced till here 62574
2014-07-13 23:42:19,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320135268 with entries=72, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320138962
2014-07-13 23:42:20,412 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:20,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62651 synced till here 62648
2014-07-13 23:42:20,487 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320138962 with entries=74, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320140412
2014-07-13 23:42:21,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:21,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62724 synced till here 62714
2014-07-13 23:42:21,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320140412 with entries=73, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320141623
2014-07-13 23:42:21,827 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13959, memsize=463.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/767f3e243a904be6955123133a84b7c0
2014-07-13 23:42:21,842 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/767f3e243a904be6955123133a84b7c0 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/767f3e243a904be6955123133a84b7c0
2014-07-13 23:42:22,003 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/767f3e243a904be6955123133a84b7c0, entries=1686920, sequenceid=13959, filesize=120.1m
2014-07-13 23:42:22,003 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~467.4m/490105120, currentsize=294.4m/308671040 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 19753ms, sequenceid=13959, compaction requested=true
2014-07-13 23:42:22,004 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:110), split_queue=0, merge_queue=0
2014-07-13 23:42:22,004 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 565.7m
2014-07-13 23:42:22,089 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:42:22,440 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:42:23,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:23,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62797 synced till here 62792
2014-07-13 23:42:23,599 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320141623 with entries=73, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320143453
2014-07-13 23:42:23,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320083437
2014-07-13 23:42:23,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320084720
2014-07-13 23:42:23,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320086128
2014-07-13 23:42:23,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320092502
2014-07-13 23:42:25,028 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:25,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62872 synced till here 62864
2014-07-13 23:42:25,176 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320143453 with entries=75, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320145028
2014-07-13 23:42:26,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:26,503 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62952 synced till here 62949
2014-07-13 23:42:26,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320145028 with entries=80, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320146328
2014-07-13 23:42:28,158 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14040, memsize=452.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/403a657bfabb411e8368dd335514c174
2014-07-13 23:42:28,173 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/403a657bfabb411e8368dd335514c174 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/403a657bfabb411e8368dd335514c174
2014-07-13 23:42:28,193 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/403a657bfabb411e8368dd335514c174, entries=1646200, sequenceid=14040, filesize=117.1m
2014-07-13 23:42:28,197 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~456.0m/478174240, currentsize=279.4m/292977760 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 17449ms, sequenceid=14040, compaction requested=true
2014-07-13 23:42:28,197 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:111), split_queue=0, merge_queue=0
2014-07-13 23:42:28,198 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 498.4m
2014-07-13 23:42:28,203 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:42:28,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:28,914 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:42:29,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63038 synced till here 63024
2014-07-13 23:42:29,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320146328 with entries=86, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320148751
2014-07-13 23:42:29,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320093843
2014-07-13 23:42:29,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320100959
2014-07-13 23:42:29,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320103782
2014-07-13 23:42:31,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:31,408 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320148751 with entries=65, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320151341
2014-07-13 23:42:34,054 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:34,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63192 synced till here 63173
2014-07-13 23:42:34,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320151341 with entries=89, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320154054
2014-07-13 23:42:35,741 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:35,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63277 synced till here 63263
2014-07-13 23:42:35,929 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320154054 with entries=85, filesize=85.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320155742
2014-07-13 23:42:37,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:37,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63341 synced till here 63336
2014-07-13 23:42:37,399 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320155742 with entries=64, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320157018
2014-07-13 23:42:38,682 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:38,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63450 synced till here 63430
2014-07-13 23:42:38,987 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320157018 with entries=109, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320158682
2014-07-13 23:42:40,742 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:41,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63570 synced till here 63565
2014-07-13 23:42:41,118 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320158682 with entries=120, filesize=106.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320160742
2014-07-13 23:42:43,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:43,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63713 synced till here 63685
2014-07-13 23:42:43,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320160742 with entries=143, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320163005
2014-07-13 23:42:44,576 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:44,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63801 synced till here 63779
2014-07-13 23:42:45,525 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320163005 with entries=88, filesize=81.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320164578
2014-07-13 23:42:46,583 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:47,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63873 synced till here 63861
2014-07-13 23:42:47,311 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320164578 with entries=72, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320166584
2014-07-13 23:42:48,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:48,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63938 synced till here 63930
2014-07-13 23:42:48,798 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320166584 with entries=65, filesize=71.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320168277
2014-07-13 23:42:49,668 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:49,684 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14155, memsize=567.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/19bcac4114e04bd6aefd1998543c74de
2014-07-13 23:42:49,697 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/19bcac4114e04bd6aefd1998543c74de as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/19bcac4114e04bd6aefd1998543c74de
2014-07-13 23:42:50,058 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/19bcac4114e04bd6aefd1998543c74de, entries=2065330, sequenceid=14155, filesize=146.9m
2014-07-13 23:42:50,059 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~571.3m/599011920, currentsize=562.8m/590146320 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 28055ms, sequenceid=14155, compaction requested=true
2014-07-13 23:42:50,059 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:112), split_queue=0, merge_queue=0
2014-07-13 23:42:50,060 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 858.2m
2014-07-13 23:42:50,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320168277 with entries=64, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320169668
2014-07-13 23:42:50,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320105608
2014-07-13 23:42:50,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320106545
2014-07-13 23:42:50,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320108424
2014-07-13 23:42:50,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320110837
2014-07-13 23:42:50,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320112849
2014-07-13 23:42:50,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320114818
2014-07-13 23:42:50,245 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:42:50,828 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:50,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64079 synced till here 64075
2014-07-13 23:42:50,882 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:42:50,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320169668 with entries=77, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320170828
2014-07-13 23:42:52,782 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:52,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64147 synced till here 64144
2014-07-13 23:42:53,125 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20500, memsize=502.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/273b9fac7e2b48e1b9d89a8807a5a269
2014-07-13 23:42:53,145 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/273b9fac7e2b48e1b9d89a8807a5a269 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/273b9fac7e2b48e1b9d89a8807a5a269
2014-07-13 23:42:53,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320170828 with entries=68, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320172782
2014-07-13 23:42:53,162 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/273b9fac7e2b48e1b9d89a8807a5a269, entries=1830090, sequenceid=20500, filesize=130.3m
2014-07-13 23:42:53,163 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~502.6m/527051280, currentsize=316.7m/332089360 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 24965ms, sequenceid=20500, compaction requested=true
2014-07-13 23:42:53,163 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:113), split_queue=0, merge_queue=0
2014-07-13 23:42:53,163 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 813.1m
2014-07-13 23:42:53,215 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:42:53,838 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:53,855 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64210 synced till here 64208
2014-07-13 23:42:53,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320172782 with entries=63, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320173839
2014-07-13 23:42:53,884 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320115566
2014-07-13 23:42:53,884 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320117287
2014-07-13 23:42:53,945 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:42:56,589 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:42:56,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320173839 with entries=107, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320176590
2014-07-13 23:43:00,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:00,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64436 synced till here 64431
2014-07-13 23:43:00,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320176590 with entries=119, filesize=102.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320180243
2014-07-13 23:43:02,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:02,086 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64512 synced till here 64509
2014-07-13 23:43:02,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320180243 with entries=76, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320182018
2014-07-13 23:43:03,757 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:04,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64591 synced till here 64588
2014-07-13 23:43:04,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320182018 with entries=79, filesize=84.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320183757
2014-07-13 23:43:06,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:06,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64674 synced till here 64673
2014-07-13 23:43:06,788 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320183757 with entries=83, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320186746
2014-07-13 23:43:10,413 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:10,437 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64741 synced till here 64732
2014-07-13 23:43:10,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320186746 with entries=67, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320190414
2014-07-13 23:43:11,754 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:11,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64811 synced till here 64810
2014-07-13 23:43:11,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320190414 with entries=70, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320191754
2014-07-13 23:43:13,241 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14449, memsize=595.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/211048af07614e2195f48776c42a99f8
2014-07-13 23:43:13,260 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/211048af07614e2195f48776c42a99f8 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/211048af07614e2195f48776c42a99f8
2014-07-13 23:43:13,277 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/211048af07614e2195f48776c42a99f8, entries=2168220, sequenceid=14449, filesize=154.4m
2014-07-13 23:43:13,278 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~862.7m/904625920, currentsize=346.1m/362902480 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 23219ms, sequenceid=14449, compaction requested=true
2014-07-13 23:43:13,278 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:114), split_queue=0, merge_queue=0
2014-07-13 23:43:13,279 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 912.9m
2014-07-13 23:43:14,035 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:43:14,058 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14481, memsize=537.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/ac9723a780d94f869b004378c4c96e11
2014-07-13 23:43:14,069 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/ac9723a780d94f869b004378c4c96e11 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ac9723a780d94f869b004378c4c96e11
2014-07-13 23:43:14,080 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ac9723a780d94f869b004378c4c96e11, entries=1957410, sequenceid=14481, filesize=139.4m
2014-07-13 23:43:14,080 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~820.1m/859909040, currentsize=273.0m/286312880 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 20917ms, sequenceid=14481, compaction requested=true
2014-07-13 23:43:14,081 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:115), split_queue=0, merge_queue=0
2014-07-13 23:43:14,081 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 554.8m
2014-07-13 23:43:14,395 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:43:22,624 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:43:22,753 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:43:24,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:24,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64892 synced till here 64891
2014-07-13 23:43:24,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320191754 with entries=81, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320204723
2014-07-13 23:43:24,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320120235
2014-07-13 23:43:24,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320122474
2014-07-13 23:43:24,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320123994
2014-07-13 23:43:24,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320127141
2014-07-13 23:43:24,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320129372
2014-07-13 23:43:24,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320131100
2014-07-13 23:43:24,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320133206
2014-07-13 23:43:24,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320135268
2014-07-13 23:43:24,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320138962
2014-07-13 23:43:24,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320140412
2014-07-13 23:43:26,017 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:26,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64965 synced till here 64961
2014-07-13 23:43:26,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320204723 with entries=73, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320206018
2014-07-13 23:43:27,327 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:27,489 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65040 synced till here 65038
2014-07-13 23:43:27,504 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320206018 with entries=75, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320207328
2014-07-13 23:43:28,686 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:28,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65107 synced till here 65105
2014-07-13 23:43:28,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320207328 with entries=67, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320208687
2014-07-13 23:43:29,956 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:29,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320208687 with entries=79, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320209956
2014-07-13 23:43:30,584 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20988, memsize=491.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/e9823fe886fd42cdafdfbb0781564494
2014-07-13 23:43:30,596 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/e9823fe886fd42cdafdfbb0781564494 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/e9823fe886fd42cdafdfbb0781564494
2014-07-13 23:43:30,612 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/e9823fe886fd42cdafdfbb0781564494, entries=1789640, sequenceid=20988, filesize=127.4m
2014-07-13 23:43:30,612 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~554.8m/581738960, currentsize=175.5m/184075840 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 16531ms, sequenceid=20988, compaction requested=true
2014-07-13 23:43:30,613 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:116), split_queue=0, merge_queue=0
2014-07-13 23:43:30,613 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. has too many store files; delaying flush up to 90000ms
2014-07-13 23:43:30,613 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:117), split_queue=0, merge_queue=0
2014-07-13 23:43:30,613 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files; delaying flush up to 90000ms
2014-07-13 23:43:30,613 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:118), split_queue=0, merge_queue=0
2014-07-13 23:43:30,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:31,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320209956 with entries=63, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320210931
2014-07-13 23:43:32,642 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:32,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65316 synced till here 65312
2014-07-13 23:43:32,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320210931 with entries=67, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320212642
2014-07-13 23:43:36,007 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14676, memsize=620.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4fce08de9e964dd0bfa7fccaa5734f52
2014-07-13 23:43:36,026 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4fce08de9e964dd0bfa7fccaa5734f52 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4fce08de9e964dd0bfa7fccaa5734f52
2014-07-13 23:43:36,038 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4fce08de9e964dd0bfa7fccaa5734f52, entries=2259510, sequenceid=14676, filesize=160.9m
2014-07-13 23:43:36,038 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~912.9m/957282880, currentsize=214.0m/224402480 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 22759ms, sequenceid=14676, compaction requested=true
2014-07-13 23:43:36,038 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:119), split_queue=0, merge_queue=0
2014-07-13 23:43:46,894 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:46,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65404 synced till here 65403
2014-07-13 23:43:47,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320212642 with entries=88, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320226895
2014-07-13 23:43:47,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320141623
2014-07-13 23:43:47,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320143453
2014-07-13 23:43:47,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320145028
2014-07-13 23:43:47,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320146328
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320148751
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320151341
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320154054
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320155742
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320157018
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320158682
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320160742
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320163005
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320164578
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320166584
2014-07-13 23:43:47,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320168277
2014-07-13 23:43:48,465 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:43:48,465 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. has too many store files; delaying flush up to 90000ms
2014-07-13 23:43:48,465 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-13 23:43:48,956 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:49,615 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65473 synced till here 65471
2014-07-13 23:43:49,643 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320226895 with entries=69, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320228956
2014-07-13 23:43:49,793 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:43:49,793 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 256.3m
2014-07-13 23:43:50,004 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:43:50,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:50,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320228956 with entries=61, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320230372
2014-07-13 23:43:51,927 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:52,570 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65624 synced till here 65619
2014-07-13 23:43:52,612 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320230372 with entries=90, filesize=89.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320231927
2014-07-13 23:43:53,595 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:54,132 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65695 synced till here 65689
2014-07-13 23:43:54,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320231927 with entries=71, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320233595
2014-07-13 23:43:56,871 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:57,013 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65774 synced till here 65772
2014-07-13 23:43:57,026 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320233595 with entries=79, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320236871
2014-07-13 23:43:58,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:43:58,391 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65839 synced till here 65835
2014-07-13 23:43:58,446 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320236871 with entries=65, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320238292
2014-07-13 23:43:59,909 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:00,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65917 synced till here 65907
2014-07-13 23:44:00,059 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14833, memsize=260.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/9932a12bdc964b3da5f65e4256630a91
2014-07-13 23:44:00,071 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/9932a12bdc964b3da5f65e4256630a91 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/9932a12bdc964b3da5f65e4256630a91
2014-07-13 23:44:00,094 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320238292 with entries=78, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320239910
2014-07-13 23:44:00,105 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/9932a12bdc964b3da5f65e4256630a91, entries=946680, sequenceid=14833, filesize=67.4m
2014-07-13 23:44:00,106 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.0m/272634960, currentsize=195.6m/205067920 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 10313ms, sequenceid=14833, compaction requested=true
2014-07-13 23:44:00,107 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:121), split_queue=0, merge_queue=0
2014-07-13 23:44:02,042 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:02,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65987 synced till here 65986
2014-07-13 23:44:02,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320239910 with entries=70, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320242042
2014-07-13 23:44:08,145 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:44:08,146 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 257.2m
2014-07-13 23:44:08,287 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:44:08,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:08,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66068 synced till here 66066
2014-07-13 23:44:09,070 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320242042 with entries=81, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320248651
2014-07-13 23:44:10,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:10,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66131 synced till here 66129
2014-07-13 23:44:10,391 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320248651 with entries=63, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320250311
2014-07-13 23:44:11,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:11,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66205 synced till here 66201
2014-07-13 23:44:12,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320250311 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320251960
2014-07-13 23:44:13,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:13,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66268 synced till here 66263
2014-07-13 23:44:13,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320251960 with entries=63, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320253583
2014-07-13 23:44:15,413 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:15,459 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320253583 with entries=69, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320255414
2014-07-13 23:44:17,084 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14979, memsize=215.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/6163ca57b5874f8eba34c0db79bff3b1
2014-07-13 23:44:17,102 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/6163ca57b5874f8eba34c0db79bff3b1 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6163ca57b5874f8eba34c0db79bff3b1
2014-07-13 23:44:17,116 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6163ca57b5874f8eba34c0db79bff3b1, entries=784310, sequenceid=14979, filesize=55.9m
2014-07-13 23:44:17,117 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.2m/269661280, currentsize=124.7m/130757360 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 8971ms, sequenceid=14979, compaction requested=true
2014-07-13 23:44:17,117 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:122), split_queue=0, merge_queue=0
2014-07-13 23:44:17,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:17,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66412 synced till here 66410
2014-07-13 23:44:17,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320255414 with entries=75, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320257759
2014-07-13 23:44:19,134 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:19,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66480 synced till here 66476
2014-07-13 23:44:19,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320257759 with entries=68, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320259135
2014-07-13 23:44:19,220 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:20,633 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:20,660 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320259135 with entries=61, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320260633
2014-07-13 23:44:20,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:22,015 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:22,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320260633 with entries=92, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320262015
2014-07-13 23:44:22,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:23,120 DEBUG [LruStats #0] hfile.LruBlockCache: Total=5.86 MB, free=3.95 GB, max=3.96 GB, blocks=19, accesses=388382, hits=131873, hitRatio=33.95%, , cachingAccesses=131922, cachingHits=131822, cachingHitsRatio=99.92%, evictions=0, evicted=81, evictedPerRun=Infinity
2014-07-13 23:44:25,613 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:44:25,614 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 256.5m
2014-07-13 23:44:25,832 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:44:26,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:26,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66707 synced till here 66705
2014-07-13 23:44:26,229 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320262015 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320266168
2014-07-13 23:44:26,231 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:27,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:27,562 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320266168 with entries=65, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320267532
2014-07-13 23:44:27,562 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:28,782 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:28,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66843 synced till here 66842
2014-07-13 23:44:28,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320267532 with entries=71, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320268782
2014-07-13 23:44:28,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:31,038 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:31,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66916 synced till here 66911
2014-07-13 23:44:31,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320268782 with entries=73, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320271038
2014-07-13 23:44:31,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:32,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:32,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67002 synced till here 66999
2014-07-13 23:44:32,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320271038 with entries=86, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320272358
2014-07-13 23:44:32,410 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:34,400 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15147, memsize=243.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/b9df96caf20b4891bb85b0720a880f10
2014-07-13 23:44:34,414 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/b9df96caf20b4891bb85b0720a880f10 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b9df96caf20b4891bb85b0720a880f10
2014-07-13 23:44:34,430 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b9df96caf20b4891bb85b0720a880f10, entries=887450, sequenceid=15147, filesize=63.2m
2014-07-13 23:44:34,431 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.8m/271334880, currentsize=149.4m/156702880 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 8817ms, sequenceid=15147, compaction requested=true
2014-07-13 23:44:34,431 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-13 23:44:35,427 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:35,489 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320272358 with entries=71, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320275428
2014-07-13 23:44:35,490 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:35,580 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/a3112caf5ef34d3bb1b249eb164aa827 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/a3112caf5ef34d3bb1b249eb164aa827
2014-07-13 23:44:35,610 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:44:35,650 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/4ace3abab2a54ff3bf581a78f1a5b1e7, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/4ace3abab2a54ff3bf581a78f1a5b1e7
2014-07-13 23:44:35,665 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5b74449f3f5b4ce787f72cb82e473fd0, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/5b74449f3f5b4ce787f72cb82e473fd0
2014-07-13 23:44:35,679 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1618333d4f844e37b9830c98f0f426a3, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1618333d4f844e37b9830c98f0f426a3
2014-07-13 23:44:35,697 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d5adeca2d3ab4173bb1725eb80b9c508, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d5adeca2d3ab4173bb1725eb80b9c508
2014-07-13 23:44:35,710 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/8dafd496f34245b5a05f6418789592bd, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/8dafd496f34245b5a05f6418789592bd
2014-07-13 23:44:35,720 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/11aa92889cdb4286942fc336b8f3ade9, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/11aa92889cdb4286942fc336b8f3ade9
2014-07-13 23:44:35,738 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d33ad8187a3b40d697540269a5146055, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d33ad8187a3b40d697540269a5146055
2014-07-13 23:44:35,743 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/01232ff87b594bc28747b91ff2943f66, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/01232ff87b594bc28747b91ff2943f66
2014-07-13 23:44:35,745 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/cced37c3e00344e0ae9fbbd4c844b5b9, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/cced37c3e00344e0ae9fbbd4c844b5b9
2014-07-13 23:44:35,750 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f7a4cc6b7826443aae565c150a69bb2c, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/f7a4cc6b7826443aae565c150a69bb2c
2014-07-13 23:44:35,750 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into a3112caf5ef34d3bb1b249eb164aa827(size=921.4m), total size for store is 3.3g. This selection was in queue for 0sec, and took 2mins, 40sec to execute.
2014-07-13 23:44:35,750 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., storeName=family, fileCount=10, fileSize=959.4m, priority=2, time=274022342559573; duration=2mins, 40sec
2014-07-13 23:44:35,750 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-13 23:44:35,750 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 23:44:35,754 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 295429325 starting at candidate #4 after considering 124 permutations with 111 in ratio
2014-07-13 23:44:35,754 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 8b827125b32700e6f7c5c34f77be22cb - family: Initiating minor compaction
2014-07-13 23:44:35,754 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:44:35,754 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp, totalSize=281.7m
2014-07-13 23:44:35,754 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/b7c30eebc1264c4c8b9a515c5d1c4ff6, keycount=112540, bloomtype=ROW, size=80.2m, encoding=NONE, seqNum=6066
2014-07-13 23:44:35,754 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7160da18b8234eb5a0917e001b769e55, keycount=168824, bloomtype=ROW, size=120.2m, encoding=NONE, seqNum=6523
2014-07-13 23:44:35,755 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ba8202c46afc4c7493fb2ee4082558ec, keycount=114200, bloomtype=ROW, size=81.3m, encoding=NONE, seqNum=6992
2014-07-13 23:44:35,876 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:44:36,265 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 918.6m
2014-07-13 23:44:36,861 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:44:44,183 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:44,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67143 synced till here 67139
2014-07-13 23:44:44,730 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320275428 with entries=70, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320284184
2014-07-13 23:44:44,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:45,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:45,797 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67212 synced till here 67209
2014-07-13 23:44:45,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320284184 with entries=69, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320285775
2014-07-13 23:44:45,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:44:47,072 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 23:44:47,197 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files, but is 1.3g vs best flushable region's 231.6m. Choosing the bigger.
2014-07-13 23:44:47,197 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. due to global heap pressure
2014-07-13 23:44:47,197 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1.3g
2014-07-13 23:44:48,316 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:44:49,329 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:49,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67296 synced till here 67294
2014-07-13 23:44:49,440 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320285775 with entries=84, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320289330
2014-07-13 23:44:49,928 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:44:50,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:44:50,988 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,008 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67369 synced till here 67368
2014-07-13 23:44:51,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320289330 with entries=73, filesize=81.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320290778
2014-07-13 23:44:51,618 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,634 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,635 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,690 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,740 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,790 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,807 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,854 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,871 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,885 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,940 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:51,991 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,033 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,054 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,104 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,126 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,196 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,205 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,231 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,251 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,259 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,277 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,288 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,324 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,353 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,387 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,388 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,402 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,433 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,466 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,475 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,606 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,656 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,669 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,673 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,691 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,707 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:52,732 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,153 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,167 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,200 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,233 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,242 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,284 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,322 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,359 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,360 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,406 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:54,415 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:44:55,988 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,619 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:56,634 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,636 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:56,690 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,740 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,791 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,808 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:56,854 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,871 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,885 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,940 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:56,992 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,034 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,054 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,104 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,126 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,197 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,206 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,232 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,252 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,260 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,277 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,288 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,324 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,354 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,387 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,388 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,403 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,433 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,466 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,475 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,606 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,656 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,669 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,673 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,692 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:57,707 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:57,733 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,154 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,167 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,201 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:59,233 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,242 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,285 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:44:59,322 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,360 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,361 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,406 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:44:59,416 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:00,989 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:01,619 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:01,634 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:01,636 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:01,691 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:01,740 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:01,832 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10025ms
2014-07-13 23:45:02,040 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10007ms
2014-07-13 23:45:02,041 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10050ms
2014-07-13 23:45:02,041 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10101ms
2014-07-13 23:45:02,041 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10156ms
2014-07-13 23:45:02,041 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10170ms
2014-07-13 23:45:02,041 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10187ms
2014-07-13 23:45:02,042 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10252ms
2014-07-13 23:45:02,054 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:02,952 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10220ms
2014-07-13 23:45:02,953 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10348ms
2014-07-13 23:45:02,953 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10297ms
2014-07-13 23:45:02,953 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10551ms
2014-07-13 23:45:02,953 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10676ms
2014-07-13 23:45:02,953 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10284ms
2014-07-13 23:45:02,954 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10281ms
2014-07-13 23:45:02,954 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10247ms
2014-07-13 23:45:02,954 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10263ms
2014-07-13 23:45:02,954 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10851ms
2014-07-13 23:45:02,957 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10832ms
2014-07-13 23:45:02,957 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10761ms
2014-07-13 23:45:02,958 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10753ms
2014-07-13 23:45:02,958 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10727ms
2014-07-13 23:45:02,958 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10707ms
2014-07-13 23:45:02,958 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10699ms
2014-07-13 23:45:02,958 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10671ms
2014-07-13 23:45:02,958 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10634ms
2014-07-13 23:45:02,959 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10606ms
2014-07-13 23:45:02,959 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10572ms
2014-07-13 23:45:02,960 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10571ms
2014-07-13 23:45:02,960 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10527ms
2014-07-13 23:45:02,960 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10494ms
2014-07-13 23:45:02,961 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10485ms
2014-07-13 23:45:04,155 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:04,167 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:04,201 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:04,234 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:04,243 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:04,285 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:04,322 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:04,360 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:04,361 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:04,406 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:04,417 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:05,990 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:45:06,960 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15220ms
2014-07-13 23:45:06,961 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15343ms
2014-07-13 23:45:06,961 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15327ms
2014-07-13 23:45:06,961 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15326ms
2014-07-13 23:45:06,962 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15271ms
2014-07-13 23:45:07,040 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15233ms
2014-07-13 23:45:07,041 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15008ms
2014-07-13 23:45:07,041 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15170ms
2014-07-13 23:45:07,042 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15157ms
2014-07-13 23:45:07,042 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15102ms
2014-07-13 23:45:07,042 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15051ms
2014-07-13 23:45:07,042 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15252ms
2014-07-13 23:45:07,042 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15188ms
2014-07-13 23:45:07,055 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:45:07,953 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15221ms
2014-07-13 23:45:07,953 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15348ms
2014-07-13 23:45:07,953 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15297ms
2014-07-13 23:45:07,953 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15551ms
2014-07-13 23:45:07,954 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15677ms
2014-07-13 23:45:07,954 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15285ms
2014-07-13 23:45:07,954 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15281ms
2014-07-13 23:45:07,954 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15247ms
2014-07-13 23:45:07,954 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15263ms
2014-07-13 23:45:07,955 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15852ms
2014-07-13 23:45:07,958 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15833ms
2014-07-13 23:45:07,958 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15762ms
2014-07-13 23:45:07,958 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15753ms
2014-07-13 23:45:07,958 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15727ms
2014-07-13 23:45:07,958 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15707ms
2014-07-13 23:45:07,958 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15699ms
2014-07-13 23:45:07,959 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15672ms
2014-07-13 23:45:07,959 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15635ms
2014-07-13 23:45:07,959 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15606ms
2014-07-13 23:45:07,960 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15572ms
2014-07-13 23:45:07,960 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15572ms
2014-07-13 23:45:07,960 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15527ms
2014-07-13 23:45:07,961 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15494ms
2014-07-13 23:45:07,961 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15486ms
2014-07-13 23:45:09,155 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:45:09,168 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:45:09,202 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:45:09,234 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:45:09,243 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:45:09,285 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:45:09,322 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:45:09,361 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:45:09,362 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:45:09,407 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:45:09,417 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:45:10,975 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1012ms
GC pool 'ParNew' had collection(s): count=1 time=1109ms
2014-07-13 23:45:10,990 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:45:11,046 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21518, memsize=891.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/217ae082dbfd48b29ba9ff20662ee216
2014-07-13 23:45:11,294 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/217ae082dbfd48b29ba9ff20662ee216 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/217ae082dbfd48b29ba9ff20662ee216
2014-07-13 23:45:11,306 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/217ae082dbfd48b29ba9ff20662ee216, entries=3245470, sequenceid=21518, filesize=231.0m
2014-07-13 23:45:11,307 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~918.6m/963190240, currentsize=133.7m/140246000 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 35042ms, sequenceid=21518, compaction requested=true
2014-07-13 23:45:11,307 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-13 23:45:11,307 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20319ms
2014-07-13 23:45:11,307 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,307 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 108683ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:45:11,308 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16893ms
2014-07-13 23:45:11,308 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,308 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.3g
2014-07-13 23:45:11,308 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16902ms
2014-07-13 23:45:11,308 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,308 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16948ms
2014-07-13 23:45:11,308 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,309 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16950ms
2014-07-13 23:45:11,309 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,309 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16987ms
2014-07-13 23:45:11,309 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,312 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17028ms
2014-07-13 23:45:11,312 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,312 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17070ms
2014-07-13 23:45:11,315 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,315 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17082ms
2014-07-13 23:45:11,315 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,315 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17115ms
2014-07-13 23:45:11,315 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,315 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17148ms
2014-07-13 23:45:11,315 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,324 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17171ms
2014-07-13 23:45:11,324 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,325 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18850ms
2014-07-13 23:45:11,325 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,325 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18859ms
2014-07-13 23:45:11,325 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,327 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18893ms
2014-07-13 23:45:11,327 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,329 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18941ms
2014-07-13 23:45:11,329 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,332 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18945ms
2014-07-13 23:45:11,332 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,334 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18980ms
2014-07-13 23:45:11,334 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,335 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19010ms
2014-07-13 23:45:11,335 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,335 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19048ms
2014-07-13 23:45:11,335 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,335 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19076ms
2014-07-13 23:45:11,335 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,336 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19085ms
2014-07-13 23:45:11,336 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,336 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19105ms
2014-07-13 23:45:11,336 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,336 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19131ms
2014-07-13 23:45:11,336 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,337 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19140ms
2014-07-13 23:45:11,337 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,339 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19214ms
2014-07-13 23:45:11,339 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,340 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19236ms
2014-07-13 23:45:11,340 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,341 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18649ms
2014-07-13 23:45:11,341 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,342 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18634ms
2014-07-13 23:45:11,342 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,342 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18669ms
2014-07-13 23:45:11,342 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,343 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18673ms
2014-07-13 23:45:11,343 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,343 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19066ms
2014-07-13 23:45:11,343 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,343 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18941ms
2014-07-13 23:45:11,343 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,344 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18687ms
2014-07-13 23:45:11,344 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,345 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18739ms
2014-07-13 23:45:11,345 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,346 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16981,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294358,"queuetimems":0,"class":"HRegionServer","responsesize":1380,"method":"Multi"}
2014-07-13 23:45:11,349 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18617ms
2014-07-13 23:45:11,349 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,349 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19295ms
2014-07-13 23:45:11,349 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,357 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19502ms
2014-07-13 23:45:11,357 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,357 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19567ms
2014-07-13 23:45:11,357 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,365 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19374ms
2014-07-13 23:45:11,365 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,365 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19425ms
2014-07-13 23:45:11,365 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,366 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19481ms
2014-07-13 23:45:11,367 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,367 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19496ms
2014-07-13 23:45:11,367 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,368 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19335ms
2014-07-13 23:45:11,368 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,369 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19561ms
2014-07-13 23:45:11,369 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,369 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19679ms
2014-07-13 23:45:11,369 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,376 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19741ms
2014-07-13 23:45:11,376 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,376 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19742ms
2014-07-13 23:45:11,376 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,376 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19758ms
2014-07-13 23:45:11,376 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,377 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19637ms
2014-07-13 23:45:11,377 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:45:11,558 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294412,"queuetimems":0,"class":"HRegionServer","responsesize":5318,"method":"Multi"}
2014-07-13 23:45:11,698 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19311,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292387,"queuetimems":0,"class":"HRegionServer","responsesize":1744,"method":"Multi"}
2014-07-13 23:45:11,699 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19224,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292474,"queuetimems":0,"class":"HRegionServer","responsesize":2113,"method":"Multi"}
2014-07-13 23:45:11,699 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17458,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294240,"queuetimems":0,"class":"HRegionServer","responsesize":4979,"method":"Multi"}
2014-07-13 23:45:11,698 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21348,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320290350,"queuetimems":1,"class":"HRegionServer","responsesize":17210,"method":"Multi"}
2014-07-13 23:45:12,022 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19764,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292257,"queuetimems":0,"class":"HRegionServer","responsesize":4552,"method":"Multi"}
2014-07-13 23:45:12,030 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19836,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292193,"queuetimems":1,"class":"HRegionServer","responsesize":6598,"method":"Multi"}
2014-07-13 23:45:12,045 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19841,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292203,"queuetimems":0,"class":"HRegionServer","responsesize":4665,"method":"Multi"}
2014-07-13 23:45:12,058 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19934,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292123,"queuetimems":1,"class":"HRegionServer","responsesize":7237,"method":"Multi"}
2014-07-13 23:45:12,066 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19398,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292667,"queuetimems":1,"class":"HRegionServer","responsesize":4870,"method":"Multi"}
2014-07-13 23:45:12,068 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292399,"queuetimems":0,"class":"HRegionServer","responsesize":6526,"method":"Multi"}
2014-07-13 23:45:12,074 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292728,"queuetimems":0,"class":"HRegionServer","responsesize":7401,"method":"Multi"}
2014-07-13 23:45:12,074 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19370,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292704,"queuetimems":0,"class":"HRegionServer","responsesize":4893,"method":"Multi"}
2014-07-13 23:45:12,080 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20448,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291632,"queuetimems":0,"class":"HRegionServer","responsesize":5318,"method":"Multi"}
2014-07-13 23:45:12,078 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20442,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291635,"queuetimems":0,"class":"HRegionServer","responsesize":1380,"method":"Multi"}
2014-07-13 23:45:12,080 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19405,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292672,"queuetimems":0,"class":"HRegionServer","responsesize":1946,"method":"Multi"}
2014-07-13 23:45:12,080 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20195,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291883,"queuetimems":0,"class":"HRegionServer","responsesize":4864,"method":"Multi"}
2014-07-13 23:45:12,079 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20027,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292052,"queuetimems":0,"class":"HRegionServer","responsesize":6545,"method":"Multi"}
2014-07-13 23:45:12,079 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19794,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292285,"queuetimems":0,"class":"HRegionServer","responsesize":4979,"method":"Multi"}
2014-07-13 23:45:12,078 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20209,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291869,"queuetimems":0,"class":"HRegionServer","responsesize":5683,"method":"Multi"}
2014-07-13 23:45:12,078 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20273,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291805,"queuetimems":0,"class":"HRegionServer","responsesize":5986,"method":"Multi"}
2014-07-13 23:45:12,077 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292689,"queuetimems":1,"class":"HRegionServer","responsesize":5398,"method":"Multi"}
2014-07-13 23:45:12,169 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:45:12,178 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17820,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294357,"queuetimems":1,"class":"HRegionServer","responsesize":15421,"method":"Multi"}
2014-07-13 23:45:13,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67455 synced till here 67432
2014-07-13 23:45:13,555 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320290778 with entries=86, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320312170
2014-07-13 23:45:13,864 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:45:13,904 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19588,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294316,"queuetimems":1,"class":"HRegionServer","responsesize":15258,"method":"Multi"}
2014-07-13 23:45:13,904 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21474,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292430,"queuetimems":0,"class":"HRegionServer","responsesize":15570,"method":"Multi"}
2014-07-13 23:45:13,904 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21915,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291989,"queuetimems":0,"class":"HRegionServer","responsesize":15186,"method":"Multi"}
2014-07-13 23:45:14,136 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21532,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292604,"queuetimems":1,"class":"HRegionServer","responsesize":14914,"method":"Multi"}
2014-07-13 23:45:14,138 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19939,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294198,"queuetimems":1,"class":"HRegionServer","responsesize":17210,"method":"Multi"}
2014-07-13 23:45:15,493 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23108,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292384,"queuetimems":0,"class":"HRegionServer","responsesize":15848,"method":"Multi"}
2014-07-13 23:45:15,493 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23392,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292101,"queuetimems":0,"class":"HRegionServer","responsesize":15786,"method":"Multi"}
2014-07-13 23:45:15,871 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:45:15,874 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23220,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292653,"queuetimems":0,"class":"HRegionServer","responsesize":15079,"method":"Multi"}
2014-07-13 23:45:15,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67559 synced till here 67525
2014-07-13 23:45:16,144 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292032,"queuetimems":1,"class":"HRegionServer","responsesize":14050,"method":"Multi"}
2014-07-13 23:45:16,150 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21916,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294233,"queuetimems":1,"class":"HRegionServer","responsesize":18376,"method":"Multi"}
2014-07-13 23:45:16,150 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24533,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291616,"queuetimems":0,"class":"HRegionServer","responsesize":17812,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291688,"queuetimems":1,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24308,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291852,"queuetimems":0,"class":"HRegionServer","responsesize":14616,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23931,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292229,"queuetimems":0,"class":"HRegionServer","responsesize":13809,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23883,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292275,"queuetimems":0,"class":"HRegionServer","responsesize":9720,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21995,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294166,"queuetimems":1,"class":"HRegionServer","responsesize":9720,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23693,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292464,"queuetimems":0,"class":"HRegionServer","responsesize":11338,"method":"Multi"}
2014-07-13 23:45:16,165 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23915,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292250,"queuetimems":0,"class":"HRegionServer","responsesize":10355,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24370,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291788,"queuetimems":0,"class":"HRegionServer","responsesize":15421,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24423,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291738,"queuetimems":0,"class":"HRegionServer","responsesize":15258,"method":"Multi"}
2014-07-13 23:45:16,161 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21762,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294399,"queuetimems":1,"class":"HRegionServer","responsesize":14323,"method":"Multi"}
2014-07-13 23:45:16,169 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24220,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320291938,"queuetimems":1,"class":"HRegionServer","responsesize":15997,"method":"Multi"}
2014-07-13 23:45:16,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320312170 with entries=104, filesize=110.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320315871
2014-07-13 23:45:17,492 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1043ms
GC pool 'ParNew' had collection(s): count=1 time=1097ms
2014-07-13 23:45:17,958 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25607,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292350,"queuetimems":0,"class":"HRegionServer","responsesize":14323,"method":"Multi"}
2014-07-13 23:45:17,959 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23678,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294280,"queuetimems":0,"class":"HRegionServer","responsesize":17812,"method":"Multi"}
2014-07-13 23:45:17,959 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25634,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320292324,"queuetimems":1,"class":"HRegionServer","responsesize":18376,"method":"Multi"}
2014-07-13 23:45:18,033 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:45:18,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:45:18,282 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67653 synced till here 67638
2014-07-13 23:45:18,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320315871 with entries=94, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320318186
2014-07-13 23:45:19,550 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25399,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320294151,"queuetimems":0,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-13 23:45:20,160 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:45:20,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67747 synced till here 67729
2014-07-13 23:45:20,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320318186 with entries=94, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320320160
2014-07-13 23:45:21,991 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:45:22,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67853 synced till here 67816
2014-07-13 23:45:23,262 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320320160 with entries=106, filesize=100.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320321991
2014-07-13 23:45:24,237 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:45:47,241 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 23922ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:45:47,241 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 23922ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:45:47,251 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22995ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=22988ms
2014-07-13 23:45:47,254 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,254 WARN  [regionserver60020] util.Sleeper: We slept 25781ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:45:47,255 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,257 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,275 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23702,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323573,"queuetimems":15348,"class":"HRegionServer","responsesize":2062,"method":"Multi"}
2014-07-13 23:45:47,276 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23686,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323589,"queuetimems":15359,"class":"HRegionServer","responsesize":573,"method":"Multi"}
2014-07-13 23:45:47,276 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23709,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323566,"queuetimems":15385,"class":"HRegionServer","responsesize":6983,"method":"Multi"}
2014-07-13 23:45:47,276 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23688,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323566,"queuetimems":15366,"class":"HRegionServer","responsesize":5521,"method":"Multi"}
2014-07-13 23:45:47,276 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25594,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320321681,"queuetimems":16835,"class":"HRegionServer","responsesize":15786,"method":"Multi"}
2014-07-13 23:45:47,276 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320321664,"queuetimems":17018,"class":"HRegionServer","responsesize":15079,"method":"Multi"}
2014-07-13 23:45:47,277 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23680,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323597,"queuetimems":15334,"class":"HRegionServer","responsesize":5510,"method":"Multi"}
2014-07-13 23:45:47,277 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23682,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323574,"queuetimems":15345,"class":"HRegionServer","responsesize":1777,"method":"Multi"}
2014-07-13 23:45:47,277 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,278 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25573,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320321681,"queuetimems":16871,"class":"HRegionServer","responsesize":15997,"method":"Multi"}
2014-07-13 23:45:47,279 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,279 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,281 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,283 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,283 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,284 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,286 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,288 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,307 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25642,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320321665,"queuetimems":16935,"class":"HRegionServer","responsesize":14914,"method":"Multi"}
2014-07-13 23:45:47,307 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25620,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320321685,"queuetimems":16786,"class":"HRegionServer","responsesize":11338,"method":"Multi"}
2014-07-13 23:45:47,307 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25607,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320321698,"queuetimems":16760,"class":"HRegionServer","responsesize":10355,"method":"Multi"}
2014-07-13 23:45:47,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67954 synced till here 67934
2014-07-13 23:45:47,435 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61907 service: ClientService methodName: Multi size: 108.7k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,437 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,437 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61834 service: ClientService methodName: Multi size: 1.8m connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,437 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,437 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61835 service: ClientService methodName: Multi size: 2.0m connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,437 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,437 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61844 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,437 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61838 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61909 service: ClientService methodName: Multi size: 323.5k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61905 service: ClientService methodName: Multi size: 990.4k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61837 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,438 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,448 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,449 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,452 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,454 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,455 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,455 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,466 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,483 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,491 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23684,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323807,"queuetimems":15362,"class":"HRegionServer","responsesize":1930,"method":"Multi"}
2014-07-13 23:45:47,491 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23683,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323807,"queuetimems":15365,"class":"HRegionServer","responsesize":801,"method":"Multi"}
2014-07-13 23:45:47,491 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23685,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323806,"queuetimems":15365,"class":"HRegionServer","responsesize":2145,"method":"Multi"}
2014-07-13 23:45:47,491 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61896 service: ClientService methodName: Multi size: 351.0k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,491 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,491 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61898 service: ClientService methodName: Multi size: 388.5k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,492 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,492 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23685,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323806,"queuetimems":15368,"class":"HRegionServer","responsesize":3830,"method":"Multi"}
2014-07-13 23:45:47,492 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61897 service: ClientService methodName: Multi size: 149.9k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,492 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,496 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,497 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,492 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61899 service: ClientService methodName: Multi size: 690.7k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,497 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,498 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,499 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23257,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324241,"queuetimems":15741,"class":"HRegionServer","responsesize":80,"method":"Multi"}
2014-07-13 23:45:47,499 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23693,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323806,"queuetimems":15396,"class":"HRegionServer","responsesize":5197,"method":"Multi"}
2014-07-13 23:45:47,499 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61893 service: ClientService methodName: Multi size: 16.3k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,499 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,499 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25736,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320321763,"queuetimems":14792,"class":"HRegionServer","responsesize":17140,"method":"Multi"}
2014-07-13 23:45:47,499 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61901 service: ClientService methodName: Multi size: 934.2k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,499 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,500 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61864 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,500 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,504 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,508 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,510 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,512 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,512 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,513 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,520 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,521 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,521 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,521 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,523 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,524 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,524 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,524 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320321991 with entries=101, filesize=84.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320324237
2014-07-13 23:45:47,539 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,555 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,573 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23331,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324241,"queuetimems":15727,"class":"HRegionServer","responsesize":2488,"method":"Multi"}
2014-07-13 23:45:47,573 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61892 service: ClientService methodName: Multi size: 452.2k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,574 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,579 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,579 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,581 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25254,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322327,"queuetimems":15349,"class":"HRegionServer","responsesize":2448,"method":"Multi"}
2014-07-13 23:45:47,581 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324249,"queuetimems":15625,"class":"HRegionServer","responsesize":625,"method":"Multi"}
2014-07-13 23:45:47,581 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,581 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61859 service: ClientService methodName: Multi size: 447.3k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,581 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,582 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61887 service: ClientService methodName: Multi size: 118.7k connection: 9.1.143.53:47036: output error
2014-07-13 23:45:47,582 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:45:47,582 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,595 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,631 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,673 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,680 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,718 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,765 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,802 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:47,807 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:45:51,495 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/07805ef2e0da41859648f71a5dec462d as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/07805ef2e0da41859648f71a5dec462d
2014-07-13 23:45:51,715 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:45:51,908 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/b7c30eebc1264c4c8b9a515c5d1c4ff6, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/b7c30eebc1264c4c8b9a515c5d1c4ff6
2014-07-13 23:45:51,913 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7160da18b8234eb5a0917e001b769e55, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7160da18b8234eb5a0917e001b769e55
2014-07-13 23:45:51,916 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ba8202c46afc4c7493fb2ee4082558ec, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/ba8202c46afc4c7493fb2ee4082558ec
2014-07-13 23:45:51,916 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into 07805ef2e0da41859648f71a5dec462d(size=263.5m), total size for store is 3.3g. This selection was in queue for 0sec, and took 1mins, 16sec to execute.
2014-07-13 23:45:51,917 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., storeName=family, fileCount=3, fileSize=281.7m, priority=-1, time=274183181170620; duration=1mins, 16sec
2014-07-13 23:45:51,917 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-13 23:45:51,917 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 23:45:51,920 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 298934837 starting at candidate #8 after considering 124 permutations with 119 in ratio
2014-07-13 23:45:51,920 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: d679c2853f294b83582eebcd030d1677 - family: Initiating minor compaction
2014-07-13 23:45:51,921 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:45:51,921 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp, totalSize=285.1m
2014-07-13 23:45:51,921 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/87ddb1e9470b4b5eba82fda01e02ae5c, keycount=113187, bloomtype=ROW, size=80.5m, encoding=NONE, seqNum=8884
2014-07-13 23:45:51,921 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/72de0aaf971e4b0f95501112ae9ebd70, keycount=161233, bloomtype=ROW, size=114.8m, encoding=NONE, seqNum=9421
2014-07-13 23:45:51,921 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/add8a32c855d49578c4f86588e361db8, keycount=126044, bloomtype=ROW, size=89.8m, encoding=NONE, seqNum=9802
2014-07-13 23:45:52,000 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:45:52,254 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,256 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,257 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,279 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:45:52,279 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,279 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:45:52,282 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,284 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,284 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,285 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,287 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,288 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,448 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,450 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,474 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5008ms
2014-07-13 23:45:52,474 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5022ms
2014-07-13 23:45:52,474 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5020ms
2014-07-13 23:45:52,475 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5020ms
2014-07-13 23:45:52,475 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5021ms
2014-07-13 23:45:52,484 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,497 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,497 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,498 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,504 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,508 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,510 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,512 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,513 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,514 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,521 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,521 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,522 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,522 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,523 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,524 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,524 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,539 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,556 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,579 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,580 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,582 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,583 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,595 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,631 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,674 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,681 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,718 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,766 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:45:52,802 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:52,808 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:45:57,255 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,256 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,257 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,279 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:45:57,280 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,280 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 23:45:57,282 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,284 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,284 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,285 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,287 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,289 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,449 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,450 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,474 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-13 23:45:57,475 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10023ms
2014-07-13 23:45:57,475 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10021ms
2014-07-13 23:45:57,475 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10020ms
2014-07-13 23:45:57,476 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10021ms
2014-07-13 23:45:57,484 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,497 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,498 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,499 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,505 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,508 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,511 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,513 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:57,513 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,514 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,521 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,521 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:57,522 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,522 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,524 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:57,524 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:57,525 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,540 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,556 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,579 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:57,581 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:45:57,582 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,583 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,595 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:57,632 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,674 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,681 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,719 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:45:57,767 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,803 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:45:57,808 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:46:02,255 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,256 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,258 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,279 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,280 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,280 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 23:46:02,283 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,284 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,284 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,285 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,287 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,289 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,449 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,450 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,475 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15009ms
2014-07-13 23:46:02,475 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15023ms
2014-07-13 23:46:02,475 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15021ms
2014-07-13 23:46:02,476 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15020ms
2014-07-13 23:46:02,476 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15022ms
2014-07-13 23:46:02,484 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,497 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,498 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,499 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,505 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,509 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,511 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,513 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,513 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,515 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,522 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,522 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,523 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,523 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,524 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,525 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:46:02,525 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,540 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,557 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,579 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:46:02,582 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 23:46:02,582 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,584 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,596 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,632 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,674 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,681 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,719 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,767 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:46:02,803 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:02,808 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:46:06,922 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15287, memsize=1.3g, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/f6138d7214954612ab132127c0d5ef1f
2014-07-13 23:46:06,941 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/f6138d7214954612ab132127c0d5ef1f as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/f6138d7214954612ab132127c0d5ef1f
2014-07-13 23:46:06,953 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/f6138d7214954612ab132127c0d5ef1f, entries=4688620, sequenceid=15287, filesize=333.6m
2014-07-13 23:46:06,954 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.3g/1426543280, currentsize=279.4m/293015680 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 79757ms, sequenceid=15287, compaction requested=true
2014-07-13 23:46:06,954 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-13 23:46:06,954 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19147ms
2014-07-13 23:46:06,954 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,955 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 491.3m
2014-07-13 23:46:06,955 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19153ms
2014-07-13 23:46:06,955 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,955 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19190ms
2014-07-13 23:46:06,955 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,957 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19239ms
2014-07-13 23:46:06,957 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,957 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19277ms
2014-07-13 23:46:06,957 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,960 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19287ms
2014-07-13 23:46:06,960 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,960 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19329ms
2014-07-13 23:46:06,960 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,960 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19365ms
2014-07-13 23:46:06,960 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,960 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19378ms
2014-07-13 23:46:06,961 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,965 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19384ms
2014-07-13 23:46:06,965 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,966 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19387ms
2014-07-13 23:46:06,966 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,966 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19387ms
2014-07-13 23:46:06,966 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,966 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19411ms
2014-07-13 23:46:06,966 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,969 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19430ms
2014-07-13 23:46:06,969 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,974 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19450ms
2014-07-13 23:46:06,974 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,974 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19450ms
2014-07-13 23:46:06,974 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,984 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19461ms
2014-07-13 23:46:06,984 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,984 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19463ms
2014-07-13 23:46:06,984 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,984 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19463ms
2014-07-13 23:46:06,985 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,985 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19464ms
2014-07-13 23:46:06,985 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,990 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19470ms
2014-07-13 23:46:06,990 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,990 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19477ms
2014-07-13 23:46:06,990 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,990 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19478ms
2014-07-13 23:46:06,990 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,991 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19479ms
2014-07-13 23:46:06,991 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,993 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19483ms
2014-07-13 23:46:06,993 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,997 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19490ms
2014-07-13 23:46:06,997 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:06,999 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19495ms
2014-07-13 23:46:06,999 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,000 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19502ms
2014-07-13 23:46:07,000 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,001 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19504ms
2014-07-13 23:46:07,001 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,001 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19505ms
2014-07-13 23:46:07,001 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,010 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19526ms
2014-07-13 23:46:07,010 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,010 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19556ms
2014-07-13 23:46:07,010 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,010 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19555ms
2014-07-13 23:46:07,010 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,011 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19557ms
2014-07-13 23:46:07,011 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,012 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19560ms
2014-07-13 23:46:07,012 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,012 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19546ms
2014-07-13 23:46:07,012 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,013 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19564ms
2014-07-13 23:46:07,013 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,013 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19565ms
2014-07-13 23:46:07,013 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,013 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19725ms
2014-07-13 23:46:07,013 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44684,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322329,"queuetimems":15320,"class":"HRegionServer","responsesize":14323,"method":"Multi"}
2014-07-13 23:46:07,013 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,014 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61878 service: ClientService methodName: Multi size: 2.5m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,014 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,017 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19731ms
2014-07-13 23:46:07,017 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,017 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19733ms
2014-07-13 23:46:07,018 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,018 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19735ms
2014-07-13 23:46:07,018 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,018 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19735ms
2014-07-13 23:46:07,018 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,019 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19738ms
2014-07-13 23:46:07,019 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,019 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19742ms
2014-07-13 23:46:07,019 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,021 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19743ms
2014-07-13 23:46:07,021 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,022 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19745ms
2014-07-13 23:46:07,022 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,022 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19766ms
2014-07-13 23:46:07,022 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,025 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19770ms
2014-07-13 23:46:07,025 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,026 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19772ms
2014-07-13 23:46:07,026 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:07,036 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:46:07,173 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":43584,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323589,"queuetimems":15336,"class":"HRegionServer","responsesize":9835,"method":"Multi"}
2014-07-13 23:46:07,173 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61906 service: ClientService methodName: Multi size: 1.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,174 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,236 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44756,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322479,"queuetimems":15275,"class":"HRegionServer","responsesize":15848,"method":"Multi"}
2014-07-13 23:46:07,237 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61872 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,237 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,290 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19616,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347674,"queuetimems":0,"class":"HRegionServer","responsesize":4665,"method":"Multi"}
2014-07-13 23:46:07,513 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347805,"queuetimems":0,"class":"HRegionServer","responsesize":4893,"method":"Multi"}
2014-07-13 23:46:07,513 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":43263,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324249,"queuetimems":15597,"class":"HRegionServer","responsesize":4914,"method":"Multi"}
2014-07-13 23:46:07,513 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20021,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347491,"queuetimems":4,"class":"HRegionServer","responsesize":4552,"method":"Multi"}
2014-07-13 23:46:07,513 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61885 service: ClientService methodName: Multi size: 885.5k connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,513 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,712 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:07,713 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45233,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322479,"queuetimems":15229,"class":"HRegionServer","responsesize":17812,"method":"Multi"}
2014-07-13 23:46:07,713 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45232,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322481,"queuetimems":15129,"class":"HRegionServer","responsesize":9720,"method":"Multi"}
2014-07-13 23:46:07,713 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45210,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322503,"queuetimems":14500,"class":"HRegionServer","responsesize":15416,"method":"Multi"}
2014-07-13 23:46:07,714 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45224,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322489,"queuetimems":14533,"class":"HRegionServer","responsesize":5978,"method":"Multi"}
2014-07-13 23:46:07,713 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323256,"queuetimems":15211,"class":"HRegionServer","responsesize":14462,"method":"Multi"}
2014-07-13 23:46:07,714 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323274,"queuetimems":15143,"class":"HRegionServer","responsesize":11150,"method":"Multi"}
2014-07-13 23:46:07,713 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323264,"queuetimems":15185,"class":"HRegionServer","responsesize":15438,"method":"Multi"}
2014-07-13 23:46:07,713 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45231,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322481,"queuetimems":15168,"class":"HRegionServer","responsesize":17210,"method":"Multi"}
2014-07-13 23:46:07,714 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45240,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322473,"queuetimems":15356,"class":"HRegionServer","responsesize":15258,"method":"Multi"}
2014-07-13 23:46:07,714 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61868 service: ClientService methodName: Multi size: 1.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,713 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322333,"queuetimems":15297,"class":"HRegionServer","responsesize":15421,"method":"Multi"}
2014-07-13 23:46:07,720 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61874 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,720 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,720 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61877 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,720 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,723 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":43474,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324249,"queuetimems":15613,"class":"HRegionServer","responsesize":3796,"method":"Multi"}
2014-07-13 23:46:07,719 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,724 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45246,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322477,"queuetimems":15309,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-13 23:46:07,724 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322328,"queuetimems":15334,"class":"HRegionServer","responsesize":17499,"method":"Multi"}
2014-07-13 23:46:07,724 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61873 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,724 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,726 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20261,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347463,"queuetimems":0,"class":"HRegionServer","responsesize":7401,"method":"Multi"}
2014-07-13 23:46:07,726 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":43486,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324240,"queuetimems":15741,"class":"HRegionServer","responsesize":15073,"method":"Multi"}
2014-07-13 23:46:07,727 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61894 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,727 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,728 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61886 service: ClientService methodName: Multi size: 688.3k connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,728 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,729 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61923 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,729 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,733 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61920 service: ClientService methodName: Multi size: 2.0m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,733 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,734 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20256,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347478,"queuetimems":0,"class":"HRegionServer","responsesize":7237,"method":"Multi"}
2014-07-13 23:46:07,737 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61924 service: ClientService methodName: Multi size: 2.5m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,737 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,737 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61884 service: ClientService methodName: Multi size: 1.1m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,737 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,741 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20297,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347444,"queuetimems":79,"class":"HRegionServer","responsesize":1380,"method":"Multi"}
2014-07-13 23:46:07,742 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20297,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347444,"queuetimems":81,"class":"HRegionServer","responsesize":6545,"method":"Multi"}
2014-07-13 23:46:07,742 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":43493,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324248,"queuetimems":15665,"class":"HRegionServer","responsesize":5027,"method":"Multi"}
2014-07-13 23:46:07,742 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61889 service: ClientService methodName: Multi size: 904.3k connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,742 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,745 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61891 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,745 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,746 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61871 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,746 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,746 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61865 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,746 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,747 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20303,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347444,"queuetimems":165,"class":"HRegionServer","responsesize":1744,"method":"Multi"}
2014-07-13 23:46:07,749 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61869 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,750 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,791 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:46:07,806 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68025 synced till here 68018
2014-07-13 23:46:07,932 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320347277,"queuetimems":38459,"class":"HRegionServer","responsesize":7401,"method":"Multi"}
2014-07-13 23:46:07,932 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61946 service: ClientService methodName: Multi size: 1.3m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:07,932 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:07,980 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320324237 with entries=71, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320367712
2014-07-13 23:46:07,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320169668
2014-07-13 23:46:07,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320170828
2014-07-13 23:46:08,327 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44084,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324242,"queuetimems":15682,"class":"HRegionServer","responsesize":15357,"method":"Multi"}
2014-07-13 23:46:08,329 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45994,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320322334,"queuetimems":15265,"class":"HRegionServer","responsesize":18376,"method":"Multi"}
2014-07-13 23:46:08,328 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44729,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323599,"queuetimems":15251,"class":"HRegionServer","responsesize":15474,"method":"Multi"}
2014-07-13 23:46:08,328 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44522,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323806,"queuetimems":15373,"class":"HRegionServer","responsesize":9414,"method":"Multi"}
2014-07-13 23:46:08,327 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44730,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323597,"queuetimems":15300,"class":"HRegionServer","responsesize":15285,"method":"Multi"}
2014-07-13 23:46:09,330 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61890 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,330 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:09,330 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61904 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,330 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:08,327 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44727,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323599,"queuetimems":15207,"class":"HRegionServer","responsesize":13896,"method":"Multi"}
2014-07-13 23:46:09,333 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61903 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,333 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:09,334 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61876 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,334 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:08,327 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44513,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320323813,"queuetimems":15348,"class":"HRegionServer","responsesize":9527,"method":"Multi"}
2014-07-13 23:46:09,337 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61895 service: ClientService methodName: Multi size: 1.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,337 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:09,339 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61900 service: ClientService methodName: Multi size: 1.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,339 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:09,345 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61902 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,345 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:09,722 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:09,724 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22447,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320347276,"queuetimems":38513,"class":"HRegionServer","responsesize":13809,"method":"Multi"}
2014-07-13 23:46:09,724 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45475,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324249,"queuetimems":15626,"class":"HRegionServer","responsesize":13945,"method":"Multi"}
2014-07-13 23:46:09,724 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61948 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,724 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22061,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347663,"queuetimems":0,"class":"HRegionServer","responsesize":15848,"method":"Multi"}
2014-07-13 23:46:09,724 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22010,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347714,"queuetimems":1,"class":"HRegionServer","responsesize":15186,"method":"Multi"}
2014-07-13 23:46:09,724 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:09,724 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61888 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,725 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:09,725 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22137,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347588,"queuetimems":0,"class":"HRegionServer","responsesize":15570,"method":"Multi"}
2014-07-13 23:46:09,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68134 synced till here 68095
2014-07-13 23:46:09,984 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22534,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347449,"queuetimems":2,"class":"HRegionServer","responsesize":15786,"method":"Multi"}
2014-07-13 23:46:09,985 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22187,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347797,"queuetimems":1,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-13 23:46:09,986 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347444,"queuetimems":98,"class":"HRegionServer","responsesize":14616,"method":"Multi"}
2014-07-13 23:46:09,984 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347757,"queuetimems":1,"class":"HRegionServer","responsesize":17210,"method":"Multi"}
2014-07-13 23:46:09,998 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22721,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320347276,"queuetimems":38475,"class":"HRegionServer","responsesize":15786,"method":"Multi"}
2014-07-13 23:46:09,998 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22553,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347444,"queuetimems":38,"class":"HRegionServer","responsesize":14914,"method":"Multi"}
2014-07-13 23:46:09,998 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61947 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:09,998 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:10,001 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22725,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320347276,"queuetimems":38546,"class":"HRegionServer","responsesize":14616,"method":"Multi"}
2014-07-13 23:46:10,002 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61949 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:10,002 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:10,006 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45756,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47036","starttimems":1405320324249,"queuetimems":15553,"class":"HRegionServer","responsesize":15079,"method":"Multi"}
2014-07-13 23:46:10,006 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 61950 service: ClientService methodName: Multi size: 2.6m connection: 9.1.143.53:47036: output error
2014-07-13 23:46:10,006 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:46:10,026 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22493,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347532,"queuetimems":0,"class":"HRegionServer","responsesize":15258,"method":"Multi"}
2014-07-13 23:46:10,068 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320367712 with entries=109, filesize=97.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320369722
2014-07-13 23:46:10,929 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23301,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320347627,"queuetimems":0,"class":"HRegionServer","responsesize":13809,"method":"Multi"}
2014-07-13 23:46:11,443 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:11,509 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68253 synced till here 68220
2014-07-13 23:46:11,989 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320369722 with entries=119, filesize=103.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320371444
2014-07-13 23:46:13,001 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:13,209 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68351 synced till here 68330
2014-07-13 23:46:13,430 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320371444 with entries=98, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320373001
2014-07-13 23:46:14,561 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:14,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68435 synced till here 68432
2014-07-13 23:46:14,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320373001 with entries=84, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320374561
2014-07-13 23:46:16,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:16,694 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68558 synced till here 68553
2014-07-13 23:46:16,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320374561 with entries=123, filesize=97.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320376293
2014-07-13 23:46:18,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:19,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68719 synced till here 68717
2014-07-13 23:46:19,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320376293 with entries=161, filesize=89.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320378104
2014-07-13 23:46:20,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:20,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320378104 with entries=87, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320380142
2014-07-13 23:46:21,304 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,304 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,305 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,306 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,306 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,319 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,320 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,320 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,320 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,320 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,320 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,320 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,325 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,341 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,342 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,362 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,366 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,376 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,377 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,379 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,425 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,425 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,425 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,427 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,427 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,428 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,428 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,428 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,428 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,441 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,441 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,442 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,442 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,442 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,443 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,490 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,505 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,508 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,510 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,512 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,512 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,523 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,525 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,538 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,539 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,628 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,629 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,661 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,719 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:21,737 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:26,156 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15442, memsize=346.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/70fac677876344a9aa25d8b16f466abf
2014-07-13 23:46:26,178 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/70fac677876344a9aa25d8b16f466abf as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/70fac677876344a9aa25d8b16f466abf
2014-07-13 23:46:26,193 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/70fac677876344a9aa25d8b16f466abf, entries=1260720, sequenceid=15442, filesize=89.8m
2014-07-13 23:46:26,193 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~491.3m/515208240, currentsize=347.9m/364800480 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 19238ms, sequenceid=15442, compaction requested=true
2014-07-13 23:46:26,193 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:124), split_queue=0, merge_queue=0
2014-07-13 23:46:26,194 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4457ms
2014-07-13 23:46:26,194 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,194 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 728.4m
2014-07-13 23:46:26,194 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4476ms
2014-07-13 23:46:26,194 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,194 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4533ms
2014-07-13 23:46:26,194 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,195 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4566ms
2014-07-13 23:46:26,195 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,195 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4567ms
2014-07-13 23:46:26,195 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,195 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4656ms
2014-07-13 23:46:26,195 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,197 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4659ms
2014-07-13 23:46:26,197 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,201 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4676ms
2014-07-13 23:46:26,201 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,201 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4678ms
2014-07-13 23:46:26,201 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,202 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4689ms
2014-07-13 23:46:26,202 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,202 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4691ms
2014-07-13 23:46:26,202 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,203 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4693ms
2014-07-13 23:46:26,203 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,205 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4698ms
2014-07-13 23:46:26,205 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,206 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4700ms
2014-07-13 23:46:26,206 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,206 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4716ms
2014-07-13 23:46:26,206 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,206 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4763ms
2014-07-13 23:46:26,206 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,207 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4764ms
2014-07-13 23:46:26,207 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,207 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4765ms
2014-07-13 23:46:26,207 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,208 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4765ms
2014-07-13 23:46:26,208 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,208 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4767ms
2014-07-13 23:46:26,208 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,208 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4767ms
2014-07-13 23:46:26,208 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,208 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4780ms
2014-07-13 23:46:26,208 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,208 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4780ms
2014-07-13 23:46:26,209 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,209 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4781ms
2014-07-13 23:46:26,209 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,209 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4781ms
2014-07-13 23:46:26,209 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,210 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4783ms
2014-07-13 23:46:26,211 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,211 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4784ms
2014-07-13 23:46:26,211 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,211 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4786ms
2014-07-13 23:46:26,211 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,212 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4786ms
2014-07-13 23:46:26,212 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,212 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4787ms
2014-07-13 23:46:26,213 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,213 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4834ms
2014-07-13 23:46:26,213 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,214 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4837ms
2014-07-13 23:46:26,214 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,215 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4838ms
2014-07-13 23:46:26,215 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,215 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4849ms
2014-07-13 23:46:26,215 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,216 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4853ms
2014-07-13 23:46:26,216 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,216 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4874ms
2014-07-13 23:46:26,216 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,220 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4878ms
2014-07-13 23:46:26,220 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,220 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4895ms
2014-07-13 23:46:26,220 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,220 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4900ms
2014-07-13 23:46:26,220 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,220 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4900ms
2014-07-13 23:46:26,220 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,229 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4909ms
2014-07-13 23:46:26,229 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,235 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4915ms
2014-07-13 23:46:26,235 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,236 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4916ms
2014-07-13 23:46:26,236 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,236 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4917ms
2014-07-13 23:46:26,237 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,237 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4918ms
2014-07-13 23:46:26,237 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,237 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4931ms
2014-07-13 23:46:26,237 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,238 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4932ms
2014-07-13 23:46:26,238 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,242 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4938ms
2014-07-13 23:46:26,242 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,242 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4938ms
2014-07-13 23:46:26,242 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,249 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4945ms
2014-07-13 23:46:26,249 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:26,313 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:26,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69005 synced till here 68996
2014-07-13 23:46:26,414 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:46:26,453 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320380142 with entries=199, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320386314
2014-07-13 23:46:27,512 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:46:27,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:28,048 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69220 synced till here 69212
2014-07-13 23:46:28,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320386314 with entries=215, filesize=86.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320387842
2014-07-13 23:46:29,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:29,746 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69323 synced till here 69317
2014-07-13 23:46:29,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320387842 with entries=103, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320389490
2014-07-13 23:46:31,111 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:31,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69403 synced till here 69399
2014-07-13 23:46:31,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320389490 with entries=80, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320391111
2014-07-13 23:46:31,770 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,808 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,809 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,857 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,900 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,905 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,907 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,927 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,928 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,929 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,929 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,929 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,930 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,941 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,943 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,943 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,977 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,977 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,978 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,986 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,986 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,996 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:31,996 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,011 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,019 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,019 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,022 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,081 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,088 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,101 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,102 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,102 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,109 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,109 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,124 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,128 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,128 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,129 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,133 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,133 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,133 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,150 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,150 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,157 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,160 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,605 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,610 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,626 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,665 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:32,696 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:46:35,850 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15307, memsize=1.2g, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/5a929381acbd403a827c2c39fb179184
2014-07-13 23:46:35,872 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/5a929381acbd403a827c2c39fb179184 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5a929381acbd403a827c2c39fb179184
2014-07-13 23:46:35,888 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5a929381acbd403a827c2c39fb179184, entries=4620140, sequenceid=15307, filesize=328.7m
2014-07-13 23:46:35,888 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.3g/1393619840, currentsize=699.5m/733451040 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 84580ms, sequenceid=15307, compaction requested=true
2014-07-13 23:46:35,889 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:125), split_queue=0, merge_queue=0
2014-07-13 23:46:35,889 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3193ms
2014-07-13 23:46:35,889 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 733.9m
2014-07-13 23:46:35,889 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,890 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3224ms
2014-07-13 23:46:35,890 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,890 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3264ms
2014-07-13 23:46:35,890 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,890 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3280ms
2014-07-13 23:46:35,890 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,890 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3285ms
2014-07-13 23:46:35,890 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,890 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3730ms
2014-07-13 23:46:35,891 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,891 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3734ms
2014-07-13 23:46:35,891 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,893 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3743ms
2014-07-13 23:46:35,893 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,893 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3743ms
2014-07-13 23:46:35,894 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,899 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3766ms
2014-07-13 23:46:35,899 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,900 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3767ms
2014-07-13 23:46:35,900 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,900 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3767ms
2014-07-13 23:46:35,900 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,900 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3771ms
2014-07-13 23:46:35,900 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,900 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3772ms
2014-07-13 23:46:35,900 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,901 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3773ms
2014-07-13 23:46:35,901 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,901 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3777ms
2014-07-13 23:46:35,901 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,901 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3792ms
2014-07-13 23:46:35,901 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,902 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3794ms
2014-07-13 23:46:35,902 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,902 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3800ms
2014-07-13 23:46:35,902 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,903 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3800ms
2014-07-13 23:46:35,903 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,903 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3802ms
2014-07-13 23:46:35,903 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,903 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3815ms
2014-07-13 23:46:35,903 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,904 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3824ms
2014-07-13 23:46:35,904 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,904 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3882ms
2014-07-13 23:46:35,904 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,904 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3885ms
2014-07-13 23:46:35,904 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,905 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3886ms
2014-07-13 23:46:35,905 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,905 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3894ms
2014-07-13 23:46:35,905 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,905 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3909ms
2014-07-13 23:46:35,905 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,905 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3909ms
2014-07-13 23:46:35,906 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,907 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:46:35,907 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3921ms
2014-07-13 23:46:35,909 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,910 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3923ms
2014-07-13 23:46:35,910 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,910 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3932ms
2014-07-13 23:46:35,910 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,910 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3933ms
2014-07-13 23:46:35,910 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,911 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3934ms
2014-07-13 23:46:35,911 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,911 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3968ms
2014-07-13 23:46:35,911 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,915 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3972ms
2014-07-13 23:46:35,915 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,915 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3974ms
2014-07-13 23:46:35,915 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,915 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3986ms
2014-07-13 23:46:35,915 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,915 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3986ms
2014-07-13 23:46:35,916 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,916 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3987ms
2014-07-13 23:46:35,916 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,916 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3987ms
2014-07-13 23:46:35,916 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,917 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3989ms
2014-07-13 23:46:35,917 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,918 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3991ms
2014-07-13 23:46:35,918 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,921 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4014ms
2014-07-13 23:46:35,921 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,921 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4017ms
2014-07-13 23:46:35,921 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,922 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4022ms
2014-07-13 23:46:35,922 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,947 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4090ms
2014-07-13 23:46:35,947 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,951 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4142ms
2014-07-13 23:46:35,951 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,951 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4144ms
2014-07-13 23:46:35,951 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:35,951 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4181ms
2014-07-13 23:46:35,951 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:46:36,603 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:46:36,682 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:37,663 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69559 synced till here 69548
2014-07-13 23:46:37,780 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320391111 with entries=156, filesize=89.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320396683
2014-07-13 23:46:37,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320172782
2014-07-13 23:46:37,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320173839
2014-07-13 23:46:37,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320176590
2014-07-13 23:46:37,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320180243
2014-07-13 23:46:37,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320182018
2014-07-13 23:46:37,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320183757
2014-07-13 23:46:37,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320186746
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320190414
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320191754
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320204723
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320206018
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320207328
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320208687
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320209956
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320210931
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320212642
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320226895
2014-07-13 23:46:37,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320228956
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320230372
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320231927
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320233595
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320236871
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320238292
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320239910
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320242042
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320248651
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320250311
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320251960
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320253583
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320255414
2014-07-13 23:46:37,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320257759
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320259135
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320260633
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320262015
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320266168
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320267532
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320268782
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320271038
2014-07-13 23:46:37,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320272358
2014-07-13 23:46:38,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:38,543 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69672 synced till here 69653
2014-07-13 23:46:38,771 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320396683 with entries=113, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320398510
2014-07-13 23:46:39,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:39,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69740 synced till here 69736
2014-07-13 23:46:39,958 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320398510 with entries=68, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320399861
2014-07-13 23:46:41,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:41,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69796 synced till here 69795
2014-07-13 23:46:41,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320399861 with entries=56, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320401428
2014-07-13 23:46:41,842 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/ab472272688b4339982b79ead297c5e2 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/ab472272688b4339982b79ead297c5e2
2014-07-13 23:46:42,321 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:46:42,333 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/87ddb1e9470b4b5eba82fda01e02ae5c, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/87ddb1e9470b4b5eba82fda01e02ae5c
2014-07-13 23:46:42,336 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/72de0aaf971e4b0f95501112ae9ebd70, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/72de0aaf971e4b0f95501112ae9ebd70
2014-07-13 23:46:42,340 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/add8a32c855d49578c4f86588e361db8, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/add8a32c855d49578c4f86588e361db8
2014-07-13 23:46:42,340 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into ab472272688b4339982b79ead297c5e2(size=267.5m), total size for store is 3.7g. This selection was in queue for 0sec, and took 50sec to execute.
2014-07-13 23:46:42,340 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., storeName=family, fileCount=3, fileSize=285.1m, priority=-1, time=274259347635474; duration=50sec
2014-07-13 23:46:42,340 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:126), split_queue=0, merge_queue=0
2014-07-13 23:46:42,340 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:126), split_queue=0, merge_queue=0
2014-07-13 23:46:42,341 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 20 store files, 0 compacting, 20 eligible, 20 blocking
2014-07-13 23:46:42,342 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 469350702 starting at candidate #9 after considering 116 permutations with 107 in ratio
2014-07-13 23:46:42,342 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 8b827125b32700e6f7c5c34f77be22cb - family: Initiating minor compaction
2014-07-13 23:46:42,342 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:46:42,343 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp, totalSize=447.6m
2014-07-13 23:46:42,343 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7e5d3fff04da41988deff0b1a02f6386, keycount=128351, bloomtype=ROW, size=91.4m, encoding=NONE, seqNum=9593
2014-07-13 23:46:42,343 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/cf617cd67d524475972a1c6e0bc38805, keycount=256659, bloomtype=ROW, size=182.7m, encoding=NONE, seqNum=10144
2014-07-13 23:46:42,343 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/c9b3498c0ff04d879301e2571d51d952, keycount=106535, bloomtype=ROW, size=75.9m, encoding=NONE, seqNum=10665
2014-07-13 23:46:42,343 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e13507f61c604318bd0ee7b7f51e3594, keycount=137094, bloomtype=ROW, size=97.6m, encoding=NONE, seqNum=11131
2014-07-13 23:46:42,731 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:42,761 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=22079, memsize=302.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/b67eff8ee4bd4caab1cf426b653025da
2014-07-13 23:46:42,790 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69858 synced till here 69855
2014-07-13 23:46:42,816 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/b67eff8ee4bd4caab1cf426b653025da as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b67eff8ee4bd4caab1cf426b653025da
2014-07-13 23:46:42,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320401428 with entries=62, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320402732
2014-07-13 23:46:42,911 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b67eff8ee4bd4caab1cf426b653025da, entries=1101880, sequenceid=22079, filesize=78.4m
2014-07-13 23:46:42,912 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~728.4m/763808960, currentsize=221.4m/232128960 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 16718ms, sequenceid=22079, compaction requested=true
2014-07-13 23:46:42,912 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:126), split_queue=0, merge_queue=0
2014-07-13 23:46:42,912 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 653.4m
2014-07-13 23:46:42,996 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:46:43,820 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:46:44,251 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:44,257 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:46:44,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69968 synced till here 69967
2014-07-13 23:46:44,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320402732 with entries=110, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320404251
2014-07-13 23:46:44,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320275428
2014-07-13 23:46:44,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320284184
2014-07-13 23:46:47,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:47,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70055 synced till here 70036
2014-07-13 23:46:47,933 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320404251 with entries=87, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320407728
2014-07-13 23:46:49,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:49,276 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70141 synced till here 70123
2014-07-13 23:46:49,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320407728 with entries=86, filesize=79.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320409183
2014-07-13 23:46:50,515 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:50,545 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70220 synced till here 70218
2014-07-13 23:46:50,570 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320409183 with entries=79, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320410516
2014-07-13 23:46:51,756 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:51,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70322 synced till here 70316
2014-07-13 23:46:51,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320410516 with entries=102, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320411757
2014-07-13 23:46:53,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:53,522 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70427 synced till here 70393
2014-07-13 23:46:53,771 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320411757 with entries=105, filesize=85.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320413402
2014-07-13 23:46:55,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:55,540 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70518 synced till here 70500
2014-07-13 23:46:55,701 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320413402 with entries=91, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320415483
2014-07-13 23:46:56,076 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15786, memsize=290.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/4666811acafa4911b03cae899a7f313b
2014-07-13 23:46:56,101 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/4666811acafa4911b03cae899a7f313b as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4666811acafa4911b03cae899a7f313b
2014-07-13 23:46:56,125 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/4666811acafa4911b03cae899a7f313b, entries=1056900, sequenceid=15786, filesize=75.2m
2014-07-13 23:46:56,126 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~733.9m/769585280, currentsize=452.6m/474631040 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 20237ms, sequenceid=15786, compaction requested=true
2014-07-13 23:46:56,126 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:127), split_queue=0, merge_queue=0
2014-07-13 23:46:56,127 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.1g
2014-07-13 23:46:56,171 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:46:57,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:57,449 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70630 synced till here 70607
2014-07-13 23:46:57,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320415483 with entries=112, filesize=79.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320417401
2014-07-13 23:46:57,787 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320285775
2014-07-13 23:46:57,787 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320289330
2014-07-13 23:46:59,381 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:46:59,423 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:46:59,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70712 synced till here 70696
2014-07-13 23:46:59,518 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320417401 with entries=82, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320419382
2014-07-13 23:47:00,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:00,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70769 synced till here 70768
2014-07-13 23:47:00,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320419382 with entries=57, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320420693
2014-07-13 23:47:02,173 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:02,222 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70837 synced till here 70831
2014-07-13 23:47:02,303 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320420693 with entries=68, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320422174
2014-07-13 23:47:03,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:04,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70907 synced till here 70900
2014-07-13 23:47:04,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320422174 with entries=70, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320423968
2014-07-13 23:47:04,447 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15879, memsize=326.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/8461b8834bd5443b80ac5da2633516c7
2014-07-13 23:47:04,460 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/8461b8834bd5443b80ac5da2633516c7 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/8461b8834bd5443b80ac5da2633516c7
2014-07-13 23:47:05,300 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/8461b8834bd5443b80ac5da2633516c7, entries=1187240, sequenceid=15879, filesize=84.5m
2014-07-13 23:47:05,301 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~655.7m/687530320, currentsize=469.4m/492181360 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 22389ms, sequenceid=15879, compaction requested=true
2014-07-13 23:47:05,302 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:128), split_queue=0, merge_queue=0
2014-07-13 23:47:05,302 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 558.4m
2014-07-13 23:47:05,305 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:47:05,357 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:05,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70971 synced till here 70970
2014-07-13 23:47:05,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320423968 with entries=64, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320425357
2014-07-13 23:47:05,795 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:47:06,122 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:06,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71040 synced till here 71037
2014-07-13 23:47:06,199 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320425357 with entries=69, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320426123
2014-07-13 23:47:07,546 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:08,178 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320426123 with entries=89, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320427546
2014-07-13 23:47:08,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:09,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71243 synced till here 71226
2014-07-13 23:47:09,781 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320427546 with entries=114, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320428922
2014-07-13 23:47:11,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:11,447 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71349 synced till here 71332
2014-07-13 23:47:11,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320428922 with entries=106, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320431424
2014-07-13 23:47:13,450 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:13,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71456 synced till here 71431
2014-07-13 23:47:13,703 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320431424 with entries=107, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320433451
2014-07-13 23:47:15,070 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:15,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71560 synced till here 71544
2014-07-13 23:47:15,335 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320433451 with entries=104, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320435070
2014-07-13 23:47:16,937 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:16,951 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71643 synced till here 71632
2014-07-13 23:47:17,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320435070 with entries=83, filesize=75.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320436937
2014-07-13 23:47:17,213 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,213 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,221 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,222 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,226 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,243 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,261 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,278 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,302 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,332 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,416 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,461 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,510 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,565 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,615 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,662 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,705 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:17,709 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,299 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,304 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,305 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,307 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,316 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,318 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,321 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,346 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,392 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,393 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,406 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,406 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,406 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,408 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,422 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,430 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,432 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,477 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,522 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,565 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,567 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,605 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,605 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,606 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,618 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,631 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,633 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,684 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,685 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,685 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,688 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:18,725 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:47:22,213 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,213 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,221 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,223 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:22,226 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,244 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:22,261 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,279 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,303 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:22,332 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,417 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,461 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,510 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,566 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:22,615 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,663 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:22,705 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:22,709 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,300 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,304 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,305 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,308 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,316 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,318 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,321 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,346 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,392 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,393 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,406 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,406 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,407 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,409 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,422 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,431 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,433 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,477 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,523 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,565 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,568 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,606 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,606 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,608 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,618 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,631 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,633 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,684 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,686 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,686 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:47:23,688 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:23,725 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:47:27,212 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=22793, memsize=434.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/aacd5ba5ddea41a191998a614540c516
2014-07-13 23:47:27,214 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:47:27,214 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:47:27,223 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:47:27,224 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:47:27,227 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:47:27,232 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/aacd5ba5ddea41a191998a614540c516 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/aacd5ba5ddea41a191998a614540c516
2014-07-13 23:47:27,244 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:47:27,250 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/aacd5ba5ddea41a191998a614540c516, entries=1580800, sequenceid=22793, filesize=112.6m
2014-07-13 23:47:27,251 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~560.9m/588158720, currentsize=182.0m/190880720 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 21949ms, sequenceid=22793, compaction requested=true
2014-07-13 23:47:27,251 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:129), split_queue=0, merge_queue=0
2014-07-13 23:47:27,251 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-13 23:47:27,251 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files; delaying flush up to 90000ms
2014-07-13 23:47:27,251 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,252 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:130), split_queue=0, merge_queue=0
2014-07-13 23:47:27,252 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10026ms
2014-07-13 23:47:27,252 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,252 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10030ms
2014-07-13 23:47:27,252 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,252 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10031ms
2014-07-13 23:47:27,252 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,252 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 755.1m
2014-07-13 23:47:27,252 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10039ms
2014-07-13 23:47:27,252 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,252 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10039ms
2014-07-13 23:47:27,252 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,253 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8528ms
2014-07-13 23:47:27,253 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,254 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8566ms
2014-07-13 23:47:27,255 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,260 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8575ms
2014-07-13 23:47:27,260 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,260 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437220,"queuetimems":0,"class":"HRegionServer","responsesize":183,"method":"Multi"}
2014-07-13 23:47:27,262 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:47:27,262 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,265 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8580ms
2014-07-13 23:47:27,265 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,279 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:47:27,279 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,282 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8598ms
2014-07-13 23:47:27,282 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,282 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8649ms
2014-07-13 23:47:27,282 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,283 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8651ms
2014-07-13 23:47:27,283 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,283 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8665ms
2014-07-13 23:47:27,283 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,287 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8681ms
2014-07-13 23:47:27,287 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,288 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8683ms
2014-07-13 23:47:27,288 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,290 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8685ms
2014-07-13 23:47:27,290 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,291 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8724ms
2014-07-13 23:47:27,291 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,291 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8726ms
2014-07-13 23:47:27,291 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,291 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8769ms
2014-07-13 23:47:27,291 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,296 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8820ms
2014-07-13 23:47:27,296 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,296 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8864ms
2014-07-13 23:47:27,296 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,296 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8866ms
2014-07-13 23:47:27,296 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,301 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8879ms
2014-07-13 23:47:27,301 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,304 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:47:27,304 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,309 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8901ms
2014-07-13 23:47:27,309 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,313 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8907ms
2014-07-13 23:47:27,313 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,314 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8907ms
2014-07-13 23:47:27,314 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,314 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8908ms
2014-07-13 23:47:27,314 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,315 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8922ms
2014-07-13 23:47:27,315 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,315 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8923ms
2014-07-13 23:47:27,315 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,316 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8970ms
2014-07-13 23:47:27,316 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,321 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9001ms
2014-07-13 23:47:27,321 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,322 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9003ms
2014-07-13 23:47:27,322 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,331 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9014ms
2014-07-13 23:47:27,331 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,331 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9024ms
2014-07-13 23:47:27,332 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,332 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10430,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320436901,"queuetimems":0,"class":"HRegionServer","responsesize":17969,"method":"Multi"}
2014-07-13 23:47:27,333 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:47:27,333 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,333 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9028ms
2014-07-13 23:47:27,333 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,333 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9029ms
2014-07-13 23:47:27,334 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,338 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9038ms
2014-07-13 23:47:27,338 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,339 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9629ms
2014-07-13 23:47:27,339 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,345 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9640ms
2014-07-13 23:47:27,345 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,353 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9691ms
2014-07-13 23:47:27,353 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,353 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9738ms
2014-07-13 23:47:27,353 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,360 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9795ms
2014-07-13 23:47:27,360 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,360 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9850ms
2014-07-13 23:47:27,360 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,361 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9899ms
2014-07-13 23:47:27,361 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,361 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9945ms
2014-07-13 23:47:27,361 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:47:27,407 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320436957,"queuetimems":1,"class":"HRegionServer","responsesize":18317,"method":"Multi"}
2014-07-13 23:47:27,459 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10239,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437220,"queuetimems":0,"class":"HRegionServer","responsesize":3902,"method":"Multi"}
2014-07-13 23:47:27,466 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10420,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437045,"queuetimems":0,"class":"HRegionServer","responsesize":18602,"method":"Multi"}
2014-07-13 23:47:27,564 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10464,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437099,"queuetimems":1,"class":"HRegionServer","responsesize":18318,"method":"Multi"}
2014-07-13 23:47:27,698 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10486,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437212,"queuetimems":0,"class":"HRegionServer","responsesize":1367,"method":"Multi"}
2014-07-13 23:47:27,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:27,959 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10810,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437147,"queuetimems":0,"class":"HRegionServer","responsesize":17892,"method":"Multi"}
2014-07-13 23:47:27,965 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10261,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437704,"queuetimems":1,"class":"HRegionServer","responsesize":1502,"method":"Multi"}
2014-07-13 23:47:27,966 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10257,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437709,"queuetimems":0,"class":"HRegionServer","responsesize":1679,"method":"Multi"}
2014-07-13 23:47:27,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71757 synced till here 71734
2014-07-13 23:47:29,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320436937 with entries=114, filesize=92.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320447952
2014-07-13 23:47:29,295 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:47:29,666 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16022, memsize=486.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/3ad03d064c62453ebc44d4e4078facd2
2014-07-13 23:47:29,678 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/3ad03d064c62453ebc44d4e4078facd2 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3ad03d064c62453ebc44d4e4078facd2
2014-07-13 23:47:29,688 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3ad03d064c62453ebc44d4e4078facd2, entries=1771930, sequenceid=16022, filesize=126.1m
2014-07-13 23:47:29,688 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1231507680, currentsize=512.1m/536949040 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 33561ms, sequenceid=16022, compaction requested=true
2014-07-13 23:47:29,689 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-13 23:47:29,831 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12620,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437211,"queuetimems":0,"class":"HRegionServer","responsesize":11768,"method":"Multi"}
2014-07-13 23:47:29,832 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:47:29,832 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. has too many store files; delaying flush up to 90000ms
2014-07-13 23:47:29,832 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:132), split_queue=0, merge_queue=0
2014-07-13 23:47:29,838 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12563,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437274,"queuetimems":0,"class":"HRegionServer","responsesize":18351,"method":"Multi"}
2014-07-13 23:47:29,838 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12424,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437413,"queuetimems":0,"class":"HRegionServer","responsesize":18436,"method":"Multi"}
2014-07-13 23:47:30,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:30,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71850 synced till here 71821
2014-07-13 23:47:31,242 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13679,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437562,"queuetimems":0,"class":"HRegionServer","responsesize":18255,"method":"Multi"}
2014-07-13 23:47:31,247 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438390,"queuetimems":0,"class":"HRegionServer","responsesize":17594,"method":"Multi"}
2014-07-13 23:47:31,251 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13742,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437507,"queuetimems":0,"class":"HRegionServer","responsesize":18256,"method":"Multi"}
2014-07-13 23:47:31,253 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12779,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438474,"queuetimems":1,"class":"HRegionServer","responsesize":16373,"method":"Multi"}
2014-07-13 23:47:31,253 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12649,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438604,"queuetimems":0,"class":"HRegionServer","responsesize":15953,"method":"Multi"}
2014-07-13 23:47:31,254 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12691,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438563,"queuetimems":1,"class":"HRegionServer","responsesize":17667,"method":"Multi"}
2014-07-13 23:47:31,257 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13645,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437612,"queuetimems":0,"class":"HRegionServer","responsesize":17837,"method":"Multi"}
2014-07-13 23:47:31,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320447952 with entries=93, filesize=83.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320450049
2014-07-13 23:47:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320290778
2014-07-13 23:47:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320312170
2014-07-13 23:47:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320315871
2014-07-13 23:47:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320318186
2014-07-13 23:47:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320320160
2014-07-13 23:47:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320321991
2014-07-13 23:47:31,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320324237
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320367712
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320369722
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320371444
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320373001
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320374561
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320376293
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320378104
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320380142
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320386314
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320387842
2014-07-13 23:47:31,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320389490
2014-07-13 23:47:31,637 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:47:31,638 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 256.7m
2014-07-13 23:47:31,855 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:47:31,913 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14254,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437659,"queuetimems":0,"class":"HRegionServer","responsesize":15500,"method":"Multi"}
2014-07-13 23:47:31,930 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13410,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438519,"queuetimems":0,"class":"HRegionServer","responsesize":18631,"method":"Multi"}
2014-07-13 23:47:31,930 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13206,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438723,"queuetimems":0,"class":"HRegionServer","responsesize":15789,"method":"Multi"}
2014-07-13 23:47:31,937 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13254,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438683,"queuetimems":1,"class":"HRegionServer","responsesize":16082,"method":"Multi"}
2014-07-13 23:47:31,945 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14243,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437702,"queuetimems":0,"class":"HRegionServer","responsesize":17824,"method":"Multi"}
2014-07-13 23:47:31,946 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14488,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320437458,"queuetimems":0,"class":"HRegionServer","responsesize":18542,"method":"Multi"}
2014-07-13 23:47:31,947 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13604,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438342,"queuetimems":0,"class":"HRegionServer","responsesize":12562,"method":"Multi"}
2014-07-13 23:47:31,953 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320438316,"queuetimems":1,"class":"HRegionServer","responsesize":15752,"method":"Multi"}
2014-07-13 23:47:33,547 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:33,919 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71967 synced till here 71953
2014-07-13 23:47:34,084 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320450049 with entries=117, filesize=111.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320453729
2014-07-13 23:47:35,779 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:35,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72076 synced till here 72043
2014-07-13 23:47:36,073 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320453729 with entries=109, filesize=98.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320455780
2014-07-13 23:47:38,191 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:38,305 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72173 synced till here 72146
2014-07-13 23:47:39,524 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320455780 with entries=97, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320458191
2014-07-13 23:47:40,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:41,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72293 synced till here 72259
2014-07-13 23:47:41,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320458191 with entries=120, filesize=103.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320460424
2014-07-13 23:47:43,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:43,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72415 synced till here 72385
2014-07-13 23:47:43,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320460424 with entries=122, filesize=106.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320463432
2014-07-13 23:47:44,533 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=23115, memsize=181.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/6104660eaa6248bb84b7dee4c93971a9
2014-07-13 23:47:44,556 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/6104660eaa6248bb84b7dee4c93971a9 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6104660eaa6248bb84b7dee4c93971a9
2014-07-13 23:47:44,570 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6104660eaa6248bb84b7dee4c93971a9, entries=660950, sequenceid=23115, filesize=47.1m
2014-07-13 23:47:44,570 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.8m/275567440, currentsize=178.0m/186673120 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 12932ms, sequenceid=23115, compaction requested=true
2014-07-13 23:47:44,570 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-13 23:47:59,725 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 22090ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:47:59,726 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 22091ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:47:59,727 WARN  [regionserver60020] util.Sleeper: We slept 16427ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 23:47:59,727 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14104ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=14593ms
2014-07-13 23:47:59,983 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:47:59,990 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17626,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462363,"queuetimems":2675,"class":"HRegionServer","responsesize":16373,"method":"Multi"}
2014-07-13 23:47:59,990 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66450 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.53:47040: output error
2014-07-13 23:47:59,993 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:47:59,997 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17924,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462073,"queuetimems":4568,"class":"HRegionServer","responsesize":16060,"method":"Multi"}
2014-07-13 23:47:59,997 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17941,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462056,"queuetimems":5965,"class":"HRegionServer","responsesize":18542,"method":"Multi"}
2014-07-13 23:47:59,998 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66431 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47040: output error
2014-07-13 23:47:59,998 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:47:59,998 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66427 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:47:59,998 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:47:59,999 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17933,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462065,"queuetimems":4794,"class":"HRegionServer","responsesize":15500,"method":"Multi"}
2014-07-13 23:47:59,999 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66424 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47040: output error
2014-07-13 23:47:59,999 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72505 synced till here 72481
2014-07-13 23:48:00,158 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17795,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462363,"queuetimems":2706,"class":"HRegionServer","responsesize":17892,"method":"Multi"}
2014-07-13 23:48:00,158 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17630,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462528,"queuetimems":2616,"class":"HRegionServer","responsesize":18318,"method":"Multi"}
2014-07-13 23:48:00,158 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462529,"queuetimems":2588,"class":"HRegionServer","responsesize":15440,"method":"Multi"}
2014-07-13 23:48:00,159 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66451 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,159 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,159 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17631,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462528,"queuetimems":2714,"class":"HRegionServer","responsesize":15500,"method":"Multi"}
2014-07-13 23:48:00,160 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66445 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,160 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,160 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66442 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,160 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,160 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66441 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,160 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,161 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17633,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462528,"queuetimems":2652,"class":"HRegionServer","responsesize":15953,"method":"Multi"}
2014-07-13 23:48:00,161 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66443 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,161 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,234 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17705,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462528,"queuetimems":2682,"class":"HRegionServer","responsesize":17667,"method":"Multi"}
2014-07-13 23:48:00,235 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66444 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,235 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,235 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17699,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462536,"queuetimems":2540,"class":"HRegionServer","responsesize":17594,"method":"Multi"}
2014-07-13 23:48:00,236 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462528,"queuetimems":2749,"class":"HRegionServer","responsesize":18255,"method":"Multi"}
2014-07-13 23:48:00,236 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66439 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,236 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,237 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17698,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462538,"queuetimems":2429,"class":"HRegionServer","responsesize":17837,"method":"Multi"}
2014-07-13 23:48:00,237 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66437 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,237 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,238 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17700,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462537,"queuetimems":2478,"class":"HRegionServer","responsesize":17969,"method":"Multi"}
2014-07-13 23:48:00,238 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66438 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,238 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,239 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17708,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462530,"queuetimems":2567,"class":"HRegionServer","responsesize":11757,"method":"Multi"}
2014-07-13 23:48:00,239 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66440 service: ClientService methodName: Multi size: 2.1m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,239 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,239 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66446 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,239 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,240 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17713,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462527,"queuetimems":2782,"class":"HRegionServer","responsesize":11768,"method":"Multi"}
2014-07-13 23:48:00,240 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66448 service: ClientService methodName: Multi size: 2.1m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,240 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,241 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17871,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462370,"queuetimems":2647,"class":"HRegionServer","responsesize":18631,"method":"Multi"}
2014-07-13 23:48:00,241 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66449 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,241 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320463432 with entries=90, filesize=94.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320479983
2014-07-13 23:48:00,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:00,518 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17969,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320462548,"queuetimems":2386,"class":"HRegionServer","responsesize":16082,"method":"Multi"}
2014-07-13 23:48:00,519 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66493 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,519 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:00,525 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17092,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320463433,"queuetimems":3146,"class":"HRegionServer","responsesize":15752,"method":"Multi"}
2014-07-13 23:48:00,526 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66484 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:00,526 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,498 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17151,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464347,"queuetimems":2776,"class":"HRegionServer","responsesize":18256,"method":"Multi"}
2014-07-13 23:48:01,499 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66500 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,499 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,501 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17154,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464347,"queuetimems":2814,"class":"HRegionServer","responsesize":18436,"method":"Multi"}
2014-07-13 23:48:01,502 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66496 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,502 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,667 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17721,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320463945,"queuetimems":3516,"class":"HRegionServer","responsesize":12562,"method":"Multi"}
2014-07-13 23:48:01,667 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66466 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,667 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,673 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17319,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464354,"queuetimems":2692,"class":"HRegionServer","responsesize":18542,"method":"Multi"}
2014-07-13 23:48:01,673 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17743,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320463929,"queuetimems":3535,"class":"HRegionServer","responsesize":15379,"method":"Multi"}
2014-07-13 23:48:01,673 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66498 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,673 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,673 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66468 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,673 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17320,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464353,"queuetimems":2725,"class":"HRegionServer","responsesize":18602,"method":"Multi"}
2014-07-13 23:48:01,673 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66499 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464361,"queuetimems":2617,"class":"HRegionServer","responsesize":18317,"method":"Multi"}
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464361,"queuetimems":2655,"class":"HRegionServer","responsesize":18351,"method":"Multi"}
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17305,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464369,"queuetimems":735,"class":"HRegionServer","responsesize":15186,"method":"Multi"}
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66503 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66497 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,674 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,675 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66507 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,675 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,845 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:01,847 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17484,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47040","starttimems":1405320464362,"queuetimems":966,"class":"HRegionServer","responsesize":15789,"method":"Multi"}
2014-07-13 23:48:01,847 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66506 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,847 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,848 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66510 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,848 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,849 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 66523 service: ClientService methodName: Multi size: 3.2m connection: 9.1.143.53:47040: output error
2014-07-13 23:48:01,849 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 23:48:01,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72600 synced till here 72593
2014-07-13 23:48:01,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320479983 with entries=95, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320481846
2014-07-13 23:48:01,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:03,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:03,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320481846 with entries=70, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320483714
2014-07-13 23:48:03,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:04,905 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:48:04,906 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 256.5m
2014-07-13 23:48:05,111 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:48:06,227 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:06,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320483714 with entries=102, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320486228
2014-07-13 23:48:06,262 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:07,519 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16276, memsize=389.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/8a95f80d56f14b10a8cfa1cf2800c739
2014-07-13 23:48:07,539 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/8a95f80d56f14b10a8cfa1cf2800c739 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/8a95f80d56f14b10a8cfa1cf2800c739
2014-07-13 23:48:07,553 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/8a95f80d56f14b10a8cfa1cf2800c739, entries=1418780, sequenceid=16276, filesize=101.1m
2014-07-13 23:48:07,554 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~755.1m/791732080, currentsize=491.9m/515764560 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 40302ms, sequenceid=16276, compaction requested=true
2014-07-13 23:48:07,554 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:134), split_queue=0, merge_queue=0
2014-07-13 23:48:07,616 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:48:07,616 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. has too many store files; delaying flush up to 90000ms
2014-07-13 23:48:07,616 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:135), split_queue=0, merge_queue=0
2014-07-13 23:48:07,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:07,712 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72831 synced till here 72829
2014-07-13 23:48:07,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320486228 with entries=59, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320487698
2014-07-13 23:48:07,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:08,315 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=23427, memsize=69.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/7f65ad6bcec3484c8b6a6cd7cbeae507
2014-07-13 23:48:08,329 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/7f65ad6bcec3484c8b6a6cd7cbeae507 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f65ad6bcec3484c8b6a6cd7cbeae507
2014-07-13 23:48:08,440 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f65ad6bcec3484c8b6a6cd7cbeae507, entries=251990, sequenceid=23427, filesize=18.0m
2014-07-13 23:48:08,440 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268946240, currentsize=40.5m/42479120 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 3534ms, sequenceid=23427, compaction requested=true
2014-07-13 23:48:08,441 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-13 23:48:08,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:08,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320487698 with entries=86, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320488883
2014-07-13 23:48:08,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:10,171 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:10,569 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73039 synced till here 73038
2014-07-13 23:48:10,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320488883 with entries=122, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320490171
2014-07-13 23:48:10,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:11,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:11,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73115 synced till here 73112
2014-07-13 23:48:11,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320490171 with entries=76, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320491921
2014-07-13 23:48:11,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:13,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:13,450 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73213 synced till here 73205
2014-07-13 23:48:13,920 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320491921 with entries=98, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320493218
2014-07-13 23:48:13,920 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:14,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:15,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73308 synced till here 73290
2014-07-13 23:48:15,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320493218 with entries=95, filesize=86.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320494935
2014-07-13 23:48:15,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:16,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:16,496 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320494935 with entries=110, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320496370
2014-07-13 23:48:16,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:18,549 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:18,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73508 synced till here 73501
2014-07-13 23:48:19,275 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320496370 with entries=90, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320498550
2014-07-13 23:48:19,276 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 8b827125b32700e6f7c5c34f77be22cb
2014-07-13 23:48:19,409 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 23:48:19,409 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files, but is 1.6g vs best flushable region's 236.0m. Choosing the bigger.
2014-07-13 23:48:19,409 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. due to global heap pressure
2014-07-13 23:48:19,410 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 1.6g
2014-07-13 23:48:20,850 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:48:26,508 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90337ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:48:26,509 DEBUG [MemStoreFlusher.1] regionserver.HRegion: NOT flushing memstore for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., flushing=true, writesEnabled=true
2014-07-13 23:48:27,127 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 23:48:27,128 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. has too many store files, but is 1.2g vs best flushable region's 239.4m. Choosing the bigger.
2014-07-13 23:48:27,128 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. due to global heap pressure
2014-07-13 23:48:27,128 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.2g
2014-07-13 23:48:27,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:27,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320498550 with entries=86, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320507563
2014-07-13 23:48:27,989 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:48:28,519 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:48:28,938 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,948 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,959 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,967 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,976 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,981 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,983 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,985 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:28,987 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,043 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,060 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,108 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,156 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,209 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,210 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,219 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,234 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,254 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,268 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,321 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,324 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,405 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,440 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,610 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,625 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,629 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,647 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,654 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,675 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,710 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,747 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,798 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,798 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,799 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,818 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/19dcfdf8f6c64c2a9c9cd56e908aedec as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/19dcfdf8f6c64c2a9c9cd56e908aedec
2014-07-13 23:48:29,827 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,831 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:48:29,839 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7e5d3fff04da41988deff0b1a02f6386, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/7e5d3fff04da41988deff0b1a02f6386
2014-07-13 23:48:29,841 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/cf617cd67d524475972a1c6e0bc38805, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/cf617cd67d524475972a1c6e0bc38805
2014-07-13 23:48:29,844 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/c9b3498c0ff04d879301e2571d51d952, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/c9b3498c0ff04d879301e2571d51d952
2014-07-13 23:48:29,845 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e13507f61c604318bd0ee7b7f51e3594, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e13507f61c604318bd0ee7b7f51e3594
2014-07-13 23:48:29,846 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into 19dcfdf8f6c64c2a9c9cd56e908aedec(size=424.8m), total size for store is 3.7g. This selection was in queue for 0sec, and took 1mins, 47sec to execute.
2014-07-13 23:48:29,846 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., storeName=family, fileCount=4, fileSize=447.6m, priority=0, time=274309769593203; duration=1mins, 47sec
2014-07-13 23:48:29,846 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-13 23:48:29,846 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 23:48:29,847 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,848 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,848 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 344807753 starting at candidate #4 after considering 124 permutations with 116 in ratio
2014-07-13 23:48:29,848 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: d679c2853f294b83582eebcd030d1677 - family: Initiating minor compaction
2014-07-13 23:48:29,848 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:48:29,848 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp, totalSize=328.8m
2014-07-13 23:48:29,849 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1c9e56e057834d75a9ee429a0a1490ba, keycount=155230, bloomtype=ROW, size=110.5m, encoding=NONE, seqNum=7073
2014-07-13 23:48:29,849 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e9aa8d1b81541c2b3b39a6e71fa6be0, keycount=155889, bloomtype=ROW, size=110.9m, encoding=NONE, seqNum=7621
2014-07-13 23:48:29,849 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/31e7f2f1eae14ea19e41a7760de9c560, keycount=150763, bloomtype=ROW, size=107.4m, encoding=NONE, seqNum=8099
2014-07-13 23:48:29,850 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,872 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,897 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,949 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,958 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,972 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,972 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:48:29,972 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,976 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,977 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:29,994 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:30,006 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:30,008 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:30,008 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:48:33,938 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:33,948 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:33,959 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:33,967 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:33,976 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:33,981 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:33,983 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:33,986 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:33,987 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,044 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,061 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,108 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,157 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,210 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,210 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,219 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,234 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,254 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,268 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,322 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,324 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,405 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,440 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,611 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,626 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,629 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,647 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,654 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:34,676 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:48:34,710 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:48:35,232 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5224ms
2014-07-13 23:48:35,233 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5284ms
2014-07-13 23:48:35,233 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5275ms
2014-07-13 23:48:35,233 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5386ms
2014-07-13 23:48:35,233 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5386ms
2014-07-13 23:48:35,234 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5263ms
2014-07-13 23:48:35,234 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5257ms
2014-07-13 23:48:35,234 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5262ms
2014-07-13 23:48:35,234 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5258ms
2014-07-13 23:48:35,234 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5241ms
2014-07-13 23:48:35,235 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5229ms
2014-07-13 23:48:35,235 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5227ms
2014-07-13 23:48:35,235 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5488ms
2014-07-13 23:48:35,241 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5444ms
2014-07-13 23:48:35,241 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5443ms
2014-07-13 23:48:35,241 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5414ms
2014-07-13 23:48:35,242 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5442ms
2014-07-13 23:48:35,242 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5370ms
2014-07-13 23:48:35,242 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5392ms
2014-07-13 23:48:35,242 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5345ms
2014-07-13 23:48:38,939 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:38,949 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:38,959 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:38,968 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:38,977 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:38,981 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:38,983 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:38,986 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:38,987 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:39,044 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,061 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,109 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,157 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,210 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,210 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,219 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:39,234 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:39,255 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,269 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:39,322 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:48:39,325 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:48:39,923 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10213ms
2014-07-13 23:48:39,923 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10518ms
2014-07-13 23:48:39,924 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10249ms
2014-07-13 23:48:39,925 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10486ms
2014-07-13 23:48:39,925 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10315ms
2014-07-13 23:48:39,925 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10300ms
2014-07-13 23:48:39,925 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10297ms
2014-07-13 23:48:39,925 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10271ms
2014-07-13 23:48:39,925 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10278ms
2014-07-13 23:48:40,233 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10225ms
2014-07-13 23:48:40,233 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10275ms
2014-07-13 23:48:40,234 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10285ms
2014-07-13 23:48:40,235 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10387ms
2014-07-13 23:48:40,235 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10242ms
2014-07-13 23:48:40,235 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10259ms
2014-07-13 23:48:40,235 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10263ms
2014-07-13 23:48:40,235 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10264ms
2014-07-13 23:48:40,236 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10389ms
2014-07-13 23:48:40,237 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10490ms
2014-07-13 23:48:40,237 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10229ms
2014-07-13 23:48:40,238 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10232ms
2014-07-13 23:48:40,238 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10261ms
2014-07-13 23:48:40,241 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10444ms
2014-07-13 23:48:40,242 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10443ms
2014-07-13 23:48:40,242 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10415ms
2014-07-13 23:48:40,242 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10443ms
2014-07-13 23:48:40,243 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10370ms
2014-07-13 23:48:40,243 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10346ms
2014-07-13 23:48:40,244 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10393ms
2014-07-13 23:48:44,219 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15009ms
2014-07-13 23:48:44,219 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15281ms
2014-07-13 23:48:44,219 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15271ms
2014-07-13 23:48:44,220 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15261ms
2014-07-13 23:48:44,220 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15253ms
2014-07-13 23:48:44,221 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15245ms
2014-07-13 23:48:44,221 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15240ms
2014-07-13 23:48:44,221 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15238ms
2014-07-13 23:48:44,221 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15236ms
2014-07-13 23:48:44,221 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15234ms
2014-07-13 23:48:44,221 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15178ms
2014-07-13 23:48:44,222 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15161ms
2014-07-13 23:48:44,222 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15114ms
2014-07-13 23:48:44,222 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15066ms
2014-07-13 23:48:44,222 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15013ms
2014-07-13 23:48:44,222 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 23:48:44,235 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:48:44,256 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:48:44,269 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:48:44,322 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:48:44,325 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:48:44,923 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15213ms
2014-07-13 23:48:44,924 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15519ms
2014-07-13 23:48:44,925 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15249ms
2014-07-13 23:48:44,925 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15486ms
2014-07-13 23:48:44,925 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15315ms
2014-07-13 23:48:44,926 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15300ms
2014-07-13 23:48:44,926 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15279ms
2014-07-13 23:48:44,927 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15273ms
2014-07-13 23:48:44,927 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15299ms
2014-07-13 23:48:45,233 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15225ms
2014-07-13 23:48:45,234 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15276ms
2014-07-13 23:48:45,234 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15285ms
2014-07-13 23:48:45,235 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15388ms
2014-07-13 23:48:45,235 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15242ms
2014-07-13 23:48:45,235 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15259ms
2014-07-13 23:48:45,236 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15264ms
2014-07-13 23:48:45,237 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15265ms
2014-07-13 23:48:45,237 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15390ms
2014-07-13 23:48:45,238 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15491ms
2014-07-13 23:48:45,238 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15230ms
2014-07-13 23:48:45,238 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15232ms
2014-07-13 23:48:45,239 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15262ms
2014-07-13 23:48:45,241 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15444ms
2014-07-13 23:48:45,242 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15444ms
2014-07-13 23:48:45,242 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15415ms
2014-07-13 23:48:45,242 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15443ms
2014-07-13 23:48:45,243 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15371ms
2014-07-13 23:48:45,244 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15346ms
2014-07-13 23:48:45,244 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15394ms
2014-07-13 23:48:49,219 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20010ms
2014-07-13 23:48:49,220 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20261ms
2014-07-13 23:48:49,220 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20272ms
2014-07-13 23:48:49,220 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20282ms
2014-07-13 23:48:49,221 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20254ms
2014-07-13 23:48:49,221 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20245ms
2014-07-13 23:48:49,221 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20240ms
2014-07-13 23:48:49,221 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20238ms
2014-07-13 23:48:49,221 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20236ms
2014-07-13 23:48:49,222 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20234ms
2014-07-13 23:48:49,222 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20179ms
2014-07-13 23:48:49,222 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20162ms
2014-07-13 23:48:49,222 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20066ms
2014-07-13 23:48:49,222 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20114ms
2014-07-13 23:48:49,222 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 23:48:49,223 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20013ms
2014-07-13 23:48:49,235 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:48:49,256 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:48:49,269 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:48:49,323 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:48:49,325 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:48:49,924 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20214ms
2014-07-13 23:48:49,924 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20519ms
2014-07-13 23:48:49,925 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20250ms
2014-07-13 23:48:49,926 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20486ms
2014-07-13 23:48:49,926 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20316ms
2014-07-13 23:48:49,926 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20301ms
2014-07-13 23:48:49,927 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20280ms
2014-07-13 23:48:49,927 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20273ms
2014-07-13 23:48:49,927 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20299ms
2014-07-13 23:48:50,234 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20226ms
2014-07-13 23:48:50,234 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20285ms
2014-07-13 23:48:50,234 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20276ms
2014-07-13 23:48:50,236 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20388ms
2014-07-13 23:48:50,236 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20264ms
2014-07-13 23:48:50,236 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20260ms
2014-07-13 23:48:50,237 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20244ms
2014-07-13 23:48:50,237 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20266ms
2014-07-13 23:48:50,238 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20391ms
2014-07-13 23:48:50,238 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20491ms
2014-07-13 23:48:50,238 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20230ms
2014-07-13 23:48:50,239 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20233ms
2014-07-13 23:48:50,239 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20262ms
2014-07-13 23:48:50,241 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20444ms
2014-07-13 23:48:50,242 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20444ms
2014-07-13 23:48:50,243 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20415ms
2014-07-13 23:48:50,243 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20444ms
2014-07-13 23:48:50,244 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20372ms
2014-07-13 23:48:50,244 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20347ms
2014-07-13 23:48:50,244 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20394ms
2014-07-13 23:48:50,770 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16671, memsize=531.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/decdfd07268a4c1d9375a9059ec74930
2014-07-13 23:48:50,789 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/decdfd07268a4c1d9375a9059ec74930 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/decdfd07268a4c1d9375a9059ec74930
2014-07-13 23:48:50,809 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/decdfd07268a4c1d9375a9059ec74930, entries=1935760, sequenceid=16671, filesize=137.9m
2014-07-13 23:48:50,810 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.2g/1277034800, currentsize=41.4m/43383360 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 23682ms, sequenceid=16671, compaction requested=true
2014-07-13 23:48:50,810 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-13 23:48:50,810 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20960ms
2014-07-13 23:48:50,810 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,811 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20914ms
2014-07-13 23:48:50,811 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 265.7m
2014-07-13 23:48:50,811 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,811 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20939ms
2014-07-13 23:48:50,811 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,813 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21014ms
2014-07-13 23:48:50,813 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,813 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20986ms
2014-07-13 23:48:50,813 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,813 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21015ms
2014-07-13 23:48:50,813 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,813 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21016ms
2014-07-13 23:48:50,813 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,814 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20837ms
2014-07-13 23:48:50,814 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,819 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20813ms
2014-07-13 23:48:50,819 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,819 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20811ms
2014-07-13 23:48:50,819 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,819 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21072ms
2014-07-13 23:48:50,820 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,820 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20973ms
2014-07-13 23:48:50,820 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,820 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20849ms
2014-07-13 23:48:50,820 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,820 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20827ms
2014-07-13 23:48:50,820 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,821 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20845ms
2014-07-13 23:48:50,821 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,821 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20849ms
2014-07-13 23:48:50,821 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,822 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20975ms
2014-07-13 23:48:50,822 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,822 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20864ms
2014-07-13 23:48:50,822 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,822 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20873ms
2014-07-13 23:48:50,822 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,823 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20815ms
2014-07-13 23:48:50,823 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,828 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21200ms
2014-07-13 23:48:50,828 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,829 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21175ms
2014-07-13 23:48:50,829 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,829 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21182ms
2014-07-13 23:48:50,829 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,829 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21204ms
2014-07-13 23:48:50,829 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,830 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21220ms
2014-07-13 23:48:50,830 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,830 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21391ms
2014-07-13 23:48:50,830 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,833 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21158ms
2014-07-13 23:48:50,833 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,841 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21436ms
2014-07-13 23:48:50,841 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,842 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21132ms
2014-07-13 23:48:50,842 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,842 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21518ms
2014-07-13 23:48:50,842 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,842 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21521ms
2014-07-13 23:48:50,842 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,842 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21574ms
2014-07-13 23:48:50,842 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,843 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21588ms
2014-07-13 23:48:50,843 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,843 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21609ms
2014-07-13 23:48:50,843 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,845 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21636ms
2014-07-13 23:48:50,845 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,849 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21630ms
2014-07-13 23:48:50,849 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,849 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21741ms
2014-07-13 23:48:50,849 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,850 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21694ms
2014-07-13 23:48:50,850 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,851 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21791ms
2014-07-13 23:48:50,851 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,856 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21813ms
2014-07-13 23:48:50,856 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,856 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21869ms
2014-07-13 23:48:50,856 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,858 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21873ms
2014-07-13 23:48:50,858 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,861 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21878ms
2014-07-13 23:48:50,861 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,864 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21067,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509797,"queuetimems":0,"class":"HRegionServer","responsesize":510,"method":"Multi"}
2014-07-13 23:48:50,865 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21884ms
2014-07-13 23:48:50,865 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,865 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21889ms
2014-07-13 23:48:50,865 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,865 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21068,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509797,"queuetimems":1,"class":"HRegionServer","responsesize":484,"method":"Multi"}
2014-07-13 23:48:50,867 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21900ms
2014-07-13 23:48:50,867 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,868 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21020,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509847,"queuetimems":0,"class":"HRegionServer","responsesize":34,"method":"Multi"}
2014-07-13 23:48:50,870 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21932ms
2014-07-13 23:48:50,870 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,870 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21922ms
2014-07-13 23:48:50,870 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,871 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21912ms
2014-07-13 23:48:50,871 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,872 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21662ms
2014-07-13 23:48:50,874 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:48:50,993 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:48:51,093 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:51,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73711 synced till here 73691
2014-07-13 23:48:51,410 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21562,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509847,"queuetimems":1,"class":"HRegionServer","responsesize":6286,"method":"Multi"}
2014-07-13 23:48:51,410 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21518,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509892,"queuetimems":0,"class":"HRegionServer","responsesize":7839,"method":"Multi"}
2014-07-13 23:48:51,410 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22426,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508984,"queuetimems":0,"class":"HRegionServer","responsesize":1556,"method":"Multi"}
2014-07-13 23:48:51,410 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22193,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509217,"queuetimems":0,"class":"HRegionServer","responsesize":2794,"method":"Multi"}
2014-07-13 23:48:51,410 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22434,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508976,"queuetimems":1,"class":"HRegionServer","responsesize":5134,"method":"Multi"}
2014-07-13 23:48:51,411 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21406,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320510004,"queuetimems":0,"class":"HRegionServer","responsesize":5332,"method":"Multi"}
2014-07-13 23:48:51,411 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21759,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509652,"queuetimems":0,"class":"HRegionServer","responsesize":4007,"method":"Multi"}
2014-07-13 23:48:51,411 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21419,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509991,"queuetimems":0,"class":"HRegionServer","responsesize":4808,"method":"Multi"}
2014-07-13 23:48:51,411 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509868,"queuetimems":0,"class":"HRegionServer","responsesize":6725,"method":"Multi"}
2014-07-13 23:48:51,417 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22209,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509208,"queuetimems":0,"class":"HRegionServer","responsesize":1540,"method":"Multi"}
2014-07-13 23:48:51,417 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21793,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509624,"queuetimems":0,"class":"HRegionServer","responsesize":5147,"method":"Multi"}
2014-07-13 23:48:51,418 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21461,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509956,"queuetimems":0,"class":"HRegionServer","responsesize":4949,"method":"Multi"}
2014-07-13 23:48:51,422 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22446,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508976,"queuetimems":1,"class":"HRegionServer","responsesize":26,"method":"Multi"}
2014-07-13 23:48:51,422 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21415,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320510007,"queuetimems":0,"class":"HRegionServer","responsesize":324,"method":"Multi"}
2014-07-13 23:48:51,429 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22665,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508764,"queuetimems":1,"class":"HRegionServer","responsesize":18815,"method":"Multi"}
2014-07-13 23:48:51,429 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21453,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509976,"queuetimems":0,"class":"HRegionServer","responsesize":183,"method":"Multi"}
2014-07-13 23:48:51,430 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21582,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509847,"queuetimems":0,"class":"HRegionServer","responsesize":225,"method":"Multi"}
2014-07-13 23:48:51,430 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21804,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509625,"queuetimems":0,"class":"HRegionServer","responsesize":207,"method":"Multi"}
2014-07-13 23:48:51,433 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509263,"queuetimems":0,"class":"HRegionServer","responsesize":4272,"method":"Multi"}
2014-07-13 23:48:51,434 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509641,"queuetimems":0,"class":"HRegionServer","responsesize":7189,"method":"Multi"}
2014-07-13 23:48:51,429 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21423,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320510006,"queuetimems":1,"class":"HRegionServer","responsesize":519,"method":"Multi"}
2014-07-13 23:48:51,430 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21453,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509976,"queuetimems":1,"class":"HRegionServer","responsesize":1879,"method":"Multi"}
2014-07-13 23:48:51,439 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22006,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509433,"queuetimems":0,"class":"HRegionServer","responsesize":8391,"method":"Multi"}
2014-07-13 23:48:51,441 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21615,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509826,"queuetimems":0,"class":"HRegionServer","responsesize":7622,"method":"Multi"}
2014-07-13 23:48:51,445 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22483,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508962,"queuetimems":0,"class":"HRegionServer","responsesize":4549,"method":"Multi"}
2014-07-13 23:48:51,915 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509248,"queuetimems":0,"class":"HRegionServer","responsesize":5425,"method":"Multi"}
2014-07-13 23:48:51,915 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22682,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509232,"queuetimems":1,"class":"HRegionServer","responsesize":4119,"method":"Multi"}
2014-07-13 23:48:51,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320507563 with entries=117, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320531093
2014-07-13 23:48:52,435 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23526,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508909,"queuetimems":0,"class":"HRegionServer","responsesize":17824,"method":"Multi"}
2014-07-13 23:48:52,435 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509317,"queuetimems":0,"class":"HRegionServer","responsesize":15263,"method":"Multi"}
2014-07-13 23:48:52,436 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22642,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509794,"queuetimems":0,"class":"HRegionServer","responsesize":14954,"method":"Multi"}
2014-07-13 23:48:52,437 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22831,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509605,"queuetimems":0,"class":"HRegionServer","responsesize":14580,"method":"Multi"}
2014-07-13 23:48:52,441 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23585,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508856,"queuetimems":0,"class":"HRegionServer","responsesize":18318,"method":"Multi"}
2014-07-13 23:48:52,442 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22495,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509946,"queuetimems":0,"class":"HRegionServer","responsesize":15636,"method":"Multi"}
2014-07-13 23:48:52,442 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23456,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508986,"queuetimems":0,"class":"HRegionServer","responsesize":1106,"method":"Multi"}
2014-07-13 23:48:52,449 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509971,"queuetimems":0,"class":"HRegionServer","responsesize":306,"method":"Multi"}
2014-07-13 23:48:52,449 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23126,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509323,"queuetimems":0,"class":"HRegionServer","responsesize":2836,"method":"Multi"}
2014-07-13 23:48:52,461 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23403,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509058,"queuetimems":0,"class":"HRegionServer","responsesize":8094,"method":"Multi"}
2014-07-13 23:48:52,465 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22494,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509971,"queuetimems":0,"class":"HRegionServer","responsesize":7466,"method":"Multi"}
2014-07-13 23:48:52,469 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509672,"queuetimems":0,"class":"HRegionServer","responsesize":10207,"method":"Multi"}
2014-07-13 23:48:52,747 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16670, memsize=743.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/5e8809e307c849b7aa926ad9cde476ce
2014-07-13 23:48:52,761 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/5e8809e307c849b7aa926ad9cde476ce as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5e8809e307c849b7aa926ad9cde476ce
2014-07-13 23:48:52,771 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/5e8809e307c849b7aa926ad9cde476ce, entries=2707190, sequenceid=16670, filesize=192.8m
2014-07-13 23:48:52,771 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.6g/1765134400, currentsize=93.5m/98070240 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 33361ms, sequenceid=16670, compaction requested=true
2014-07-13 23:48:52,772 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:137), split_queue=0, merge_queue=0
2014-07-13 23:48:53,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:53,806 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320508952,"queuetimems":0,"class":"HRegionServer","responsesize":11722,"method":"Multi"}
2014-07-13 23:48:53,822 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24669,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509152,"queuetimems":0,"class":"HRegionServer","responsesize":18143,"method":"Multi"}
2014-07-13 23:48:53,822 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24421,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509401,"queuetimems":1,"class":"HRegionServer","responsesize":18145,"method":"Multi"}
2014-07-13 23:48:53,824 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24719,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509105,"queuetimems":0,"class":"HRegionServer","responsesize":17682,"method":"Multi"}
2014-07-13 23:48:53,825 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24783,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509041,"queuetimems":1,"class":"HRegionServer","responsesize":15606,"method":"Multi"}
2014-07-13 23:48:53,826 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24619,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509206,"queuetimems":0,"class":"HRegionServer","responsesize":18144,"method":"Multi"}
2014-07-13 23:48:53,827 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24121,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509706,"queuetimems":1,"class":"HRegionServer","responsesize":13931,"method":"Multi"}
2014-07-13 23:48:53,829 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24084,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320509745,"queuetimems":1,"class":"HRegionServer","responsesize":15964,"method":"Multi"}
2014-07-13 23:48:53,909 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73864 synced till here 73861
2014-07-13 23:48:53,937 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320531093 with entries=153, filesize=96.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320533797
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320391111
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320396683
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320398510
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320399861
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320401428
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320402732
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320404251
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320407728
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320409183
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320410516
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320411757
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320413402
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320415483
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320417401
2014-07-13 23:48:53,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320419382
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320420693
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320422174
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320423968
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320425357
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320426123
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320427546
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320428922
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320431424
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320433451
2014-07-13 23:48:53,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320435070
2014-07-13 23:48:55,335 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:55,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73999 synced till here 73969
2014-07-13 23:48:55,544 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320533797 with entries=135, filesize=99.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320535336
2014-07-13 23:48:56,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:57,055 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74144 synced till here 74103
2014-07-13 23:48:57,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320535336 with entries=145, filesize=108.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320536963
2014-07-13 23:48:59,056 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:48:59,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74279 synced till here 74253
2014-07-13 23:48:59,718 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320536963 with entries=135, filesize=97.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320539057
2014-07-13 23:48:59,993 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:48:59,993 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. has too many store files; delaying flush up to 90000ms
2014-07-13 23:48:59,994 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:138), split_queue=0, merge_queue=0
2014-07-13 23:49:00,002 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:49:00,003 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 256.6m
2014-07-13 23:49:01,042 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:01,239 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74434 synced till here 74425
2014-07-13 23:49:01,347 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320539057 with entries=155, filesize=91.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320541043
2014-07-13 23:49:01,394 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:02,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:02,669 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=23717, memsize=220.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/c74b4ae2b131439eb16d07c68fbdc031
2014-07-13 23:49:02,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74573 synced till here 74559
2014-07-13 23:49:02,784 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/c74b4ae2b131439eb16d07c68fbdc031 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c74b4ae2b131439eb16d07c68fbdc031
2014-07-13 23:49:02,796 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c74b4ae2b131439eb16d07c68fbdc031, entries=800890, sequenceid=23717, filesize=57.1m
2014-07-13 23:49:02,796 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~265.7m/278589600, currentsize=344.3m/361059840 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 11985ms, sequenceid=23717, compaction requested=true
2014-07-13 23:49:02,796 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:139), split_queue=0, merge_queue=0
2014-07-13 23:49:02,822 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:49:02,823 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 347.5m
2014-07-13 23:49:02,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320541043 with entries=139, filesize=97.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320542562
2014-07-13 23:49:03,883 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:03,928 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:04,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74694 synced till here 74656
2014-07-13 23:49:04,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320542562 with entries=121, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320543928
2014-07-13 23:49:06,000 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:06,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74770 synced till here 74761
2014-07-13 23:49:06,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320543928 with entries=76, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320546000
2014-07-13 23:49:06,788 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16857, memsize=87.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/46f901853c81475591d63b8aed09d7b7
2014-07-13 23:49:06,802 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/46f901853c81475591d63b8aed09d7b7 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/46f901853c81475591d63b8aed09d7b7
2014-07-13 23:49:06,816 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/46f901853c81475591d63b8aed09d7b7, entries=317390, sequenceid=16857, filesize=22.6m
2014-07-13 23:49:06,816 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~274.5m/287833760, currentsize=122.9m/128896560 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 6813ms, sequenceid=16857, compaction requested=true
2014-07-13 23:49:06,817 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:140), split_queue=0, merge_queue=0
2014-07-13 23:49:07,478 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=24074, memsize=58.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/6cb38cb2d71440648590e612868af04f
2014-07-13 23:49:07,490 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/6cb38cb2d71440648590e612868af04f as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6cb38cb2d71440648590e612868af04f
2014-07-13 23:49:07,508 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6cb38cb2d71440648590e612868af04f, entries=214180, sequenceid=24074, filesize=15.3m
2014-07-13 23:49:07,508 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~364.0m/381639680, currentsize=88.2m/92436320 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 4685ms, sequenceid=24074, compaction requested=true
2014-07-13 23:49:07,509 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:141), split_queue=0, merge_queue=0
2014-07-13 23:49:08,493 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:08,528 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320546000 with entries=97, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320548494
2014-07-13 23:49:10,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:10,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74974 synced till here 74972
2014-07-13 23:49:10,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320548494 with entries=107, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320550069
2014-07-13 23:49:11,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:11,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75055 synced till here 75054
2014-07-13 23:49:11,231 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320550069 with entries=81, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320551152
2014-07-13 23:49:12,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:12,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75129 synced till here 75126
2014-07-13 23:49:12,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320551152 with entries=74, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320552563
2014-07-13 23:49:12,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:13,874 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:13,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320552563 with entries=61, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320553874
2014-07-13 23:49:13,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:14,056 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:49:14,057 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 256.8m
2014-07-13 23:49:14,336 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:15,287 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:15,794 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75319 synced till here 75315
2014-07-13 23:49:15,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320553874 with entries=129, filesize=101.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320555287
2014-07-13 23:49:15,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:15,895 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:49:15,895 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 257.0m
2014-07-13 23:49:16,046 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:17,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:17,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75393 synced till here 75390
2014-07-13 23:49:17,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320555287 with entries=74, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320557125
2014-07-13 23:49:17,211 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:18,433 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:18,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75491 synced till here 75488
2014-07-13 23:49:18,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320557125 with entries=98, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320558433
2014-07-13 23:49:18,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:20,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:20,266 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75569 synced till here 75559
2014-07-13 23:49:20,349 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320558433 with entries=78, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320560223
2014-07-13 23:49:20,349 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:21,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:21,730 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75646 synced till here 75645
2014-07-13 23:49:21,831 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320560223 with entries=77, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320561695
2014-07-13 23:49:21,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:22,157 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17027, memsize=163.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/c50f71bc6bb24019a4a34bf58e123800
2014-07-13 23:49:22,180 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/c50f71bc6bb24019a4a34bf58e123800 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/c50f71bc6bb24019a4a34bf58e123800
2014-07-13 23:49:22,662 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/c50f71bc6bb24019a4a34bf58e123800, entries=595510, sequenceid=17027, filesize=42.5m
2014-07-13 23:49:22,663 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.5m/274217200, currentsize=186.1m/195174800 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 8606ms, sequenceid=17027, compaction requested=true
2014-07-13 23:49:22,663 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:142), split_queue=0, merge_queue=0
2014-07-13 23:49:22,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:22,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75735 synced till here 75734
2014-07-13 23:49:23,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320561695 with entries=89, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320562971
2014-07-13 23:49:23,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:23,111 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.59 MB, free=3.95 GB, max=3.96 GB, blocks=6, accesses=464494, hits=161688, hitRatio=34.80%, , cachingAccesses=161746, cachingHits=161626, cachingHitsRatio=99.92%, evictions=0, evicted=114, evictedPerRun=Infinity
2014-07-13 23:49:24,353 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:24,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75822 synced till here 75820
2014-07-13 23:49:24,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320562971 with entries=87, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320564353
2014-07-13 23:49:24,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:25,320 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:49:25,321 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files; delaying flush up to 90000ms
2014-07-13 23:49:25,321 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:143), split_queue=0, merge_queue=0
2014-07-13 23:49:26,066 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:26,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75923 synced till here 75918
2014-07-13 23:49:26,127 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320564353 with entries=101, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320566067
2014-07-13 23:49:26,127 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:26,503 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=24360, memsize=218.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/31e661b7230041b0bf17c814968b660f
2014-07-13 23:49:26,516 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/31e661b7230041b0bf17c814968b660f as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/31e661b7230041b0bf17c814968b660f
2014-07-13 23:49:26,528 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/31e661b7230041b0bf17c814968b660f, entries=796120, sequenceid=24360, filesize=56.7m
2014-07-13 23:49:26,528 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.0m/269465520, currentsize=163.1m/171038480 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 10633ms, sequenceid=24360, compaction requested=true
2014-07-13 23:49:26,528 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:144), split_queue=0, merge_queue=0
2014-07-13 23:49:26,995 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:27,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76017 synced till here 76014
2014-07-13 23:49:27,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320566067 with entries=94, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320566996
2014-07-13 23:49:27,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:28,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:28,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76085 synced till here 76083
2014-07-13 23:49:28,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320566996 with entries=68, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320568390
2014-07-13 23:49:28,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:29,580 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/5272598a214f4a778b2d6b7a80adc396 as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/5272598a214f4a778b2d6b7a80adc396
2014-07-13 23:49:29,603 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:49:29,648 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1c9e56e057834d75a9ee429a0a1490ba, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/1c9e56e057834d75a9ee429a0a1490ba
2014-07-13 23:49:29,752 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:49:29,753 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 257.7m
2014-07-13 23:49:29,797 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e9aa8d1b81541c2b3b39a6e71fa6be0, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e9aa8d1b81541c2b3b39a6e71fa6be0
2014-07-13 23:49:29,810 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/31e7f2f1eae14ea19e41a7760de9c560, to hdfs://master:54310/hbase/archive/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/31e7f2f1eae14ea19e41a7760de9c560
2014-07-13 23:49:29,811 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into 5272598a214f4a778b2d6b7a80adc396(size=308.4m), total size for store is 3.9g. This selection was in queue for 0sec, and took 59sec to execute.
2014-07-13 23:49:29,811 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., storeName=family, fileCount=3, fileSize=328.8m, priority=-1, time=274417275168766; duration=59sec
2014-07-13 23:49:29,811 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:145), split_queue=0, merge_queue=0
2014-07-13 23:49:29,811 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:145), split_queue=0, merge_queue=0
2014-07-13 23:49:29,811 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 23:49:29,813 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 195588914 starting at candidate #15 after considering 124 permutations with 118 in ratio
2014-07-13 23:49:29,813 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 6935e08926c94c414c50c4e2b2667be2 - family: Initiating minor compaction
2014-07-13 23:49:29,813 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:49:29,813 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp, totalSize=186.5m
2014-07-13 23:49:29,814 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/9932a12bdc964b3da5f65e4256630a91, keycount=94668, bloomtype=ROW, size=67.4m, encoding=NONE, seqNum=14833
2014-07-13 23:49:29,814 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6163ca57b5874f8eba34c0db79bff3b1, keycount=78431, bloomtype=ROW, size=55.9m, encoding=NONE, seqNum=14979
2014-07-13 23:49:29,814 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b9df96caf20b4891bb85b0720a880f10, keycount=88745, bloomtype=ROW, size=63.2m, encoding=NONE, seqNum=15147
2014-07-13 23:49:29,831 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:29,847 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 870.8m
2014-07-13 23:49:29,888 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:29,951 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:30,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76166 synced till here 76164
2014-07-13 23:49:30,225 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320568390 with entries=81, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320569831
2014-07-13 23:49:30,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:31,031 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:31,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:31,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320569831 with entries=60, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320571470
2014-07-13 23:49:31,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:32,908 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:32,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76302 synced till here 76300
2014-07-13 23:49:32,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320571470 with entries=76, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320572908
2014-07-13 23:49:32,958 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:34,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:34,370 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76373 synced till here 76369
2014-07-13 23:49:34,426 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320572908 with entries=71, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320574320
2014-07-13 23:49:34,426 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:35,677 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:36,545 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320574320 with entries=103, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320575677
2014-07-13 23:49:36,546 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:37,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:37,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76551 synced till here 76544
2014-07-13 23:49:38,217 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320575677 with entries=75, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320577591
2014-07-13 23:49:38,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:39,107 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:39,127 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76627 synced till here 76623
2014-07-13 23:49:39,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320577591 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320579107
2014-07-13 23:49:39,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): 6935e08926c94c414c50c4e2b2667be2
2014-07-13 23:49:40,708 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=24634, memsize=250.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1cbc0760908f4ab782638ca5deb1f059
2014-07-13 23:49:40,733 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/1cbc0760908f4ab782638ca5deb1f059 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1cbc0760908f4ab782638ca5deb1f059
2014-07-13 23:49:40,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:41,499 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/1cbc0760908f4ab782638ca5deb1f059, entries=911770, sequenceid=24634, filesize=65.0m
2014-07-13 23:49:41,499 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.5m/272152960, currentsize=210.4m/220670880 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 11746ms, sequenceid=24634, compaction requested=true
2014-07-13 23:49:41,499 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:145), split_queue=0, merge_queue=0
2014-07-13 23:49:41,500 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 93884ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:49:41,500 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 1.8g
2014-07-13 23:49:41,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76711 synced till here 76704
2014-07-13 23:49:41,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320579107 with entries=84, filesize=82.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320580739
2014-07-13 23:49:43,048 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:43,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76815 synced till here 76795
2014-07-13 23:49:43,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320580739 with entries=104, filesize=75.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320583048
2014-07-13 23:49:43,625 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:49:44,001 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:49:44,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:44,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76878 synced till here 76876
2014-07-13 23:49:44,685 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320583048 with entries=63, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320584142
2014-07-13 23:49:44,782 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,803 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,807 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,810 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,834 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,847 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,880 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,888 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,903 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,909 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:44,965 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,002 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,002 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,023 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,030 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,051 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,066 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,127 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,129 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,131 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,151 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,224 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,285 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,319 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,354 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,385 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,387 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,387 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,423 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,433 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,447 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,454 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,463 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,491 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,820 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,833 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,834 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:45,880 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,025 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,028 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,043 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,045 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,087 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,094 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,108 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,109 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,157 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,165 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,180 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:46,278 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:49:49,782 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,804 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:49,807 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,810 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,834 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,847 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,880 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,889 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:49,903 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,909 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:49,966 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:50,002 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,002 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,024 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:50,030 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,051 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,066 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,128 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:50,130 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:50,131 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,151 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,224 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,285 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,319 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,354 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,385 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,387 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,387 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,423 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,434 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:50,447 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,454 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,463 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:50,491 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,821 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,833 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:50,834 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:50,880 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,025 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,029 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:51,043 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,045 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,088 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:49:51,094 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,108 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,109 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,157 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,165 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,181 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:51,278 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:49:53,235 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17219, memsize=471.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/19882b204b2647b1a4223c07015b27ee
2014-07-13 23:49:53,249 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/19882b204b2647b1a4223c07015b27ee as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/19882b204b2647b1a4223c07015b27ee
2014-07-13 23:49:53,260 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/19882b204b2647b1a4223c07015b27ee, entries=1717580, sequenceid=17219, filesize=122.4m
2014-07-13 23:49:53,260 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~873.5m/915954320, currentsize=316.9m/332293680 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 23413ms, sequenceid=17219, compaction requested=true
2014-07-13 23:49:53,260 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:146), split_queue=0, merge_queue=0
2014-07-13 23:49:53,261 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6983ms
2014-07-13 23:49:53,261 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. has too many store files; delaying flush up to 90000ms
2014-07-13 23:49:53,261 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,261 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:147), split_queue=0, merge_queue=0
2014-07-13 23:49:53,261 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7081ms
2014-07-13 23:49:53,261 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,261 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7096ms
2014-07-13 23:49:53,261 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,261 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7104ms
2014-07-13 23:49:53,261 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,261 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7152ms
2014-07-13 23:49:53,262 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,262 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7154ms
2014-07-13 23:49:53,262 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,262 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7168ms
2014-07-13 23:49:53,262 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,262 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7175ms
2014-07-13 23:49:53,262 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,269 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7223ms
2014-07-13 23:49:53,269 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,269 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7226ms
2014-07-13 23:49:53,269 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,269 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7241ms
2014-07-13 23:49:53,269 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,269 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7244ms
2014-07-13 23:49:53,269 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,269 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7389ms
2014-07-13 23:49:53,269 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,269 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7435ms
2014-07-13 23:49:53,270 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,275 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7443ms
2014-07-13 23:49:53,275 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,275 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7455ms
2014-07-13 23:49:53,275 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,277 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7786ms
2014-07-13 23:49:53,277 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,280 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7818ms
2014-07-13 23:49:53,280 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,280 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7826ms
2014-07-13 23:49:53,280 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,281 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7834ms
2014-07-13 23:49:53,281 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,285 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7852ms
2014-07-13 23:49:53,285 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,285 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7862ms
2014-07-13 23:49:53,285 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,285 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7898ms
2014-07-13 23:49:53,285 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,285 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7898ms
2014-07-13 23:49:53,285 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,291 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7906ms
2014-07-13 23:49:53,291 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,295 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7941ms
2014-07-13 23:49:53,295 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,295 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7976ms
2014-07-13 23:49:53,295 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,295 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8010ms
2014-07-13 23:49:53,295 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,297 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8073ms
2014-07-13 23:49:53,297 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,297 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8146ms
2014-07-13 23:49:53,297 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,297 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8166ms
2014-07-13 23:49:53,297 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,298 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8169ms
2014-07-13 23:49:53,298 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,298 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8171ms
2014-07-13 23:49:53,299 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,300 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8234ms
2014-07-13 23:49:53,300 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,300 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8249ms
2014-07-13 23:49:53,300 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,301 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8271ms
2014-07-13 23:49:53,301 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,301 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8278ms
2014-07-13 23:49:53,301 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,301 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8299ms
2014-07-13 23:49:53,301 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,301 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8299ms
2014-07-13 23:49:53,301 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,302 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8337ms
2014-07-13 23:49:53,302 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,302 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8393ms
2014-07-13 23:49:53,302 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,304 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8401ms
2014-07-13 23:49:53,304 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,304 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8416ms
2014-07-13 23:49:53,304 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,304 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8424ms
2014-07-13 23:49:53,304 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,305 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8458ms
2014-07-13 23:49:53,305 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,305 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8471ms
2014-07-13 23:49:53,305 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,313 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8503ms
2014-07-13 23:49:53,313 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,314 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8507ms
2014-07-13 23:49:53,314 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,315 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8512ms
2014-07-13 23:49:53,315 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,316 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8533ms
2014-07-13 23:49:53,316 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:49:53,527 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:49:53,528 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. has too many store files; delaying flush up to 90000ms
2014-07-13 23:49:53,528 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-13 23:49:53,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:54,857 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76966 synced till here 76947
2014-07-13 23:49:55,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320584142 with entries=88, filesize=78.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320593953
2014-07-13 23:49:55,407 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10715,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320584692,"queuetimems":1,"class":"HRegionServer","responsesize":16230,"method":"Multi"}
2014-07-13 23:49:55,410 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320584083,"queuetimems":0,"class":"HRegionServer","responsesize":18544,"method":"Multi"}
2014-07-13 23:49:55,417 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10680,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320584737,"queuetimems":0,"class":"HRegionServer","responsesize":17071,"method":"Multi"}
2014-07-13 23:49:55,426 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11211,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320584215,"queuetimems":1,"class":"HRegionServer","responsesize":18654,"method":"Multi"}
2014-07-13 23:49:55,585 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10585,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585000,"queuetimems":0,"class":"HRegionServer","responsesize":10280,"method":"Multi"}
2014-07-13 23:49:55,587 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585384,"queuetimems":0,"class":"HRegionServer","responsesize":15976,"method":"Multi"}
2014-07-13 23:49:55,587 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10270,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585316,"queuetimems":1,"class":"HRegionServer","responsesize":15613,"method":"Multi"}
2014-07-13 23:49:55,585 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10235,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585350,"queuetimems":0,"class":"HRegionServer","responsesize":16087,"method":"Multi"}
2014-07-13 23:49:55,593 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585489,"queuetimems":0,"class":"HRegionServer","responsesize":15433,"method":"Multi"}
2014-07-13 23:49:55,601 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10474,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585127,"queuetimems":1,"class":"HRegionServer","responsesize":15840,"method":"Multi"}
2014-07-13 23:49:55,609 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10189,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585420,"queuetimems":1,"class":"HRegionServer","responsesize":17314,"method":"Multi"}
2014-07-13 23:49:55,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:55,748 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10784,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320584963,"queuetimems":1,"class":"HRegionServer","responsesize":17619,"method":"Multi"}
2014-07-13 23:49:55,748 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10902,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320584845,"queuetimems":0,"class":"HRegionServer","responsesize":11501,"method":"Multi"}
2014-07-13 23:49:55,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77065 synced till here 77032
2014-07-13 23:49:56,624 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11820,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320584804,"queuetimems":0,"class":"HRegionServer","responsesize":13687,"method":"Multi"}
2014-07-13 23:49:56,624 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11404,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585220,"queuetimems":0,"class":"HRegionServer","responsesize":17546,"method":"Multi"}
2014-07-13 23:49:56,626 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11344,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320585281,"queuetimems":0,"class":"HRegionServer","responsesize":16108,"method":"Multi"}
2014-07-13 23:49:56,723 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320593953 with entries=99, filesize=95.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320595746
2014-07-13 23:49:57,429 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:49:58,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77145 synced till here 77134
2014-07-13 23:49:58,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320595746 with entries=80, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320597429
2014-07-13 23:49:59,518 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:00,267 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77247 synced till here 77215
2014-07-13 23:50:00,589 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320597429 with entries=102, filesize=100.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320599518
2014-07-13 23:50:01,861 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 23:50:01,861 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files, but is 822.2m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 23:50:01,862 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. due to global heap pressure
2014-07-13 23:50:01,862 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 822.2m
2014-07-13 23:50:02,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:03,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77356 synced till here 77335
2014-07-13 23:50:03,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320599518 with entries=109, filesize=96.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320602963
2014-07-13 23:50:04,421 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,422 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,423 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,423 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,423 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,424 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,426 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,445 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:50:04,460 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,496 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,562 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,572 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,589 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,603 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,689 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,695 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,697 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,697 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,701 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,712 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,715 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,731 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,737 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,741 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,751 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,751 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:04,885 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,887 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,889 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,896 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,899 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,900 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,903 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,904 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,905 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,905 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,906 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,910 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,911 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,911 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,918 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,918 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77443 synced till here 77439
2014-07-13 23:50:04,939 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320602963 with entries=87, filesize=82.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320604878
2014-07-13 23:50:04,940 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,940 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,941 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,944 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,951 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:04,979 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:05,015 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:06,171 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:06,175 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:06,176 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:50:08,790 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/e006adfaed124b94bcc73c4a7cc9e0d5 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e006adfaed124b94bcc73c4a7cc9e0d5
2014-07-13 23:50:08,852 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:50:08,863 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/9932a12bdc964b3da5f65e4256630a91, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/9932a12bdc964b3da5f65e4256630a91
2014-07-13 23:50:08,868 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6163ca57b5874f8eba34c0db79bff3b1, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/6163ca57b5874f8eba34c0db79bff3b1
2014-07-13 23:50:08,873 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b9df96caf20b4891bb85b0720a880f10, to hdfs://master:54310/hbase/archive/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/b9df96caf20b4891bb85b0720a880f10
2014-07-13 23:50:08,874 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. into e006adfaed124b94bcc73c4a7cc9e0d5(size=185.5m), total size for store is 3.8g. This selection was in queue for 0sec, and took 39sec to execute.
2014-07-13 23:50:08,874 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., storeName=family, fileCount=3, fileSize=186.5m, priority=-1, time=274477240221373; duration=39sec
2014-07-13 23:50:08,875 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-13 23:50:08,875 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 23:50:08,877 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 377574654 starting at candidate #5 after considering 124 permutations with 107 in ratio
2014-07-13 23:50:08,878 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: 8b827125b32700e6f7c5c34f77be22cb - family: Initiating minor compaction
2014-07-13 23:50:08,878 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:50:08,878 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp, totalSize=360.1m
2014-07-13 23:50:08,879 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8940e542a43a46069c460ef54f1932bb, keycount=137876, bloomtype=ROW, size=98.2m, encoding=NONE, seqNum=7493
2014-07-13 23:50:08,879 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8093fc6bd66143b0a625f8db92195200, keycount=189871, bloomtype=ROW, size=135.3m, encoding=NONE, seqNum=8037
2014-07-13 23:50:08,879 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6b7fa8b576094f499adfe2db74c7dd27, keycount=177857, bloomtype=ROW, size=126.7m, encoding=NONE, seqNum=8556
2014-07-13 23:50:09,011 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:50:09,422 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,423 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,424 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,424 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 23:50:09,424 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,425 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,426 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,460 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,497 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,562 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,573 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,590 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,603 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,689 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,695 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,698 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,698 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,701 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,712 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,715 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,732 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,737 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,741 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,751 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,751 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,885 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,887 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,889 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,897 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,899 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,901 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,904 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,905 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,905 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,905 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,907 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,910 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,911 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,911 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,918 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,940 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,941 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,942 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,945 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:09,951 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:09,980 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:50:10,015 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:50:11,258 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-13 23:50:11,258 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5087ms
2014-07-13 23:50:11,258 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5083ms
2014-07-13 23:50:14,423 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:50:14,424 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:50:14,424 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,424 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:50:14,425 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,425 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,427 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:50:14,461 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,497 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,563 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,573 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,590 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,604 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,690 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,695 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,698 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,698 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,701 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,712 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,715 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,732 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,738 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,742 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,751 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,751 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,886 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,888 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,890 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,897 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,899 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,901 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,904 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,905 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,906 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,907 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,907 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,911 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,912 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,912 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,923 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 23:50:14,941 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:14,941 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,942 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,945 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,951 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:14,981 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:50:15,016 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:50:16,258 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10082ms
2014-07-13 23:50:16,259 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10084ms
2014-07-13 23:50:16,259 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10088ms
2014-07-13 23:50:19,424 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,424 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,425 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 23:50:19,425 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,425 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,425 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,427 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,461 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,497 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,563 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,573 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,590 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,604 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,690 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,696 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,698 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,698 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,702 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:50:19,713 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,715 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,733 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,738 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,742 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,751 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:50:19,752 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,886 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,889 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,890 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,898 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,899 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:50:19,902 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,905 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,906 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,906 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,907 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,907 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,911 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,912 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,913 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,923 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15005ms
2014-07-13 23:50:19,941 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,942 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,943 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,945 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:19,952 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:19,981 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:50:20,016 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:50:21,259 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15083ms
2014-07-13 23:50:21,259 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15084ms
2014-07-13 23:50:21,259 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15088ms
2014-07-13 23:50:24,424 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 23:50:24,425 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 23:50:24,425 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 23:50:24,425 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,425 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,425 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,428 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 23:50:24,461 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,498 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,563 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,573 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,590 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,604 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,690 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,696 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,699 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,699 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,702 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,713 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,716 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,733 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,738 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,742 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,752 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,752 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,887 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,889 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,890 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,898 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,900 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,902 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,905 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,906 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,907 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,907 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,907 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,911 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,913 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,913 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,923 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20005ms
2014-07-13 23:50:24,941 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,942 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,943 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,945 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:24,952 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:24,981 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 23:50:25,016 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 23:50:25,473 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17494, memsize=588.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/0c559acdee774578b3884437b751b78f
2014-07-13 23:50:25,754 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/0c559acdee774578b3884437b751b78f as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/0c559acdee774578b3884437b751b78f
2014-07-13 23:50:25,774 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/0c559acdee774578b3884437b751b78f, entries=2143900, sequenceid=17494, filesize=152.6m
2014-07-13 23:50:25,774 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~853.2m/894646320, currentsize=60.3m/63234400 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 23912ms, sequenceid=17494, compaction requested=true
2014-07-13 23:50:25,775 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-13 23:50:25,775 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20760ms
2014-07-13 23:50:25,775 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,775 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20796ms
2014-07-13 23:50:25,775 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,775 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20825ms
2014-07-13 23:50:25,775 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,775 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20831ms
2014-07-13 23:50:25,775 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,775 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20834ms
2014-07-13 23:50:25,776 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,776 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20836ms
2014-07-13 23:50:25,776 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,776 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20836ms
2014-07-13 23:50:25,776 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,776 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20858ms
2014-07-13 23:50:25,776 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,776 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20865ms
2014-07-13 23:50:25,776 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,776 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20865ms
2014-07-13 23:50:25,776 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,777 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20867ms
2014-07-13 23:50:25,777 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,781 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20875ms
2014-07-13 23:50:25,781 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,782 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20877ms
2014-07-13 23:50:25,782 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,782 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20877ms
2014-07-13 23:50:25,782 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,783 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20879ms
2014-07-13 23:50:25,783 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,790 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20887ms
2014-07-13 23:50:25,791 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,791 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20891ms
2014-07-13 23:50:25,791 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,792 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20777,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320605014,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:50:25,792 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20812,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604979,"queuetimems":0,"class":"HRegionServer","responsesize":8,"method":"Multi"}
2014-07-13 23:50:25,792 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604917,"queuetimems":0,"class":"HRegionServer","responsesize":110,"method":"Multi"}
2014-07-13 23:50:25,792 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20893ms
2014-07-13 23:50:25,792 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,792 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20896ms
2014-07-13 23:50:25,792 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,798 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20909ms
2014-07-13 23:50:25,798 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,805 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20918ms
2014-07-13 23:50:25,805 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,805 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20920ms
2014-07-13 23:50:25,805 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,805 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21054ms
2014-07-13 23:50:25,805 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,813 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21062ms
2014-07-13 23:50:25,813 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,821 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21080ms
2014-07-13 23:50:25,821 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,821 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21084ms
2014-07-13 23:50:25,821 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,821 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21090ms
2014-07-13 23:50:25,821 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,821 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21107ms
2014-07-13 23:50:25,821 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,821 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21110ms
2014-07-13 23:50:25,821 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,833 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21132ms
2014-07-13 23:50:25,833 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,833 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21136ms
2014-07-13 23:50:25,833 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,840 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22507,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603331,"queuetimems":1341,"class":"HRegionServer","responsesize":732509,"method":"Multi"}
2014-07-13 23:50:25,841 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21144ms
2014-07-13 23:50:25,841 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,841 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21147ms
2014-07-13 23:50:25,841 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,849 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21160ms
2014-07-13 23:50:25,849 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,849 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21246ms
2014-07-13 23:50:25,849 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,853 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21264ms
2014-07-13 23:50:25,853 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,861 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21289ms
2014-07-13 23:50:25,861 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,861 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21299ms
2014-07-13 23:50:25,861 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,866 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21370ms
2014-07-13 23:50:25,866 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,867 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21408ms
2014-07-13 23:50:25,867 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,873 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21448ms
2014-07-13 23:50:25,873 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,877 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21453ms
2014-07-13 23:50:25,877 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,877 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21454ms
2014-07-13 23:50:25,877 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,877 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21454ms
2014-07-13 23:50:25,877 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:25,881 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21459ms
2014-07-13 23:50:25,881 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:26,107 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22704,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603401,"queuetimems":1258,"class":"HRegionServer","responsesize":1245502,"method":"Multi"}
2014-07-13 23:50:26,110 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603005,"queuetimems":2257,"class":"HRegionServer","responsesize":1103342,"method":"Multi"}
2014-07-13 23:50:26,117 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603202,"queuetimems":2410,"class":"HRegionServer","responsesize":1144895,"method":"Multi"}
2014-07-13 23:50:26,118 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23131,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602985,"queuetimems":2618,"class":"HRegionServer","responsesize":1281713,"method":"Multi"}
2014-07-13 23:50:26,121 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23126,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602993,"queuetimems":2403,"class":"HRegionServer","responsesize":1238390,"method":"Multi"}
2014-07-13 23:50:26,154 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22762,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603391,"queuetimems":1261,"class":"HRegionServer","responsesize":1145620,"method":"Multi"}
2014-07-13 23:50:26,179 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23193,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602985,"queuetimems":2661,"class":"HRegionServer","responsesize":841918,"method":"Multi"}
2014-07-13 23:50:26,180 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21758ms
2014-07-13 23:50:26,190 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:26,190 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21769ms
2014-07-13 23:50:26,190 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:26,190 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20019ms
2014-07-13 23:50:26,190 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:26,190 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20015ms
2014-07-13 23:50:26,190 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:26,190 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20014ms
2014-07-13 23:50:26,190 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:50:26,187 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22798,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603388,"queuetimems":1341,"class":"HRegionServer","responsesize":1153433,"method":"Multi"}
2014-07-13 23:50:26,204 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23210,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602993,"queuetimems":2536,"class":"HRegionServer","responsesize":1324221,"method":"Multi"}
2014-07-13 23:50:26,208 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23213,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602993,"queuetimems":2492,"class":"HRegionServer","responsesize":1143290,"method":"Multi"}
2014-07-13 23:50:26,212 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23203,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603005,"queuetimems":2299,"class":"HRegionServer","responsesize":1137463,"method":"Multi"}
2014-07-13 23:50:26,225 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23248,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602972,"queuetimems":2679,"class":"HRegionServer","responsesize":1195444,"method":"Multi"}
2014-07-13 23:50:26,233 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23229,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603002,"queuetimems":2390,"class":"HRegionServer","responsesize":1165109,"method":"Multi"}
2014-07-13 23:50:26,242 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23247,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602993,"queuetimems":2584,"class":"HRegionServer","responsesize":1116727,"method":"Multi"}
2014-07-13 23:50:26,304 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24248,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320602054,"queuetimems":2648,"class":"HRegionServer","responsesize":1076905,"method":"Multi"}
2014-07-13 23:50:26,313 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23074,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603208,"queuetimems":2384,"class":"HRegionServer","responsesize":1009310,"method":"Multi"}
2014-07-13 23:50:26,326 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21419,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604907,"queuetimems":0,"class":"HRegionServer","responsesize":4918,"method":"Multi"}
2014-07-13 23:50:26,327 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21443,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604884,"queuetimems":0,"class":"HRegionServer","responsesize":457,"method":"Multi"}
2014-07-13 23:50:26,444 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21693,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604750,"queuetimems":1,"class":"HRegionServer","responsesize":1632,"method":"Multi"}
2014-07-13 23:50:26,468 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604396,"queuetimems":166,"class":"HRegionServer","responsesize":841918,"method":"Multi"}
2014-07-13 23:50:26,473 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22066,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604406,"queuetimems":109,"class":"HRegionServer","responsesize":1116727,"method":"Multi"}
2014-07-13 23:50:26,475 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22091,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604383,"queuetimems":199,"class":"HRegionServer","responsesize":1103342,"method":"Multi"}
2014-07-13 23:50:26,477 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22087,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604389,"queuetimems":172,"class":"HRegionServer","responsesize":1165109,"method":"Multi"}
2014-07-13 23:50:26,479 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22072,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604405,"queuetimems":147,"class":"HRegionServer","responsesize":1143290,"method":"Multi"}
2014-07-13 23:50:26,479 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22064,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604413,"queuetimems":94,"class":"HRegionServer","responsesize":1281713,"method":"Multi"}
2014-07-13 23:50:26,588 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21849,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604739,"queuetimems":0,"class":"HRegionServer","responsesize":2404,"method":"Multi"}
2014-07-13 23:50:26,588 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21858,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604730,"queuetimems":0,"class":"HRegionServer","responsesize":469,"method":"Multi"}
2014-07-13 23:50:26,589 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21843,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604746,"queuetimems":0,"class":"HRegionServer","responsesize":4220,"method":"Multi"}
2014-07-13 23:50:26,590 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21994,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604596,"queuetimems":0,"class":"HRegionServer","responsesize":4052,"method":"Multi"}
2014-07-13 23:50:26,598 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22017,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604581,"queuetimems":0,"class":"HRegionServer","responsesize":4790,"method":"Multi"}
2014-07-13 23:50:26,607 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604566,"queuetimems":0,"class":"HRegionServer","responsesize":4206,"method":"Multi"}
2014-07-13 23:50:26,617 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22404,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604212,"queuetimems":1354,"class":"HRegionServer","responsesize":1088853,"method":"Multi"}
2014-07-13 23:50:26,962 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23504,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603456,"queuetimems":641,"class":"HRegionServer","responsesize":1157256,"method":"Multi"}
2014-07-13 23:50:26,970 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23514,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320603455,"queuetimems":1283,"class":"HRegionServer","responsesize":1226389,"method":"Multi"}
2014-07-13 23:50:26,989 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22778,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604210,"queuetimems":1371,"class":"HRegionServer","responsesize":1076905,"method":"Multi"}
2014-07-13 23:50:27,004 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22522,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604482,"queuetimems":1,"class":"HRegionServer","responsesize":8258,"method":"Multi"}
2014-07-13 23:50:27,006 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20835,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320606171,"queuetimems":0,"class":"HRegionServer","responsesize":26,"method":"Multi"}
2014-07-13 23:50:27,007 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20832,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320606175,"queuetimems":0,"class":"HRegionServer","responsesize":98,"method":"Multi"}
2014-07-13 23:50:27,021 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20846,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320606175,"queuetimems":0,"class":"HRegionServer","responsesize":1794,"method":"Multi"}
2014-07-13 23:50:27,549 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:27,586 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604418,"queuetimems":1,"class":"HRegionServer","responsesize":1225159,"method":"Multi"}
2014-07-13 23:50:27,608 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23154,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604453,"queuetimems":0,"class":"HRegionServer","responsesize":1009310,"method":"Multi"}
2014-07-13 23:50:27,608 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23189,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604418,"queuetimems":75,"class":"HRegionServer","responsesize":1238390,"method":"Multi"}
2014-07-13 23:50:28,037 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23482,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604554,"queuetimems":0,"class":"HRegionServer","responsesize":1137463,"method":"Multi"}
2014-07-13 23:50:28,038 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23308,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604729,"queuetimems":0,"class":"HRegionServer","responsesize":1195444,"method":"Multi"}
2014-07-13 23:50:28,040 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23622,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604418,"queuetimems":50,"class":"HRegionServer","responsesize":1144895,"method":"Multi"}
2014-07-13 23:50:28,043 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23362,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320604681,"queuetimems":0,"class":"HRegionServer","responsesize":1324221,"method":"Multi"}
2014-07-13 23:50:28,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77563 synced till here 77547
2014-07-13 23:50:28,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320604878 with entries=120, filesize=100.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320627549
2014-07-13 23:50:29,415 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:29,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77683 synced till here 77661
2014-07-13 23:50:29,519 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17366, memsize=944.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/e779ee59ae75405fb41f08e6e88dc3aa
2014-07-13 23:50:29,535 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/e779ee59ae75405fb41f08e6e88dc3aa as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e779ee59ae75405fb41f08e6e88dc3aa
2014-07-13 23:50:29,574 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/e779ee59ae75405fb41f08e6e88dc3aa, entries=3438740, sequenceid=17366, filesize=244.8m
2014-07-13 23:50:29,574 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.8g/1957708800, currentsize=206.5m/216493200 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 48074ms, sequenceid=17366, compaction requested=true
2014-07-13 23:50:29,575 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:149), split_queue=0, merge_queue=0
2014-07-13 23:50:29,716 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320627549 with entries=120, filesize=93.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320629416
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320436937
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320447952
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320450049
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320453729
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320455780
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320458191
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320460424
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320463432
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320479983
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320481846
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320483714
2014-07-13 23:50:29,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320486228
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320487698
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320488883
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320490171
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320491921
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320493218
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320494935
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320496370
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320498550
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320507563
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320531093
2014-07-13 23:50:29,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320533797
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320535336
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320536963
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320539057
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320541043
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320542562
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320543928
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320546000
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320548494
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320550069
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320551152
2014-07-13 23:50:29,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320552563
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320553874
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320555287
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320557125
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320558433
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320560223
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320561695
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320562971
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320564353
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320566067
2014-07-13 23:50:29,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320566996
2014-07-13 23:50:37,938 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:37,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77752 synced till here 77750
2014-07-13 23:50:38,019 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320629416 with entries=69, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320637941
2014-07-13 23:50:38,104 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:50:38,104 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 256.7m
2014-07-13 23:50:38,307 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:50:38,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:38,907 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77816 synced till here 77813
2014-07-13 23:50:39,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320637941 with entries=64, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320638873
2014-07-13 23:50:39,862 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:50:39,862 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files; delaying flush up to 90000ms
2014-07-13 23:50:39,863 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-13 23:50:40,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:40,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77895 synced till here 77888
2014-07-13 23:50:40,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320638873 with entries=79, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320640369
2014-07-13 23:50:41,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:41,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77958 synced till here 77955
2014-07-13 23:50:41,759 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320640369 with entries=63, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320641690
2014-07-13 23:50:43,107 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:43,485 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17492, memsize=112.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4b811f3c097f438b84c714dbb0564098
2014-07-13 23:50:43,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78040 synced till here 78038
2014-07-13 23:50:43,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320641690 with entries=82, filesize=81.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320643107
2014-07-13 23:50:43,551 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/4b811f3c097f438b84c714dbb0564098 as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4b811f3c097f438b84c714dbb0564098
2014-07-13 23:50:43,574 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/4b811f3c097f438b84c714dbb0564098, entries=409620, sequenceid=17492, filesize=29.2m
2014-07-13 23:50:43,574 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269201680, currentsize=132.7m/139123520 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 5470ms, sequenceid=17492, compaction requested=true
2014-07-13 23:50:43,575 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:151), split_queue=0, merge_queue=0
2014-07-13 23:50:44,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:44,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78105 synced till here 78104
2014-07-13 23:50:44,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320643107 with entries=65, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320644727
2014-07-13 23:50:46,166 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:46,359 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78195 synced till here 78192
2014-07-13 23:50:46,392 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320644727 with entries=90, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320646167
2014-07-13 23:50:47,766 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:47,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78277 synced till here 78269
2014-07-13 23:50:48,087 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320646167 with entries=82, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320647766
2014-07-13 23:50:49,231 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:49,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78372 synced till here 78371
2014-07-13 23:50:49,280 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320647766 with entries=95, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320649231
2014-07-13 23:50:49,411 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2.
2014-07-13 23:50:49,411 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. has too many store files; delaying flush up to 90000ms
2014-07-13 23:50:49,411 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:152), split_queue=0, merge_queue=0
2014-07-13 23:50:50,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:50,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320649231 with entries=59, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320650914
2014-07-13 23:50:51,826 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:51,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78502 synced till here 78499
2014-07-13 23:50:52,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320650914 with entries=71, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320651827
2014-07-13 23:50:53,077 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:53,195 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78570 synced till here 78566
2014-07-13 23:50:53,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320651827 with entries=68, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320653077
2014-07-13 23:50:54,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:54,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78632 synced till here 78631
2014-07-13 23:50:54,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320653077 with entries=62, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320654572
2014-07-13 23:50:55,542 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90222ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:50:55,542 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 607.3m
2014-07-13 23:50:55,836 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:55,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78696 synced till here 78694
2014-07-13 23:50:55,927 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320654572 with entries=64, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320655837
2014-07-13 23:50:56,019 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:50:57,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:57,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78757 synced till here 78756
2014-07-13 23:50:57,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320655837 with entries=61, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320657379
2014-07-13 23:50:57,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 2 regions(s): baaed08b3b283bc33b53e718e07d0f23, d679c2853f294b83582eebcd030d1677
2014-07-13 23:50:58,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:50:59,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78823 synced till here 78822
2014-07-13 23:50:59,143 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320657379 with entries=66, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320658964
2014-07-13 23:50:59,144 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 2 regions(s): baaed08b3b283bc33b53e718e07d0f23, d679c2853f294b83582eebcd030d1677
2014-07-13 23:51:00,886 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:00,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78887 synced till here 78886
2014-07-13 23:51:00,933 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320658964 with entries=64, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320660886
2014-07-13 23:51:00,933 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 2 regions(s): baaed08b3b283bc33b53e718e07d0f23, d679c2853f294b83582eebcd030d1677
2014-07-13 23:51:02,936 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:02,958 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78958 synced till here 78951
2014-07-13 23:51:02,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320660886 with entries=71, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320662936
2014-07-13 23:51:02,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 2 regions(s): baaed08b3b283bc33b53e718e07d0f23, d679c2853f294b83582eebcd030d1677
2014-07-13 23:51:04,350 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:04,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79046 synced till here 79040
2014-07-13 23:51:04,558 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320662936 with entries=88, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320664350
2014-07-13 23:51:04,559 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 2 regions(s): baaed08b3b283bc33b53e718e07d0f23, d679c2853f294b83582eebcd030d1677
2014-07-13 23:51:04,835 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 23:51:04,836 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. has too many store files, but is 1.3g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 23:51:04,836 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. due to global heap pressure
2014-07-13 23:51:04,836 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 1.3g
2014-07-13 23:51:05,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:06,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79125 synced till here 79118
2014-07-13 23:51:06,184 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320664350 with entries=79, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320665528
2014-07-13 23:51:06,184 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): baaed08b3b283bc33b53e718e07d0f23
2014-07-13 23:51:06,755 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:51:06,971 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:06,992 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,019 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,029 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,030 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:07,045 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,072 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79186 synced till here 79185
2014-07-13 23:51:07,078 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,087 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320665528 with entries=61, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320667030
2014-07-13 23:51:07,087 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): baaed08b3b283bc33b53e718e07d0f23
2014-07-13 23:51:07,088 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,096 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,111 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,166 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,179 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,183 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,243 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,866 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,875 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,893 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,899 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,907 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:07,981 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:08,061 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:08,063 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:08,095 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:08,105 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:08,134 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,152 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,167 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,180 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,192 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,235 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,243 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,282 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,329 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,374 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,406 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,414 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,460 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:09,505 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,150 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,162 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,164 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,200 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,228 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,264 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,277 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,316 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,354 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,394 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,402 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:11,467 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/dc4b1751b887468e99d13c9184dd757f as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/dc4b1751b887468e99d13c9184dd757f
2014-07-13 23:51:11,486 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:51:11,495 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8940e542a43a46069c460ef54f1932bb, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8940e542a43a46069c460ef54f1932bb
2014-07-13 23:51:11,499 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8093fc6bd66143b0a625f8db92195200, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/8093fc6bd66143b0a625f8db92195200
2014-07-13 23:51:11,501 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6b7fa8b576094f499adfe2db74c7dd27, to hdfs://master:54310/hbase/archive/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/6b7fa8b576094f499adfe2db74c7dd27
2014-07-13 23:51:11,501 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. into dc4b1751b887468e99d13c9184dd757f(size=339.9m), total size for store is 4.1g. This selection was in queue for 0sec, and took 1mins, 2sec to execute.
2014-07-13 23:51:11,501 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., storeName=family, fileCount=3, fileSize=360.1m, priority=-1, time=274516305011994; duration=1mins, 2sec
2014-07-13 23:51:11,502 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-13 23:51:11,502 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-13 23:51:11,502 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 23:51:11,503 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 94676091 starting at candidate #16 after considering 124 permutations with 98 in ratio
2014-07-13 23:51:11,503 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: baaed08b3b283bc33b53e718e07d0f23 - family: Initiating minor compaction
2014-07-13 23:51:11,503 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:51:11,504 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp, totalSize=90.3m
2014-07-13 23:51:11,504 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f65ad6bcec3484c8b6a6cd7cbeae507, keycount=25199, bloomtype=ROW, size=18.0m, encoding=NONE, seqNum=23427
2014-07-13 23:51:11,504 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c74b4ae2b131439eb16d07c68fbdc031, keycount=80089, bloomtype=ROW, size=57.1m, encoding=NONE, seqNum=23717
2014-07-13 23:51:11,504 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6cb38cb2d71440648590e612868af04f, keycount=21418, bloomtype=ROW, size=15.3m, encoding=NONE, seqNum=24074
2014-07-13 23:51:11,561 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:51:11,972 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:11,992 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:12,019 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:12,030 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:12,435 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5192ms
2014-07-13 23:51:12,435 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5324ms
2014-07-13 23:51:12,436 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5270ms
2014-07-13 23:51:12,436 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5253ms
2014-07-13 23:51:12,436 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5257ms
2014-07-13 23:51:12,437 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5392ms
2014-07-13 23:51:12,437 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5359ms
2014-07-13 23:51:12,437 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5349ms
2014-07-13 23:51:12,438 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5342ms
2014-07-13 23:51:12,866 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:12,875 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:12,894 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:12,899 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:12,907 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:12,981 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:13,062 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:13,063 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:13,095 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:13,105 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:13,135 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:13,254 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:13,262 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:13,443 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17790, memsize=397.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/e6f60e41da8640f1966c8a1539932ab4
2014-07-13 23:51:13,457 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/.tmp/e6f60e41da8640f1966c8a1539932ab4 as hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e6f60e41da8640f1966c8a1539932ab4
2014-07-13 23:51:13,467 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/8b827125b32700e6f7c5c34f77be22cb/family/e6f60e41da8640f1966c8a1539932ab4, entries=1445980, sequenceid=17790, filesize=102.9m
2014-07-13 23:51:13,467 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~609.4m/638998880, currentsize=221.0m/231741520 for region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. in 17925ms, sequenceid=17790, compaction requested=true
2014-07-13 23:51:13,467 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-13 23:51:13,468 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 206ms
2014-07-13 23:51:13,468 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,468 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 214ms
2014-07-13 23:51:13,468 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,469 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5334ms
2014-07-13 23:51:13,469 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,469 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5364ms
2014-07-13 23:51:13,469 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,469 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5374ms
2014-07-13 23:51:13,469 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,475 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5412ms
2014-07-13 23:51:13,475 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,475 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5414ms
2014-07-13 23:51:13,475 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,475 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5494ms
2014-07-13 23:51:13,475 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,477 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5570ms
2014-07-13 23:51:13,477 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,477 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5578ms
2014-07-13 23:51:13,477 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,477 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5584ms
2014-07-13 23:51:13,477 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,484 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5609ms
2014-07-13 23:51:13,484 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,485 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5619ms
2014-07-13 23:51:13,485 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,485 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6389ms
2014-07-13 23:51:13,485 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,485 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6397ms
2014-07-13 23:51:13,485 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,488 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6410ms
2014-07-13 23:51:13,488 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,488 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6444ms
2014-07-13 23:51:13,488 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,489 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6309ms
2014-07-13 23:51:13,489 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,490 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6306ms
2014-07-13 23:51:13,490 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,493 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6327ms
2014-07-13 23:51:13,493 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,493 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6382ms
2014-07-13 23:51:13,493 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,501 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6258ms
2014-07-13 23:51:13,502 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,505 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6476ms
2014-07-13 23:51:13,505 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,514 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6494ms
2014-07-13 23:51:13,514 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,515 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6522ms
2014-07-13 23:51:13,515 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,516 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6544ms
2014-07-13 23:51:13,516 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,516 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2114ms
2014-07-13 23:51:13,517 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,525 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2131ms
2014-07-13 23:51:13,525 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,525 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2171ms
2014-07-13 23:51:13,525 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,525 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2209ms
2014-07-13 23:51:13,525 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,525 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2248ms
2014-07-13 23:51:13,525 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,526 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2262ms
2014-07-13 23:51:13,526 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,528 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2299ms
2014-07-13 23:51:13,528 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,528 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2328ms
2014-07-13 23:51:13,528 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,528 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2364ms
2014-07-13 23:51:13,528 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,530 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2368ms
2014-07-13 23:51:13,530 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,530 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2380ms
2014-07-13 23:51:13,530 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,537 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4032ms
2014-07-13 23:51:13,537 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,537 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4077ms
2014-07-13 23:51:13,537 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,538 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4123ms
2014-07-13 23:51:13,538 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,538 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4132ms
2014-07-13 23:51:13,538 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,549 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4175ms
2014-07-13 23:51:13,549 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,550 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4220ms
2014-07-13 23:51:13,550 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,550 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4269ms
2014-07-13 23:51:13,550 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,550 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4307ms
2014-07-13 23:51:13,550 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,551 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4316ms
2014-07-13 23:51:13,551 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,552 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4359ms
2014-07-13 23:51:13,552 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,557 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4377ms
2014-07-13 23:51:13,557 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,557 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4390ms
2014-07-13 23:51:13,557 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:13,557 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4405ms
2014-07-13 23:51:13,557 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:15,201 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:15,474 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:51:15,474 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb. has too many store files; delaying flush up to 90000ms
2014-07-13 23:51:15,474 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:154), split_queue=0, merge_queue=0
2014-07-13 23:51:15,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79354 synced till here 79314
2014-07-13 23:51:16,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320667030 with entries=168, filesize=145.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320675201
2014-07-13 23:51:16,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): baaed08b3b283bc33b53e718e07d0f23
2014-07-13 23:51:17,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:17,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320675201 with entries=84, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320677322
2014-07-13 23:51:17,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): baaed08b3b283bc33b53e718e07d0f23
2014-07-13 23:51:17,633 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 23:51:17,633 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. has too many store files, but is 1.3g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 23:51:17,633 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. due to global heap pressure
2014-07-13 23:51:17,634 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 1.3g
2014-07-13 23:51:18,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:18,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79502 synced till here 79495
2014-07-13 23:51:18,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320677322 with entries=64, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320678542
2014-07-13 23:51:19,224 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:51:19,682 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,688 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,694 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,712 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,712 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,727 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,739 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,750 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,782 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:19,988 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,029 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,046 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,092 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,097 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,134 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,153 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,199 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,262 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,264 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,319 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,328 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,340 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,342 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,464 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,464 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,528 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,573 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,575 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,585 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,595 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,749 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,870 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:20,952 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,014 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,826 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,834 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,869 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,898 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,905 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,935 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,963 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:21,992 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,900 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,907 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,916 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,916 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,916 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,916 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,928 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:23,941 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405318163017: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 23:51:24,682 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:24,688 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:24,694 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:24,712 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:24,712 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:24,727 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:24,739 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:24,751 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:24,783 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:24,988 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,030 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,047 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,092 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,097 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,134 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,153 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,199 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,263 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,265 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,319 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,329 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,340 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,343 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,464 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,465 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,528 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,573 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,575 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,586 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,595 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,735 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/55e5e72ceb0848bdb1b71472e0b574a3 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/55e5e72ceb0848bdb1b71472e0b574a3
2014-07-13 23:51:25,749 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:25,755 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Removing store files after compaction...
2014-07-13 23:51:25,769 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f65ad6bcec3484c8b6a6cd7cbeae507, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/7f65ad6bcec3484c8b6a6cd7cbeae507
2014-07-13 23:51:25,776 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c74b4ae2b131439eb16d07c68fbdc031, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/c74b4ae2b131439eb16d07c68fbdc031
2014-07-13 23:51:25,781 DEBUG [regionserver60020-smallCompactions-1405318202263] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6cb38cb2d71440648590e612868af04f, to hdfs://master:54310/hbase/archive/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/6cb38cb2d71440648590e612868af04f
2014-07-13 23:51:25,782 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. into 55e5e72ceb0848bdb1b71472e0b574a3(size=79.3m), total size for store is 3.9g. This selection was in queue for 0sec, and took 14sec to execute.
2014-07-13 23:51:25,782 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., storeName=family, fileCount=3, fileSize=90.3m, priority=-1, time=274578930530929; duration=14sec
2014-07-13 23:51:25,783 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:154), split_queue=0, merge_queue=0
2014-07-13 23:51:25,783 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 23:51:25,786 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 592553809 starting at candidate #7 after considering 124 permutations with 116 in ratio
2014-07-13 23:51:25,786 DEBUG [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: d679c2853f294b83582eebcd030d1677 - family: Initiating minor compaction
2014-07-13 23:51:25,787 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:51:25,787 INFO  [regionserver60020-smallCompactions-1405318202263] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp, totalSize=565.1m
2014-07-13 23:51:25,788 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/8e52eece5fa64a4d83dcd468032f385a, keycount=188861, bloomtype=ROW, size=134.5m, encoding=NONE, seqNum=10319
2014-07-13 23:51:25,788 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/25b75ced49634ed6954a5f2b307e905f, keycount=142715, bloomtype=ROW, size=101.7m, encoding=NONE, seqNum=10758
2014-07-13 23:51:25,788 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/3e59221dcbe74033bbb6b27e15363255, keycount=170126, bloomtype=ROW, size=121.1m, encoding=NONE, seqNum=11263
2014-07-13 23:51:25,788 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/97af7dcaf50942e49f1a7f30316e1c5e, keycount=178845, bloomtype=ROW, size=127.4m, encoding=NONE, seqNum=11792
2014-07-13 23:51:25,788 DEBUG [regionserver60020-smallCompactions-1405318202263] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/be672ff979a64225b4ec805601d46de9, keycount=112966, bloomtype=ROW, size=80.4m, encoding=NONE, seqNum=12313
2014-07-13 23:51:25,871 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:25,886 DEBUG [regionserver60020-smallCompactions-1405318202263] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:51:25,952 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:26,014 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:26,826 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:26,834 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:26,870 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:26,899 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:26,906 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:26,935 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:26,964 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:26,993 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:28,901 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:28,907 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:28,916 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:28,916 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:28,916 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:28,917 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:28,929 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 23:51:28,941 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 23:51:29,682 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:29,688 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:29,695 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:29,713 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:29,713 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:29,728 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:29,740 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:29,751 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:29,783 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:29,989 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,030 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,047 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,093 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,098 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,135 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,154 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 23:51:30,199 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:30,263 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,265 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,320 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,329 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,340 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:30,343 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,464 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,465 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,529 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,573 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:30,575 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:30,586 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,596 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:30,750 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:30,872 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:30,953 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,014 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:31,827 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,835 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,870 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,899 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,906 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,936 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,964 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:31,993 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:33,901 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:33,907 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:33,917 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 23:51:33,917 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:33,917 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:33,918 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:33,929 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:33,942 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 23:51:34,683 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:51:34,688 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:51:34,695 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:34,713 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:34,713 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:34,728 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:34,740 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:34,752 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:34,783 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:34,989 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,030 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,047 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,093 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,098 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,135 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,156 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-13 23:51:35,199 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:51:35,263 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,265 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,320 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,329 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,341 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,344 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,464 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,465 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,529 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,574 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,576 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,587 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:51:35,596 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,750 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:35,872 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:51:35,953 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:51:36,015 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,827 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,835 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,870 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,899 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,906 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,936 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,964 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:36,994 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:51:38,902 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:51:38,907 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 23:51:38,917 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:38,917 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:38,917 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:38,918 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 23:51:38,929 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:38,942 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 23:51:38,997 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17861, memsize=831.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/53b16a65644341aba0e48d64f993595f
2014-07-13 23:51:39,016 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/53b16a65644341aba0e48d64f993595f as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/53b16a65644341aba0e48d64f993595f
2014-07-13 23:51:39,037 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/53b16a65644341aba0e48d64f993595f, entries=3026770, sequenceid=17861, filesize=215.4m
2014-07-13 23:51:39,037 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.3g/1350883600, currentsize=207.7m/217807520 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 34201ms, sequenceid=17861, compaction requested=true
2014-07-13 23:51:39,037 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:154), split_queue=0, merge_queue=0
2014-07-13 23:51:39,038 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15097ms
2014-07-13 23:51:39,038 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 105511ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:51:39,038 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,038 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15110ms
2014-07-13 23:51:39,038 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,038 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677., current region memstore size 207.7m
2014-07-13 23:51:39,041 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15125ms
2014-07-13 23:51:39,041 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,041 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15125ms
2014-07-13 23:51:39,041 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,041 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15125ms
2014-07-13 23:51:39,041 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,044 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15128ms
2014-07-13 23:51:39,044 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,044 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15137ms
2014-07-13 23:51:39,044 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,044 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15144ms
2014-07-13 23:51:39,044 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,044 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17052ms
2014-07-13 23:51:39,044 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,045 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17082ms
2014-07-13 23:51:39,046 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,052 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17117ms
2014-07-13 23:51:39,052 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,053 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17147ms
2014-07-13 23:51:39,053 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,061 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17163ms
2014-07-13 23:51:39,061 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,063 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17194ms
2014-07-13 23:51:39,063 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,067 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17233ms
2014-07-13 23:51:39,067 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,068 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17241ms
2014-07-13 23:51:39,068 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,068 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18054ms
2014-07-13 23:51:39,068 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,069 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18117ms
2014-07-13 23:51:39,069 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,070 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18200ms
2014-07-13 23:51:39,070 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,070 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18321ms
2014-07-13 23:51:39,070 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,078 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18483ms
2014-07-13 23:51:39,078 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,078 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18493ms
2014-07-13 23:51:39,078 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,078 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18503ms
2014-07-13 23:51:39,078 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,079 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18506ms
2014-07-13 23:51:39,079 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,082 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18554ms
2014-07-13 23:51:39,082 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,083 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18619ms
2014-07-13 23:51:39,083 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,083 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18620ms
2014-07-13 23:51:39,083 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,083 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18741ms
2014-07-13 23:51:39,083 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,085 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18745ms
2014-07-13 23:51:39,085 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,086 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18757ms
2014-07-13 23:51:39,086 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,089 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18770ms
2014-07-13 23:51:39,089 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,089 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18825ms
2014-07-13 23:51:39,089 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,093 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18831ms
2014-07-13 23:51:39,093 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,093 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18894ms
2014-07-13 23:51:39,093 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,094 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18941ms
2014-07-13 23:51:39,094 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,098 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18964ms
2014-07-13 23:51:39,098 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,099 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19002ms
2014-07-13 23:51:39,099 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,099 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19007ms
2014-07-13 23:51:39,100 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,100 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19054ms
2014-07-13 23:51:39,100 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,101 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19071ms
2014-07-13 23:51:39,101 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:39,109 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19121ms
2014-07-13 23:51:39,109 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,109 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19327ms
2014-07-13 23:51:39,109 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,114 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19364ms
2014-07-13 23:51:39,114 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,115 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19376ms
2014-07-13 23:51:39,115 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,115 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19388ms
2014-07-13 23:51:39,115 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,115 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19403ms
2014-07-13 23:51:39,115 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,115 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19403ms
2014-07-13 23:51:39,116 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,116 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19422ms
2014-07-13 23:51:39,116 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,116 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19428ms
2014-07-13 23:51:39,116 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,125 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19443ms
2014-07-13 23:51:39,125 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405318163017
2014-07-13 23:51:39,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79591 synced till here 79574
2014-07-13 23:51:39,171 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:51:39,200 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683916,"queuetimems":0,"class":"HRegionServer","responsesize":255,"method":"Multi"}
2014-07-13 23:51:39,200 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15294,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683905,"queuetimems":1,"class":"HRegionServer","responsesize":2646,"method":"Multi"}
2014-07-13 23:51:39,200 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683916,"queuetimems":1,"class":"HRegionServer","responsesize":44,"method":"Multi"}
2014-07-13 23:51:39,200 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683916,"queuetimems":0,"class":"HRegionServer","responsesize":80,"method":"Multi"}
2014-07-13 23:51:39,200 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15260,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683939,"queuetimems":0,"class":"HRegionServer","responsesize":5065,"method":"Multi"}
2014-07-13 23:51:39,200 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15300,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683899,"queuetimems":0,"class":"HRegionServer","responsesize":1603,"method":"Multi"}
2014-07-13 23:51:39,264 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17361,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681903,"queuetimems":0,"class":"HRegionServer","responsesize":4270,"method":"Multi"}
2014-07-13 23:51:39,273 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320678542 with entries=89, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320699104
2014-07-13 23:51:39,362 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19793,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679568,"queuetimems":1,"class":"HRegionServer","responsesize":15353,"method":"Multi"}
2014-07-13 23:51:39,365 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15450,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683915,"queuetimems":0,"class":"HRegionServer","responsesize":1611,"method":"Multi"}
2014-07-13 23:51:39,366 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19846,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679519,"queuetimems":0,"class":"HRegionServer","responsesize":15642,"method":"Multi"}
2014-07-13 23:51:39,563 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19220,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680342,"queuetimems":1,"class":"HRegionServer","responsesize":1603,"method":"Multi"}
2014-07-13 23:51:39,563 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680091,"queuetimems":0,"class":"HRegionServer","responsesize":1650,"method":"Multi"}
2014-07-13 23:51:39,563 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17730,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681832,"queuetimems":0,"class":"HRegionServer","responsesize":4891,"method":"Multi"}
2014-07-13 23:51:39,563 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19410,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680152,"queuetimems":0,"class":"HRegionServer","responsesize":1688,"method":"Multi"}
2014-07-13 23:51:39,563 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19301,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680262,"queuetimems":0,"class":"HRegionServer","responsesize":589,"method":"Multi"}
2014-07-13 23:51:39,563 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19225,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680338,"queuetimems":0,"class":"HRegionServer","responsesize":4109,"method":"Multi"}
2014-07-13 23:51:39,565 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19101,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680464,"queuetimems":0,"class":"HRegionServer","responsesize":631,"method":"Multi"}
2014-07-13 23:51:39,565 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18970,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680595,"queuetimems":0,"class":"HRegionServer","responsesize":44,"method":"Multi"}
2014-07-13 23:51:39,567 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19523,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680044,"queuetimems":0,"class":"HRegionServer","responsesize":4932,"method":"Multi"}
2014-07-13 23:51:39,570 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680133,"queuetimems":0,"class":"HRegionServer","responsesize":1500,"method":"Multi"}
2014-07-13 23:51:39,573 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15646,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320683927,"queuetimems":0,"class":"HRegionServer","responsesize":4604,"method":"Multi"}
2014-07-13 23:51:39,576 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17752,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681823,"queuetimems":0,"class":"HRegionServer","responsesize":5139,"method":"Multi"}
2014-07-13 23:51:39,581 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19009,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680572,"queuetimems":0,"class":"HRegionServer","responsesize":255,"method":"Multi"}
2014-07-13 23:51:39,585 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19000,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680585,"queuetimems":0,"class":"HRegionServer","responsesize":80,"method":"Multi"}
2014-07-13 23:51:39,585 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19387,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680198,"queuetimems":1,"class":"HRegionServer","responsesize":1810,"method":"Multi"}
2014-07-13 23:51:39,594 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19131,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680463,"queuetimems":0,"class":"HRegionServer","responsesize":1588,"method":"Multi"}
2014-07-13 23:51:39,600 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19571,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680028,"queuetimems":0,"class":"HRegionServer","responsesize":2646,"method":"Multi"}
2014-07-13 23:51:39,602 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19616,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679986,"queuetimems":1,"class":"HRegionServer","responsesize":5065,"method":"Multi"}
2014-07-13 23:51:39,605 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19868,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679737,"queuetimems":1,"class":"HRegionServer","responsesize":5139,"method":"Multi"}
2014-07-13 23:51:39,610 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680326,"queuetimems":0,"class":"HRegionServer","responsesize":4241,"method":"Multi"}
2014-07-13 23:51:39,621 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19929,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679692,"queuetimems":0,"class":"HRegionServer","responsesize":4891,"method":"Multi"}
2014-07-13 23:51:39,691 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20082,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679609,"queuetimems":0,"class":"HRegionServer","responsesize":17597,"method":"Multi"}
2014-07-13 23:51:39,695 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17734,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681961,"queuetimems":1,"class":"HRegionServer","responsesize":15311,"method":"Multi"}
2014-07-13 23:51:39,901 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20153,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679748,"queuetimems":0,"class":"HRegionServer","responsesize":4270,"method":"Multi"}
2014-07-13 23:51:39,902 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17911,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681990,"queuetimems":0,"class":"HRegionServer","responsesize":15642,"method":"Multi"}
2014-07-13 23:51:40,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:40,777 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18845,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681932,"queuetimems":0,"class":"HRegionServer","responsesize":15353,"method":"Multi"}
2014-07-13 23:51:40,781 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:51:40,856 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79705 synced till here 79682
2014-07-13 23:51:40,982 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19085,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681896,"queuetimems":0,"class":"HRegionServer","responsesize":15614,"method":"Multi"}
2014-07-13 23:51:40,982 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20031,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680951,"queuetimems":0,"class":"HRegionServer","responsesize":4604,"method":"Multi"}
2014-07-13 23:51:40,987 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20890,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680096,"queuetimems":0,"class":"HRegionServer","responsesize":1611,"method":"Multi"}
2014-07-13 23:51:40,987 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19973,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681013,"queuetimems":0,"class":"HRegionServer","responsesize":2970,"method":"Multi"}
2014-07-13 23:51:40,993 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20246,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680747,"queuetimems":0,"class":"HRegionServer","responsesize":11305,"method":"Multi"}
2014-07-13 23:51:40,994 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20125,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680869,"queuetimems":0,"class":"HRegionServer","responsesize":7125,"method":"Multi"}
2014-07-13 23:51:41,031 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320699104 with entries=114, filesize=91.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320700775
2014-07-13 23:51:41,429 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680572,"queuetimems":1,"class":"HRegionServer","responsesize":17605,"method":"Multi"}
2014-07-13 23:51:41,438 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679725,"queuetimems":0,"class":"HRegionServer","responsesize":15614,"method":"Multi"}
2014-07-13 23:51:41,429 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679684,"queuetimems":1,"class":"HRegionServer","responsesize":15311,"method":"Multi"}
2014-07-13 23:51:41,429 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680262,"queuetimems":1,"class":"HRegionServer","responsesize":17995,"method":"Multi"}
2014-07-13 23:51:41,438 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20912,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680525,"queuetimems":0,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-13 23:51:41,445 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19578,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320681866,"queuetimems":0,"class":"HRegionServer","responsesize":17597,"method":"Multi"}
2014-07-13 23:51:41,466 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320680316,"queuetimems":0,"class":"HRegionServer","responsesize":17423,"method":"Multi"}
2014-07-13 23:51:42,645 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:42,680 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22900,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47043","starttimems":1405320679780,"queuetimems":0,"class":"HRegionServer","responsesize":15478,"method":"Multi"}
2014-07-13 23:51:42,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79848 synced till here 79832
2014-07-13 23:51:43,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320700775 with entries=143, filesize=112.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320702646
2014-07-13 23:51:44,598 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:44,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79957 synced till here 79943
2014-07-13 23:51:44,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320702646 with entries=109, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320704599
2014-07-13 23:51:46,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:46,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320704599 with entries=81, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320706182
2014-07-13 23:51:46,709 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17968, memsize=129.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/df955411838b436ba3875d488c6bcf7b
2014-07-13 23:51:46,723 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/.tmp/df955411838b436ba3875d488c6bcf7b as hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/df955411838b436ba3875d488c6bcf7b
2014-07-13 23:51:46,845 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d679c2853f294b83582eebcd030d1677/family/df955411838b436ba3875d488c6bcf7b, entries=473100, sequenceid=17968, filesize=33.7m
2014-07-13 23:51:46,845 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~207.7m/217807520, currentsize=174.4m/182867040 for region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. in 7807ms, sequenceid=17968, compaction requested=true
2014-07-13 23:51:46,846 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:155), split_queue=0, merge_queue=0
2014-07-13 23:51:46,846 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677. has too many store files; delaying flush up to 90000ms
2014-07-13 23:51:46,846 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:156), split_queue=0, merge_queue=0
2014-07-13 23:51:49,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:49,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80126 synced till here 80124
2014-07-13 23:51:49,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320706182 with entries=88, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320709637
2014-07-13 23:51:51,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:51,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320709637 with entries=68, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320711221
2014-07-13 23:51:52,087 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405318543624.d679c2853f294b83582eebcd030d1677.
2014-07-13 23:51:52,524 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:52,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80256 synced till here 80254
2014-07-13 23:51:52,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320711221 with entries=62, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320712525
2014-07-13 23:51:53,603 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:53,664 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80326 synced till here 80325
2014-07-13 23:51:53,714 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320712525 with entries=70, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320713604
2014-07-13 23:51:55,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:55,203 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320713604 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320715168
2014-07-13 23:51:55,869 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 23:51:55,869 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. has too many store files, but is 1.1g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 23:51:55,869 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. due to global heap pressure
2014-07-13 23:51:55,869 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2., current region memstore size 1.1g
2014-07-13 23:51:56,195 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=25880, memsize=896.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d352ee5359d6438b96cb2d273cbbb5a6
2014-07-13 23:51:56,210 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/d352ee5359d6438b96cb2d273cbbb5a6 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d352ee5359d6438b96cb2d273cbbb5a6
2014-07-13 23:51:56,223 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/d352ee5359d6438b96cb2d273cbbb5a6, entries=3263250, sequenceid=25880, filesize=232.2m
2014-07-13 23:51:56,224 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.3g/1419127360, currentsize=343.8m/360513920 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 38590ms, sequenceid=25880, compaction requested=true
2014-07-13 23:51:56,224 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-13 23:51:56,288 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23.
2014-07-13 23:51:56,288 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23., current region memstore size 344.1m
2014-07-13 23:51:56,350 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:56,494 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:51:56,570 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80467 synced till here 80466
2014-07-13 23:51:56,821 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:51:56,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320715168 with entries=69, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320716350
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320568390
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320569831
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320571470
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320572908
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320574320
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320575677
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320577591
2014-07-13 23:51:56,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320579107
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320580739
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320583048
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320584142
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320593953
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320595746
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320597429
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320599518
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320602963
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320604878
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320627549
2014-07-13 23:51:56,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320629416
2014-07-13 23:51:58,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:51:58,361 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320716350 with entries=76, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320718339
2014-07-13 23:52:00,276 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:52:00,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80614 synced till here 80613
2014-07-13 23:52:00,311 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320718339 with entries=71, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320720276
2014-07-13 23:52:02,418 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 23:52:02,443 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320720276 with entries=74, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405318163017/slave1%2C60020%2C1405318163017.1405320722418
2014-07-13 23:52:04,558 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=26256, memsize=232.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/b061879ac1d14fd5b45c7b0fccdece90
2014-07-13 23:52:04,573 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/.tmp/b061879ac1d14fd5b45c7b0fccdece90 as hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b061879ac1d14fd5b45c7b0fccdece90
2014-07-13 23:52:04,585 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/baaed08b3b283bc33b53e718e07d0f23/family/b061879ac1d14fd5b45c7b0fccdece90, entries=846380, sequenceid=26256, filesize=60.3m
2014-07-13 23:52:04,586 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~344.1m/360784640, currentsize=94.7m/99294160 for region usertable,user2,1405318543623.baaed08b3b283bc33b53e718e07d0f23. in 8298ms, sequenceid=26256, compaction requested=true
2014-07-13 23:52:04,586 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:158), split_queue=0, merge_queue=0
2014-07-13 23:52:09,987 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90125ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb.
2014-07-13 23:52:09,988 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405318543624.8b827125b32700e6f7c5c34f77be22cb., current region memstore size 833.9m
2014-07-13 23:52:10,519 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 23:52:26,144 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18060, memsize=863.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f8808a00fe0a421f85ca4980f8a8d03f
2014-07-13 23:52:26,161 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/.tmp/f8808a00fe0a421f85ca4980f8a8d03f as hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f8808a00fe0a421f85ca4980f8a8d03f
2014-07-13 23:52:26,179 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6935e08926c94c414c50c4e2b2667be2/family/f8808a00fe0a421f85ca4980f8a8d03f, entries=3143310, sequenceid=18060, filesize=223.7m
2014-07-13 23:52:26,179 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1176207120, currentsize=115.2m/120758320 for region usertable,user8,1405318543624.6935e08926c94c414c50c4e2b2667be2. in 30310ms, sequenceid=18060, compaction requested=true
2014-07-13 23:52:26,180 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:159), split_queue=0, merge_queue=0
