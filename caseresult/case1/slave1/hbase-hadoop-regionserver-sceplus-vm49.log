Wed Jul  2 03:03:15 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-02 03:03:15,558 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-02 03:03:15,558 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-02 03:03:15,558 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-02 03:03:15,778 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-02 03:03:15,778 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-02 03:03:15,778 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-02 03:03:15,778 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-02 03:03:15,778 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-02 03:03:15,778 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-02 03:03:15,778 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 41884 22
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-02 03:03:15,779 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 41884 9.1.143.59 22
2014-07-02 03:03:15,780 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-02 03:03:15,780 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-02 03:03:15,780 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-02 03:03:15,782 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=14
2014-07-02 03:03:15,783 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-02 03:03:15,783 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-02 03:03:15,783 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-02 03:03:15,783 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-02 03:03:15,783 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-02 03:03:15,785 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-02 03:03:15,785 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-02 03:03:15,981 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-02 03:03:16,313 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-02 03:03:16,397 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-02 03:03:16,408 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-02 03:03:16,465 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-02 03:03:16,466 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-02 03:03:16,466 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-02 03:03:16,470 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-02 03:03:16,474 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-02 03:03:16,556 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-02 03:03:16,557 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-02 03:03:16,560 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-02 03:03:16,562 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-02 03:03:16,624 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-02 03:03:16,688 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-02 03:03:16,695 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-02 03:03:16,697 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-02 03:03:16,697 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-02 03:03:16,697 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-02 03:03:16,968 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-02 03:03:17,008 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-02 03:03:17,008 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-02 03:03:17,009 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-02 03:03:17,030 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-02 03:03:17,032 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 03:03:17,036 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-02 03:03:17,046 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x46f6873b540002, negotiated timeout = 90000
2014-07-02 03:03:36,600 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x28a13626, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-02 03:03:36,601 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x28a13626 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-02 03:03:36,601 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 03:03:36,602 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-02 03:03:36,606 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x46f6873b540005, negotiated timeout = 90000
2014-07-02 03:03:36,837 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2894d02c
2014-07-02 03:03:36,840 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-02 03:03:36,844 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-02 03:03:36,883 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-02 03:03:36,909 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-02 03:03:36,914 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-02 03:03:36,917 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-02 03:03:36,933 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1404295396535 with port=60020, startcode=1404295396492
2014-07-02 03:03:37,214 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-02 03:03:37,214 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-02 03:03:37,214 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-02 03:03:37,237 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-02 03:03:37,244 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492
2014-07-02 03:03:37,274 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-02 03:03:37,285 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-02 03:03:37,380 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295417291
2014-07-02 03:03:37,400 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-02 03:03:37,404 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-02 03:03:37,408 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-02 03:03:37,412 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-02 03:03:37,414 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-02 03:03:37,414 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-02 03:03:37,414 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-02 03:03:37,414 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-02 03:03:37,415 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-02 03:03:37,422 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,60020,1404295397977, slave1,60020,1404295396492] other RSs: [sceplus-vm48.almaden.ibm.com,60020,1404295397977, slave1,60020,1404295396492]
2014-07-02 03:03:37,442 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-02 03:03:37,444 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x7ab2b76c, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-02 03:03:37,445 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x7ab2b76c connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-02 03:03:37,446 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 03:03:37,446 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-02 03:03:37,451 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x46f6873b540007, negotiated timeout = 90000
2014-07-02 03:03:37,457 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-02 03:03:37,457 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-02 03:03:37,497 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1404295396492, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x46f6873b540002
2014-07-02 03:03:37,497 INFO  [SplitLogWorker-slave1,60020,1404295396492] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1404295396492 starting
2014-07-02 03:03:37,497 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-02 03:03:37,497 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1404295396492
2014-07-02 03:03:37,497 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1404295396492'
2014-07-02 03:03:37,498 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-02 03:03:37,499 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-02 03:03:37,500 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-02 03:03:41,215 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-02 03:03:45,518 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-02 03:03:46,590 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-02 03:03:46,678 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-02 03:03:46,695 INFO  [SplitLogWorker-slave1,60020,1404295396492] regionserver.SplitLogWorker: worker slave1,60020,1404295396492 acquired task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404292707206-splitting%2Fslave1%252C60020%252C1404292707206.1404292737995
2014-07-02 03:03:46,739 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,60020,1404292707206-splitting/slave1%2C60020%2C1404292707206.1404292737995, length=3473
2014-07-02 03:03:46,739 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-02 03:03:46,746 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,60020,1404292707206-splitting/slave1%2C60020%2C1404292707206.1404292737995
2014-07-02 03:03:46,748 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=false, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,60020,1404292707206-splitting/slave1%2C60020%2C1404292707206.1404292737995 after 2ms
2014-07-02 03:03:50,676 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-02 03:03:50,679 DEBUG [SplitLogWorker-slave1,60020,1404295396492] regionserver.SplitLogWorker: Current region server slave1,60020,1404295396492 has 1 tasks in progress and can't take more.
2014-07-02 03:03:50,750 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=1 on file=hdfs://master:54310/hbase/WALs/slave1,60020,1404292707206-splitting/slave1%2C60020%2C1404292707206.1404292737995 after 4004ms
2014-07-02 03:03:50,775 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:50,796 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-02 03:03:50,796 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-02 03:03:50,797 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-02 03:03:50,882 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-02 03:03:50,882 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-02 03:03:50,889 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d779c9adf529b07dcceb0e4bd05e3373/recovered.edits/0000000000000001478.temp region=d779c9adf529b07dcceb0e4bd05e3373
2014-07-02 03:03:50,890 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448.temp region=9d63bbb258f2aef76a672dc0d6cecb61
2014-07-02 03:03:50,896 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/804f215a15af0984f46b747c7365b6ba/recovered.edits/0000000000000001448.temp region=804f215a15af0984f46b747c7365b6ba
2014-07-02 03:03:50,911 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445.temp region=520855c1b3b93d946764e9da9d0edf80
2014-07-02 03:03:50,911 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/a6fd625a1cd753fcf5a9e9a8c2f95570/recovered.edits/0000000000000001447.temp region=a6fd625a1cd753fcf5a9e9a8c2f95570
2014-07-02 03:03:50,916 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478.temp region=b62b022cd2443b4bab3918f838588116
2014-07-02 03:03:50,929 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450.temp region=a9e2628e1077954adea88f83afa06062
2014-07-02 03:03:50,932 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:50,932 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b62b022cd2443b4bab3918f838588116 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:50,933 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:50,934 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9d63bbb258f2aef76a672dc0d6cecb61 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:50,935 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 520855c1b3b93d946764e9da9d0edf80 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:50,946 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 520855c1b3b93d946764e9da9d0edf80 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:50,946 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b62b022cd2443b4bab3918f838588116 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:50,946 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9d63bbb258f2aef76a672dc0d6cecb61 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:50,947 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 520855c1b3b93d946764e9da9d0edf80, NAME => 'usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-02 03:03:50,947 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 9d63bbb258f2aef76a672dc0d6cecb61, NAME => 'usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-02 03:03:50,947 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => b62b022cd2443b4bab3918f838588116, NAME => 'usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-02 03:03:50,964 INFO  [RS_OPEN_REGION-slave1:60020-1] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-02 03:03:50,964 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 9d63bbb258f2aef76a672dc0d6cecb61
2014-07-02 03:03:50,964 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable b62b022cd2443b4bab3918f838588116
2014-07-02 03:03:50,964 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 520855c1b3b93d946764e9da9d0edf80
2014-07-02 03:03:50,965 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:50,965 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:50,965 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:50,966 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478.temp region=fbe435cd163a5ff9fb80c02d23b905fa
2014-07-02 03:03:50,966 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-02 03:03:50,968 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445.temp
2014-07-02 03:03:50,972 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/804f215a15af0984f46b747c7365b6ba/recovered.edits/0000000000000001448.temp
2014-07-02 03:03:50,972 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445.temp
2014-07-02 03:03:50,972 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448.temp
2014-07-02 03:03:50,973 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/804f215a15af0984f46b747c7365b6ba/recovered.edits/0000000000000001448.temp
2014-07-02 03:03:50,973 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/a6fd625a1cd753fcf5a9e9a8c2f95570/recovered.edits/0000000000000001447.temp
2014-07-02 03:03:50,974 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448.temp
2014-07-02 03:03:50,974 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450.temp
2014-07-02 03:03:50,975 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478.temp
2014-07-02 03:03:50,975 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d779c9adf529b07dcceb0e4bd05e3373/recovered.edits/0000000000000001478.temp
2014-07-02 03:03:50,976 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478.temp
2014-07-02 03:03:50,977 INFO  [RS_OPEN_REGION-slave1:60020-1] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-02 03:03:50,978 INFO  [RS_OPEN_REGION-slave1:60020-1] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-02 03:03:50,980 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-02 03:03:50,980 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-02 03:03:50,981 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-02 03:03:50,994 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445.temp (wrote 1 edits in 17ms)
2014-07-02 03:03:50,995 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/804f215a15af0984f46b747c7365b6ba/recovered.edits/0000000000000001448.temp (wrote 1 edits in 28ms)
2014-07-02 03:03:51,001 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448.temp (wrote 1 edits in 33ms)
2014-07-02 03:03:51,003 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445.temp to hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445
2014-07-02 03:03:51,004 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/a6fd625a1cd753fcf5a9e9a8c2f95570/recovered.edits/0000000000000001447.temp
2014-07-02 03:03:51,005 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/804f215a15af0984f46b747c7365b6ba/recovered.edits/0000000000000001448.temp to hdfs://master:54310/hbase/data/default/usertable/804f215a15af0984f46b747c7365b6ba/recovered.edits/0000000000000001448
2014-07-02 03:03:51,005 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450.temp
2014-07-02 03:03:51,007 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448.temp to hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448
2014-07-02 03:03:51,007 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478.temp
2014-07-02 03:03:51,017 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/a6fd625a1cd753fcf5a9e9a8c2f95570/recovered.edits/0000000000000001447.temp (wrote 1 edits in 17ms)
2014-07-02 03:03:51,019 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450.temp (wrote 1 edits in 17ms)
2014-07-02 03:03:51,037 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/a6fd625a1cd753fcf5a9e9a8c2f95570/recovered.edits/0000000000000001447.temp to hdfs://master:54310/hbase/data/default/usertable/a6fd625a1cd753fcf5a9e9a8c2f95570/recovered.edits/0000000000000001447
2014-07-02 03:03:51,038 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d779c9adf529b07dcceb0e4bd05e3373/recovered.edits/0000000000000001478.temp
2014-07-02 03:03:51,039 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450.temp to hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450
2014-07-02 03:03:51,040 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478.temp
2014-07-02 03:03:51,045 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478.temp (wrote 1 edits in 19ms)
2014-07-02 03:03:51,058 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d779c9adf529b07dcceb0e4bd05e3373/recovered.edits/0000000000000001478.temp (wrote 1 edits in 34ms)
2014-07-02 03:03:51,060 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478.temp to hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478
2014-07-02 03:03:51,061 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478.temp (wrote 1 edits in 54ms)
2014-07-02 03:03:51,065 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d779c9adf529b07dcceb0e4bd05e3373/recovered.edits/0000000000000001478.temp to hdfs://master:54310/hbase/data/default/usertable/d779c9adf529b07dcceb0e4bd05e3373/recovered.edits/0000000000000001478
2014-07-02 03:03:51,070 INFO  [StoreOpener-b62b022cd2443b4bab3918f838588116-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 03:03:51,070 INFO  [StoreOpener-520855c1b3b93d946764e9da9d0edf80-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 03:03:51,070 INFO  [StoreOpener-9d63bbb258f2aef76a672dc0d6cecb61-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 03:03:51,081 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478.temp to hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478
2014-07-02 03:03:51,082 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 8 edits across 8 regions; log file=hdfs://master:54310/hbase/WALs/slave1,60020,1404292707206-splitting/slave1%2C60020%2C1404292707206.1404292737995 is corrupted = false progress failed = false
2014-07-02 03:03:51,091 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404292707206-splitting%2Fslave1%252C60020%252C1404292707206.1404292737995 to final state DONE slave1,60020,1404295396492
2014-07-02 03:03:51,091 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1404295396492 done with task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404292707206-splitting%2Fslave1%252C60020%252C1404292707206.1404292737995 in 4380ms
2014-07-02 03:03:51,105 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-02 03:03:51,114 INFO  [StoreFileOpenerThread-family-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-02 03:03:51,149 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Open usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:51,152 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Open usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:51,156 WARN  [StoreFileOpenerThread-family-1] snappy.LoadSnappy: Snappy native library is available
2014-07-02 03:03:51,156 INFO  [StoreFileOpenerThread-family-1] snappy.LoadSnappy: Snappy native library loaded
2014-07-02 03:03:51,158 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-02 03:03:51,158 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-02 03:03:51,158 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-02 03:03:51,169 DEBUG [StoreOpener-9d63bbb258f2aef76a672dc0d6cecb61-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/family/cccffc3a97854b09b08415b18bf46ba2, isReference=false, isBulkLoadResult=false, seqid=1446, majorCompaction=true
2014-07-02 03:03:51,169 DEBUG [StoreOpener-520855c1b3b93d946764e9da9d0edf80-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/family/184e84fed5af4f978905de78464eeab7, isReference=false, isBulkLoadResult=false, seqid=1443, majorCompaction=true
2014-07-02 03:03:51,169 DEBUG [StoreOpener-b62b022cd2443b4bab3918f838588116-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/family/3642fd439d404b29b0e8a6460704acc1, isReference=false, isBulkLoadResult=false, seqid=1476, majorCompaction=true
2014-07-02 03:03:51,199 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 1 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116
2014-07-02 03:03:51,199 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 1 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61
2014-07-02 03:03:51,200 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 1 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80
2014-07-02 03:03:51,201 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478
2014-07-02 03:03:51,202 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448
2014-07-02 03:03:51,202 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445
2014-07-02 03:03:51,212 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Completing compaction from the WAL marker
2014-07-02 03:03:51,212 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Completing compaction from the WAL marker
2014-07-02 03:03:51,214 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:03:51,215 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:03:51,217 DEBUG [RS_OPEN_REGION-slave1:60020-0] backup.HFileArchiver: No store files to dispose, done!
2014-07-02 03:03:51,217 DEBUG [RS_OPEN_REGION-slave1:60020-1] backup.HFileArchiver: No store files to dispose, done!
2014-07-02 03:03:51,217 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node b62b022cd2443b4bab3918f838588116
2014-07-02 03:03:51,217 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9d63bbb258f2aef76a672dc0d6cecb61
2014-07-02 03:03:51,219 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 0, skipped 1, firstSequenceidInLog=1478, maxSequenceidInLog=1478, path=hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478
2014-07-02 03:03:51,219 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 0, skipped 1, firstSequenceidInLog=1448, maxSequenceidInLog=1448, path=hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448
2014-07-02 03:03:51,219 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Empty memstore size for the current region usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:51,219 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Empty memstore size for the current region usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:51,223 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/b62b022cd2443b4bab3918f838588116/recovered.edits/0000000000000001478
2014-07-02 03:03:51,223 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9d63bbb258f2aef76a672dc0d6cecb61/recovered.edits/0000000000000001448
2014-07-02 03:03:51,224 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Completing compaction from the WAL marker
2014-07-02 03:03:51,227 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined b62b022cd2443b4bab3918f838588116; next sequenceid=1479
2014-07-02 03:03:51,227 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node b62b022cd2443b4bab3918f838588116
2014-07-02 03:03:51,227 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:03:51,227 DEBUG [RS_OPEN_REGION-slave1:60020-2] backup.HFileArchiver: No store files to dispose, done!
2014-07-02 03:03:51,227 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 520855c1b3b93d946764e9da9d0edf80
2014-07-02 03:03:51,230 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 0, skipped 1, firstSequenceidInLog=1445, maxSequenceidInLog=1445, path=hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445
2014-07-02 03:03:51,230 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Empty memstore size for the current region usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:51,231 INFO  [PostOpenDeployTasks:b62b022cd2443b4bab3918f838588116] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:51,231 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 9d63bbb258f2aef76a672dc0d6cecb61; next sequenceid=1449
2014-07-02 03:03:51,231 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9d63bbb258f2aef76a672dc0d6cecb61
2014-07-02 03:03:51,233 INFO  [PostOpenDeployTasks:9d63bbb258f2aef76a672dc0d6cecb61] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:51,270 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/520855c1b3b93d946764e9da9d0edf80/recovered.edits/0000000000000001445
2014-07-02 03:03:51,274 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 520855c1b3b93d946764e9da9d0edf80; next sequenceid=1446
2014-07-02 03:03:51,274 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 520855c1b3b93d946764e9da9d0edf80
2014-07-02 03:03:51,276 INFO  [PostOpenDeployTasks:520855c1b3b93d946764e9da9d0edf80] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:51,322 INFO  [PostOpenDeployTasks:520855c1b3b93d946764e9da9d0edf80] catalog.MetaEditor: Updated row usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80. with server=slave1,60020,1404295396492
2014-07-02 03:03:51,322 INFO  [PostOpenDeployTasks:9d63bbb258f2aef76a672dc0d6cecb61] catalog.MetaEditor: Updated row usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61. with server=slave1,60020,1404295396492
2014-07-02 03:03:51,322 INFO  [PostOpenDeployTasks:b62b022cd2443b4bab3918f838588116] catalog.MetaEditor: Updated row usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116. with server=slave1,60020,1404295396492
2014-07-02 03:03:51,323 INFO  [PostOpenDeployTasks:9d63bbb258f2aef76a672dc0d6cecb61] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:51,322 INFO  [PostOpenDeployTasks:520855c1b3b93d946764e9da9d0edf80] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:51,323 INFO  [PostOpenDeployTasks:b62b022cd2443b4bab3918f838588116] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:51,324 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9d63bbb258f2aef76a672dc0d6cecb61 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,324 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 520855c1b3b93d946764e9da9d0edf80 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,325 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b62b022cd2443b4bab3918f838588116 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,329 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9d63bbb258f2aef76a672dc0d6cecb61 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,329 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 9d63bbb258f2aef76a672dc0d6cecb61 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:03:51,329 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 520855c1b3b93d946764e9da9d0edf80 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,329 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61. on slave1,60020,1404295396492
2014-07-02 03:03:51,330 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b62b022cd2443b4bab3918f838588116 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,330 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned b62b022cd2443b4bab3918f838588116 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:03:51,330 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 520855c1b3b93d946764e9da9d0edf80 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:03:51,331 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116. on slave1,60020,1404295396492
2014-07-02 03:03:51,331 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fbe435cd163a5ff9fb80c02d23b905fa from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:51,331 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80. on slave1,60020,1404295396492
2014-07-02 03:03:51,332 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a9e2628e1077954adea88f83afa06062 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:51,335 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fbe435cd163a5ff9fb80c02d23b905fa from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:51,336 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a9e2628e1077954adea88f83afa06062 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:03:51,336 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => fbe435cd163a5ff9fb80c02d23b905fa, NAME => 'usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-02 03:03:51,336 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => a9e2628e1077954adea88f83afa06062, NAME => 'usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-02 03:03:51,337 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable fbe435cd163a5ff9fb80c02d23b905fa
2014-07-02 03:03:51,337 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:51,337 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a9e2628e1077954adea88f83afa06062
2014-07-02 03:03:51,338 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:51,344 INFO  [StoreOpener-fbe435cd163a5ff9fb80c02d23b905fa-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 03:03:51,344 INFO  [StoreOpener-a9e2628e1077954adea88f83afa06062-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 03:03:51,366 DEBUG [StoreOpener-fbe435cd163a5ff9fb80c02d23b905fa-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/family/153ff32d2386456f9d7036c11ed4b4b6, isReference=false, isBulkLoadResult=false, seqid=1476, majorCompaction=false
2014-07-02 03:03:51,409 DEBUG [StoreOpener-a9e2628e1077954adea88f83afa06062-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/family/4f69947130f64516b46221cba18da487, isReference=false, isBulkLoadResult=false, seqid=1448, majorCompaction=true
2014-07-02 03:03:51,453 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 1 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062
2014-07-02 03:03:51,458 DEBUG [StoreOpener-fbe435cd163a5ff9fb80c02d23b905fa-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/family/611a3fa8869044fdab4d67c0503cc4f0, isReference=false, isBulkLoadResult=false, seqid=1020, majorCompaction=true
2014-07-02 03:03:51,460 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450
2014-07-02 03:03:51,465 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 1 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa
2014-07-02 03:03:51,468 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Completing compaction from the WAL marker
2014-07-02 03:03:51,469 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:03:51,469 DEBUG [RS_OPEN_REGION-slave1:60020-0] backup.HFileArchiver: No store files to dispose, done!
2014-07-02 03:03:51,469 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a9e2628e1077954adea88f83afa06062
2014-07-02 03:03:51,471 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 0, skipped 1, firstSequenceidInLog=1450, maxSequenceidInLog=1450, path=hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450
2014-07-02 03:03:51,471 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Empty memstore size for the current region usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:51,472 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478
2014-07-02 03:03:51,473 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/a9e2628e1077954adea88f83afa06062/recovered.edits/0000000000000001450
2014-07-02 03:03:51,481 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Completing compaction from the WAL marker
2014-07-02 03:03:51,483 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:03:51,483 DEBUG [RS_OPEN_REGION-slave1:60020-1] backup.HFileArchiver: No store files to dispose, done!
2014-07-02 03:03:51,483 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fbe435cd163a5ff9fb80c02d23b905fa
2014-07-02 03:03:51,486 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 0, skipped 1, firstSequenceidInLog=1478, maxSequenceidInLog=1478, path=hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478
2014-07-02 03:03:51,486 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Empty memstore size for the current region usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:51,487 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined a9e2628e1077954adea88f83afa06062; next sequenceid=1451
2014-07-02 03:03:51,487 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a9e2628e1077954adea88f83afa06062
2014-07-02 03:03:51,489 INFO  [PostOpenDeployTasks:a9e2628e1077954adea88f83afa06062] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:51,497 INFO  [PostOpenDeployTasks:a9e2628e1077954adea88f83afa06062] catalog.MetaEditor: Updated row usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062. with server=slave1,60020,1404295396492
2014-07-02 03:03:51,498 INFO  [PostOpenDeployTasks:a9e2628e1077954adea88f83afa06062] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:51,498 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a9e2628e1077954adea88f83afa06062 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,504 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a9e2628e1077954adea88f83afa06062 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,504 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned a9e2628e1077954adea88f83afa06062 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:03:51,504 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062. on slave1,60020,1404295396492
2014-07-02 03:03:51,525 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/fbe435cd163a5ff9fb80c02d23b905fa/recovered.edits/0000000000000001478
2014-07-02 03:03:51,529 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined fbe435cd163a5ff9fb80c02d23b905fa; next sequenceid=1479
2014-07-02 03:03:51,529 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fbe435cd163a5ff9fb80c02d23b905fa
2014-07-02 03:03:51,532 INFO  [PostOpenDeployTasks:fbe435cd163a5ff9fb80c02d23b905fa] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:51,540 INFO  [PostOpenDeployTasks:fbe435cd163a5ff9fb80c02d23b905fa] catalog.MetaEditor: Updated row usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa. with server=slave1,60020,1404295396492
2014-07-02 03:03:51,541 INFO  [PostOpenDeployTasks:fbe435cd163a5ff9fb80c02d23b905fa] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:51,541 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fbe435cd163a5ff9fb80c02d23b905fa from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,553 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fbe435cd163a5ff9fb80c02d23b905fa from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:03:51,553 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned fbe435cd163a5ff9fb80c02d23b905fa to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:03:51,553 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa. on slave1,60020,1404295396492
2014-07-02 03:03:53,560 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close fbe435cd163a5ff9fb80c02d23b905fa, via zk=yes, znode version=0, on null
2014-07-02 03:03:53,560 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close 9d63bbb258f2aef76a672dc0d6cecb61, via zk=yes, znode version=0, on null
2014-07-02 03:03:53,560 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close b62b022cd2443b4bab3918f838588116, via zk=yes, znode version=0, on null
2014-07-02 03:03:53,560 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Close a9e2628e1077954adea88f83afa06062, via zk=yes, znode version=0, on null
2014-07-02 03:03:53,561 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Close 520855c1b3b93d946764e9da9d0edf80, via zk=yes, znode version=0, on null
2014-07-02 03:03:53,563 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:53,563 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:53,563 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:53,568 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.: disabling compactions & flushes
2014-07-02 03:03:53,568 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.: disabling compactions & flushes
2014-07-02 03:03:53,568 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:53,568 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:53,568 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.: disabling compactions & flushes
2014-07-02 03:03:53,569 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:53,599 INFO  [StoreCloserThread-usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.-1] regionserver.HStore: Closed family
2014-07-02 03:03:53,599 INFO  [StoreCloserThread-usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.-1] regionserver.HStore: Closed family
2014-07-02 03:03:53,601 INFO  [StoreCloserThread-usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.-1] regionserver.HStore: Closed family
2014-07-02 03:03:53,603 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:53,603 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:53,603 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9d63bbb258f2aef76a672dc0d6cecb61 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,603 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fbe435cd163a5ff9fb80c02d23b905fa from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,603 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:53,603 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a9e2628e1077954adea88f83afa06062 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,607 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9d63bbb258f2aef76a672dc0d6cecb61 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,607 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61. on slave1,60020,1404295396492
2014-07-02 03:03:53,607 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user7,1404281258516.9d63bbb258f2aef76a672dc0d6cecb61.
2014-07-02 03:03:53,607 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:53,607 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fbe435cd163a5ff9fb80c02d23b905fa from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,607 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa. on slave1,60020,1404295396492
2014-07-02 03:03:53,607 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user2,1404281258515.fbe435cd163a5ff9fb80c02d23b905fa.
2014-07-02 03:03:53,608 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:53,609 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a9e2628e1077954adea88f83afa06062 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,609 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062. on slave1,60020,1404295396492
2014-07-02 03:03:53,609 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user5,1404281258516.a9e2628e1077954adea88f83afa06062.
2014-07-02 03:03:53,610 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.: disabling compactions & flushes
2014-07-02 03:03:53,610 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:53,611 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.: disabling compactions & flushes
2014-07-02 03:03:53,611 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:53,612 INFO  [StoreCloserThread-usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.-1] regionserver.HStore: Closed family
2014-07-02 03:03:53,612 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:53,612 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b62b022cd2443b4bab3918f838588116 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,614 INFO  [StoreCloserThread-usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.-1] regionserver.HStore: Closed family
2014-07-02 03:03:53,614 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:03:53,614 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 520855c1b3b93d946764e9da9d0edf80 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,621 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b62b022cd2443b4bab3918f838588116 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,621 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116. on slave1,60020,1404295396492
2014-07-02 03:03:53,621 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user1,1404281258515.b62b022cd2443b4bab3918f838588116.
2014-07-02 03:03:53,622 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 520855c1b3b93d946764e9da9d0edf80 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 03:03:53,622 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80. on slave1,60020,1404295396492
2014-07-02 03:03:53,622 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user9,1404281258516.520855c1b3b93d946764e9da9d0edf80.
2014-07-02 03:08:16,570 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=0, evicted=0, evictedPerRun=NaN
2014-07-02 03:09:01,775 INFO  [Priority.RpcServer.handler=8,port=60020] regionserver.HRegionServer: Open usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:09:01,790 INFO  [Priority.RpcServer.handler=8,port=60020] regionserver.HRegionServer: Open usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:09:01,791 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4fd5002bd7e150c46650daf5ebb5e2b8 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,791 INFO  [Priority.RpcServer.handler=8,port=60020] regionserver.HRegionServer: Open usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:09:01,792 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5f58b71b81e6d85caf1b01aa1abb7cf9 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,792 INFO  [Priority.RpcServer.handler=8,port=60020] regionserver.HRegionServer: Open usertable,,1404295742993.f5a48430e63c8501e0f358a3807ebb17.
2014-07-02 03:09:01,793 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b77d45ebabc849ed2a34dcd31b167abf from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,794 INFO  [Priority.RpcServer.handler=8,port=60020] regionserver.HRegionServer: Open usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:09:01,869 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4fd5002bd7e150c46650daf5ebb5e2b8 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,870 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 4fd5002bd7e150c46650daf5ebb5e2b8, NAME => 'usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-02 03:09:01,870 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5f58b71b81e6d85caf1b01aa1abb7cf9 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,870 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b77d45ebabc849ed2a34dcd31b167abf from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,870 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 5f58b71b81e6d85caf1b01aa1abb7cf9, NAME => 'usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-02 03:09:01,871 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 4fd5002bd7e150c46650daf5ebb5e2b8
2014-07-02 03:09:01,871 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => b77d45ebabc849ed2a34dcd31b167abf, NAME => 'usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-02 03:09:01,871 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:09:01,871 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5f58b71b81e6d85caf1b01aa1abb7cf9
2014-07-02 03:09:01,872 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:09:01,872 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable b77d45ebabc849ed2a34dcd31b167abf
2014-07-02 03:09:01,872 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:09:01,886 INFO  [StoreOpener-4fd5002bd7e150c46650daf5ebb5e2b8-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-02 03:09:01,886 INFO  [StoreOpener-5f58b71b81e6d85caf1b01aa1abb7cf9-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-02 03:09:01,888 INFO  [StoreOpener-b77d45ebabc849ed2a34dcd31b167abf-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-02 03:09:01,890 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8
2014-07-02 03:09:01,891 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9
2014-07-02 03:09:01,893 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf
2014-07-02 03:09:01,894 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 4fd5002bd7e150c46650daf5ebb5e2b8; next sequenceid=1
2014-07-02 03:09:01,894 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 4fd5002bd7e150c46650daf5ebb5e2b8
2014-07-02 03:09:01,895 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 5f58b71b81e6d85caf1b01aa1abb7cf9; next sequenceid=1
2014-07-02 03:09:01,895 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5f58b71b81e6d85caf1b01aa1abb7cf9
2014-07-02 03:09:01,905 INFO  [PostOpenDeployTasks:4fd5002bd7e150c46650daf5ebb5e2b8] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:09:01,905 INFO  [PostOpenDeployTasks:5f58b71b81e6d85caf1b01aa1abb7cf9] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:09:01,929 INFO  [PostOpenDeployTasks:5f58b71b81e6d85caf1b01aa1abb7cf9] catalog.MetaEditor: Updated row usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. with server=slave1,60020,1404295396492
2014-07-02 03:09:01,929 INFO  [PostOpenDeployTasks:5f58b71b81e6d85caf1b01aa1abb7cf9] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:09:01,929 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5f58b71b81e6d85caf1b01aa1abb7cf9 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:01,931 INFO  [PostOpenDeployTasks:4fd5002bd7e150c46650daf5ebb5e2b8] catalog.MetaEditor: Updated row usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. with server=slave1,60020,1404295396492
2014-07-02 03:09:01,932 INFO  [PostOpenDeployTasks:4fd5002bd7e150c46650daf5ebb5e2b8] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:09:01,932 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4fd5002bd7e150c46650daf5ebb5e2b8 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:01,934 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined b77d45ebabc849ed2a34dcd31b167abf; next sequenceid=1
2014-07-02 03:09:01,934 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node b77d45ebabc849ed2a34dcd31b167abf
2014-07-02 03:09:01,943 INFO  [PostOpenDeployTasks:b77d45ebabc849ed2a34dcd31b167abf] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:09:01,976 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5f58b71b81e6d85caf1b01aa1abb7cf9 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:01,976 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 5f58b71b81e6d85caf1b01aa1abb7cf9 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:09:01,977 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. on slave1,60020,1404295396492
2014-07-02 03:09:01,977 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f5a48430e63c8501e0f358a3807ebb17 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,977 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4fd5002bd7e150c46650daf5ebb5e2b8 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:01,977 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 4fd5002bd7e150c46650daf5ebb5e2b8 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:09:01,978 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. on slave1,60020,1404295396492
2014-07-02 03:09:01,978 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5469e92a8a85cbc117b35a3d69349c81 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:01,988 INFO  [PostOpenDeployTasks:b77d45ebabc849ed2a34dcd31b167abf] catalog.MetaEditor: Updated row usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. with server=slave1,60020,1404295396492
2014-07-02 03:09:01,988 INFO  [PostOpenDeployTasks:b77d45ebabc849ed2a34dcd31b167abf] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:09:01,989 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b77d45ebabc849ed2a34dcd31b167abf from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:02,001 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f5a48430e63c8501e0f358a3807ebb17 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:02,002 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => f5a48430e63c8501e0f358a3807ebb17, NAME => 'usertable,,1404295742993.f5a48430e63c8501e0f358a3807ebb17.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-02 03:09:02,003 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable f5a48430e63c8501e0f358a3807ebb17
2014-07-02 03:09:02,003 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,,1404295742993.f5a48430e63c8501e0f358a3807ebb17.
2014-07-02 03:09:02,014 INFO  [StoreOpener-f5a48430e63c8501e0f358a3807ebb17-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-02 03:09:02,020 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/f5a48430e63c8501e0f358a3807ebb17
2014-07-02 03:09:02,023 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined f5a48430e63c8501e0f358a3807ebb17; next sequenceid=1
2014-07-02 03:09:02,024 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node f5a48430e63c8501e0f358a3807ebb17
2014-07-02 03:09:02,025 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5469e92a8a85cbc117b35a3d69349c81 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 03:09:02,025 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 5469e92a8a85cbc117b35a3d69349c81, NAME => 'usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-02 03:09:02,026 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5469e92a8a85cbc117b35a3d69349c81
2014-07-02 03:09:02,027 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:09:02,027 INFO  [PostOpenDeployTasks:f5a48430e63c8501e0f358a3807ebb17] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1404295742993.f5a48430e63c8501e0f358a3807ebb17.
2014-07-02 03:09:02,038 INFO  [StoreOpener-5469e92a8a85cbc117b35a3d69349c81-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-02 03:09:02,043 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81
2014-07-02 03:09:02,047 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 5469e92a8a85cbc117b35a3d69349c81; next sequenceid=1
2014-07-02 03:09:02,047 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5469e92a8a85cbc117b35a3d69349c81
2014-07-02 03:09:02,049 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b77d45ebabc849ed2a34dcd31b167abf from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:02,049 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned b77d45ebabc849ed2a34dcd31b167abf to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:09:02,049 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. on slave1,60020,1404295396492
2014-07-02 03:09:02,050 INFO  [PostOpenDeployTasks:5469e92a8a85cbc117b35a3d69349c81] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:09:02,056 INFO  [PostOpenDeployTasks:f5a48430e63c8501e0f358a3807ebb17] catalog.MetaEditor: Updated row usertable,,1404295742993.f5a48430e63c8501e0f358a3807ebb17. with server=slave1,60020,1404295396492
2014-07-02 03:09:02,056 INFO  [PostOpenDeployTasks:f5a48430e63c8501e0f358a3807ebb17] regionserver.HRegionServer: Finished post open deploy task for usertable,,1404295742993.f5a48430e63c8501e0f358a3807ebb17.
2014-07-02 03:09:02,057 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f5a48430e63c8501e0f358a3807ebb17 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:02,061 INFO  [PostOpenDeployTasks:5469e92a8a85cbc117b35a3d69349c81] catalog.MetaEditor: Updated row usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. with server=slave1,60020,1404295396492
2014-07-02 03:09:02,061 INFO  [PostOpenDeployTasks:5469e92a8a85cbc117b35a3d69349c81] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:09:02,062 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5469e92a8a85cbc117b35a3d69349c81 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:02,084 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f5a48430e63c8501e0f358a3807ebb17 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:02,084 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned f5a48430e63c8501e0f358a3807ebb17 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:09:02,084 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,,1404295742993.f5a48430e63c8501e0f358a3807ebb17. on slave1,60020,1404295396492
2014-07-02 03:09:02,085 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x46f6873b540002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5469e92a8a85cbc117b35a3d69349c81 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 03:09:02,085 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 5469e92a8a85cbc117b35a3d69349c81 to OPENED in zk on slave1,60020,1404295396492
2014-07-02 03:09:02,085 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. on slave1,60020,1404295396492
2014-07-02 03:09:21,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:21,682 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 122 synced till here 83
2014-07-02 03:09:22,042 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295417291 with entries=122, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295761343
2014-07-02 03:09:23,804 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:23,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 238 synced till here 202
2014-07-02 03:09:24,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295761343 with entries=116, filesize=83.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295763805
2014-07-02 03:09:26,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:26,792 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 352 synced till here 328
2014-07-02 03:09:27,640 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295763805 with entries=114, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295766768
2014-07-02 03:09:30,123 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:30,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 481 synced till here 449
2014-07-02 03:09:31,281 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295766768 with entries=129, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295770123
2014-07-02 03:09:32,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:33,033 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 592 synced till here 573
2014-07-02 03:09:33,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295770123 with entries=111, filesize=74.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295772988
2014-07-02 03:09:34,697 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:09:34,848 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 293.3m
2014-07-02 03:09:35,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:35,793 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 714 synced till here 680
2014-07-02 03:09:36,198 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:09:36,345 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:09:36,347 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 257.0m
2014-07-02 03:09:36,561 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295772988 with entries=122, filesize=92.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295775772
2014-07-02 03:09:37,333 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:09:37,767 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:09:38,303 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:38,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 832 synced till here 790
2014-07-02 03:09:38,852 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295775772 with entries=118, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295778304
2014-07-02 03:09:41,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:41,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 965 synced till here 937
2014-07-02 03:09:42,035 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295778304 with entries=133, filesize=104.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295781432
2014-07-02 03:09:42,375 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=192, memsize=87.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/7181b77d0fa44b8a8a31a38b8e3cd4fa
2014-07-02 03:09:42,396 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/7181b77d0fa44b8a8a31a38b8e3cd4fa as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/7181b77d0fa44b8a8a31a38b8e3cd4fa
2014-07-02 03:09:42,413 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/7181b77d0fa44b8a8a31a38b8e3cd4fa, entries=318050, sequenceid=192, filesize=47.4m
2014-07-02 03:09:42,414 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~296.5m/310940160, currentsize=108.8m/114134320 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 7566ms, sequenceid=192, compaction requested=false
2014-07-02 03:09:42,415 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 351.0m
2014-07-02 03:09:43,330 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:43,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1088 synced till here 1068
2014-07-02 03:09:43,617 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=197, memsize=87.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/6a5e528c76e347bb94ad8705af3d940e
2014-07-02 03:09:43,636 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/6a5e528c76e347bb94ad8705af3d940e as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6a5e528c76e347bb94ad8705af3d940e
2014-07-02 03:09:43,798 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6a5e528c76e347bb94ad8705af3d940e, entries=317610, sequenceid=197, filesize=47.4m
2014-07-02 03:09:43,798 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~304.0m/318756880, currentsize=128.0m/134193120 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 7451ms, sequenceid=197, compaction requested=false
2014-07-02 03:09:43,835 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:09:44,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295781432 with entries=123, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295783330
2014-07-02 03:09:46,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:47,696 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1274 synced till here 1232
2014-07-02 03:09:48,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295783330 with entries=186, filesize=139.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295786401
2014-07-02 03:09:49,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:49,762 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:09:49,762 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 260.3m
2014-07-02 03:09:49,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1409 synced till here 1382
2014-07-02 03:09:50,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295786401 with entries=135, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295789655
2014-07-02 03:09:51,108 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=262, memsize=86.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/740a215f1286466693c7f84ff7c85881
2014-07-02 03:09:51,109 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:09:51,126 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/740a215f1286466693c7f84ff7c85881 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/740a215f1286466693c7f84ff7c85881
2014-07-02 03:09:51,139 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/740a215f1286466693c7f84ff7c85881, entries=315540, sequenceid=262, filesize=47.1m
2014-07-02 03:09:51,139 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~402.2m/421690240, currentsize=128.4m/134630800 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 8724ms, sequenceid=262, compaction requested=false
2014-07-02 03:09:51,219 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:09:51,221 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 260.8m
2014-07-02 03:09:51,982 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:09:52,037 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:52,287 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1533 synced till here 1512
2014-07-02 03:09:52,383 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295789655 with entries=124, filesize=96.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295792037
2014-07-02 03:09:53,669 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:53,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1655 synced till here 1631
2014-07-02 03:09:54,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295792037 with entries=122, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295793669
2014-07-02 03:09:55,110 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:09:55,297 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:55,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1757 synced till here 1748
2014-07-02 03:09:55,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295793669 with entries=102, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295795297
2014-07-02 03:09:55,644 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=380, memsize=84.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/0a4ea8a461104444bb42f469dbb5c77f
2014-07-02 03:09:55,666 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/0a4ea8a461104444bb42f469dbb5c77f as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0a4ea8a461104444bb42f469dbb5c77f
2014-07-02 03:09:55,687 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0a4ea8a461104444bb42f469dbb5c77f, entries=306580, sequenceid=380, filesize=45.7m
2014-07-02 03:09:55,688 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~291.4m/305565040, currentsize=101.4m/106355600 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 5926ms, sequenceid=380, compaction requested=false
2014-07-02 03:09:55,688 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 281.5m
2014-07-02 03:09:55,848 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=382, memsize=84.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/2f6d6edaaaf74ca8b18b869bbfa12ef5
2014-07-02 03:09:55,873 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/2f6d6edaaaf74ca8b18b869bbfa12ef5 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2f6d6edaaaf74ca8b18b869bbfa12ef5
2014-07-02 03:09:55,892 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2f6d6edaaaf74ca8b18b869bbfa12ef5, entries=306870, sequenceid=382, filesize=45.8m
2014-07-02 03:09:55,893 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~287.3m/301206720, currentsize=99.7m/104555760 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 4672ms, sequenceid=382, compaction requested=false
2014-07-02 03:09:56,004 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:09:58,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:09:58,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1847 synced till here 1844
2014-07-02 03:09:58,103 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295795297 with entries=90, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295798024
2014-07-02 03:09:59,265 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=445, memsize=83.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/ae890e77dccd43c8b34262a2b307c687
2014-07-02 03:09:59,282 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/ae890e77dccd43c8b34262a2b307c687 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/ae890e77dccd43c8b34262a2b307c687
2014-07-02 03:09:59,301 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/ae890e77dccd43c8b34262a2b307c687, entries=304020, sequenceid=445, filesize=45.3m
2014-07-02 03:09:59,302 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~281.5m/295143680, currentsize=51.5m/54007840 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 3614ms, sequenceid=445, compaction requested=false
2014-07-02 03:10:00,154 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:00,189 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1938 synced till here 1936
2014-07-02 03:10:00,242 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295798024 with entries=91, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295800154
2014-07-02 03:10:04,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:04,294 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2058 synced till here 2028
2014-07-02 03:10:05,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295800154 with entries=120, filesize=93.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295804091
2014-07-02 03:10:06,704 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:10:06,718 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 265.6m
2014-07-02 03:10:07,938 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:10:07,939 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.7m
2014-07-02 03:10:08,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:08,351 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:08,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2222 synced till here 2197
2014-07-02 03:10:09,383 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295804091 with entries=164, filesize=112.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295808318
2014-07-02 03:10:09,540 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:10,816 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:10:11,243 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:11,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2344 synced till here 2315
2014-07-02 03:10:12,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295808318 with entries=122, filesize=86.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295811244
2014-07-02 03:10:27,951 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 20523ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:10:27,951 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 20522ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:10:27,971 WARN  [regionserver60020] util.Sleeper: We slept 16440ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:10:28,003 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13372ms
GC pool 'ParNew' had collection(s): count=2 time=133ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=13617ms
2014-07-02 03:10:28,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:28,227 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18770,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295809366,"queuetimems":1736,"class":"HRegionServer","responsesize":12869,"method":"Multi"}
2014-07-02 03:10:28,227 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18765,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295809367,"queuetimems":1599,"class":"HRegionServer","responsesize":13109,"method":"Multi"}
2014-07-02 03:10:28,228 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 776 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:28,233 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:28,233 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 777 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:28,233 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:28,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2471 synced till here 2434
2014-07-02 03:10:28,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295811244 with entries=127, filesize=95.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295828091
2014-07-02 03:10:28,680 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295810866,"queuetimems":2893,"class":"HRegionServer","responsesize":13229,"method":"Multi"}
2014-07-02 03:10:28,680 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295810866,"queuetimems":2925,"class":"HRegionServer","responsesize":12861,"method":"Multi"}
2014-07-02 03:10:28,680 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 787 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:28,680 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:28,681 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295810866,"queuetimems":2879,"class":"HRegionServer","responsesize":12854,"method":"Multi"}
2014-07-02 03:10:28,681 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 786 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:28,681 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:28,681 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17861,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295810818,"queuetimems":2888,"class":"HRegionServer","responsesize":12798,"method":"Multi"}
2014-07-02 03:10:28,681 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 789 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:28,681 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:28,689 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 788 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:28,689 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:29,010 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:10:29,010 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17764,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295811246,"queuetimems":2610,"class":"HRegionServer","responsesize":13174,"method":"Multi"}
2014-07-02 03:10:29,011 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 794 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:29,011 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:29,012 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295810867,"queuetimems":2388,"class":"HRegionServer","responsesize":13084,"method":"Multi"}
2014-07-02 03:10:29,012 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 793 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:29,012 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:29,018 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295811250,"queuetimems":2587,"class":"HRegionServer","responsesize":12985,"method":"Multi"}
2014-07-02 03:10:29,018 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 795 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:29,018 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:29,022 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295811254,"queuetimems":2442,"class":"HRegionServer","responsesize":12866,"method":"Multi"}
2014-07-02 03:10:29,022 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 799 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:29,022 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:29,022 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16929,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812092,"queuetimems":2402,"class":"HRegionServer","responsesize":13147,"method":"Multi"}
2014-07-02 03:10:29,029 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 820 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:29,029 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:29,034 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16973,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812060,"queuetimems":3126,"class":"HRegionServer","responsesize":12916,"method":"Multi"}
2014-07-02 03:10:29,034 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16975,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812058,"queuetimems":3226,"class":"HRegionServer","responsesize":13291,"method":"Multi"}
2014-07-02 03:10:29,034 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 797 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:29,034 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:29,034 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 798 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:29,034 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,093 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16964,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812061,"queuetimems":3119,"class":"HRegionServer","responsesize":12792,"method":"Multi"}
2014-07-02 03:10:30,094 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 796 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,094 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,299 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=552, memsize=168.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/21e73e7060e44e55a3c19e44d2114b7d
2014-07-02 03:10:30,326 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/21e73e7060e44e55a3c19e44d2114b7d as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/21e73e7060e44e55a3c19e44d2114b7d
2014-07-02 03:10:30,348 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/21e73e7060e44e55a3c19e44d2114b7d, entries=611720, sequenceid=552, filesize=91.2m
2014-07-02 03:10:30,349 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~263.1m/275843120, currentsize=147.5m/154633680 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 22410ms, sequenceid=552, compaction requested=true
2014-07-02 03:10:30,355 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:10:30,356 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., current region memstore size 284.7m
2014-07-02 03:10:30,356 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:10:30,357 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 193298673 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:10:30,358 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating major compaction
2014-07-02 03:10:30,359 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:10:30,359 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=184.3m
2014-07-02 03:10:30,360 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6a5e528c76e347bb94ad8705af3d940e, keycount=31761, bloomtype=ROW, size=47.4m, encoding=NONE, seqNum=197, earliestPutTs=1404295763006
2014-07-02 03:10:30,360 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2f6d6edaaaf74ca8b18b869bbfa12ef5, keycount=30687, bloomtype=ROW, size=45.8m, encoding=NONE, seqNum=382, earliestPutTs=1404295785184
2014-07-02 03:10:30,360 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/21e73e7060e44e55a3c19e44d2114b7d, keycount=61172, bloomtype=ROW, size=91.2m, encoding=NONE, seqNum=552, earliestPutTs=1404295793916
2014-07-02 03:10:30,386 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:30,430 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18344,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812086,"queuetimems":2926,"class":"HRegionServer","responsesize":13062,"method":"Multi"}
2014-07-02 03:10:30,430 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18087,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812343,"queuetimems":2073,"class":"HRegionServer","responsesize":12854,"method":"Multi"}
2014-07-02 03:10:30,430 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 809 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,431 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,431 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 825 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,431 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,437 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18343,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812093,"queuetimems":2298,"class":"HRegionServer","responsesize":13144,"method":"Multi"}
2014-07-02 03:10:30,437 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18374,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812062,"queuetimems":3099,"class":"HRegionServer","responsesize":12924,"method":"Multi"}
2014-07-02 03:10:30,437 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 802 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,437 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18347,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812090,"queuetimems":2544,"class":"HRegionServer","responsesize":12869,"method":"Multi"}
2014-07-02 03:10:30,437 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,437 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 813 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,438 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,452 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 819 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,452 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,529 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=553, memsize=167.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/c66595f19fe547839840660a55d145dc
2014-07-02 03:10:30,542 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/c66595f19fe547839840660a55d145dc as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c66595f19fe547839840660a55d145dc
2014-07-02 03:10:30,554 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c66595f19fe547839840660a55d145dc, entries=610370, sequenceid=553, filesize=91.0m
2014-07-02 03:10:30,555 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~267.2m/280184480, currentsize=167.5m/175591600 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 23837ms, sequenceid=553, compaction requested=true
2014-07-02 03:10:30,555 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:10:30,556 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 290.5m
2014-07-02 03:10:30,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18253,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812342,"queuetimems":2228,"class":"HRegionServer","responsesize":13109,"method":"Multi"}
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18513,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812082,"queuetimems":2939,"class":"HRegionServer","responsesize":12523,"method":"Multi"}
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18507,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812088,"queuetimems":2564,"class":"HRegionServer","responsesize":12791,"method":"Multi"}
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18322,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812273,"queuetimems":2457,"class":"HRegionServer","responsesize":13030,"method":"Multi"}
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18507,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812088,"queuetimems":2688,"class":"HRegionServer","responsesize":12943,"method":"Multi"}
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18533,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812062,"queuetimems":3109,"class":"HRegionServer","responsesize":13131,"method":"Multi"}
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18532,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812063,"queuetimems":3086,"class":"HRegionServer","responsesize":13018,"method":"Multi"}
2014-07-02 03:10:30,595 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 814 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,599 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,599 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 801 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,599 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,605 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 806 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,605 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,616 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2594 synced till here 2568
2014-07-02 03:10:30,621 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 803 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,621 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,621 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 807 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,622 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,623 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 818 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,623 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,623 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 812 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,623 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,793 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812335,"queuetimems":2370,"class":"HRegionServer","responsesize":12595,"method":"Multi"}
2014-07-02 03:10:30,793 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812081,"queuetimems":2955,"class":"HRegionServer","responsesize":12481,"method":"Multi"}
2014-07-02 03:10:30,793 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18519,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812273,"queuetimems":2442,"class":"HRegionServer","responsesize":13247,"method":"Multi"}
2014-07-02 03:10:30,793 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18518,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812275,"queuetimems":2329,"class":"HRegionServer","responsesize":13055,"method":"Multi"}
2014-07-02 03:10:30,793 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 815 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,794 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,794 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18706,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812088,"queuetimems":2782,"class":"HRegionServer","responsesize":13146,"method":"Multi"}
2014-07-02 03:10:30,794 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812091,"queuetimems":2435,"class":"HRegionServer","responsesize":13010,"method":"Multi"}
2014-07-02 03:10:30,794 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 808 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,794 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16855,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813939,"queuetimems":2345,"class":"HRegionServer","responsesize":12924,"method":"Multi"}
2014-07-02 03:10:30,795 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 822 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,795 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,795 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 841 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,795 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,801 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 816 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,801 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,794 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,805 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 817 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,805 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,809 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 800 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,809 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,809 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813693,"queuetimems":3380,"class":"HRegionServer","responsesize":12798,"method":"Multi"}
2014-07-02 03:10:30,810 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 828 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,810 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,821 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295828091 with entries=123, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295830593
2014-07-02 03:10:30,824 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17150,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813673,"queuetimems":3390,"class":"HRegionServer","responsesize":13405,"method":"Multi"}
2014-07-02 03:10:30,824 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 826 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,824 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,824 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295812091,"queuetimems":2421,"class":"HRegionServer","responsesize":13091,"method":"Multi"}
2014-07-02 03:10:30,825 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 821 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,825 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,824 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813707,"queuetimems":2623,"class":"HRegionServer","responsesize":13174,"method":"Multi"}
2014-07-02 03:10:30,825 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 833 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,825 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,938 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:30,979 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17036,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813942,"queuetimems":2324,"class":"HRegionServer","responsesize":12481,"method":"Multi"}
2014-07-02 03:10:30,979 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17279,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813699,"queuetimems":2633,"class":"HRegionServer","responsesize":13084,"method":"Multi"}
2014-07-02 03:10:30,979 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17248,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813730,"queuetimems":2498,"class":"HRegionServer","responsesize":12916,"method":"Multi"}
2014-07-02 03:10:30,979 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 843 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,979 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 838 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 832 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17271,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813708,"queuetimems":2487,"class":"HRegionServer","responsesize":12866,"method":"Multi"}
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17054,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813926,"queuetimems":2683,"class":"HRegionServer","responsesize":12792,"method":"Multi"}
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813940,"queuetimems":2336,"class":"HRegionServer","responsesize":13018,"method":"Multi"}
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 834 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 837 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,980 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17291,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813689,"queuetimems":3388,"class":"HRegionServer","responsesize":12861,"method":"Multi"}
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17038,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813942,"queuetimems":2132,"class":"HRegionServer","responsesize":13062,"method":"Multi"}
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 829 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17042,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813939,"queuetimems":2356,"class":"HRegionServer","responsesize":12985,"method":"Multi"}
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 835 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17039,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813942,"queuetimems":2158,"class":"HRegionServer","responsesize":13131,"method":"Multi"}
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813698,"queuetimems":3280,"class":"HRegionServer","responsesize":13229,"method":"Multi"}
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 842 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813934,"queuetimems":2676,"class":"HRegionServer","responsesize":13291,"method":"Multi"}
2014-07-02 03:10:30,981 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 836 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 844 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 827 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,982 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,983 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 848 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,983 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:30,985 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17042,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34286","starttimems":1404295813943,"queuetimems":2107,"class":"HRegionServer","responsesize":13146,"method":"Multi"}
2014-07-02 03:10:30,986 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 847 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34286: output error
2014-07-02 03:10:30,986 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:10:31,082 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:31,992 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:32,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2700 synced till here 2691
2014-07-02 03:10:32,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295830593 with entries=106, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295831992
2014-07-02 03:10:32,520 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=621, memsize=54.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/670e14e25af5473f9ffb35f1b8cc9771
2014-07-02 03:10:32,533 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/670e14e25af5473f9ffb35f1b8cc9771 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/670e14e25af5473f9ffb35f1b8cc9771
2014-07-02 03:10:32,542 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/670e14e25af5473f9ffb35f1b8cc9771, entries=198350, sequenceid=621, filesize=29.5m
2014-07-02 03:10:32,542 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~290.5m/304610800, currentsize=27.4m/28721840 for region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. in 2186ms, sequenceid=621, compaction requested=false
2014-07-02 03:10:33,456 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=649, memsize=170.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/437f22b3a5194fe0ada4a078efd859e6
2014-07-02 03:10:33,469 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/437f22b3a5194fe0ada4a078efd859e6 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/437f22b3a5194fe0ada4a078efd859e6
2014-07-02 03:10:33,487 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/437f22b3a5194fe0ada4a078efd859e6, entries=620490, sequenceid=649, filesize=92.5m
2014-07-02 03:10:33,487 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~313.5m/328746400, currentsize=49.5m/51913600 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2931ms, sequenceid=649, compaction requested=true
2014-07-02 03:10:33,487 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:10:34,991 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/10284b1ada1e4292940c7fee09200f11 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/10284b1ada1e4292940c7fee09200f11
2014-07-02 03:10:35,082 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:10:35,093 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6a5e528c76e347bb94ad8705af3d940e, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6a5e528c76e347bb94ad8705af3d940e
2014-07-02 03:10:35,095 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2f6d6edaaaf74ca8b18b869bbfa12ef5, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2f6d6edaaaf74ca8b18b869bbfa12ef5
2014-07-02 03:10:35,098 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/21e73e7060e44e55a3c19e44d2114b7d, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/21e73e7060e44e55a3c19e44d2114b7d
2014-07-02 03:10:35,098 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 10284b1ada1e4292940c7fee09200f11(size=92.2m), total size for store is 92.2m. This selection was in queue for 0sec, and took 4sec to execute.
2014-07-02 03:10:35,099 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=184.3m, priority=17, time=14044757364316; duration=4sec
2014-07-02 03:10:35,099 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:10:35,099 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:10:35,099 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 193108790 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:10:35,100 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating major compaction
2014-07-02 03:10:35,100 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:10:35,100 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=184.2m
2014-07-02 03:10:35,100 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/7181b77d0fa44b8a8a31a38b8e3cd4fa, keycount=31805, bloomtype=ROW, size=47.4m, encoding=NONE, seqNum=192, earliestPutTs=1404295762713
2014-07-02 03:10:35,100 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0a4ea8a461104444bb42f469dbb5c77f, keycount=30658, bloomtype=ROW, size=45.7m, encoding=NONE, seqNum=380, earliestPutTs=1404295783474
2014-07-02 03:10:35,100 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c66595f19fe547839840660a55d145dc, keycount=61037, bloomtype=ROW, size=91.0m, encoding=NONE, seqNum=553, earliestPutTs=1404295793164
2014-07-02 03:10:35,111 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:35,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:35,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2797 synced till here 2786
2014-07-02 03:10:35,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295831992 with entries=97, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295835241
2014-07-02 03:10:35,295 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295417291
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295761343
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295763805
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295766768
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295770123
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295772988
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295775772
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295778304
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295781432
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295783330
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295786401
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295789655
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295792037
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295793669
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295795297
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295798024
2014-07-02 03:10:35,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295800154
2014-07-02 03:10:36,261 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:10:36,262 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.5m
2014-07-02 03:10:36,298 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:10:36,298 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.2m
2014-07-02 03:10:36,522 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:36,560 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:36,601 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:36,925 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2894 synced till here 2893
2014-07-02 03:10:36,939 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295835241 with entries=97, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295836601
2014-07-02 03:10:38,287 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=722, memsize=115.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/862498ceb5c2410685751082bc549cb4
2014-07-02 03:10:38,304 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/862498ceb5c2410685751082bc549cb4 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/862498ceb5c2410685751082bc549cb4
2014-07-02 03:10:38,315 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/862498ceb5c2410685751082bc549cb4, entries=418980, sequenceid=722, filesize=62.5m
2014-07-02 03:10:38,316 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.7m/273330000, currentsize=26.6m/27878000 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 2054ms, sequenceid=722, compaction requested=false
2014-07-02 03:10:38,642 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=722, memsize=113.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/aafd640b33474144861a1980b84f5b6c
2014-07-02 03:10:38,904 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/aafd640b33474144861a1980b84f5b6c as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/aafd640b33474144861a1980b84f5b6c
2014-07-02 03:10:38,959 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/aafd640b33474144861a1980b84f5b6c, entries=413670, sequenceid=722, filesize=61.7m
2014-07-02 03:10:38,959 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~261.1m/273768400, currentsize=37.0m/38827680 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 2661ms, sequenceid=722, compaction requested=false
2014-07-02 03:10:39,463 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:39,492 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295836601 with entries=85, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295839463
2014-07-02 03:10:39,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295804091
2014-07-02 03:10:39,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295808318
2014-07-02 03:10:39,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295811244
2014-07-02 03:10:39,555 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/cd6012667ee1469a96098e7febff8814 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/cd6012667ee1469a96098e7febff8814
2014-07-02 03:10:39,568 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:10:39,574 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/7181b77d0fa44b8a8a31a38b8e3cd4fa, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/7181b77d0fa44b8a8a31a38b8e3cd4fa
2014-07-02 03:10:39,576 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0a4ea8a461104444bb42f469dbb5c77f, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0a4ea8a461104444bb42f469dbb5c77f
2014-07-02 03:10:39,578 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c66595f19fe547839840660a55d145dc, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c66595f19fe547839840660a55d145dc
2014-07-02 03:10:39,579 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into cd6012667ee1469a96098e7febff8814(size=92.1m), total size for store is 154.6m. This selection was in queue for 0sec, and took 4sec to execute.
2014-07-02 03:10:39,579 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=3, fileSize=184.2m, priority=17, time=14049498484720; duration=4sec
2014-07-02 03:10:39,579 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:10:39,579 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:10:39,579 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 193902585 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:10:39,579 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating major compaction
2014-07-02 03:10:39,580 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:10:39,580 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=184.9m
2014-07-02 03:10:39,580 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/740a215f1286466693c7f84ff7c85881, keycount=31554, bloomtype=ROW, size=47.1m, encoding=NONE, seqNum=262, earliestPutTs=1404295763928
2014-07-02 03:10:39,580 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/ae890e77dccd43c8b34262a2b307c687, keycount=30402, bloomtype=ROW, size=45.3m, encoding=NONE, seqNum=445, earliestPutTs=1404295791784
2014-07-02 03:10:39,580 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/437f22b3a5194fe0ada4a078efd859e6, keycount=62049, bloomtype=ROW, size=92.5m, encoding=NONE, seqNum=649, earliestPutTs=1404295795834
2014-07-02 03:10:39,591 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:41,640 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:41,660 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3073 synced till here 3066
2014-07-02 03:10:41,710 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295839463 with entries=94, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295841641
2014-07-02 03:10:43,082 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:43,107 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3175 synced till here 3155
2014-07-02 03:10:43,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295841641 with entries=102, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295843083
2014-07-02 03:10:43,982 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/1e1d40712cf5450d97c8b59e198de375 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/1e1d40712cf5450d97c8b59e198de375
2014-07-02 03:10:44,014 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:10:44,040 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/740a215f1286466693c7f84ff7c85881, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/740a215f1286466693c7f84ff7c85881
2014-07-02 03:10:44,061 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/ae890e77dccd43c8b34262a2b307c687, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/ae890e77dccd43c8b34262a2b307c687
2014-07-02 03:10:44,070 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/437f22b3a5194fe0ada4a078efd859e6, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/437f22b3a5194fe0ada4a078efd859e6
2014-07-02 03:10:44,070 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into 1e1d40712cf5450d97c8b59e198de375(size=96.9m), total size for store is 96.9m. This selection was in queue for 0sec, and took 4sec to execute.
2014-07-02 03:10:44,070 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=3, fileSize=184.9m, priority=17, time=14053978447160; duration=4sec
2014-07-02 03:10:44,070 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:10:44,783 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:10:44,784 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.8m
2014-07-02 03:10:45,229 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:45,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3276 synced till here 3268
2014-07-02 03:10:45,263 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:45,335 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295843083 with entries=101, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295845230
2014-07-02 03:10:47,592 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=819, memsize=208.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/cc53d7015d05468fa2a5d4d3683aa6ad
2014-07-02 03:10:47,615 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/cc53d7015d05468fa2a5d4d3683aa6ad as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/cc53d7015d05468fa2a5d4d3683aa6ad
2014-07-02 03:10:47,627 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/cc53d7015d05468fa2a5d4d3683aa6ad, entries=760500, sequenceid=819, filesize=113.4m
2014-07-02 03:10:47,628 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.9m/272570880, currentsize=38.8m/40647200 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2844ms, sequenceid=819, compaction requested=false
2014-07-02 03:10:48,348 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:48,372 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3367 synced till here 3366
2014-07-02 03:10:48,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295845230 with entries=91, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295848349
2014-07-02 03:10:51,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:52,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3461 synced till here 3460
2014-07-02 03:10:52,365 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295848349 with entries=94, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295851902
2014-07-02 03:10:54,503 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:10:54,504 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.9m
2014-07-02 03:10:54,558 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:10:54,558 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 257.5m
2014-07-02 03:10:54,703 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:54,712 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:54,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3551 synced till here 3549
2014-07-02 03:10:54,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295851902 with entries=90, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295854703
2014-07-02 03:10:54,802 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:57,092 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=891, memsize=252.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/ff95b90b18204432948b72229a6c785c
2014-07-02 03:10:57,107 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/ff95b90b18204432948b72229a6c785c as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ff95b90b18204432948b72229a6c785c
2014-07-02 03:10:57,194 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=892, memsize=254.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/b61b9a53199f43dfb256378bf49dfb12
2014-07-02 03:10:57,221 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/b61b9a53199f43dfb256378bf49dfb12 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/b61b9a53199f43dfb256378bf49dfb12
2014-07-02 03:10:57,398 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ff95b90b18204432948b72229a6c785c, entries=918670, sequenceid=891, filesize=136.9m
2014-07-02 03:10:57,399 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.0m/272642160, currentsize=39.2m/41085120 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 2895ms, sequenceid=891, compaction requested=true
2014-07-02 03:10:57,399 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:10:57,400 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:10:57,400 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 305687407 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:10:57,400 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating major compaction
2014-07-02 03:10:57,400 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:10:57,401 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=291.5m
2014-07-02 03:10:57,401 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/cd6012667ee1469a96098e7febff8814, keycount=62184, bloomtype=ROW, size=92.1m, encoding=NONE, seqNum=553, earliestPutTs=1404295762713
2014-07-02 03:10:57,401 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/862498ceb5c2410685751082bc549cb4, keycount=41898, bloomtype=ROW, size=62.5m, encoding=NONE, seqNum=722, earliestPutTs=1404295828236
2014-07-02 03:10:57,401 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ff95b90b18204432948b72229a6c785c, keycount=91867, bloomtype=ROW, size=136.9m, encoding=NONE, seqNum=891, earliestPutTs=1404295836270
2014-07-02 03:10:57,424 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:10:57,454 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:10:57,730 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/b61b9a53199f43dfb256378bf49dfb12, entries=925570, sequenceid=892, filesize=138.0m
2014-07-02 03:10:57,731 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.0m/274760960, currentsize=38.9m/40797120 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3173ms, sequenceid=892, compaction requested=true
2014-07-02 03:10:57,731 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:10:58,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3654 synced till here 3653
2014-07-02 03:10:58,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295854703 with entries=103, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295857454
2014-07-02 03:11:04,099 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:11:04,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295857454 with entries=87, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295864099
2014-07-02 03:11:05,743 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:11:05,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3830 synced till here 3828
2014-07-02 03:11:05,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295864099 with entries=89, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295865743
2014-07-02 03:11:06,160 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/072957a84d3d4c84b9acfaa56fa07be6 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/072957a84d3d4c84b9acfaa56fa07be6
2014-07-02 03:11:06,188 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:11:06,209 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/cd6012667ee1469a96098e7febff8814, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/cd6012667ee1469a96098e7febff8814
2014-07-02 03:11:06,217 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/862498ceb5c2410685751082bc549cb4, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/862498ceb5c2410685751082bc549cb4
2014-07-02 03:11:06,220 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ff95b90b18204432948b72229a6c785c, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ff95b90b18204432948b72229a6c785c
2014-07-02 03:11:06,221 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into 072957a84d3d4c84b9acfaa56fa07be6(size=214.1m), total size for store is 214.1m. This selection was in queue for 0sec, and took 8sec to execute.
2014-07-02 03:11:06,233 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=3, fileSize=291.5m, priority=17, time=14071798951327; duration=8sec
2014-07-02 03:11:06,243 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:11:06,243 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:11:06,244 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 306036057 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:11:06,244 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating major compaction
2014-07-02 03:11:06,250 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:11:06,250 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=291.9m
2014-07-02 03:11:06,250 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/10284b1ada1e4292940c7fee09200f11, keycount=62246, bloomtype=ROW, size=92.2m, encoding=NONE, seqNum=552, earliestPutTs=1404295763006
2014-07-02 03:11:06,251 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/aafd640b33474144861a1980b84f5b6c, keycount=41367, bloomtype=ROW, size=61.7m, encoding=NONE, seqNum=722, earliestPutTs=1404295829025
2014-07-02 03:11:06,251 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/b61b9a53199f43dfb256378bf49dfb12, keycount=92557, bloomtype=ROW, size=138.0m, encoding=NONE, seqNum=892, earliestPutTs=1404295836322
2014-07-02 03:11:06,330 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:11:10,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:11:10,427 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:11:10,429 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.6m
2014-07-02 03:11:10,807 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:11:11,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3954 synced till here 3953
2014-07-02 03:11:11,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295865743 with entries=124, filesize=86.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295870403
2014-07-02 03:11:14,756 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=987, memsize=259.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/97bef6bfebd543b081a2c91236a1e7d1
2014-07-02 03:11:14,818 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/97bef6bfebd543b081a2c91236a1e7d1 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/97bef6bfebd543b081a2c91236a1e7d1
2014-07-02 03:11:14,864 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/97bef6bfebd543b081a2c91236a1e7d1, entries=945500, sequenceid=987, filesize=140.9m
2014-07-02 03:11:14,865 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.7m/272296320, currentsize=25.0m/26189840 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 4436ms, sequenceid=987, compaction requested=true
2014-07-02 03:11:14,865 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:11:16,427 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/3bc118d1705749efabafc3a60168f91a as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3bc118d1705749efabafc3a60168f91a
2014-07-02 03:11:16,860 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:11:30,807 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 22852ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:11:30,807 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 22851ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:11:30,812 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13401ms
No GCs detected
2014-07-02 03:11:30,807 WARN  [regionserver60020] util.Sleeper: We slept 14311ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:11:32,475 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/10284b1ada1e4292940c7fee09200f11, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/10284b1ada1e4292940c7fee09200f11
2014-07-02 03:11:32,481 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/aafd640b33474144861a1980b84f5b6c, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/aafd640b33474144861a1980b84f5b6c
2014-07-02 03:11:32,483 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/b61b9a53199f43dfb256378bf49dfb12, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/b61b9a53199f43dfb256378bf49dfb12
2014-07-02 03:11:32,484 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 3bc118d1705749efabafc3a60168f91a(size=214.1m), total size for store is 214.1m. This selection was in queue for 0sec, and took 26sec to execute.
2014-07-02 03:11:32,484 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=291.9m, priority=17, time=14080642718947; duration=26sec
2014-07-02 03:11:32,485 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:11:32,485 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:11:32,486 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 368323016 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:11:32,486 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating major compaction
2014-07-02 03:11:32,487 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:11:32,487 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=351.3m
2014-07-02 03:11:32,487 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/1e1d40712cf5450d97c8b59e198de375, keycount=65435, bloomtype=ROW, size=96.9m, encoding=NONE, seqNum=649, earliestPutTs=1404295763928
2014-07-02 03:11:32,487 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/cc53d7015d05468fa2a5d4d3683aa6ad, keycount=76050, bloomtype=ROW, size=113.4m, encoding=NONE, seqNum=819, earliestPutTs=1404295834742
2014-07-02 03:11:32,488 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/97bef6bfebd543b081a2c91236a1e7d1, keycount=94550, bloomtype=ROW, size=140.9m, encoding=NONE, seqNum=987, earliestPutTs=1404295845157
2014-07-02 03:11:32,501 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:11:33,066 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1663 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34315: output error
2014-07-02 03:11:33,067 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:11:35,737 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:11:35,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4047 synced till here 4041
2014-07-02 03:11:36,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295870403 with entries=93, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295895785
2014-07-02 03:11:41,404 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2421ms
GC pool 'ParNew' had collection(s): count=1 time=2472ms
2014-07-02 03:11:41,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:11:41,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4141 synced till here 4139
2014-07-02 03:11:41,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295895785 with entries=94, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295901513
2014-07-02 03:11:43,073 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:11:43,085 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.4m
2014-07-02 03:11:55,654 WARN  [regionserver60020] util.Sleeper: We slept 14133ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:11:55,659 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12250ms
GC pool 'ParNew' had collection(s): count=1 time=12558ms
2014-07-02 03:11:55,902 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:11:55,913 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.1m
2014-07-02 03:11:56,199 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:11:56,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4239 synced till here 4229
2014-07-02 03:11:56,467 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:11:56,708 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14496,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902192,"queuetimems":1,"class":"HRegionServer","responsesize":12663,"method":"Multi"}
2014-07-02 03:11:56,709 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1777 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34428: output error
2014-07-02 03:11:56,708 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902139,"queuetimems":1,"class":"HRegionServer","responsesize":13063,"method":"Multi"}
2014-07-02 03:11:56,709 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14527,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902161,"queuetimems":0,"class":"HRegionServer","responsesize":13370,"method":"Multi"}
2014-07-02 03:11:56,821 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:11:56,821 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1778 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:11:56,821 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:11:56,821 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1780 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:11:56,822 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:11:56,844 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295901513 with entries=98, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295916199
2014-07-02 03:11:57,201 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:12:02,537 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3872ms
GC pool 'ParNew' had collection(s): count=1 time=4228ms
2014-07-02 03:12:02,802 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902298,"queuetimems":1,"class":"HRegionServer","responsesize":12934,"method":"Multi"}
2014-07-02 03:12:02,803 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1770 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:02,803 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:02,806 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20536,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902269,"queuetimems":4,"class":"HRegionServer","responsesize":12938,"method":"Multi"}
2014-07-02 03:12:02,806 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1772 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:02,806 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:02,826 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20604,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902221,"queuetimems":0,"class":"HRegionServer","responsesize":13167,"method":"Multi"}
2014-07-02 03:12:02,826 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1775 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:02,826 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,046 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20564,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902482,"queuetimems":4,"class":"HRegionServer","responsesize":13014,"method":"Multi"}
2014-07-02 03:12:03,047 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1764 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,047 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,054 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20492,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902561,"queuetimems":0,"class":"HRegionServer","responsesize":13014,"method":"Multi"}
2014-07-02 03:12:03,054 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902416,"queuetimems":0,"class":"HRegionServer","responsesize":12683,"method":"Multi"}
2014-07-02 03:12:03,054 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1762 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,054 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,054 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1769 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,055 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,055 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20299,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902756,"queuetimems":1,"class":"HRegionServer","responsesize":13111,"method":"Multi"}
2014-07-02 03:12:03,055 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1753 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,055 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,066 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902587,"queuetimems":0,"class":"HRegionServer","responsesize":13183,"method":"Multi"}
2014-07-02 03:12:03,066 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20539,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902527,"queuetimems":0,"class":"HRegionServer","responsesize":12845,"method":"Multi"}
2014-07-02 03:12:03,067 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1761 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,067 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,067 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1763 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,067 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20623,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902448,"queuetimems":1,"class":"HRegionServer","responsesize":12928,"method":"Multi"}
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20452,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902619,"queuetimems":0,"class":"HRegionServer","responsesize":12860,"method":"Multi"}
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1768 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20219,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902853,"queuetimems":8,"class":"HRegionServer","responsesize":13469,"method":"Multi"}
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1751 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,073 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1760 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,073 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20099,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902973,"queuetimems":3,"class":"HRegionServer","responsesize":13263,"method":"Multi"}
2014-07-02 03:12:03,076 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1748 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,076 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,072 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902914,"queuetimems":0,"class":"HRegionServer","responsesize":12985,"method":"Multi"}
2014-07-02 03:12:03,076 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20262,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902809,"queuetimems":0,"class":"HRegionServer","responsesize":12905,"method":"Multi"}
2014-07-02 03:12:03,076 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1749 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,077 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,077 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1752 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,077 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,078 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20351,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902720,"queuetimems":6,"class":"HRegionServer","responsesize":13184,"method":"Multi"}
2014-07-02 03:12:03,078 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1754 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,078 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,076 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20186,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902890,"queuetimems":0,"class":"HRegionServer","responsesize":13379,"method":"Multi"}
2014-07-02 03:12:03,081 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1750 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,081 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,077 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20425,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295902651,"queuetimems":1,"class":"HRegionServer","responsesize":13253,"method":"Multi"}
2014-07-02 03:12:03,082 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1757 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,082 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,611 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1741 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,612 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,624 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20570,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295903053,"queuetimems":1,"class":"HRegionServer","responsesize":13032,"method":"Multi"}
2014-07-02 03:12:03,624 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1745 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,624 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,626 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1746 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,626 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:03,626 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20604,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34428","starttimems":1404295903021,"queuetimems":2,"class":"HRegionServer","responsesize":12737,"method":"Multi"}
2014-07-02 03:12:03,627 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1747 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34428: output error
2014-07-02 03:12:03,627 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:06,366 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2303ms
GC pool 'ParNew' had collection(s): count=1 time=2694ms
2014-07-02 03:12:06,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:06,522 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4380 synced till here 4330
2014-07-02 03:12:13,048 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295916199 with entries=141, filesize=107.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295926434
2014-07-02 03:12:13,232 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4346ms
GC pool 'ParNew' had collection(s): count=1 time=4543ms
2014-07-02 03:12:14,760 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18153,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295916604,"queuetimems":2,"class":"HRegionServer","responsesize":13111,"method":"Multi"}
2014-07-02 03:12:14,761 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1859 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:14,762 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18280,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295916482,"queuetimems":10,"class":"HRegionServer","responsesize":13184,"method":"Multi"}
2014-07-02 03:12:14,863 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:14,863 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1858 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:14,863 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:14,892 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18564,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295916327,"queuetimems":17,"class":"HRegionServer","responsesize":13092,"method":"Multi"}
2014-07-02 03:12:14,892 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1889 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:14,892 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,058 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18186,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295916872,"queuetimems":0,"class":"HRegionServer","responsesize":12965,"method":"Multi"}
2014-07-02 03:12:15,059 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1861 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,059 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,065 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917211,"queuetimems":1,"class":"HRegionServer","responsesize":13379,"method":"Multi"}
2014-07-02 03:12:15,066 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1865 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,069 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,069 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17713,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917356,"queuetimems":1,"class":"HRegionServer","responsesize":12928,"method":"Multi"}
2014-07-02 03:12:15,070 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1866 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,070 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,075 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17628,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917447,"queuetimems":1,"class":"HRegionServer","responsesize":12683,"method":"Multi"}
2014-07-02 03:12:15,075 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1867 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,076 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,086 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17397,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917688,"queuetimems":0,"class":"HRegionServer","responsesize":13407,"method":"Multi"}
2014-07-02 03:12:15,086 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917753,"queuetimems":0,"class":"HRegionServer","responsesize":12964,"method":"Multi"}
2014-07-02 03:12:15,086 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1871 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,086 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,086 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17505,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917580,"queuetimems":1,"class":"HRegionServer","responsesize":12905,"method":"Multi"}
2014-07-02 03:12:15,086 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917090,"queuetimems":1,"class":"HRegionServer","responsesize":13263,"method":"Multi"}
2014-07-02 03:12:15,086 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1869 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,087 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,087 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1863 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,087 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,089 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295916957,"queuetimems":2,"class":"HRegionServer","responsesize":12985,"method":"Multi"}
2014-07-02 03:12:15,090 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1862 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,090 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,090 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1872 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,090 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,106 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18418,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295916687,"queuetimems":2,"class":"HRegionServer","responsesize":13183,"method":"Multi"}
2014-07-02 03:12:15,106 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1860 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,106 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,107 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17971,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917136,"queuetimems":1,"class":"HRegionServer","responsesize":12724,"method":"Multi"}
2014-07-02 03:12:15,108 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1864 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,108 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,108 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17592,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917516,"queuetimems":1,"class":"HRegionServer","responsesize":13032,"method":"Multi"}
2014-07-02 03:12:15,109 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1868 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,109 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,109 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17298,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917811,"queuetimems":0,"class":"HRegionServer","responsesize":12860,"method":"Multi"}
2014-07-02 03:12:15,110 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1873 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,110 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,113 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17482,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917631,"queuetimems":0,"class":"HRegionServer","responsesize":12737,"method":"Multi"}
2014-07-02 03:12:15,114 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1870 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,114 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,115 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17230,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917884,"queuetimems":4,"class":"HRegionServer","responsesize":13283,"method":"Multi"}
2014-07-02 03:12:15,115 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1874 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,115 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,143 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17179,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295917964,"queuetimems":0,"class":"HRegionServer","responsesize":13063,"method":"Multi"}
2014-07-02 03:12:15,143 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922552,"queuetimems":0,"class":"HRegionServer","responsesize":13014,"method":"Multi"}
2014-07-02 03:12:15,144 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1875 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,144 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,144 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12581,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922562,"queuetimems":1,"class":"HRegionServer","responsesize":13370,"method":"Multi"}
2014-07-02 03:12:15,144 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1880 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,144 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,145 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1879 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,145 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,768 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13198,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922569,"queuetimems":0,"class":"HRegionServer","responsesize":13036,"method":"Multi"}
2014-07-02 03:12:15,768 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17674,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295918094,"queuetimems":1,"class":"HRegionServer","responsesize":13167,"method":"Multi"}
2014-07-02 03:12:15,768 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13173,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922594,"queuetimems":0,"class":"HRegionServer","responsesize":13270,"method":"Multi"}
2014-07-02 03:12:15,768 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17550,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295918217,"queuetimems":0,"class":"HRegionServer","responsesize":13233,"method":"Multi"}
2014-07-02 03:12:15,768 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1881 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13150,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922619,"queuetimems":0,"class":"HRegionServer","responsesize":12934,"method":"Multi"}
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922806,"queuetimems":124,"class":"HRegionServer","responsesize":13014,"method":"Multi"}
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1878 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12942,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922827,"queuetimems":116,"class":"HRegionServer","responsesize":13010,"method":"Multi"}
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1883 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,770 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1882 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,770 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,769 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,770 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12966,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295922803,"queuetimems":149,"class":"HRegionServer","responsesize":12845,"method":"Multi"}
2014-07-02 03:12:15,770 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1877 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,770 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,770 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1884 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,770 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,851 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17723,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295918047,"queuetimems":0,"class":"HRegionServer","responsesize":12938,"method":"Multi"}
2014-07-02 03:12:15,851 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1886 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,851 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,856 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1885 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,856 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:15,856 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1876 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:15,856 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:16,362 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:16,369 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12742,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923627,"queuetimems":200,"class":"HRegionServer","responsesize":13233,"method":"Multi"}
2014-07-02 03:12:16,370 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1915 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:16,370 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:16,392 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13319,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923073,"queuetimems":74,"class":"HRegionServer","responsesize":13370,"method":"Multi"}
2014-07-02 03:12:16,393 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13337,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923055,"queuetimems":216,"class":"HRegionServer","responsesize":13036,"method":"Multi"}
2014-07-02 03:12:16,393 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1928 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:16,393 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:16,394 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923626,"queuetimems":244,"class":"HRegionServer","responsesize":13014,"method":"Multi"}
2014-07-02 03:12:16,394 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1916 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:16,394 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:16,398 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13343,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923054,"queuetimems":276,"class":"HRegionServer","responsesize":13154,"method":"Multi"}
2014-07-02 03:12:19,220 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1888 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,221 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2423ms
GC pool 'ParNew' had collection(s): count=1 time=2812ms
2014-07-02 03:12:19,222 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1934 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,223 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,222 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,274 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923630,"queuetimems":169,"class":"HRegionServer","responsesize":13167,"method":"Multi"}
2014-07-02 03:12:19,275 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1914 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,275 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,323 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16247,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923076,"queuetimems":17,"class":"HRegionServer","responsesize":12683,"method":"Multi"}
2014-07-02 03:12:19,324 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1926 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,324 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4506 synced till here 4494
2014-07-02 03:12:19,539 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16344,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923195,"queuetimems":0,"class":"HRegionServer","responsesize":13183,"method":"Multi"}
2014-07-02 03:12:19,539 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15927,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923612,"queuetimems":310,"class":"HRegionServer","responsesize":13184,"method":"Multi"}
2014-07-02 03:12:19,540 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1920 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,540 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,540 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1918 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,540 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,541 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16296,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923245,"queuetimems":0,"class":"HRegionServer","responsesize":13469,"method":"Multi"}
2014-07-02 03:12:19,542 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16382,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923159,"queuetimems":1,"class":"HRegionServer","responsesize":12985,"method":"Multi"}
2014-07-02 03:12:19,542 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15918,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923624,"queuetimems":285,"class":"HRegionServer","responsesize":13111,"method":"Multi"}
2014-07-02 03:12:19,542 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1919 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,542 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,542 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1921 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,542 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,543 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1917 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,543 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,542 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923073,"queuetimems":46,"class":"HRegionServer","responsesize":13032,"method":"Multi"}
2014-07-02 03:12:19,543 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1927 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,543 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,552 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295926434 with entries=126, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295936363
2014-07-02 03:12:19,991 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16918,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923072,"queuetimems":121,"class":"HRegionServer","responsesize":12905,"method":"Multi"}
2014-07-02 03:12:19,991 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16882,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923109,"queuetimems":0,"class":"HRegionServer","responsesize":13263,"method":"Multi"}
2014-07-02 03:12:19,991 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16936,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923055,"queuetimems":243,"class":"HRegionServer","responsesize":13253,"method":"Multi"}
2014-07-02 03:12:19,991 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1929 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,991 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,991 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16902,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923088,"queuetimems":0,"class":"HRegionServer","responsesize":13379,"method":"Multi"}
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1857 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16924,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923067,"queuetimems":200,"class":"HRegionServer","responsesize":13283,"method":"Multi"}
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1923 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,991 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16944,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923047,"queuetimems":308,"class":"HRegionServer","responsesize":12663,"method":"Multi"}
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1931 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16924,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34465","starttimems":1404295923067,"queuetimems":152,"class":"HRegionServer","responsesize":12737,"method":"Multi"}
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1887 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1930 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,993 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,992 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:19,993 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1922 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34465: output error
2014-07-02 03:12:19,993 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:25,353 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4628ms
GC pool 'ParNew' had collection(s): count=1 time=4674ms
2014-07-02 03:12:25,566 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1078, memsize=238.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/88444526ad454ac496f9d3bdfa0b52b0
2014-07-02 03:12:25,578 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/88444526ad454ac496f9d3bdfa0b52b0 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/88444526ad454ac496f9d3bdfa0b52b0
2014-07-02 03:12:25,593 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/88444526ad454ac496f9d3bdfa0b52b0, entries=868900, sequenceid=1078, filesize=129.5m
2014-07-02 03:12:25,594 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~287.4m/301344960, currentsize=110.7m/116032480 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 29681ms, sequenceid=1078, compaction requested=false
2014-07-02 03:12:25,628 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10568,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935059,"queuetimems":172,"class":"HRegionServer","responsesize":13014,"method":"Multi"}
2014-07-02 03:12:25,628 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2057 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:25,630 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,736 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:26,750 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:12:26,750 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 257.3m
2014-07-02 03:12:26,757 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935904,"queuetimems":0,"class":"HRegionServer","responsesize":12964,"method":"Multi"}
2014-07-02 03:12:26,757 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2064 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,758 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,758 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11670,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935087,"queuetimems":86,"class":"HRegionServer","responsesize":13014,"method":"Multi"}
2014-07-02 03:12:26,758 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2053 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,758 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,762 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11693,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935069,"queuetimems":164,"class":"HRegionServer","responsesize":13407,"method":"Multi"}
2014-07-02 03:12:26,763 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2056 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,763 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11676,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935086,"queuetimems":116,"class":"HRegionServer","responsesize":12845,"method":"Multi"}
2014-07-02 03:12:26,763 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,763 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2052 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,763 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,764 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935090,"queuetimems":49,"class":"HRegionServer","responsesize":12663,"method":"Multi"}
2014-07-02 03:12:26,764 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935955,"queuetimems":0,"class":"HRegionServer","responsesize":12860,"method":"Multi"}
2014-07-02 03:12:26,764 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2047 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,764 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,764 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11658,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935106,"queuetimems":13,"class":"HRegionServer","responsesize":12938,"method":"Multi"}
2014-07-02 03:12:26,763 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935173,"queuetimems":0,"class":"HRegionServer","responsesize":13036,"method":"Multi"}
2014-07-02 03:12:26,898 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11621,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935276,"queuetimems":4,"class":"HRegionServer","responsesize":13092,"method":"Multi"}
2014-07-02 03:12:26,897 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11412,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935354,"queuetimems":0,"class":"HRegionServer","responsesize":12965,"method":"Multi"}
2014-07-02 03:12:26,889 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935087,"queuetimems":69,"class":"HRegionServer","responsesize":12934,"method":"Multi"}
2014-07-02 03:12:26,889 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11011,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935877,"queuetimems":0,"class":"HRegionServer","responsesize":12928,"method":"Multi"}
2014-07-02 03:12:26,885 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935122,"queuetimems":0,"class":"HRegionServer","responsesize":12724,"method":"Multi"}
2014-07-02 03:12:26,885 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11794,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935090,"queuetimems":16,"class":"HRegionServer","responsesize":13233,"method":"Multi"}
2014-07-02 03:12:26,885 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11726,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935158,"queuetimems":1,"class":"HRegionServer","responsesize":13010,"method":"Multi"}
2014-07-02 03:12:26,884 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11690,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935076,"queuetimems":126,"class":"HRegionServer","responsesize":13270,"method":"Multi"}
2014-07-02 03:12:26,872 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11801,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34479","starttimems":1404295935070,"queuetimems":140,"class":"HRegionServer","responsesize":13167,"method":"Multi"}
2014-07-02 03:12:26,764 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2065 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,903 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,903 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2055 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,903 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,904 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2054 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,904 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,904 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2051 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,904 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,909 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2048 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,909 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,909 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2050 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,909 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,910 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2062 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,910 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,913 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2063 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,913 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,913 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2046 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,913 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,913 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2060 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,914 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,914 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2074 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,914 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2061 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,914 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,914 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:26,914 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2049 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:26,914 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,151 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:12:27,313 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2068 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,313 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,314 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2072 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,314 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,315 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2075 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,315 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,315 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2076 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,315 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,315 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2073 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,315 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,330 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2071 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,330 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,988 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2088 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,988 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,998 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2081 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,998 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,998 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2079 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,998 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:27,998 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2087 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:27,999 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,011 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2086 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,011 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,042 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2085 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,042 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,042 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2078 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,042 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,066 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2069 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,066 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,084 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2084 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,084 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,103 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2070 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,103 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,215 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2082 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,215 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,215 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2080 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,215 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,215 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2083 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,215 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,217 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2077 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,217 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,217 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2097 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,217 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1075, memsize=237.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/1bfcb6c81de74be6b769b01bcd1ff75f
2014-07-02 03:12:28,217 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295936363 with entries=151, filesize=101.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295946750
2014-07-02 03:12:28,248 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/1bfcb6c81de74be6b769b01bcd1ff75f as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/1bfcb6c81de74be6b769b01bcd1ff75f
2014-07-02 03:12:28,271 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2093 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34479: output error
2014-07-02 03:12:28,271 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:12:28,284 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/1bfcb6c81de74be6b769b01bcd1ff75f, entries=865220, sequenceid=1075, filesize=129.0m
2014-07-02 03:12:28,284 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~282.5m/296241440, currentsize=152.2m/159590880 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 45199ms, sequenceid=1075, compaction requested=false
2014-07-02 03:12:28,944 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/79671203b80a467f84536f774a7ac2fe as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/79671203b80a467f84536f774a7ac2fe
2014-07-02 03:12:28,970 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:12:28,981 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/1e1d40712cf5450d97c8b59e198de375, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/1e1d40712cf5450d97c8b59e198de375
2014-07-02 03:12:28,988 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/cc53d7015d05468fa2a5d4d3683aa6ad, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/cc53d7015d05468fa2a5d4d3683aa6ad
2014-07-02 03:12:28,991 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/97bef6bfebd543b081a2c91236a1e7d1, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/97bef6bfebd543b081a2c91236a1e7d1
2014-07-02 03:12:28,991 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into 79671203b80a467f84536f774a7ac2fe(size=288.7m), total size for store is 288.7m. This selection was in queue for 0sec, and took 56sec to execute.
2014-07-02 03:12:28,991 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=3, fileSize=351.3m, priority=17, time=14106884986404; duration=56sec
2014-07-02 03:12:28,992 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:12:29,118 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:12:29,118 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., current region memstore size 256.4m
2014-07-02 03:12:29,673 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:12:30,959 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1055ms
GC pool 'ParNew' had collection(s): count=1 time=1267ms
2014-07-02 03:12:32,422 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1155, memsize=95.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/4d3b40880afe4863a89c995283427640
2014-07-02 03:12:32,462 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/4d3b40880afe4863a89c995283427640 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/4d3b40880afe4863a89c995283427640
2014-07-02 03:12:32,473 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/4d3b40880afe4863a89c995283427640, entries=346340, sequenceid=1155, filesize=51.6m
2014-07-02 03:12:32,474 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.9m/271424080, currentsize=51.6m/54127840 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 5724ms, sequenceid=1155, compaction requested=false
2014-07-02 03:12:33,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:33,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4749 synced till here 4743
2014-07-02 03:12:33,144 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295946750 with entries=92, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295953011
2014-07-02 03:12:35,311 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1816ms
GC pool 'ParNew' had collection(s): count=1 time=2161ms
2014-07-02 03:12:36,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:36,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4854 synced till here 4832
2014-07-02 03:12:36,891 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1170, memsize=165.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/dd4d0e73378a4c28890b66f460bc2b00
2014-07-02 03:12:39,291 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1979ms
GC pool 'ParNew' had collection(s): count=1 time=2393ms
2014-07-02 03:12:39,316 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/dd4d0e73378a4c28890b66f460bc2b00 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/dd4d0e73378a4c28890b66f460bc2b00
2014-07-02 03:12:39,332 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/dd4d0e73378a4c28890b66f460bc2b00, entries=602670, sequenceid=1170, filesize=89.7m
2014-07-02 03:12:39,332 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268855520, currentsize=9.5m/9963760 for region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. in 10214ms, sequenceid=1170, compaction requested=false
2014-07-02 03:12:39,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295953011 with entries=105, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295956800
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295828091
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295830593
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295831992
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295835241
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295836601
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295839463
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295841641
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295843083
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295845230
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295848349
2014-07-02 03:12:39,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295851902
2014-07-02 03:12:39,583 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295854703
2014-07-02 03:12:39,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295857454
2014-07-02 03:12:39,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295864099
2014-07-02 03:12:39,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295865743
2014-07-02 03:12:39,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295870403
2014-07-02 03:12:39,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295895785
2014-07-02 03:12:40,005 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:12:40,007 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.1m
2014-07-02 03:12:40,254 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:12:40,255 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 261.9m
2014-07-02 03:12:40,285 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:12:40,382 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:40,497 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:12:40,650 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4963 synced till here 4956
2014-07-02 03:12:40,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295956800 with entries=109, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295960382
2014-07-02 03:12:43,968 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1249, memsize=91.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/d97e4db2d6d3466c890a396790c08c4c
2014-07-02 03:12:43,992 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/d97e4db2d6d3466c890a396790c08c4c as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d97e4db2d6d3466c890a396790c08c4c
2014-07-02 03:12:44,002 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d97e4db2d6d3466c890a396790c08c4c, entries=332440, sequenceid=1249, filesize=49.6m
2014-07-02 03:12:44,003 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~268.7m/281734080, currentsize=15.5m/16242880 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 3996ms, sequenceid=1249, compaction requested=true
2014-07-02 03:12:44,003 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:12:44,003 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:12:44,004 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 411699803 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:12:44,004 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating major compaction
2014-07-02 03:12:44,004 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:12:44,004 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=392.6m
2014-07-02 03:12:44,004 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/072957a84d3d4c84b9acfaa56fa07be6, keycount=144557, bloomtype=ROW, size=214.1m, encoding=NONE, seqNum=891, earliestPutTs=1404295762713
2014-07-02 03:12:44,005 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/1bfcb6c81de74be6b769b01bcd1ff75f, keycount=86522, bloomtype=ROW, size=129.0m, encoding=NONE, seqNum=1075, earliestPutTs=1404295854511
2014-07-02 03:12:44,005 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d97e4db2d6d3466c890a396790c08c4c, keycount=33244, bloomtype=ROW, size=49.6m, encoding=NONE, seqNum=1249, earliestPutTs=1404295947987
2014-07-02 03:12:44,041 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:12:44,180 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1249, memsize=92.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/e91ec2ba8b844d308b564b4918e45160
2014-07-02 03:12:44,244 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/e91ec2ba8b844d308b564b4918e45160 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/e91ec2ba8b844d308b564b4918e45160
2014-07-02 03:12:44,273 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/e91ec2ba8b844d308b564b4918e45160, entries=334900, sequenceid=1249, filesize=49.9m
2014-07-02 03:12:44,273 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~263.4m/276225200, currentsize=18.7m/19606800 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 4018ms, sequenceid=1249, compaction requested=true
2014-07-02 03:12:44,273 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:12:46,886 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1200ms
GC pool 'ParNew' had collection(s): count=1 time=1444ms
2014-07-02 03:12:46,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:46,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5060 synced till here 5050
2014-07-02 03:12:47,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295960382 with entries=97, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295966893
2014-07-02 03:12:47,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295901513
2014-07-02 03:12:47,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295916199
2014-07-02 03:12:47,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295926434
2014-07-02 03:12:48,007 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:48,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5151 synced till here 5150
2014-07-02 03:12:48,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295966893 with entries=91, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295968007
2014-07-02 03:12:50,173 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:50,894 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:12:50,895 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.9m
2014-07-02 03:12:51,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295968007 with entries=114, filesize=80.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295970173
2014-07-02 03:12:51,194 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:12:56,309 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1326, memsize=152.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/e7417ef26f764c80a006a20e22e307cb
2014-07-02 03:12:56,332 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/e7417ef26f764c80a006a20e22e307cb as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7417ef26f764c80a006a20e22e307cb
2014-07-02 03:12:56,344 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7417ef26f764c80a006a20e22e307cb, entries=555420, sequenceid=1326, filesize=82.8m
2014-07-02 03:12:56,344 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.5m/274198320, currentsize=29.6m/31022560 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 5449ms, sequenceid=1326, compaction requested=true
2014-07-02 03:12:56,357 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:12:57,038 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:12:57,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5356 synced till here 5354
2014-07-02 03:12:57,135 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295970173 with entries=91, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295977038
2014-07-02 03:12:57,135 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295936363
2014-07-02 03:12:59,009 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1319ms
GC pool 'ParNew' had collection(s): count=1 time=1339ms
2014-07-02 03:12:59,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:00,438 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295977038 with entries=109, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295979693
2014-07-02 03:13:02,692 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1169ms
GC pool 'ParNew' had collection(s): count=1 time=1582ms
2014-07-02 03:13:03,653 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:03,686 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5561 synced till here 5556
2014-07-02 03:13:03,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295979693 with entries=96, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295983653
2014-07-02 03:13:07,691 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2971ms
GC pool 'ParNew' had collection(s): count=1 time=3390ms
2014-07-02 03:13:07,822 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/2b7f272ec9974ed7979ee426d874eef3 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2b7f272ec9974ed7979ee426d874eef3
2014-07-02 03:13:07,934 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:13:07,934 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.4m
2014-07-02 03:13:08,048 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:13:08,057 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/072957a84d3d4c84b9acfaa56fa07be6, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/072957a84d3d4c84b9acfaa56fa07be6
2014-07-02 03:13:08,064 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/1bfcb6c81de74be6b769b01bcd1ff75f, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/1bfcb6c81de74be6b769b01bcd1ff75f
2014-07-02 03:13:08,067 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d97e4db2d6d3466c890a396790c08c4c, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d97e4db2d6d3466c890a396790c08c4c
2014-07-02 03:13:08,067 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into 2b7f272ec9974ed7979ee426d874eef3(size=361.3m), total size for store is 361.3m. This selection was in queue for 0sec, and took 24sec to execute.
2014-07-02 03:13:08,067 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=3, fileSize=392.6m, priority=17, time=14178402717509; duration=24sec
2014-07-02 03:13:08,067 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:13:08,067 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:13:08,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 412686448 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:13:08,068 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating major compaction
2014-07-02 03:13:08,068 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:13:08,068 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=393.6m
2014-07-02 03:13:08,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3bc118d1705749efabafc3a60168f91a, keycount=144574, bloomtype=ROW, size=214.1m, encoding=NONE, seqNum=892, earliestPutTs=1404295763006
2014-07-02 03:13:08,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/88444526ad454ac496f9d3bdfa0b52b0, keycount=86890, bloomtype=ROW, size=129.5m, encoding=NONE, seqNum=1078, earliestPutTs=1404295854624
2014-07-02 03:13:08,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/e91ec2ba8b844d308b564b4918e45160, keycount=33490, bloomtype=ROW, size=49.9m, encoding=NONE, seqNum=1249, earliestPutTs=1404295948271
2014-07-02 03:13:08,155 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:13:08,232 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:13:08,233 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 259.3m
2014-07-02 03:13:08,452 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:13:08,784 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:13:09,237 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:15,319 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5616ms
GC pool 'ParNew' had collection(s): count=2 time=6062ms
2014-07-02 03:13:15,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5682 synced till here 5649
2014-07-02 03:13:15,627 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295984195,"queuetimems":0,"class":"HRegionServer","responsesize":13020,"method":"Multi"}
2014-07-02 03:13:15,627 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11386,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295984240,"queuetimems":0,"class":"HRegionServer","responsesize":13004,"method":"Multi"}
2014-07-02 03:13:15,627 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11514,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295984112,"queuetimems":0,"class":"HRegionServer","responsesize":12857,"method":"Multi"}
2014-07-02 03:13:15,627 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11473,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295984153,"queuetimems":0,"class":"HRegionServer","responsesize":12850,"method":"Multi"}
2014-07-02 03:13:15,627 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11561,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295984065,"queuetimems":1,"class":"HRegionServer","responsesize":13034,"method":"Multi"}
2014-07-02 03:13:15,627 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2477 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,629 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,629 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2482 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,630 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,631 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2479 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,632 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,640 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2478 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,640 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,660 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2480 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,660 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,877 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2476 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,877 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,878 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2497 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,878 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,878 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2495 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:15,878 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:15,903 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295983653 with entries=121, filesize=89.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295989238
2014-07-02 03:13:16,624 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.28 MB, free=3.95 GB, max=3.96 GB, blocks=1, accesses=33383, hits=2492, hitRatio=7.46%, , cachingAccesses=2500, cachingHits=2497, cachingHitsRatio=99.87%, evictions=0, evicted=2, evictedPerRun=Infinity
2014-07-02 03:13:16,826 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2493 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:16,826 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:16,827 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2491 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:16,827 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:16,854 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2492 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:16,854 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:19,906 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2585ms
GC pool 'ParNew' had collection(s): count=1 time=3041ms
2014-07-02 03:13:20,051 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12148,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295987902,"queuetimems":1,"class":"HRegionServer","responsesize":12987,"method":"Multi"}
2014-07-02 03:13:20,052 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2522 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,052 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,074 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12143,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295987930,"queuetimems":0,"class":"HRegionServer","responsesize":13034,"method":"Multi"}
2014-07-02 03:13:20,074 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2519 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,074 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,202 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12038,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988163,"queuetimems":1,"class":"HRegionServer","responsesize":13427,"method":"Multi"}
2014-07-02 03:13:20,202 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12186,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988003,"queuetimems":1,"class":"HRegionServer","responsesize":13004,"method":"Multi"}
2014-07-02 03:13:20,202 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2513 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,203 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,203 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2517 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,203 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,203 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12144,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988059,"queuetimems":0,"class":"HRegionServer","responsesize":12777,"method":"Multi"}
2014-07-02 03:13:20,203 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2515 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,203 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,973 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:20,975 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13003,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295987972,"queuetimems":0,"class":"HRegionServer","responsesize":12850,"method":"Multi"}
2014-07-02 03:13:20,975 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988208,"queuetimems":0,"class":"HRegionServer","responsesize":13517,"method":"Multi"}
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2518 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988385,"queuetimems":0,"class":"HRegionServer","responsesize":12802,"method":"Multi"}
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2512 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2508 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12648,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988328,"queuetimems":0,"class":"HRegionServer","responsesize":13202,"method":"Multi"}
2014-07-02 03:13:20,977 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12688,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988288,"queuetimems":1,"class":"HRegionServer","responsesize":12647,"method":"Multi"}
2014-07-02 03:13:20,977 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2510 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,977 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,977 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2511 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,977 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,975 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988116,"queuetimems":1,"class":"HRegionServer","responsesize":13200,"method":"Multi"}
2014-07-02 03:13:20,977 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2514 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:20,977 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,976 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:20,975 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12939,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988036,"queuetimems":0,"class":"HRegionServer","responsesize":13020,"method":"Multi"}
2014-07-02 03:13:21,008 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2516 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:21,008 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:21,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5819 synced till here 5799
2014-07-02 03:13:21,345 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988716,"queuetimems":0,"class":"HRegionServer","responsesize":13427,"method":"Multi"}
2014-07-02 03:13:21,345 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12582,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988763,"queuetimems":0,"class":"HRegionServer","responsesize":13200,"method":"Multi"}
2014-07-02 03:13:21,345 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12991,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988354,"queuetimems":0,"class":"HRegionServer","responsesize":12857,"method":"Multi"}
2014-07-02 03:13:21,346 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2533 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:21,346 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:21,346 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2532 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:21,346 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:21,346 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2509 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:21,346 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:21,345 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12850,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988495,"queuetimems":0,"class":"HRegionServer","responsesize":12981,"method":"Multi"}
2014-07-02 03:13:21,345 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12441,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988904,"queuetimems":0,"class":"HRegionServer","responsesize":12966,"method":"Multi"}
2014-07-02 03:13:26,401 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4987ms
GC pool 'ParNew' had collection(s): count=1 time=5047ms
2014-07-02 03:13:26,397 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2499 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,407 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:21,346 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12321,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295989024,"queuetimems":0,"class":"HRegionServer","responsesize":12955,"method":"Multi"}
2014-07-02 03:13:26,407 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2527 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,407 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,407 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2525 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,407 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18222,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988413,"queuetimems":0,"class":"HRegionServer","responsesize":12857,"method":"Multi"}
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2507 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988827,"queuetimems":1,"class":"HRegionServer","responsesize":13169,"method":"Multi"}
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11220,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995415,"queuetimems":1,"class":"HRegionServer","responsesize":13034,"method":"Multi"}
2014-07-02 03:13:26,640 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17511,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295989128,"queuetimems":0,"class":"HRegionServer","responsesize":12857,"method":"Multi"}
2014-07-02 03:13:26,640 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18168,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988472,"queuetimems":0,"class":"HRegionServer","responsesize":13110,"method":"Multi"}
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295995384,"queuetimems":0,"class":"HRegionServer","responsesize":12802,"method":"Multi"}
2014-07-02 03:13:26,640 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18186,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988454,"queuetimems":0,"class":"HRegionServer","responsesize":12931,"method":"Multi"}
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17670,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988965,"queuetimems":0,"class":"HRegionServer","responsesize":13341,"method":"Multi"}
2014-07-02 03:13:26,636 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11278,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295995357,"queuetimems":14,"class":"HRegionServer","responsesize":13110,"method":"Multi"}
2014-07-02 03:13:26,640 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18056,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988584,"queuetimems":0,"class":"HRegionServer","responsesize":13517,"method":"Multi"}
2014-07-02 03:13:26,640 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17987,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295988652,"queuetimems":0,"class":"HRegionServer","responsesize":12647,"method":"Multi"}
2014-07-02 03:13:26,637 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2528 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,656 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,656 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2534 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,656 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,656 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2535 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,656 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,656 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2543 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,657 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,657 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2526 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,657 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,657 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2503 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,657 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,657 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2542 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,657 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,661 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2501 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,661 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,661 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2545 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,661 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,749 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17543,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295989204,"queuetimems":0,"class":"HRegionServer","responsesize":12981,"method":"Multi"}
2014-07-02 03:13:26,750 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2544 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:26,750 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:26,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295989238 with entries=137, filesize=95.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296000973
2014-07-02 03:13:27,671 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1423, memsize=195.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/8145c96c2704441aafeb4a09b56f5644
2014-07-02 03:13:27,695 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/8145c96c2704441aafeb4a09b56f5644 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/8145c96c2704441aafeb4a09b56f5644
2014-07-02 03:13:27,706 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/8145c96c2704441aafeb4a09b56f5644, entries=712760, sequenceid=1423, filesize=106.3m
2014-07-02 03:13:27,706 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~263.9m/276770720, currentsize=101.4m/106347920 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 19772ms, sequenceid=1423, compaction requested=false
2014-07-02 03:13:27,947 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995823,"queuetimems":0,"class":"HRegionServer","responsesize":12981,"method":"Multi"}
2014-07-02 03:13:27,948 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2589 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:27,950 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:31,821 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3407ms
GC pool 'ParNew' had collection(s): count=1 time=3832ms
2014-07-02 03:13:32,180 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1421, memsize=198.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/d913e9c7a7944977839ab5d5dc202f44
2014-07-02 03:13:32,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:32,190 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16315,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995874,"queuetimems":1,"class":"HRegionServer","responsesize":12987,"method":"Multi"}
2014-07-02 03:13:32,190 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16054,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996136,"queuetimems":0,"class":"HRegionServer","responsesize":12966,"method":"Multi"}
2014-07-02 03:13:32,190 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15363,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996827,"queuetimems":616,"class":"HRegionServer","responsesize":12850,"method":"Multi"}
2014-07-02 03:13:32,190 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2588 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,191 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,191 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16755,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34480","starttimems":1404295995436,"queuetimems":0,"class":"HRegionServer","responsesize":12857,"method":"Multi"}
2014-07-02 03:13:32,191 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2541 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34480: output error
2014-07-02 03:13:32,191 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,192 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16073,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996118,"queuetimems":0,"class":"HRegionServer","responsesize":12802,"method":"Multi"}
2014-07-02 03:13:32,192 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2583 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,192 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,193 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16091,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996102,"queuetimems":0,"class":"HRegionServer","responsesize":12647,"method":"Multi"}
2014-07-02 03:13:32,194 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2585 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,194 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,198 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16695,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995502,"queuetimems":0,"class":"HRegionServer","responsesize":13202,"method":"Multi"}
2014-07-02 03:13:32,198 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000052,"queuetimems":3782,"class":"HRegionServer","responsesize":12857,"method":"Multi"}
2014-07-02 03:13:32,191 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996008,"queuetimems":0,"class":"HRegionServer","responsesize":12777,"method":"Multi"}
2014-07-02 03:13:32,198 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2594 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,198 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995971,"queuetimems":0,"class":"HRegionServer","responsesize":13517,"method":"Multi"}
2014-07-02 03:13:32,198 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2580 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,199 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,199 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2582 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,199 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,199 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16482,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995717,"queuetimems":0,"class":"HRegionServer","responsesize":13341,"method":"Multi"}
2014-07-02 03:13:32,199 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2592 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,199 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,200 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2584 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,200 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,201 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/d913e9c7a7944977839ab5d5dc202f44 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/d913e9c7a7944977839ab5d5dc202f44
2014-07-02 03:13:32,198 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,199 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16035,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996163,"queuetimems":0,"class":"HRegionServer","responsesize":13200,"method":"Multi"}
2014-07-02 03:13:32,216 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995604,"queuetimems":1,"class":"HRegionServer","responsesize":13427,"method":"Multi"}
2014-07-02 03:13:32,216 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2576 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,216 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,216 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2581 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,216 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,216 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2593 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,216 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,220 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2575 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,220 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,225 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16199,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996026,"queuetimems":1,"class":"HRegionServer","responsesize":13169,"method":"Multi"}
2014-07-02 03:13:32,226 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2577 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,226 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,229 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/d913e9c7a7944977839ab5d5dc202f44, entries=721000, sequenceid=1421, filesize=107.5m
2014-07-02 03:13:32,229 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.0m/276820400, currentsize=110.2m/115504880 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 23996ms, sequenceid=1421, compaction requested=false
2014-07-02 03:13:32,254 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16181,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996072,"queuetimems":13,"class":"HRegionServer","responsesize":12955,"method":"Multi"}
2014-07-02 03:13:32,254 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2586 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,254 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,287 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5928 synced till here 5901
2014-07-02 03:13:32,544 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16602,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995942,"queuetimems":0,"class":"HRegionServer","responsesize":12931,"method":"Multi"}
2014-07-02 03:13:32,545 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2587 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,545 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,577 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16823,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995753,"queuetimems":1,"class":"HRegionServer","responsesize":13110,"method":"Multi"}
2014-07-02 03:13:32,577 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12502,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000074,"queuetimems":159,"class":"HRegionServer","responsesize":12931,"method":"Multi"}
2014-07-02 03:13:32,578 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2591 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,578 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,578 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2597 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,578 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,651 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296000973 with entries=109, filesize=80.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296012188
2014-07-02 03:13:32,973 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295995790,"queuetimems":0,"class":"HRegionServer","responsesize":12857,"method":"Multi"}
2014-07-02 03:13:32,973 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996854,"queuetimems":617,"class":"HRegionServer","responsesize":13020,"method":"Multi"}
2014-07-02 03:13:32,973 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000977,"queuetimems":760,"class":"HRegionServer","responsesize":13341,"method":"Multi"}
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2590 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2621 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16147,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404295996826,"queuetimems":644,"class":"HRegionServer","responsesize":13004,"method":"Multi"}
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2579 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2578 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,973 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12770,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000203,"queuetimems":201,"class":"HRegionServer","responsesize":13110,"method":"Multi"}
2014-07-02 03:13:32,973 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12770,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000203,"queuetimems":255,"class":"HRegionServer","responsesize":12955,"method":"Multi"}
2014-07-02 03:13:32,973 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000976,"queuetimems":875,"class":"HRegionServer","responsesize":12981,"method":"Multi"}
2014-07-02 03:13:32,974 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,975 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2600 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,975 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,975 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2599 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,975 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:32,975 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2601 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:32,975 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,037 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12060,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000977,"queuetimems":796,"class":"HRegionServer","responsesize":13202,"method":"Multi"}
2014-07-02 03:13:33,038 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2622 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,038 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,038 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11692,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296001346,"queuetimems":958,"class":"HRegionServer","responsesize":12966,"method":"Multi"}
2014-07-02 03:13:33,039 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2616 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,039 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,039 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12060,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000979,"queuetimems":695,"class":"HRegionServer","responsesize":12850,"method":"Multi"}
2014-07-02 03:13:33,039 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2619 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,039 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,040 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12837,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000203,"queuetimems":280,"class":"HRegionServer","responsesize":13200,"method":"Multi"}
2014-07-02 03:13:33,040 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11694,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296001346,"queuetimems":991,"class":"HRegionServer","responsesize":13263,"method":"Multi"}
2014-07-02 03:13:33,040 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2614 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,040 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,040 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2617 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,040 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,040 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2602 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2607 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12033,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296001008,"queuetimems":687,"class":"HRegionServer","responsesize":13169,"method":"Multi"}
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12065,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000976,"queuetimems":838,"class":"HRegionServer","responsesize":12987,"method":"Multi"}
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2618 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12063,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296000978,"queuetimems":728,"class":"HRegionServer","responsesize":12683,"method":"Multi"}
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2598 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2620 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11695,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34539","starttimems":1404296001346,"queuetimems":927,"class":"HRegionServer","responsesize":13020,"method":"Multi"}
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,041 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2612 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2608 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2613 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2615 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,042 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,043 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,057 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:13:33,066 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 260.4m
2014-07-02 03:13:33,216 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2626 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,216 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,216 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2606 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,216 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,293 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2630 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,294 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,294 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2603 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,294 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,300 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2605 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,300 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,300 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2604 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,300 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,300 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2623 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,300 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,301 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2609 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34539: output error
2014-07-02 03:13:33,301 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:13:33,459 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:35,524 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1689ms
GC pool 'ParNew' had collection(s): count=1 time=2053ms
2014-07-02 03:13:35,527 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6032 synced till here 6022
2014-07-02 03:13:35,619 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:13:35,946 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296012188 with entries=104, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296013459
2014-07-02 03:13:38,057 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1503, memsize=115.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/b5ee7704fa314d7ba47b40f2b358a761
2014-07-02 03:13:38,075 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/b5ee7704fa314d7ba47b40f2b358a761 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b5ee7704fa314d7ba47b40f2b358a761
2014-07-02 03:13:38,104 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b5ee7704fa314d7ba47b40f2b358a761, entries=419680, sequenceid=1503, filesize=62.6m
2014-07-02 03:13:38,104 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~269.7m/282753280, currentsize=49.4m/51843600 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 5038ms, sequenceid=1503, compaction requested=true
2014-07-02 03:13:38,104 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:13:39,734 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:39,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6128 synced till here 6127
2014-07-02 03:13:39,759 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296013459 with entries=96, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296019734
2014-07-02 03:13:43,831 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:43,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6216 synced till here 6215
2014-07-02 03:13:44,129 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296019734 with entries=88, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296023831
2014-07-02 03:13:44,844 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/720acbc35c1f4c148c42f244cf016fe5 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/720acbc35c1f4c148c42f244cf016fe5
2014-07-02 03:13:44,902 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:13:44,946 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3bc118d1705749efabafc3a60168f91a, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3bc118d1705749efabafc3a60168f91a
2014-07-02 03:13:44,955 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/88444526ad454ac496f9d3bdfa0b52b0, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/88444526ad454ac496f9d3bdfa0b52b0
2014-07-02 03:13:44,969 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/e91ec2ba8b844d308b564b4918e45160, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/e91ec2ba8b844d308b564b4918e45160
2014-07-02 03:13:44,969 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 720acbc35c1f4c148c42f244cf016fe5(size=361.2m), total size for store is 468.7m. This selection was in queue for 0sec, and took 36sec to execute.
2014-07-02 03:13:44,970 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=393.6m, priority=17, time=14202466647477; duration=36sec
2014-07-02 03:13:44,970 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:13:44,970 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:13:44,970 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 206606815 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:13:44,970 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating minor compaction
2014-07-02 03:13:44,971 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:13:44,971 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=197.0m
2014-07-02 03:13:44,971 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/4d3b40880afe4863a89c995283427640, keycount=34634, bloomtype=ROW, size=51.6m, encoding=NONE, seqNum=1155
2014-07-02 03:13:44,971 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7417ef26f764c80a006a20e22e307cb, keycount=55542, bloomtype=ROW, size=82.8m, encoding=NONE, seqNum=1326
2014-07-02 03:13:44,971 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b5ee7704fa314d7ba47b40f2b358a761, keycount=41968, bloomtype=ROW, size=62.6m, encoding=NONE, seqNum=1503
2014-07-02 03:13:45,035 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:13:46,650 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1451ms
GC pool 'ParNew' had collection(s): count=1 time=1568ms
2014-07-02 03:13:47,043 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:13:47,043 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.7m
2014-07-02 03:13:47,103 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:47,207 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:13:47,207 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.6m
2014-07-02 03:13:47,313 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:13:47,331 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296023831 with entries=106, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296027103
2014-07-02 03:13:47,521 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:13:49,998 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1845ms
GC pool 'ParNew' had collection(s): count=1 time=1990ms
2014-07-02 03:13:50,570 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:50,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6419 synced till here 6411
2014-07-02 03:13:50,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296027103 with entries=97, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296030571
2014-07-02 03:13:51,350 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1588, memsize=94.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/ff57316156304b7883ea8e772b68474e
2014-07-02 03:13:51,594 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/ff57316156304b7883ea8e772b68474e as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/ff57316156304b7883ea8e772b68474e
2014-07-02 03:13:52,655 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/ff57316156304b7883ea8e772b68474e, entries=345320, sequenceid=1588, filesize=51.5m
2014-07-02 03:13:52,656 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269177360, currentsize=57.7m/60530400 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 5613ms, sequenceid=1588, compaction requested=true
2014-07-02 03:13:52,656 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:13:52,749 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1593, memsize=101.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/0641dc7ef6a843c3932a67fa74daf0f6
2014-07-02 03:13:52,829 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/0641dc7ef6a843c3932a67fa74daf0f6 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0641dc7ef6a843c3932a67fa74daf0f6
2014-07-02 03:13:52,871 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0641dc7ef6a843c3932a67fa74daf0f6, entries=369590, sequenceid=1593, filesize=55.1m
2014-07-02 03:13:52,872 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.1m/270604720, currentsize=55.6m/58292480 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 5665ms, sequenceid=1593, compaction requested=true
2014-07-02 03:13:52,872 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-02 03:13:54,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:13:54,069 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6511 synced till here 6508
2014-07-02 03:13:54,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296030571 with entries=92, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296034029
2014-07-02 03:13:56,546 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1412ms
GC pool 'ParNew' had collection(s): count=1 time=1883ms
2014-07-02 03:13:57,691 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:14:01,919 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3865ms
GC pool 'ParNew' had collection(s): count=1 time=4194ms
2014-07-02 03:14:01,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6625 synced till here 6601
2014-07-02 03:14:02,066 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/0c731178c98544578fcbd9150eac9026 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/0c731178c98544578fcbd9150eac9026
2014-07-02 03:14:02,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296034029 with entries=114, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296037691
2014-07-02 03:14:02,105 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:14:02,112 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/4d3b40880afe4863a89c995283427640, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/4d3b40880afe4863a89c995283427640
2014-07-02 03:14:02,114 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7417ef26f764c80a006a20e22e307cb, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7417ef26f764c80a006a20e22e307cb
2014-07-02 03:14:02,117 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b5ee7704fa314d7ba47b40f2b358a761, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b5ee7704fa314d7ba47b40f2b358a761
2014-07-02 03:14:02,117 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into 0c731178c98544578fcbd9150eac9026(size=153.7m), total size for store is 442.4m. This selection was in queue for 0sec, and took 17sec to execute.
2014-07-02 03:14:02,117 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=3, fileSize=197.0m, priority=16, time=14239369269633; duration=17sec
2014-07-02 03:14:02,118 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-02 03:14:02,118 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:14:02,118 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:14:02,118 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. because compaction request was cancelled
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. because compaction request was cancelled
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:14:02,119 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. because compaction request was cancelled
2014-07-02 03:14:06,019 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2082ms
GC pool 'ParNew' had collection(s): count=1 time=2457ms
2014-07-02 03:14:06,170 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:14:06,178 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:14:06,188 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 260.8m
2014-07-02 03:14:06,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6733 synced till here 6710
2014-07-02 03:14:06,784 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296037691 with entries=108, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296046171
2014-07-02 03:14:07,336 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:14:07,412 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10352,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296037058,"queuetimems":0,"class":"HRegionServer","responsesize":13092,"method":"Multi"}
2014-07-02 03:14:07,442 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10192,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296037250,"queuetimems":0,"class":"HRegionServer","responsesize":13340,"method":"Multi"}
2014-07-02 03:14:07,444 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10345,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296037096,"queuetimems":1,"class":"HRegionServer","responsesize":13085,"method":"Multi"}
2014-07-02 03:14:07,450 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296037300,"queuetimems":0,"class":"HRegionServer","responsesize":12948,"method":"Multi"}
2014-07-02 03:14:07,450 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296037117,"queuetimems":0,"class":"HRegionServer","responsesize":12966,"method":"Multi"}
2014-07-02 03:15:06,118 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 62914ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:15:06,118 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 62914ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:15:06,130 WARN  [regionserver60020] util.Sleeper: We slept 60096ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:15:06,130 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 63353ms for sessionid 0x46f6873b540002, closing socket connection and attempting reconnect
2014-07-02 03:15:06,130 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 79466ms for sessionid 0x46f6873b540007, closing socket connection and attempting reconnect
2014-07-02 03:15:06,130 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 63337ms for sessionid 0x46f6873b540005, closing socket connection and attempting reconnect
2014-07-02 03:15:06,131 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 58109ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=58338ms
2014-07-02 03:15:06,445 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:06,460 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042402,"queuetimems":0,"class":"HRegionServer","responsesize":12991,"method":"Multi"}
2014-07-02 03:15:06,460 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64196,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042251,"queuetimems":0,"class":"HRegionServer","responsesize":13001,"method":"Multi"}
2014-07-02 03:15:06,460 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64264,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042183,"queuetimems":1,"class":"HRegionServer","responsesize":13047,"method":"Multi"}
2014-07-02 03:15:06,460 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64217,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042231,"queuetimems":1,"class":"HRegionServer","responsesize":12966,"method":"Multi"}
2014-07-02 03:15:06,460 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2991 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,461 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,461 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2996 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,461 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,461 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2999 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,461 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64361,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042101,"queuetimems":1,"class":"HRegionServer","responsesize":13064,"method":"Multi"}
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64093,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042369,"queuetimems":1,"class":"HRegionServer","responsesize":12841,"method":"Multi"}
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64113,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042349,"queuetimems":2,"class":"HRegionServer","responsesize":12948,"method":"Multi"}
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2997 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64027,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042435,"queuetimems":0,"class":"HRegionServer","responsesize":13340,"method":"Multi"}
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2992 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63970,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042492,"queuetimems":0,"class":"HRegionServer","responsesize":12915,"method":"Multi"}
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64253,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042209,"queuetimems":0,"class":"HRegionServer","responsesize":12930,"method":"Multi"}
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042280,"queuetimems":1,"class":"HRegionServer","responsesize":13085,"method":"Multi"}
2014-07-02 03:15:06,462 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2993 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,463 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,463 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2934 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,463 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,463 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2995 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,463 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,463 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2998 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,463 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,464 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2989 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,464 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,464 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2990 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,464 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,465 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":64154,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296042311,"queuetimems":0,"class":"HRegionServer","responsesize":13123,"method":"Multi"}
2014-07-02 03:15:06,466 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2994 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,466 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,491 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6848 synced till here 6832
2014-07-02 03:15:06,648 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63634,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296043014,"queuetimems":492,"class":"HRegionServer","responsesize":13013,"method":"Multi"}
2014-07-02 03:15:06,649 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2988 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:06,649 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:06,656 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296046171 with entries=115, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296106445
2014-07-02 03:15:06,728 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 03:15:06,728 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-02 03:15:06,760 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 03:15:06,761 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-02 03:15:06,762 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 03:15:06,763 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-02 03:15:06,764 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x46f6873b540007, negotiated timeout = 90000
2014-07-02 03:15:06,779 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x46f6873b540005, negotiated timeout = 90000
2014-07-02 03:15:06,816 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x46f6873b540002, negotiated timeout = 90000
2014-07-02 03:15:07,001 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63977,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296043023,"queuetimems":417,"class":"HRegionServer","responsesize":12970,"method":"Multi"}
2014-07-02 03:15:07,030 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60852,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296046178,"queuetimems":3180,"class":"HRegionServer","responsesize":13058,"method":"Multi"}
2014-07-02 03:15:07,030 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60857,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296046173,"queuetimems":3302,"class":"HRegionServer","responsesize":13407,"method":"Multi"}
2014-07-02 03:15:07,030 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60833,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296046196,"queuetimems":2947,"class":"HRegionServer","responsesize":13064,"method":"Multi"}
2014-07-02 03:15:07,022 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60836,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296046186,"queuetimems":2979,"class":"HRegionServer","responsesize":12928,"method":"Multi"}
2014-07-02 03:15:07,022 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63995,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296043027,"queuetimems":273,"class":"HRegionServer","responsesize":13052,"method":"Multi"}
2014-07-02 03:15:07,021 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63998,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296043023,"queuetimems":454,"class":"HRegionServer","responsesize":13043,"method":"Multi"}
2014-07-02 03:15:07,016 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60837,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296046179,"queuetimems":3046,"class":"HRegionServer","responsesize":13011,"method":"Multi"}
2014-07-02 03:15:07,016 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60819,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296046197,"queuetimems":2848,"class":"HRegionServer","responsesize":13161,"method":"Multi"}
2014-07-02 03:15:07,016 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296043350,"queuetimems":537,"class":"HRegionServer","responsesize":12893,"method":"Multi"}
2014-07-02 03:15:07,016 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63991,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296043024,"queuetimems":333,"class":"HRegionServer","responsesize":12811,"method":"Multi"}
2014-07-02 03:15:07,016 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":63992,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296043023,"queuetimems":381,"class":"HRegionServer","responsesize":13092,"method":"Multi"}
2014-07-02 03:15:07,073 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2982 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,073 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,073 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2979 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2978 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2976 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3003 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3006 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2985 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,074 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2977 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3005 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3007 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3004 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 2975 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,075 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,365 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047054,"queuetimems":3601,"class":"HRegionServer","responsesize":13085,"method":"Multi"}
2014-07-02 03:15:07,365 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047054,"queuetimems":3555,"class":"HRegionServer","responsesize":12915,"method":"Multi"}
2014-07-02 03:15:07,365 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3023 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,365 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,365 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3022 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,366 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,384 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60321,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047062,"queuetimems":1023,"class":"HRegionServer","responsesize":12893,"method":"Multi"}
2014-07-02 03:15:07,384 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":61210,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296046173,"queuetimems":3231,"class":"HRegionServer","responsesize":12970,"method":"Multi"}
2014-07-02 03:15:07,384 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3020 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,384 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,384 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3010 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,384 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,384 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60345,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047038,"queuetimems":3640,"class":"HRegionServer","responsesize":13043,"method":"Multi"}
2014-07-02 03:15:07,388 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3013 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,388 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,390 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047054,"queuetimems":1030,"class":"HRegionServer","responsesize":12930,"method":"Multi"}
2014-07-02 03:15:07,390 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3021 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,390 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:07,514 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047410,"queuetimems":1289,"class":"HRegionServer","responsesize":13407,"method":"Multi"}
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60052,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047462,"queuetimems":870,"class":"HRegionServer","responsesize":13092,"method":"Multi"}
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047444,"queuetimems":1043,"class":"HRegionServer","responsesize":12928,"method":"Multi"}
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047444,"queuetimems":992,"class":"HRegionServer","responsesize":13047,"method":"Multi"}
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60069,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047445,"queuetimems":952,"class":"HRegionServer","responsesize":12974,"method":"Multi"}
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60078,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047436,"queuetimems":1120,"class":"HRegionServer","responsesize":13161,"method":"Multi"}
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60093,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047421,"queuetimems":1183,"class":"HRegionServer","responsesize":13064,"method":"Multi"}
2014-07-02 03:15:07,514 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60117,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047397,"queuetimems":1304,"class":"HRegionServer","responsesize":13001,"method":"Multi"}
2014-07-02 03:15:07,514 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., current region memstore size 257.7m
2014-07-02 03:15:07,515 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047411,"queuetimems":1266,"class":"HRegionServer","responsesize":13013,"method":"Multi"}
2014-07-02 03:15:07,515 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3017 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,515 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047397,"queuetimems":1343,"class":"HRegionServer","responsesize":12966,"method":"Multi"}
2014-07-02 03:15:07,515 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,515 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3018 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,516 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60103,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047412,"queuetimems":1245,"class":"HRegionServer","responsesize":13043,"method":"Multi"}
2014-07-02 03:15:07,516 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,516 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60065,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047450,"queuetimems":894,"class":"HRegionServer","responsesize":12811,"method":"Multi"}
2014-07-02 03:15:07,516 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3031 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:07,516 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:07,516 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3032 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,543 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,543 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3041 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,544 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,544 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3040 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,544 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,544 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3034 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,545 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,545 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3038 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,545 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,545 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3035 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,545 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,545 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3042 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,545 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,546 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3019 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,546 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,546 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3016 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,546 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,555 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6955 synced till here 6941
2014-07-02 03:15:08,625 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":61153,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047472,"queuetimems":821,"class":"HRegionServer","responsesize":13123,"method":"Multi"}
2014-07-02 03:15:08,625 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":61154,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047471,"queuetimems":852,"class":"HRegionServer","responsesize":12948,"method":"Multi"}
2014-07-02 03:15:08,625 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60918,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047707,"queuetimems":1038,"class":"HRegionServer","responsesize":12991,"method":"Multi"}
2014-07-02 03:15:08,625 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":61182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047443,"queuetimems":1077,"class":"HRegionServer","responsesize":12970,"method":"Multi"}
2014-07-02 03:15:08,626 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3029 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,626 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,625 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":61179,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047446,"queuetimems":913,"class":"HRegionServer","responsesize":13052,"method":"Multi"}
2014-07-02 03:15:08,625 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60915,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047710,"queuetimems":979,"class":"HRegionServer","responsesize":12841,"method":"Multi"}
2014-07-02 03:15:08,626 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":60916,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34554","starttimems":1404296047709,"queuetimems":1010,"class":"HRegionServer","responsesize":13340,"method":"Multi"}
2014-07-02 03:15:08,626 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3028 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,626 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,626 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3026 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,627 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,627 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3033 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,627 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,627 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3039 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,627 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,627 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3030 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,628 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,628 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3027 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34554: output error
2014-07-02 03:15:08,628 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:08,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296106445 with entries=107, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296107513
2014-07-02 03:15:08,880 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:09,410 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1692, memsize=149.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/6e5d81707fd34fafae8de9aa55582fc9
2014-07-02 03:15:09,422 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/6e5d81707fd34fafae8de9aa55582fc9 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/6e5d81707fd34fafae8de9aa55582fc9
2014-07-02 03:15:09,453 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/6e5d81707fd34fafae8de9aa55582fc9, entries=542790, sequenceid=1692, filesize=80.9m
2014-07-02 03:15:09,454 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~288.8m/302795840, currentsize=98.0m/102786880 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 63265ms, sequenceid=1692, compaction requested=true
2014-07-02 03:15:09,454 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:15:09,454 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:15:09,454 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:15:09,454 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:15:09,454 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. because compaction request was cancelled
2014-07-02 03:15:10,298 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1733, memsize=103.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/0bee96fbda8c4490bc6eef01c1e66f4c
2014-07-02 03:15:10,308 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/0bee96fbda8c4490bc6eef01c1e66f4c as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/0bee96fbda8c4490bc6eef01c1e66f4c
2014-07-02 03:15:10,320 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/0bee96fbda8c4490bc6eef01c1e66f4c, entries=377810, sequenceid=1733, filesize=56.2m
2014-07-02 03:15:10,320 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~262.4m/275166080, currentsize=6.2m/6539920 for region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. in 2806ms, sequenceid=1733, compaction requested=true
2014-07-02 03:15:10,321 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:15:10,321 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:15:10,321 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 184004837 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:15:10,321 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5f58b71b81e6d85caf1b01aa1abb7cf9 - family: Initiating major compaction
2014-07-02 03:15:10,321 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:15:10,321 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp, totalSize=175.5m
2014-07-02 03:15:10,322 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/670e14e25af5473f9ffb35f1b8cc9771, keycount=19835, bloomtype=ROW, size=29.5m, encoding=NONE, seqNum=621, earliestPutTs=1404295764376
2014-07-02 03:15:10,322 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/dd4d0e73378a4c28890b66f460bc2b00, keycount=60267, bloomtype=ROW, size=89.7m, encoding=NONE, seqNum=1170, earliestPutTs=1404295834788
2014-07-02 03:15:10,322 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/0bee96fbda8c4490bc6eef01c1e66f4c, keycount=37781, bloomtype=ROW, size=56.2m, encoding=NONE, seqNum=1733, earliestPutTs=1404295949292
2014-07-02 03:15:10,362 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:10,545 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:15:10,546 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 257.3m
2014-07-02 03:15:10,730 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:15:10,730 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.5m
2014-07-02 03:15:10,793 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:10,980 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:13,768 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1759, memsize=77.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/25e07c1e8e5d4d9486398ffb84695a73
2014-07-02 03:15:13,819 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/25e07c1e8e5d4d9486398ffb84695a73 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/25e07c1e8e5d4d9486398ffb84695a73
2014-07-02 03:15:13,841 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/25e07c1e8e5d4d9486398ffb84695a73, entries=282140, sequenceid=1759, filesize=42.1m
2014-07-02 03:15:13,841 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.5m/269002800, currentsize=15.4m/16159360 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 3111ms, sequenceid=1759, compaction requested=true
2014-07-02 03:15:13,842 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:15:13,931 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1759, memsize=80.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/771736fabb074036b011723bfdaca945
2014-07-02 03:15:13,960 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/771736fabb074036b011723bfdaca945 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/771736fabb074036b011723bfdaca945
2014-07-02 03:15:13,986 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/771736fabb074036b011723bfdaca945, entries=292580, sequenceid=1759, filesize=43.6m
2014-07-02 03:15:13,987 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.9m/271460480, currentsize=18.7m/19600800 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3442ms, sequenceid=1759, compaction requested=true
2014-07-02 03:15:13,988 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:15:14,575 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:14,919 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7057 synced till here 7056
2014-07-02 03:15:14,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296107513 with entries=102, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296114575
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295946750
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295953011
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295956800
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295960382
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295966893
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295968007
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295970173
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295977038
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295979693
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295983653
2014-07-02 03:15:14,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404295989238
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296000973
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296012188
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296013459
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296019734
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296023831
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296027103
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296030571
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296034029
2014-07-02 03:15:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296037691
2014-07-02 03:15:16,032 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/9b724325a4d140e88e150ee5928de751 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/9b724325a4d140e88e150ee5928de751
2014-07-02 03:15:16,045 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:15:16,061 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/670e14e25af5473f9ffb35f1b8cc9771, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/670e14e25af5473f9ffb35f1b8cc9771
2014-07-02 03:15:16,067 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/dd4d0e73378a4c28890b66f460bc2b00, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/dd4d0e73378a4c28890b66f460bc2b00
2014-07-02 03:15:16,069 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/0bee96fbda8c4490bc6eef01c1e66f4c, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/0bee96fbda8c4490bc6eef01c1e66f4c
2014-07-02 03:15:16,069 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. into 9b724325a4d140e88e150ee5928de751(size=150.4m), total size for store is 150.4m. This selection was in queue for 0sec, and took 5sec to execute.
2014-07-02 03:15:16,069 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., storeName=family, fileCount=3, fileSize=175.5m, priority=17, time=14324719922022; duration=5sec
2014-07-02 03:15:16,070 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:15:16,070 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:15:16,070 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 213333404 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:15:16,070 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating minor compaction
2014-07-02 03:15:16,070 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:15:16,071 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=203.5m
2014-07-02 03:15:16,071 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/8145c96c2704441aafeb4a09b56f5644, keycount=71276, bloomtype=ROW, size=106.3m, encoding=NONE, seqNum=1423
2014-07-02 03:15:16,071 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0641dc7ef6a843c3932a67fa74daf0f6, keycount=36959, bloomtype=ROW, size=55.1m, encoding=NONE, seqNum=1593
2014-07-02 03:15:16,071 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/25e07c1e8e5d4d9486398ffb84695a73, keycount=28214, bloomtype=ROW, size=42.1m, encoding=NONE, seqNum=1759
2014-07-02 03:15:16,118 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:19,199 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:19,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7145 synced till here 7144
2014-07-02 03:15:19,243 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296114575 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296119199
2014-07-02 03:15:20,671 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/551c24ef3359488087627340cb248252 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/551c24ef3359488087627340cb248252
2014-07-02 03:15:20,698 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:15:20,707 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/8145c96c2704441aafeb4a09b56f5644, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/8145c96c2704441aafeb4a09b56f5644
2014-07-02 03:15:20,715 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0641dc7ef6a843c3932a67fa74daf0f6, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/0641dc7ef6a843c3932a67fa74daf0f6
2014-07-02 03:15:20,719 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/25e07c1e8e5d4d9486398ffb84695a73, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/25e07c1e8e5d4d9486398ffb84695a73
2014-07-02 03:15:20,719 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into 551c24ef3359488087627340cb248252(size=167.2m), total size for store is 528.5m. This selection was in queue for 0sec, and took 4sec to execute.
2014-07-02 03:15:20,719 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=3, fileSize=203.5m, priority=16, time=14330468953902; duration=4sec
2014-07-02 03:15:20,719 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:15:20,719 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:15:20,720 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 212461166 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:15:20,720 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating minor compaction
2014-07-02 03:15:20,720 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:15:20,720 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=202.6m
2014-07-02 03:15:20,720 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/d913e9c7a7944977839ab5d5dc202f44, keycount=72100, bloomtype=ROW, size=107.5m, encoding=NONE, seqNum=1421
2014-07-02 03:15:20,720 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/ff57316156304b7883ea8e772b68474e, keycount=34532, bloomtype=ROW, size=51.5m, encoding=NONE, seqNum=1588
2014-07-02 03:15:20,720 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/771736fabb074036b011723bfdaca945, keycount=29258, bloomtype=ROW, size=43.6m, encoding=NONE, seqNum=1759
2014-07-02 03:15:20,743 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:23,162 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:23,423 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7240 synced till here 7239
2014-07-02 03:15:23,972 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296119199 with entries=95, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296123162
2014-07-02 03:15:26,361 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:26,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7337 synced till here 7326
2014-07-02 03:15:26,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296123162 with entries=97, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296126362
2014-07-02 03:15:26,709 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/7f8a888edc09428f977b8c7cc381e7d6 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/7f8a888edc09428f977b8c7cc381e7d6
2014-07-02 03:15:28,205 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1243ms
GC pool 'ParNew' had collection(s): count=1 time=1489ms
2014-07-02 03:15:28,237 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:15:28,243 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/d913e9c7a7944977839ab5d5dc202f44, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/d913e9c7a7944977839ab5d5dc202f44
2014-07-02 03:15:28,246 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/ff57316156304b7883ea8e772b68474e, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/ff57316156304b7883ea8e772b68474e
2014-07-02 03:15:28,248 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/771736fabb074036b011723bfdaca945, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/771736fabb074036b011723bfdaca945
2014-07-02 03:15:28,249 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 7f8a888edc09428f977b8c7cc381e7d6(size=166.0m), total size for store is 527.1m. This selection was in queue for 0sec, and took 7sec to execute.
2014-07-02 03:15:28,249 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=202.6m, priority=16, time=14335118582725; duration=7sec
2014-07-02 03:15:28,249 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:15:28,555 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:15:28,555 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 257.6m
2014-07-02 03:15:28,845 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:28,933 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:29,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7449 synced till here 7448
2014-07-02 03:15:29,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296126362 with entries=112, filesize=78.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296128846
2014-07-02 03:15:31,639 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:31,866 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296128846 with entries=95, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296131653
2014-07-02 03:15:32,734 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1864, memsize=182.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/b6651e4aaa524a19ba9505f1e66db1f9
2014-07-02 03:15:32,766 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/b6651e4aaa524a19ba9505f1e66db1f9 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b6651e4aaa524a19ba9505f1e66db1f9
2014-07-02 03:15:32,790 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b6651e4aaa524a19ba9505f1e66db1f9, entries=665530, sequenceid=1864, filesize=99.2m
2014-07-02 03:15:32,791 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~263.7m/276537280, currentsize=60.5m/63421440 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 4236ms, sequenceid=1864, compaction requested=true
2014-07-02 03:15:32,791 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:15:32,791 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:15:32,792 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 652804602 starting at candidate #0 after considering 3 permutations with 2 in ratio
2014-07-02 03:15:32,792 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating major compaction
2014-07-02 03:15:32,792 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:15:32,792 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=622.6m
2014-07-02 03:15:32,792 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/79671203b80a467f84536f774a7ac2fe, keycount=194938, bloomtype=ROW, size=288.7m, encoding=NONE, seqNum=987, earliestPutTs=1404295763928
2014-07-02 03:15:32,792 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/0c731178c98544578fcbd9150eac9026, keycount=103811, bloomtype=ROW, size=153.7m, encoding=NONE, seqNum=1503, earliestPutTs=1404295870772
2014-07-02 03:15:32,792 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/6e5d81707fd34fafae8de9aa55582fc9, keycount=54279, bloomtype=ROW, size=80.9m, encoding=NONE, seqNum=1692, earliestPutTs=1404296016444
2014-07-02 03:15:32,792 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b6651e4aaa524a19ba9505f1e66db1f9, keycount=66553, bloomtype=ROW, size=99.2m, encoding=NONE, seqNum=1864, earliestPutTs=1404296107386
2014-07-02 03:15:32,844 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:34,252 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1144ms
GC pool 'ParNew' had collection(s): count=1 time=1261ms
2014-07-02 03:15:36,346 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:36,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7642 synced till here 7639
2014-07-02 03:15:36,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296131653 with entries=98, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296136346
2014-07-02 03:15:36,569 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296046171
2014-07-02 03:15:36,653 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.6m
2014-07-02 03:15:36,653 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:15:37,952 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1198ms
GC pool 'ParNew' had collection(s): count=1 time=1241ms
2014-07-02 03:15:38,007 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:15:38,011 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.5m
2014-07-02 03:15:38,170 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:38,281 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:15:44,108 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3586ms
GC pool 'ParNew' had collection(s): count=1 time=4074ms
2014-07-02 03:15:44,282 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:44,537 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7754 synced till here 7747
2014-07-02 03:15:44,603 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296136346 with entries=112, filesize=79.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296144283
2014-07-02 03:15:48,616 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3507ms
GC pool 'ParNew' had collection(s): count=1 time=3631ms
2014-07-02 03:15:53,735 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4112ms
GC pool 'ParNew' had collection(s): count=1 time=4253ms
2014-07-02 03:15:54,051 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:15:54,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7890 synced till here 7854
2014-07-02 03:15:54,441 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1929, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/8e78b75ed16e45c79132b61247d27907
2014-07-02 03:15:54,452 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/8e78b75ed16e45c79132b61247d27907 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/8e78b75ed16e45c79132b61247d27907
2014-07-02 03:15:54,477 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/8e78b75ed16e45c79132b61247d27907, entries=934490, sequenceid=1929, filesize=139.3m
2014-07-02 03:15:54,477 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.2m/270742160, currentsize=79.8m/83673200 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 17824ms, sequenceid=1929, compaction requested=true
2014-07-02 03:15:54,477 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:15:54,490 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3658 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:54,491 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:54,491 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3664 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:54,492 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:54,492 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3662 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:54,492 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:54,600 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3659 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:54,600 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:54,606 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3660 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:54,606 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:58,401 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3650ms
GC pool 'ParNew' had collection(s): count=1 time=3790ms
2014-07-02 03:15:58,422 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13618,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296144804,"queuetimems":1,"class":"HRegionServer","responsesize":12752,"method":"Multi"}
2014-07-02 03:15:58,423 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3656 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:58,423 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:58,430 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13660,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296144769,"queuetimems":0,"class":"HRegionServer","responsesize":13163,"method":"Multi"}
2014-07-02 03:15:58,430 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3657 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:58,430 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:58,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296144283 with entries=136, filesize=103.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296154052
2014-07-02 03:15:58,606 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1931, memsize=260.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/e6e99ff60d69485584137afa484da382
2014-07-02 03:15:58,618 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/e6e99ff60d69485584137afa484da382 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e6e99ff60d69485584137afa484da382
2014-07-02 03:15:58,627 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e6e99ff60d69485584137afa484da382, entries=948740, sequenceid=1931, filesize=141.4m
2014-07-02 03:15:58,628 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.2m/274901920, currentsize=119.3m/125056880 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 20617ms, sequenceid=1931, compaction requested=true
2014-07-02 03:15:58,628 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:15:58,728 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13889,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296144839,"queuetimems":2,"class":"HRegionServer","responsesize":12899,"method":"Multi"}
2014-07-02 03:15:58,729 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13839,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296144889,"queuetimems":1,"class":"HRegionServer","responsesize":12936,"method":"Multi"}
2014-07-02 03:15:58,729 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3653 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:58,729 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:58,729 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3650 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:58,729 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:58,731 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13799,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296144932,"queuetimems":0,"class":"HRegionServer","responsesize":13164,"method":"Multi"}
2014-07-02 03:15:58,731 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3700 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:58,731 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:58,864 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10245,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148618,"queuetimems":3636,"class":"HRegionServer","responsesize":12830,"method":"Multi"}
2014-07-02 03:15:58,864 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3699 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:58,864 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:58,869 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10238,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148625,"queuetimems":0,"class":"HRegionServer","responsesize":12936,"method":"Multi"}
2014-07-02 03:15:58,870 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3706 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:58,870 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148688,"queuetimems":0,"class":"HRegionServer","responsesize":13072,"method":"Multi"}
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10418,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148634,"queuetimems":0,"class":"HRegionServer","responsesize":12749,"method":"Multi"}
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10343,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148709,"queuetimems":0,"class":"HRegionServer","responsesize":12970,"method":"Multi"}
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3688 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10224,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148829,"queuetimems":0,"class":"HRegionServer","responsesize":12862,"method":"Multi"}
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10377,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148675,"queuetimems":0,"class":"HRegionServer","responsesize":13316,"method":"Multi"}
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148740,"queuetimems":0,"class":"HRegionServer","responsesize":13550,"method":"Multi"}
2014-07-02 03:15:59,054 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3697 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,054 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,054 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10161,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148893,"queuetimems":0,"class":"HRegionServer","responsesize":12875,"method":"Multi"}
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10407,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148646,"queuetimems":0,"class":"HRegionServer","responsesize":12758,"method":"Multi"}
2014-07-02 03:15:59,053 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10301,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148752,"queuetimems":0,"class":"HRegionServer","responsesize":13071,"method":"Multi"}
2014-07-02 03:15:59,054 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10287,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148767,"queuetimems":0,"class":"HRegionServer","responsesize":13075,"method":"Multi"}
2014-07-02 03:15:59,054 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3754 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,066 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,066 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3687 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,066 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,066 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3689 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,066 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,069 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3744 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,069 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,081 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3749 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,081 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,085 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3753 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,085 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,085 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3690 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,085 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:15:59,089 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3741 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:15:59,089 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,258 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1856ms
GC pool 'ParNew' had collection(s): count=1 time=1938ms
2014-07-02 03:16:01,260 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:01,266 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12348,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148918,"queuetimems":1,"class":"HRegionServer","responsesize":13466,"method":"Multi"}
2014-07-02 03:16:01,267 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3740 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,267 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,270 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12486,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148783,"queuetimems":1,"class":"HRegionServer","responsesize":12892,"method":"Multi"}
2014-07-02 03:16:01,270 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12454,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148815,"queuetimems":0,"class":"HRegionServer","responsesize":12891,"method":"Multi"}
2014-07-02 03:16:01,270 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3748 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,270 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,270 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12309,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148957,"queuetimems":1,"class":"HRegionServer","responsesize":12767,"method":"Multi"}
2014-07-02 03:16:01,271 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3739 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,271 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,271 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12424,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148847,"queuetimems":1,"class":"HRegionServer","responsesize":13655,"method":"Multi"}
2014-07-02 03:16:01,272 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3742 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,272 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,281 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3745 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,282 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8025 synced till here 7984
2014-07-02 03:16:01,512 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12297,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149214,"queuetimems":0,"class":"HRegionServer","responsesize":13164,"method":"Multi"}
2014-07-02 03:16:01,512 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149198,"queuetimems":0,"class":"HRegionServer","responsesize":12869,"method":"Multi"}
2014-07-02 03:16:01,512 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12285,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149227,"queuetimems":0,"class":"HRegionServer","responsesize":12440,"method":"Multi"}
2014-07-02 03:16:01,512 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3733 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,512 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,512 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3734 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12206,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149306,"queuetimems":0,"class":"HRegionServer","responsesize":13037,"method":"Multi"}
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3732 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3725 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,512 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12540,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296148972,"queuetimems":0,"class":"HRegionServer","responsesize":12749,"method":"Multi"}
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3738 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,513 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12192,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149320,"queuetimems":0,"class":"HRegionServer","responsesize":13136,"method":"Multi"}
2014-07-02 03:16:01,518 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3722 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,518 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3936 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,518 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12260,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149258,"queuetimems":0,"class":"HRegionServer","responsesize":13620,"method":"Multi"}
2014-07-02 03:16:01,520 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3710 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,520 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: RpcServer.handler=0,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,520 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3730 service: ClientService methodName: Multi size: 2.4m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12106,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149414,"queuetimems":0,"class":"HRegionServer","responsesize":13181,"method":"Multi"}
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3715 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,520 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3935 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,520 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,518 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3898 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,522 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12139,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149382,"queuetimems":0,"class":"HRegionServer","responsesize":13175,"method":"Multi"}
2014-07-02 03:16:01,522 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3718 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,522 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,520 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12151,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149367,"queuetimems":0,"class":"HRegionServer","responsesize":13054,"method":"Multi"}
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12432,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149089,"queuetimems":0,"class":"HRegionServer","responsesize":13012,"method":"Multi"}
2014-07-02 03:16:01,526 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3720 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,526 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,526 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3736 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,526 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,521 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12230,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149291,"queuetimems":1,"class":"HRegionServer","responsesize":13073,"method":"Multi"}
2014-07-02 03:16:01,533 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296154052 with entries=135, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296161260
2014-07-02 03:16:01,529 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12460,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149069,"queuetimems":0,"class":"HRegionServer","responsesize":12830,"method":"Multi"}
2014-07-02 03:16:01,538 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12294,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149243,"queuetimems":1,"class":"HRegionServer","responsesize":13065,"method":"Multi"}
2014-07-02 03:16:01,538 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12065,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149472,"queuetimems":0,"class":"HRegionServer","responsesize":13278,"method":"Multi"}
2014-07-02 03:16:01,537 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12390,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149147,"queuetimems":1,"class":"HRegionServer","responsesize":13110,"method":"Multi"}
2014-07-02 03:16:01,537 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12201,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:34699","starttimems":1404296149336,"queuetimems":0,"class":"HRegionServer","responsesize":12814,"method":"Multi"}
2014-07-02 03:16:01,534 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3709 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3708 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3721 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: RpcServer.handler=7,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3735 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3711 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,546 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,547 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3731 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,547 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,554 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3737 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,554 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: RpcServer.handler=21,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,554 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3729 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34699: output error
2014-07-02 03:16:01,554 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,666 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3933 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,666 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,670 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3932 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,670 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,967 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3930 service: ClientService methodName: Multi size: 2.2m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,968 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,968 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3929 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,968 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:01,997 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3928 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:01,998 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: RpcServer.handler=31,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:03,879 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1619ms
GC pool 'ParNew' had collection(s): count=2 time=1849ms
2014-07-02 03:16:04,078 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3934 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:04,078 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:04,085 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3931 service: ClientService methodName: Multi size: 2.3m connection: 9.1.143.58:34828: output error
2014-07-02 03:16:04,085 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 03:16:04,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:04,418 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:16:04,419 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 258.4m
2014-07-02 03:16:04,494 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8147 synced till here 8130
2014-07-02 03:16:04,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296161260 with entries=122, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296164397
2014-07-02 03:16:06,728 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1347ms
GC pool 'ParNew' had collection(s): count=1 time=1828ms
2014-07-02 03:16:06,968 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:07,268 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:10,227 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2498ms
GC pool 'ParNew' had collection(s): count=1 time=2538ms
2014-07-02 03:16:10,294 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8310 synced till here 8296
2014-07-02 03:16:10,439 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296164397 with entries=163, filesize=108.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296167268
2014-07-02 03:16:10,705 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:16:10,717 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 274.5m
2014-07-02 03:16:11,176 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:12,278 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1050ms
GC pool 'ParNew' had collection(s): count=1 time=1098ms
2014-07-02 03:16:12,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:12,566 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:16:12,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8399 synced till here 8391
2014-07-02 03:16:12,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296167268 with entries=89, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296172561
2014-07-02 03:16:13,298 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2035, memsize=182.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/18bb4c30d3fb43efa8d6a99ff0438ad1
2014-07-02 03:16:13,313 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/18bb4c30d3fb43efa8d6a99ff0438ad1 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/18bb4c30d3fb43efa8d6a99ff0438ad1
2014-07-02 03:16:13,344 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/18bb4c30d3fb43efa8d6a99ff0438ad1, entries=663150, sequenceid=2035, filesize=98.9m
2014-07-02 03:16:13,369 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~262.9m/275671440, currentsize=130.9m/137268320 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 8950ms, sequenceid=2035, compaction requested=false
2014-07-02 03:16:13,370 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 327.1m
2014-07-02 03:16:14,364 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:14,421 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8522 synced till here 8510
2014-07-02 03:16:14,425 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:14,489 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296172561 with entries=123, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296174364
2014-07-02 03:16:16,465 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2132, memsize=88.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/92952200fc1b4d889c57048946d38713
2014-07-02 03:16:16,482 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/92952200fc1b4d889c57048946d38713 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/92952200fc1b4d889c57048946d38713
2014-07-02 03:16:16,505 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/92952200fc1b4d889c57048946d38713, entries=321130, sequenceid=2132, filesize=47.9m
2014-07-02 03:16:16,505 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~306.9m/321779520, currentsize=66.2m/69460240 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 5788ms, sequenceid=2132, compaction requested=true
2014-07-02 03:16:16,506 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-02 03:16:16,511 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:16,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8632 synced till here 8612
2014-07-02 03:16:16,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296174364 with entries=110, filesize=79.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296176511
2014-07-02 03:16:17,454 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2142, memsize=95.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/f86acd4576ce4483b2eed4432370bb11
2014-07-02 03:16:17,465 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/f86acd4576ce4483b2eed4432370bb11 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f86acd4576ce4483b2eed4432370bb11
2014-07-02 03:16:17,475 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f86acd4576ce4483b2eed4432370bb11, entries=346550, sequenceid=2142, filesize=51.7m
2014-07-02 03:16:17,476 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~327.1m/342961360, currentsize=56.1m/58784880 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 4106ms, sequenceid=2142, compaction requested=true
2014-07-02 03:16:17,476 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-02 03:16:18,806 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/8290089527fc4121939f545a27b60cae as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8290089527fc4121939f545a27b60cae
2014-07-02 03:16:18,821 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:16:18,829 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/79671203b80a467f84536f774a7ac2fe, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/79671203b80a467f84536f774a7ac2fe
2014-07-02 03:16:18,832 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/0c731178c98544578fcbd9150eac9026, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/0c731178c98544578fcbd9150eac9026
2014-07-02 03:16:18,835 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/6e5d81707fd34fafae8de9aa55582fc9, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/6e5d81707fd34fafae8de9aa55582fc9
2014-07-02 03:16:18,849 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b6651e4aaa524a19ba9505f1e66db1f9, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b6651e4aaa524a19ba9505f1e66db1f9
2014-07-02 03:16:18,849 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into 8290089527fc4121939f545a27b60cae(size=571.2m), total size for store is 670.1m. This selection was in queue for 0sec, and took 46sec to execute.
2014-07-02 03:16:18,849 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=4, fileSize=622.6m, priority=16, time=14347190619852; duration=46sec
2014-07-02 03:16:18,849 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-02 03:16:18,849 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:16:18,850 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 752683922 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-02 03:16:18,850 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating major compaction
2014-07-02 03:16:18,850 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:16:18,850 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=717.8m
2014-07-02 03:16:18,850 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2b7f272ec9974ed7979ee426d874eef3, keycount=244007, bloomtype=ROW, size=361.3m, encoding=NONE, seqNum=1249, earliestPutTs=1404295762713
2014-07-02 03:16:18,850 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/551c24ef3359488087627340cb248252, keycount=112889, bloomtype=ROW, size=167.2m, encoding=NONE, seqNum=1759, earliestPutTs=1404295961267
2014-07-02 03:16:18,850 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e6e99ff60d69485584137afa484da382, keycount=94874, bloomtype=ROW, size=141.4m, encoding=NONE, seqNum=1931, earliestPutTs=1404296111155
2014-07-02 03:16:18,851 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/92952200fc1b4d889c57048946d38713, keycount=32113, bloomtype=ROW, size=47.9m, encoding=NONE, seqNum=2132, earliestPutTs=1404296138065
2014-07-02 03:16:18,973 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:24,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:25,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8771 synced till here 8760
2014-07-02 03:16:25,328 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:16:25,328 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.9m
2014-07-02 03:16:25,353 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296176511 with entries=139, filesize=96.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296184069
2014-07-02 03:16:25,618 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:27,285 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:27,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8919 synced till here 8909
2014-07-02 03:16:27,858 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2207, memsize=77.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/8f148e5c6c014c12b38adb7f6c0cdb91
2014-07-02 03:16:27,870 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/8f148e5c6c014c12b38adb7f6c0cdb91 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8f148e5c6c014c12b38adb7f6c0cdb91
2014-07-02 03:16:27,902 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8f148e5c6c014c12b38adb7f6c0cdb91, entries=283550, sequenceid=2207, filesize=42.3m
2014-07-02 03:16:27,902 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~264.9m/277753600, currentsize=49.7m/52158160 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2574ms, sequenceid=2207, compaction requested=true
2014-07-02 03:16:27,903 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-02 03:16:27,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296184069 with entries=148, filesize=105.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296187285
2014-07-02 03:16:29,546 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1333ms
GC pool 'ParNew' had collection(s): count=1 time=1546ms
2014-07-02 03:16:30,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:30,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9025 synced till here 9005
2014-07-02 03:16:30,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296187285 with entries=106, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296190340
2014-07-02 03:16:31,693 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1145ms
GC pool 'ParNew' had collection(s): count=1 time=1175ms
2014-07-02 03:16:32,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:32,462 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9126 synced till here 9118
2014-07-02 03:16:32,563 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296190340 with entries=101, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296192437
2014-07-02 03:16:32,634 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:16:32,634 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., current region memstore size 257.0m
2014-07-02 03:16:32,778 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:16:32,779 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.1m
2014-07-02 03:16:33,566 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:33,606 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:16:33,663 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:35,309 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:35,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296192437 with entries=96, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296195310
2014-07-02 03:16:36,116 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2303, memsize=170.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/4ff2519b83f548b48fa438cd3527056f
2014-07-02 03:16:36,118 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2287, memsize=134.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/710ce948b31f40a7bb6797d4ed4a3b71
2014-07-02 03:16:36,168 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/4ff2519b83f548b48fa438cd3527056f as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/4ff2519b83f548b48fa438cd3527056f
2014-07-02 03:16:36,171 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/710ce948b31f40a7bb6797d4ed4a3b71 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/710ce948b31f40a7bb6797d4ed4a3b71
2014-07-02 03:16:36,192 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/4ff2519b83f548b48fa438cd3527056f, entries=620960, sequenceid=2303, filesize=92.6m
2014-07-02 03:16:36,192 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.3m/272915040, currentsize=36.4m/38116080 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 3413ms, sequenceid=2303, compaction requested=false
2014-07-02 03:16:36,193 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 288.0m
2014-07-02 03:16:36,195 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/710ce948b31f40a7bb6797d4ed4a3b71, entries=488150, sequenceid=2287, filesize=72.6m
2014-07-02 03:16:36,196 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.4m/269903680, currentsize=13.2m/13802880 for region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. in 3562ms, sequenceid=2287, compaction requested=false
2014-07-02 03:16:36,386 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:37,991 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:39,465 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2331, memsize=203.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/f0ff4e16bcd14c5db1e27bf38fb034d9
2014-07-02 03:16:39,552 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/f0ff4e16bcd14c5db1e27bf38fb034d9 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f0ff4e16bcd14c5db1e27bf38fb034d9
2014-07-02 03:16:39,588 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9346 synced till here 9345
2014-07-02 03:16:39,749 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f0ff4e16bcd14c5db1e27bf38fb034d9, entries=740490, sequenceid=2331, filesize=110.4m
2014-07-02 03:16:39,749 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~288.0m/302014720, currentsize=34.7m/36405520 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3556ms, sequenceid=2331, compaction requested=true
2014-07-02 03:16:39,750 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-02 03:16:39,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296195310 with entries=124, filesize=85.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296197991
2014-07-02 03:16:39,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296106445
2014-07-02 03:16:39,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296107513
2014-07-02 03:16:39,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296114575
2014-07-02 03:16:39,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296119199
2014-07-02 03:16:39,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296123162
2014-07-02 03:16:39,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296126362
2014-07-02 03:16:39,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296128846
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296131653
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296136346
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296144283
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296154052
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296161260
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296164397
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296167268
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296172561
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296174364
2014-07-02 03:16:39,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296176511
2014-07-02 03:16:41,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:41,282 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9434 synced till here 9433
2014-07-02 03:16:41,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296197991 with entries=88, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296201266
2014-07-02 03:16:41,373 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/edf25999e8f54f25b67fc25cff398f54 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/edf25999e8f54f25b67fc25cff398f54
2014-07-02 03:16:41,389 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:16:41,408 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2b7f272ec9974ed7979ee426d874eef3, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2b7f272ec9974ed7979ee426d874eef3
2014-07-02 03:16:41,421 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/551c24ef3359488087627340cb248252, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/551c24ef3359488087627340cb248252
2014-07-02 03:16:41,425 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e6e99ff60d69485584137afa484da382, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e6e99ff60d69485584137afa484da382
2014-07-02 03:16:41,428 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/92952200fc1b4d889c57048946d38713, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/92952200fc1b4d889c57048946d38713
2014-07-02 03:16:41,429 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into edf25999e8f54f25b67fc25cff398f54(size=665.3m), total size for store is 757.9m. This selection was in queue for 0sec, and took 22sec to execute.
2014-07-02 03:16:41,429 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=4, fileSize=717.8m, priority=16, time=14393248674430; duration=22sec
2014-07-02 03:16:41,430 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-02 03:16:41,430 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-02 03:16:41,431 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 868755618 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-02 03:16:41,431 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating major compaction
2014-07-02 03:16:41,431 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:16:41,431 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=828.5m
2014-07-02 03:16:41,431 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/720acbc35c1f4c148c42f244cf016fe5, keycount=243889, bloomtype=ROW, size=361.2m, encoding=NONE, seqNum=1249, earliestPutTs=1404295763006
2014-07-02 03:16:41,431 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/7f8a888edc09428f977b8c7cc381e7d6, keycount=112087, bloomtype=ROW, size=166.0m, encoding=NONE, seqNum=1759, earliestPutTs=1404295960255
2014-07-02 03:16:41,431 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/8e78b75ed16e45c79132b61247d27907, keycount=93449, bloomtype=ROW, size=139.3m, encoding=NONE, seqNum=1929, earliestPutTs=1404296110723
2014-07-02 03:16:41,432 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f86acd4576ce4483b2eed4432370bb11, keycount=34655, bloomtype=ROW, size=51.7m, encoding=NONE, seqNum=2142, earliestPutTs=1404296138011
2014-07-02 03:16:41,432 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f0ff4e16bcd14c5db1e27bf38fb034d9, keycount=74049, bloomtype=ROW, size=110.4m, encoding=NONE, seqNum=2331, earliestPutTs=1404296176174
2014-07-02 03:16:41,608 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:41,849 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:16:41,850 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.2m
2014-07-02 03:16:43,499 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:16:46,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:46,515 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9526 synced till here 9525
2014-07-02 03:16:46,532 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296201266 with entries=92, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296206474
2014-07-02 03:16:48,056 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2377, memsize=210.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/23acabec07ab430abfb0a596e380bcde
2014-07-02 03:16:48,073 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/23acabec07ab430abfb0a596e380bcde as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/23acabec07ab430abfb0a596e380bcde
2014-07-02 03:16:48,085 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/23acabec07ab430abfb0a596e380bcde, entries=765890, sequenceid=2377, filesize=114.2m
2014-07-02 03:16:48,085 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.9m/270396480, currentsize=55.3m/57993040 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 6235ms, sequenceid=2377, compaction requested=true
2014-07-02 03:16:48,086 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-02 03:16:48,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:49,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296206474 with entries=109, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296208730
2014-07-02 03:16:49,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296184069
2014-07-02 03:16:49,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296187285
2014-07-02 03:16:49,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296190340
2014-07-02 03:16:52,660 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:53,068 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296208730 with entries=108, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296212661
2014-07-02 03:16:54,744 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1048ms
GC pool 'ParNew' had collection(s): count=1 time=1129ms
2014-07-02 03:16:57,935 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1189ms
GC pool 'ParNew' had collection(s): count=1 time=1526ms
2014-07-02 03:16:58,009 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:16:58,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9835 synced till here 9834
2014-07-02 03:16:58,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296212661 with entries=92, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296218009
2014-07-02 03:16:58,486 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:16:58,487 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.3m
2014-07-02 03:16:58,697 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:17:00,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:17:01,024 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2479, memsize=259.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/3effaf6b68c74fb08b41b18a12c2f39a
2014-07-02 03:17:01,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296218009 with entries=94, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296220692
2014-07-02 03:17:01,095 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/3effaf6b68c74fb08b41b18a12c2f39a as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/3effaf6b68c74fb08b41b18a12c2f39a
2014-07-02 03:17:01,105 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/3effaf6b68c74fb08b41b18a12c2f39a, entries=945360, sequenceid=2479, filesize=140.9m
2014-07-02 03:17:01,111 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.6m/272255280, currentsize=30.2m/31664640 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 2624ms, sequenceid=2479, compaction requested=true
2014-07-02 03:17:01,111 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-02 03:17:01,399 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:17:01,400 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.5m
2014-07-02 03:17:01,570 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:17:04,350 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2504, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/66bfe56671ae4173994c836546fa5d5c
2014-07-02 03:17:04,365 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/66bfe56671ae4173994c836546fa5d5c as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/66bfe56671ae4173994c836546fa5d5c
2014-07-02 03:17:04,771 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/66bfe56671ae4173994c836546fa5d5c, entries=933970, sequenceid=2504, filesize=139.2m
2014-07-02 03:17:04,771 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.5m/268978800, currentsize=26.2m/27495200 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3371ms, sequenceid=2504, compaction requested=false
2014-07-02 03:17:04,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:17:04,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296220692 with entries=94, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296224819
2014-07-02 03:17:10,667 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/555f8b1ce42e4a73810a038c22435a9c as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/555f8b1ce42e4a73810a038c22435a9c
2014-07-02 03:17:10,687 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:17:10,696 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/720acbc35c1f4c148c42f244cf016fe5, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/720acbc35c1f4c148c42f244cf016fe5
2014-07-02 03:17:10,698 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/7f8a888edc09428f977b8c7cc381e7d6, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/7f8a888edc09428f977b8c7cc381e7d6
2014-07-02 03:17:10,705 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/8e78b75ed16e45c79132b61247d27907, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/8e78b75ed16e45c79132b61247d27907
2014-07-02 03:17:10,709 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f86acd4576ce4483b2eed4432370bb11, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f86acd4576ce4483b2eed4432370bb11
2014-07-02 03:17:10,711 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f0ff4e16bcd14c5db1e27bf38fb034d9, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f0ff4e16bcd14c5db1e27bf38fb034d9
2014-07-02 03:17:10,711 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 555f8b1ce42e4a73810a038c22435a9c(size=734.4m), total size for store is 873.6m. This selection was in queue for 0sec, and took 29sec to execute.
2014-07-02 03:17:10,712 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=5, fileSize=828.5m, priority=15, time=14415829599263; duration=29sec
2014-07-02 03:17:10,712 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-02 03:17:10,712 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:17:10,712 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 267752994 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:17:10,712 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating minor compaction
2014-07-02 03:17:10,712 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:17:10,713 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=255.3m
2014-07-02 03:17:10,713 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/18bb4c30d3fb43efa8d6a99ff0438ad1, keycount=66315, bloomtype=ROW, size=98.9m, encoding=NONE, seqNum=2035
2014-07-02 03:17:10,713 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8f148e5c6c014c12b38adb7f6c0cdb91, keycount=28355, bloomtype=ROW, size=42.3m, encoding=NONE, seqNum=2207
2014-07-02 03:17:10,713 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/23acabec07ab430abfb0a596e380bcde, keycount=76589, bloomtype=ROW, size=114.2m, encoding=NONE, seqNum=2377
2014-07-02 03:17:10,741 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:17:16,947 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/b09e699b0c9c47d7a2d09d1434687fad as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b09e699b0c9c47d7a2d09d1434687fad
2014-07-02 03:17:16,961 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:17:16,979 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/18bb4c30d3fb43efa8d6a99ff0438ad1, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/18bb4c30d3fb43efa8d6a99ff0438ad1
2014-07-02 03:17:16,982 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8f148e5c6c014c12b38adb7f6c0cdb91, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8f148e5c6c014c12b38adb7f6c0cdb91
2014-07-02 03:17:16,984 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/23acabec07ab430abfb0a596e380bcde, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/23acabec07ab430abfb0a596e380bcde
2014-07-02 03:17:16,984 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into b09e699b0c9c47d7a2d09d1434687fad(size=203.9m), total size for store is 775.2m. This selection was in queue for 0sec, and took 6sec to execute.
2014-07-02 03:17:16,985 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=3, fileSize=255.3m, priority=16, time=14445111151949; duration=6sec
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. because compaction request was cancelled
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:17:16,985 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. because compaction request was cancelled
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. because compaction request was cancelled
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. because compaction request was cancelled
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:17:16,986 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. because compaction request was cancelled
2014-07-02 03:18:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=35 MB, free=3.92 GB, max=3.96 GB, blocks=456, accesses=1864959, hits=1777118, hitRatio=95.28%, , cachingAccesses=1777649, cachingHits=1777109, cachingHitsRatio=99.96%, evictions=0, evicted=16, evictedPerRun=Infinity
2014-07-02 03:22:22,996 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1882ms
GC pool 'ParNew' had collection(s): count=1 time=1885ms
2014-07-02 03:22:45,065 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1072ms
GC pool 'ParNew' had collection(s): count=1 time=1220ms
2014-07-02 03:23:10,870 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9587ms
No GCs detected
2014-07-02 03:23:16,568 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.29 GB, free=2.67 GB, max=3.96 GB, blocks=20798, accesses=10853926, hits=10745635, hitRatio=99.00%, , cachingAccesses=10766617, cachingHits=10745626, cachingHitsRatio=99.80%, evictions=0, evicted=16, evictedPerRun=Infinity
2014-07-02 03:23:25,062 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2268ms
GC pool 'ParNew' had collection(s): count=1 time=2679ms
2014-07-02 03:23:25,868 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:23:25,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296224819 with entries=98, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296605883
2014-07-02 03:23:27,411 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:23:27,441 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.7m
2014-07-02 03:23:27,633 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:23:44,328 WARN  [regionserver60020] util.Sleeper: We slept 13245ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 03:23:44,328 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12232ms
GC pool 'ParNew' had collection(s): count=1 time=12326ms
2014-07-02 03:23:44,346 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12366,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:36117","starttimems":1404296611973,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-02 03:23:44,356 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12383,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:36117","starttimems":1404296611973,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-02 03:23:44,388 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12423,"call":"Get(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$GetRequest)","client":"9.1.143.58:36117","starttimems":1404296611965,"queuetimems":0,"class":"HRegionServer","responsesize":1553,"method":"Get"}
2014-07-02 03:23:47,202 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2553, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/80a1f60bcc344d2c87a6adeaedf3179d
2014-07-02 03:23:47,339 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/80a1f60bcc344d2c87a6adeaedf3179d as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/80a1f60bcc344d2c87a6adeaedf3179d
2014-07-02 03:23:47,405 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/80a1f60bcc344d2c87a6adeaedf3179d, entries=934650, sequenceid=2553, filesize=139.3m
2014-07-02 03:23:47,454 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269173600, currentsize=7.6m/7980480 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 20013ms, sequenceid=2553, compaction requested=true
2014-07-02 03:23:47,465 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:23:47,465 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:23:47,473 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:23:47,473 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:23:47,473 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. because compaction request was cancelled
2014-07-02 03:24:20,879 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5065ms
GC pool 'ParNew' had collection(s): count=1 time=4978ms
2014-07-02 03:25:03,198 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1444ms
GC pool 'ParNew' had collection(s): count=1 time=1793ms
2014-07-02 03:25:25,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:25:25,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10209 synced till here 10208
2014-07-02 03:25:25,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296605883 with entries=88, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296725127
2014-07-02 03:26:28,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:26:28,353 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296725127 with entries=87, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296788272
2014-07-02 03:27:29,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:27:29,577 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296788272 with entries=87, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296849517
2014-07-02 03:28:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=2.23 GB, free=1.73 GB, max=3.96 GB, blocks=36049, accesses=16003164, hits=15879594, hitRatio=99.22%, , cachingAccesses=15915868, cachingHits=15879599, cachingHitsRatio=99.77%, evictions=0, evicted=16, evictedPerRun=Infinity
2014-07-02 03:28:48,907 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:28:49,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296849517 with entries=93, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296928915
2014-07-02 03:29:44,930 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.7m
2014-07-02 03:29:44,931 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:29:46,016 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:29:47,896 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2664, memsize=250.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/2afc1df9a17547edae43b97b131197f1
2014-07-02 03:29:47,907 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/2afc1df9a17547edae43b97b131197f1 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2afc1df9a17547edae43b97b131197f1
2014-07-02 03:29:47,915 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2afc1df9a17547edae43b97b131197f1, entries=912010, sequenceid=2664, filesize=135.9m
2014-07-02 03:29:47,915 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.9m/272568480, currentsize=3.2m/3329040 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 2985ms, sequenceid=2664, compaction requested=true
2014-07-02 03:29:47,927 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:29:47,927 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:29:47,927 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 387394011 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:29:47,928 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating minor compaction
2014-07-02 03:29:47,928 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:29:47,928 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=369.4m
2014-07-02 03:29:47,928 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/4ff2519b83f548b48fa438cd3527056f, keycount=62096, bloomtype=ROW, size=92.6m, encoding=NONE, seqNum=2303
2014-07-02 03:29:47,928 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/3effaf6b68c74fb08b41b18a12c2f39a, keycount=94536, bloomtype=ROW, size=140.9m, encoding=NONE, seqNum=2479
2014-07-02 03:29:47,928 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2afc1df9a17547edae43b97b131197f1, keycount=91201, bloomtype=ROW, size=135.9m, encoding=NONE, seqNum=2664
2014-07-02 03:29:47,955 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:29:49,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:29:49,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10621 synced till here 10620
2014-07-02 03:29:49,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296928915 with entries=145, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296989096
2014-07-02 03:29:55,378 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1510ms
GC pool 'ParNew' had collection(s): count=1 time=1646ms
2014-07-02 03:29:58,170 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/9428bbbe62ab47f4acc23090166194f8 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9428bbbe62ab47f4acc23090166194f8
2014-07-02 03:29:58,185 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:29:58,259 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/4ff2519b83f548b48fa438cd3527056f, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/4ff2519b83f548b48fa438cd3527056f
2014-07-02 03:29:58,262 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/3effaf6b68c74fb08b41b18a12c2f39a, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/3effaf6b68c74fb08b41b18a12c2f39a
2014-07-02 03:29:58,264 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2afc1df9a17547edae43b97b131197f1, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/2afc1df9a17547edae43b97b131197f1
2014-07-02 03:29:58,264 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into 9428bbbe62ab47f4acc23090166194f8(size=356.2m), total size for store is 1021.5m. This selection was in queue for 0sec, and took 10sec to execute.
2014-07-02 03:29:58,265 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=3, fileSize=369.4m, priority=16, time=15202326506297; duration=10sec
2014-07-02 03:29:58,265 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:30:00,519 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1139ms
GC pool 'ParNew' had collection(s): count=1 time=1400ms
2014-07-02 03:30:03,019 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:30:03,020 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.9m
2014-07-02 03:30:03,266 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:30:03,770 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:30:04,116 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10713 synced till here 10712
2014-07-02 03:30:04,165 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296989096 with entries=92, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297003770
2014-07-02 03:30:06,053 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1533ms
GC pool 'ParNew' had collection(s): count=1 time=1754ms
2014-07-02 03:30:07,893 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2688, memsize=216.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/9120066a2b5d457f85d18cb607076c74
2014-07-02 03:30:07,903 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/9120066a2b5d457f85d18cb607076c74 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9120066a2b5d457f85d18cb607076c74
2014-07-02 03:30:07,940 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9120066a2b5d457f85d18cb607076c74, entries=788450, sequenceid=2688, filesize=117.5m
2014-07-02 03:30:07,941 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.4m/270982640, currentsize=20.3m/21242640 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 4920ms, sequenceid=2688, compaction requested=true
2014-07-02 03:30:07,962 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:30:07,963 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:30:07,963 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:30:07,963 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:30:07,963 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. because compaction request was cancelled
2014-07-02 03:30:15,878 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1821ms
GC pool 'ParNew' had collection(s): count=1 time=2169ms
2014-07-02 03:30:24,142 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2261ms
GC pool 'ParNew' had collection(s): count=1 time=2307ms
2014-07-02 03:30:24,207 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:30:24,264 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297003770 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297024207
2014-07-02 03:30:39,963 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1433ms
GC pool 'ParNew' had collection(s): count=1 time=1683ms
2014-07-02 03:30:40,754 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:30:40,760 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 257.4m
2014-07-02 03:30:40,990 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:30:43,348 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2733, memsize=165.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/32460587a57c40e68058f768dab5b5cd
2014-07-02 03:30:43,358 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/32460587a57c40e68058f768dab5b5cd as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/32460587a57c40e68058f768dab5b5cd
2014-07-02 03:30:43,381 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/32460587a57c40e68058f768dab5b5cd, entries=603500, sequenceid=2733, filesize=90.0m
2014-07-02 03:30:43,386 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.4m/269905360, currentsize=3.2m/3332080 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2625ms, sequenceid=2733, compaction requested=true
2014-07-02 03:30:43,386 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:30:43,387 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:30:43,387 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 454312567 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:30:43,387 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating minor compaction
2014-07-02 03:30:43,387 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:30:43,387 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=433.3m
2014-07-02 03:30:43,390 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b09e699b0c9c47d7a2d09d1434687fad, keycount=137703, bloomtype=ROW, size=203.9m, encoding=NONE, seqNum=2377
2014-07-02 03:30:43,390 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/80a1f60bcc344d2c87a6adeaedf3179d, keycount=93465, bloomtype=ROW, size=139.3m, encoding=NONE, seqNum=2553
2014-07-02 03:30:43,390 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/32460587a57c40e68058f768dab5b5cd, keycount=60350, bloomtype=ROW, size=90.0m, encoding=NONE, seqNum=2733
2014-07-02 03:30:43,410 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:30:44,297 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:30:44,334 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10888 synced till here 10887
2014-07-02 03:30:44,347 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297024207 with entries=88, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297044298
2014-07-02 03:30:46,945 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1954ms
GC pool 'ParNew' had collection(s): count=1 time=2180ms
2014-07-02 03:30:57,664 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/e7471681b80346799e61f52e81818b4b as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7471681b80346799e61f52e81818b4b
2014-07-02 03:30:57,675 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:30:57,705 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b09e699b0c9c47d7a2d09d1434687fad, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/b09e699b0c9c47d7a2d09d1434687fad
2014-07-02 03:30:57,710 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/80a1f60bcc344d2c87a6adeaedf3179d, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/80a1f60bcc344d2c87a6adeaedf3179d
2014-07-02 03:30:57,712 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/32460587a57c40e68058f768dab5b5cd, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/32460587a57c40e68058f768dab5b5cd
2014-07-02 03:30:57,713 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into e7471681b80346799e61f52e81818b4b(size=419.1m), total size for store is 990.4m. This selection was in queue for 0sec, and took 14sec to execute.
2014-07-02 03:30:57,713 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=3, fileSize=433.3m, priority=16, time=15257785983693; duration=14sec
2014-07-02 03:30:57,714 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:31:06,080 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2009ms
GC pool 'ParNew' had collection(s): count=1 time=2309ms
2014-07-02 03:31:12,922 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:31:12,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297044298 with entries=88, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297072922
2014-07-02 03:31:17,409 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1825ms
GC pool 'ParNew' had collection(s): count=1 time=1947ms
2014-07-02 03:31:35,560 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3134ms
GC pool 'ParNew' had collection(s): count=1 time=3432ms
2014-07-02 03:31:35,570 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:31:35,626 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297072922 with entries=86, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297095570
2014-07-02 03:31:53,608 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2513ms
GC pool 'ParNew' had collection(s): count=1 time=2722ms
2014-07-02 03:31:58,046 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:31:58,081 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297095570 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297118047
2014-07-02 03:32:05,843 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1727ms
GC pool 'ParNew' had collection(s): count=1 time=1796ms
2014-07-02 03:32:15,988 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:32:16,039 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297118047 with entries=87, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297135989
2014-07-02 03:32:17,540 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:32:17,540 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.9m
2014-07-02 03:32:17,861 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:32:20,402 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2053ms
GC pool 'ParNew' had collection(s): count=1 time=2091ms
2014-07-02 03:32:22,108 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2831, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/9efecb54d5374d94abec09d70dec64cd
2014-07-02 03:32:22,130 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/9efecb54d5374d94abec09d70dec64cd as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9efecb54d5374d94abec09d70dec64cd
2014-07-02 03:32:22,150 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9efecb54d5374d94abec09d70dec64cd, entries=935470, sequenceid=2831, filesize=139.4m
2014-07-02 03:32:22,158 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.9m/269406080, currentsize=7.7m/8106880 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 4618ms, sequenceid=2831, compaction requested=true
2014-07-02 03:32:22,177 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:32:22,177 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:32:22,178 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:32:22,178 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:32:22,178 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. because compaction request was cancelled
2014-07-02 03:32:27,819 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1414ms
GC pool 'ParNew' had collection(s): count=1 time=1603ms
2014-07-02 03:32:35,231 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:32:35,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297135989 with entries=89, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297155231
2014-07-02 03:32:35,651 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:32:35,651 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.0m
2014-07-02 03:32:35,814 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:32:38,497 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1168ms
GC pool 'ParNew' had collection(s): count=1 time=1573ms
2014-07-02 03:32:39,793 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2854, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/6b65d7126e034bc8a0ee630058f32c83
2014-07-02 03:32:39,804 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/6b65d7126e034bc8a0ee630058f32c83 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6b65d7126e034bc8a0ee630058f32c83
2014-07-02 03:32:39,812 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6b65d7126e034bc8a0ee630058f32c83, entries=932170, sequenceid=2854, filesize=138.9m
2014-07-02 03:32:39,812 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.0m/268460560, currentsize=9.3m/9705520 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 4161ms, sequenceid=2854, compaction requested=true
2014-07-02 03:32:39,817 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:32:39,822 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:32:39,823 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 414928503 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:32:39,823 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating minor compaction
2014-07-02 03:32:39,823 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:32:39,823 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=395.7m
2014-07-02 03:32:39,823 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/66bfe56671ae4173994c836546fa5d5c, keycount=93397, bloomtype=ROW, size=139.2m, encoding=NONE, seqNum=2504
2014-07-02 03:32:39,824 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9120066a2b5d457f85d18cb607076c74, keycount=78845, bloomtype=ROW, size=117.5m, encoding=NONE, seqNum=2688
2014-07-02 03:32:39,831 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6b65d7126e034bc8a0ee630058f32c83, keycount=93217, bloomtype=ROW, size=138.9m, encoding=NONE, seqNum=2854
2014-07-02 03:32:39,849 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:32:44,513 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1471ms
GC pool 'ParNew' had collection(s): count=1 time=1602ms
2014-07-02 03:32:50,574 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1058ms
GC pool 'ParNew' had collection(s): count=1 time=1149ms
2014-07-02 03:32:51,426 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/4fcab57ff09a4e1c86500d9fa568de8d as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/4fcab57ff09a4e1c86500d9fa568de8d
2014-07-02 03:32:51,445 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:32:51,469 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/66bfe56671ae4173994c836546fa5d5c, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/66bfe56671ae4173994c836546fa5d5c
2014-07-02 03:32:51,471 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9120066a2b5d457f85d18cb607076c74, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9120066a2b5d457f85d18cb607076c74
2014-07-02 03:32:51,472 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6b65d7126e034bc8a0ee630058f32c83, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6b65d7126e034bc8a0ee630058f32c83
2014-07-02 03:32:51,473 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 4fcab57ff09a4e1c86500d9fa568de8d(size=326.3m), total size for store is 1.0g. This selection was in queue for 0sec, and took 11sec to execute.
2014-07-02 03:32:51,473 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=395.7m, priority=16, time=15374221866442; duration=11sec
2014-07-02 03:32:51,473 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:33:01,005 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:33:01,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297155231 with entries=88, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297181006
2014-07-02 03:33:04,585 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:33:04,586 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., current region memstore size 256.2m
2014-07-02 03:33:05,675 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:33:10,110 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2860, memsize=206.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/d3766b841ddc4cfeb340b28495e48fa0
2014-07-02 03:33:10,125 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/d3766b841ddc4cfeb340b28495e48fa0 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/d3766b841ddc4cfeb340b28495e48fa0
2014-07-02 03:33:10,144 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/d3766b841ddc4cfeb340b28495e48fa0, entries=751350, sequenceid=2860, filesize=111.8m
2014-07-02 03:33:10,144 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268675440, currentsize=2.4m/2482320 for region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. in 5558ms, sequenceid=2860, compaction requested=true
2014-07-02 03:33:10,144 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:33:10,154 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:33:10,154 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 351116200 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:33:10,162 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5f58b71b81e6d85caf1b01aa1abb7cf9 - family: Initiating major compaction
2014-07-02 03:33:10,162 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:33:10,162 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp, totalSize=334.9m
2014-07-02 03:33:10,162 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/9b724325a4d140e88e150ee5928de751, keycount=101715, bloomtype=ROW, size=150.4m, encoding=NONE, seqNum=1733, earliestPutTs=1404295764376
2014-07-02 03:33:10,162 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/710ce948b31f40a7bb6797d4ed4a3b71, keycount=48815, bloomtype=ROW, size=72.6m, encoding=NONE, seqNum=2287, earliestPutTs=1404296108626
2014-07-02 03:33:10,162 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/d3766b841ddc4cfeb340b28495e48fa0, keycount=75135, bloomtype=ROW, size=111.8m, encoding=NONE, seqNum=2860, earliestPutTs=1404296193507
2014-07-02 03:33:10,194 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:33:13,409 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2399ms
GC pool 'ParNew' had collection(s): count=1 time=2389ms
2014-07-02 03:33:16,584 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.21 GB, free=763.92 MB, max=3.96 GB, blocks=51946, accesses=19791067, hits=19630025, hitRatio=99.18%, , cachingAccesses=19683689, cachingHits=19621628, cachingHitsRatio=99.68%, evictions=0, evicted=9823, evictedPerRun=Infinity
2014-07-02 03:33:23,729 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2867ms
GC pool 'ParNew' had collection(s): count=1 time=2885ms
2014-07-02 03:33:27,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:33:27,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297181006 with entries=86, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297207813
2014-07-02 03:33:27,909 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296192437
2014-07-02 03:33:27,909 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296195310
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296197991
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296201266
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296206474
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296208730
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296212661
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296218009
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296220692
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296224819
2014-07-02 03:33:27,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296605883
2014-07-02 03:33:27,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296725127
2014-07-02 03:33:27,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296788272
2014-07-02 03:33:27,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296849517
2014-07-02 03:33:27,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296928915
2014-07-02 03:33:27,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404296989096
2014-07-02 03:33:27,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297003770
2014-07-02 03:33:28,052 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/80f88a9b633948dead05d496fa643caf as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/80f88a9b633948dead05d496fa643caf
2014-07-02 03:33:28,082 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:33:28,144 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/9b724325a4d140e88e150ee5928de751, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/9b724325a4d140e88e150ee5928de751
2014-07-02 03:33:28,149 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/710ce948b31f40a7bb6797d4ed4a3b71, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/710ce948b31f40a7bb6797d4ed4a3b71
2014-07-02 03:33:28,152 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/d3766b841ddc4cfeb340b28495e48fa0, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/d3766b841ddc4cfeb340b28495e48fa0
2014-07-02 03:33:28,152 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. into 80f88a9b633948dead05d496fa643caf(size=268.1m), total size for store is 268.1m. This selection was in queue for 0sec, and took 17sec to execute.
2014-07-02 03:33:28,152 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., storeName=family, fileCount=3, fileSize=334.9m, priority=17, time=15404560518521; duration=17sec
2014-07-02 03:33:28,152 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:33:33,085 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:33:33,086 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 257.0m
2014-07-02 03:33:33,255 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:33:35,470 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2901, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/7180569a6a4442bdb9baab111281aa10
2014-07-02 03:33:35,490 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/7180569a6a4442bdb9baab111281aa10 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7180569a6a4442bdb9baab111281aa10
2014-07-02 03:33:35,507 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7180569a6a4442bdb9baab111281aa10, entries=935710, sequenceid=2901, filesize=139.5m
2014-07-02 03:33:35,508 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.0m/269477280, currentsize=0.0/0 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2422ms, sequenceid=2901, compaction requested=true
2014-07-02 03:33:35,508 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:33:35,508 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:33:35,508 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 1184716423 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:33:35,509 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating major compaction
2014-07-02 03:33:35,509 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:33:35,509 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=1.1g
2014-07-02 03:33:35,509 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8290089527fc4121939f545a27b60cae, keycount=385719, bloomtype=ROW, size=571.2m, encoding=NONE, seqNum=1864, earliestPutTs=1404295763928
2014-07-02 03:33:35,509 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7471681b80346799e61f52e81818b4b, keycount=282984, bloomtype=ROW, size=419.1m, encoding=NONE, seqNum=2733, earliestPutTs=1404296128734
2014-07-02 03:33:35,509 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7180569a6a4442bdb9baab111281aa10, keycount=93571, bloomtype=ROW, size=139.5m, encoding=NONE, seqNum=2901, earliestPutTs=1404297040910
2014-07-02 03:33:35,514 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:33:38,219 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1575ms
GC pool 'ParNew' had collection(s): count=1 time=1748ms
2014-07-02 03:33:47,384 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3163ms
GC pool 'ParNew' had collection(s): count=1 time=3246ms
2014-07-02 03:33:51,276 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:33:51,507 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297207813 with entries=93, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297231276
2014-07-02 03:33:51,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297024207
2014-07-02 03:33:51,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297044298
2014-07-02 03:33:51,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297072922
2014-07-02 03:33:51,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297095570
2014-07-02 03:33:51,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297118047
2014-07-02 03:33:54,220 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1333ms
GC pool 'ParNew' had collection(s): count=1 time=1666ms
2014-07-02 03:34:07,409 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3684ms
GC pool 'ParNew' had collection(s): count=1 time=3785ms
2014-07-02 03:34:17,234 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:34:17,276 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297231276 with entries=86, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297257235
2014-07-02 03:34:29,617 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/99cee5f5d1b248b8b0f997e68a020f84 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/99cee5f5d1b248b8b0f997e68a020f84
2014-07-02 03:34:29,632 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:34:29,728 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8290089527fc4121939f545a27b60cae, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8290089527fc4121939f545a27b60cae
2014-07-02 03:34:29,731 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7471681b80346799e61f52e81818b4b, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/e7471681b80346799e61f52e81818b4b
2014-07-02 03:34:29,737 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7180569a6a4442bdb9baab111281aa10, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7180569a6a4442bdb9baab111281aa10
2014-07-02 03:34:29,737 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into 99cee5f5d1b248b8b0f997e68a020f84(size=891.7m), total size for store is 891.7m. This selection was in queue for 0sec, and took 54sec to execute.
2014-07-02 03:34:29,738 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=3, fileSize=1.1g, priority=17, time=15429907476388; duration=54sec
2014-07-02 03:34:29,738 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:34:33,831 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1702ms
GC pool 'ParNew' had collection(s): count=1 time=1945ms
2014-07-02 03:34:38,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:34:38,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297257235 with entries=88, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297278614
2014-07-02 03:34:43,403 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2068ms
GC pool 'ParNew' had collection(s): count=1 time=2169ms
2014-07-02 03:34:57,754 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2845ms
GC pool 'ParNew' had collection(s): count=1 time=3009ms
2014-07-02 03:35:00,172 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1917ms
No GCs detected
2014-07-02 03:35:06,545 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:35:06,572 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297278614 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297306546
2014-07-02 03:35:12,301 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1089ms
No GCs detected
2014-07-02 03:35:17,575 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1772ms
GC pool 'ParNew' had collection(s): count=1 time=2109ms
2014-07-02 03:35:23,498 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:35:23,499 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.6m
2014-07-02 03:35:23,944 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:35:27,727 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2998, memsize=258.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/009417ddfd83480a947bd6903281ed9b
2014-07-02 03:35:27,739 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/009417ddfd83480a947bd6903281ed9b as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/009417ddfd83480a947bd6903281ed9b
2014-07-02 03:35:27,748 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/009417ddfd83480a947bd6903281ed9b, entries=940050, sequenceid=2998, filesize=140.1m
2014-07-02 03:35:27,748 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.2m/270727040, currentsize=3.1m/3254080 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 4249ms, sequenceid=2998, compaction requested=true
2014-07-02 03:35:27,748 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:35:27,748 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:35:27,749 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 1364293337 starting at candidate #0 after considering 3 permutations with 1 in ratio
2014-07-02 03:35:27,749 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating major compaction
2014-07-02 03:35:27,749 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:35:27,749 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=1.3g
2014-07-02 03:35:27,749 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/edf25999e8f54f25b67fc25cff398f54, keycount=449300, bloomtype=ROW, size=665.3m, encoding=NONE, seqNum=2132, earliestPutTs=1404295762713
2014-07-02 03:35:27,749 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9428bbbe62ab47f4acc23090166194f8, keycount=240529, bloomtype=ROW, size=356.2m, encoding=NONE, seqNum=2664, earliestPutTs=1404296174845
2014-07-02 03:35:27,750 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9efecb54d5374d94abec09d70dec64cd, keycount=93547, bloomtype=ROW, size=139.4m, encoding=NONE, seqNum=2831, earliestPutTs=1404296984958
2014-07-02 03:35:27,750 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/009417ddfd83480a947bd6903281ed9b, keycount=94005, bloomtype=ROW, size=140.1m, encoding=NONE, seqNum=2998, earliestPutTs=1404297137629
2014-07-02 03:35:27,762 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:35:47,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:35:47,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297306546 with entries=86, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297347318
2014-07-02 03:35:47,368 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297135989
2014-07-02 03:36:03,253 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:36:03,254 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.6m
2014-07-02 03:36:03,412 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:36:06,812 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3021, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/3f5788723b674a14b4bb6536a34354b9
2014-07-02 03:36:06,830 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/3f5788723b674a14b4bb6536a34354b9 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3f5788723b674a14b4bb6536a34354b9
2014-07-02 03:36:06,846 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3f5788723b674a14b4bb6536a34354b9, entries=934180, sequenceid=3021, filesize=139.2m
2014-07-02 03:36:06,847 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.6m/269037200, currentsize=1.5m/1621360 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3593ms, sequenceid=3021, compaction requested=true
2014-07-02 03:36:06,847 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:36:24,735 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:36:24,913 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297347318 with entries=92, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297384781
2014-07-02 03:36:24,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297155231
2014-07-02 03:36:30,108 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/ac7a3426c56b4a1d83fc7f132480e13b as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ac7a3426c56b4a1d83fc7f132480e13b
2014-07-02 03:36:30,123 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:36:30,183 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/edf25999e8f54f25b67fc25cff398f54, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/edf25999e8f54f25b67fc25cff398f54
2014-07-02 03:36:30,186 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9428bbbe62ab47f4acc23090166194f8, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9428bbbe62ab47f4acc23090166194f8
2014-07-02 03:36:30,188 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9efecb54d5374d94abec09d70dec64cd, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9efecb54d5374d94abec09d70dec64cd
2014-07-02 03:36:30,190 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/009417ddfd83480a947bd6903281ed9b, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/009417ddfd83480a947bd6903281ed9b
2014-07-02 03:36:30,195 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into ac7a3426c56b4a1d83fc7f132480e13b(size=892.3m), total size for store is 892.3m. This selection was in queue for 0sec, and took 1mins, 2sec to execute.
2014-07-02 03:36:30,195 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=4, fileSize=1.3g, priority=16, time=15542147708419; duration=1mins, 2sec
2014-07-02 03:36:30,195 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:36:30,195 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:36:30,195 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:36:30,195 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:36:30,195 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. because compaction request was cancelled
2014-07-02 03:36:52,588 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:36:52,644 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12121 synced till here 12120
2014-07-02 03:36:52,662 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297384781 with entries=89, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297412589
2014-07-02 03:36:57,896 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2017ms
GC pool 'ParNew' had collection(s): count=1 time=2263ms
2014-07-02 03:37:17,901 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2498ms
GC pool 'ParNew' had collection(s): count=1 time=2749ms
2014-07-02 03:37:21,695 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:37:21,696 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 257.2m
2014-07-02 03:37:21,921 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:37:24,158 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3068, memsize=257.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/7751c7a8e1fc4be8873d339b87c006cf
2014-07-02 03:37:24,170 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/7751c7a8e1fc4be8873d339b87c006cf as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7751c7a8e1fc4be8873d339b87c006cf
2014-07-02 03:37:24,181 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7751c7a8e1fc4be8873d339b87c006cf, entries=936540, sequenceid=3068, filesize=139.6m
2014-07-02 03:37:24,182 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.2m/269715280, currentsize=3.0m/3188160 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2487ms, sequenceid=3068, compaction requested=false
2014-07-02 03:37:24,667 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:37:24,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12209 synced till here 12208
2014-07-02 03:37:24,765 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297412589 with entries=88, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297444667
2014-07-02 03:37:27,410 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1501ms
GC pool 'ParNew' had collection(s): count=1 time=1727ms
2014-07-02 03:37:49,096 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1677ms
GC pool 'ParNew' had collection(s): count=1 time=1991ms
2014-07-02 03:37:56,629 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:37:56,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12297 synced till here 12296
2014-07-02 03:37:56,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297444667 with entries=88, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297476633
2014-07-02 03:38:16,572 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.1 GB, free=873.66 MB, max=3.96 GB, blocks=50206, accesses=21860381, hits=21655847, hitRatio=99.06%, , cachingAccesses=21709869, cachingHits=21607483, cachingHitsRatio=99.52%, evictions=0, evicted=51819, evictedPerRun=Infinity
2014-07-02 03:38:34,259 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2362ms
GC pool 'ParNew' had collection(s): count=1 time=2430ms
2014-07-02 03:38:34,675 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:38:34,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297476633 with entries=87, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297514675
2014-07-02 03:38:56,593 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1823ms
GC pool 'ParNew' had collection(s): count=1 time=1899ms
2014-07-02 03:39:02,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:39:02,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297514675 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297542778
2014-07-02 03:39:24,890 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1286ms
GC pool 'ParNew' had collection(s): count=1 time=1477ms
2014-07-02 03:39:41,834 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:39:41,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297542778 with entries=86, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297581834
2014-07-02 03:40:06,120 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:40:06,120 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.4m
2014-07-02 03:40:06,318 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:40:08,674 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3166, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/9a6adad168ac4be1ab4ce82119890f05
2014-07-02 03:40:08,710 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/9a6adad168ac4be1ab4ce82119890f05 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9a6adad168ac4be1ab4ce82119890f05
2014-07-02 03:40:08,749 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9a6adad168ac4be1ab4ce82119890f05, entries=937280, sequenceid=3166, filesize=139.7m
2014-07-02 03:40:08,749 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.4m/269929440, currentsize=3.0m/3167920 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 2629ms, sequenceid=3166, compaction requested=false
2014-07-02 03:40:14,508 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2592ms
GC pool 'ParNew' had collection(s): count=1 time=2794ms
2014-07-02 03:40:25,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:40:25,439 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12645 synced till here 12644
2014-07-02 03:40:25,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297581834 with entries=88, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297625253
2014-07-02 03:40:37,341 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:40:37,341 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.5m
2014-07-02 03:40:37,572 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:40:40,398 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1879ms
GC pool 'ParNew' had collection(s): count=1 time=1937ms
2014-07-02 03:40:43,242 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3188, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/f22e5664290c4c698138ce3a1a473472
2014-07-02 03:40:43,261 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/f22e5664290c4c698138ce3a1a473472 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f22e5664290c4c698138ce3a1a473472
2014-07-02 03:40:43,296 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f22e5664290c4c698138ce3a1a473472, entries=933820, sequenceid=3188, filesize=139.2m
2014-07-02 03:40:43,297 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268931840, currentsize=8.6m/8979520 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 5955ms, sequenceid=3188, compaction requested=true
2014-07-02 03:40:43,308 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:40:43,308 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:40:43,313 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 634109835 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:40:43,313 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating minor compaction
2014-07-02 03:40:43,314 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:40:43,314 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=604.7m
2014-07-02 03:40:43,319 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/4fcab57ff09a4e1c86500d9fa568de8d, keycount=220340, bloomtype=ROW, size=326.3m, encoding=NONE, seqNum=2854
2014-07-02 03:40:43,319 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3f5788723b674a14b4bb6536a34354b9, keycount=93418, bloomtype=ROW, size=139.2m, encoding=NONE, seqNum=3021
2014-07-02 03:40:43,319 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f22e5664290c4c698138ce3a1a473472, keycount=93382, bloomtype=ROW, size=139.2m, encoding=NONE, seqNum=3188
2014-07-02 03:40:43,329 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:40:59,523 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/2398de3c68c7409e8f53ab77d9f92dbb as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2398de3c68c7409e8f53ab77d9f92dbb
2014-07-02 03:40:59,568 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:40:59,609 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/4fcab57ff09a4e1c86500d9fa568de8d, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/4fcab57ff09a4e1c86500d9fa568de8d
2014-07-02 03:40:59,612 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3f5788723b674a14b4bb6536a34354b9, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/3f5788723b674a14b4bb6536a34354b9
2014-07-02 03:40:59,619 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f22e5664290c4c698138ce3a1a473472, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/f22e5664290c4c698138ce3a1a473472
2014-07-02 03:40:59,619 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 2398de3c68c7409e8f53ab77d9f92dbb(size=602.9m), total size for store is 1.3g. This selection was in queue for 0sec, and took 16sec to execute.
2014-07-02 03:40:59,619 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=604.7m, priority=16, time=15857712289124; duration=16sec
2014-07-02 03:40:59,620 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:41:18,134 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2221ms
GC pool 'ParNew' had collection(s): count=1 time=2354ms
2014-07-02 03:41:18,144 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:41:18,295 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12773 synced till here 12763
2014-07-02 03:41:18,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297625253 with entries=128, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297678152
2014-07-02 03:41:22,099 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:41:22,149 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297678152 with entries=91, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297682099
2014-07-02 03:41:24,801 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1647ms
GC pool 'ParNew' had collection(s): count=1 time=1974ms
2014-07-02 03:41:25,081 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:41:25,081 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.8m
2014-07-02 03:41:25,253 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:41:27,435 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3242, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/5f73bd6b3057424d85e202c0d0ac6cf2
2014-07-02 03:41:27,447 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/5f73bd6b3057424d85e202c0d0ac6cf2 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/5f73bd6b3057424d85e202c0d0ac6cf2
2014-07-02 03:41:27,471 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/5f73bd6b3057424d85e202c0d0ac6cf2, entries=935110, sequenceid=3242, filesize=139.4m
2014-07-02 03:41:27,471 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.8m/269304480, currentsize=3.0m/3144960 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2390ms, sequenceid=3242, compaction requested=true
2014-07-02 03:41:27,472 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:41:27,473 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:41:27,472 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:41:27,473 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:41:27,473 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. because compaction request was cancelled
2014-07-02 03:41:30,811 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1003ms
GC pool 'ParNew' had collection(s): count=1 time=1356ms
2014-07-02 03:41:31,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:41:31,635 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12956 synced till here 12953
2014-07-02 03:41:31,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297682099 with entries=92, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297691530
2014-07-02 03:41:39,262 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1947ms
GC pool 'ParNew' had collection(s): count=1 time=2279ms
2014-07-02 03:41:39,536 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:41:39,605 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297691530 with entries=89, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297699536
2014-07-02 03:41:50,842 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2570ms
GC pool 'ParNew' had collection(s): count=1 time=3016ms
2014-07-02 03:41:51,197 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:41:51,375 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297699536 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297711197
2014-07-02 03:42:02,902 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:42:02,984 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297711197 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297722904
2014-07-02 03:42:07,787 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:42:07,788 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.0m
2014-07-02 03:42:08,024 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:42:10,386 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3340, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/c0bf71f0865e4b0ea5860ae5ae047ae5
2014-07-02 03:42:10,398 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/c0bf71f0865e4b0ea5860ae5ae047ae5 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c0bf71f0865e4b0ea5860ae5ae047ae5
2014-07-02 03:42:10,408 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c0bf71f0865e4b0ea5860ae5ae047ae5, entries=935780, sequenceid=3340, filesize=139.5m
2014-07-02 03:42:10,409 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.0m/269495840, currentsize=6.1m/6381920 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 2621ms, sequenceid=3340, compaction requested=true
2014-07-02 03:42:10,409 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:42:10,409 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:42:10,409 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:42:10,409 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:42:10,409 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. because compaction request was cancelled
2014-07-02 03:42:13,380 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:42:13,453 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297722904 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297733381
2014-07-02 03:42:16,878 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:42:16,879 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.7m
2014-07-02 03:42:17,052 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:42:20,392 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3362, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/6efbde87ad48449c97b109fe7003ac1e
2014-07-02 03:42:20,436 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/6efbde87ad48449c97b109fe7003ac1e as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6efbde87ad48449c97b109fe7003ac1e
2014-07-02 03:42:20,463 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6efbde87ad48449c97b109fe7003ac1e, entries=934560, sequenceid=3362, filesize=139.3m
2014-07-02 03:42:20,463 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269148160, currentsize=3.1m/3291840 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3584ms, sequenceid=3362, compaction requested=true
2014-07-02 03:42:20,463 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:42:20,463 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:42:20,464 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 1548406503 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:42:20,464 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating major compaction
2014-07-02 03:42:20,464 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:42:20,464 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=1.4g
2014-07-02 03:42:20,464 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/555f8b1ce42e4a73810a038c22435a9c, keycount=495914, bloomtype=ROW, size=734.4m, encoding=NONE, seqNum=2331, earliestPutTs=1404295763006
2014-07-02 03:42:20,464 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2398de3c68c7409e8f53ab77d9f92dbb, keycount=407140, bloomtype=ROW, size=602.9m, encoding=NONE, seqNum=3188, earliestPutTs=1404296196257
2014-07-02 03:42:20,464 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6efbde87ad48449c97b109fe7003ac1e, keycount=93456, bloomtype=ROW, size=139.3m, encoding=NONE, seqNum=3362, earliestPutTs=1404297637977
2014-07-02 03:42:20,539 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:43:08,819 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:43:08,884 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297733381 with entries=88, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297788841
2014-07-02 03:43:16,584 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.45 GB, free=516.33 MB, max=3.96 GB, blocks=55854, accesses=22766538, hits=22541746, hitRatio=99.01%, , cachingAccesses=22590104, cachingHits=22474411, cachingHitsRatio=99.48%, evictions=0, evicted=59433, evictedPerRun=Infinity
2014-07-02 03:43:18,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:43:20,713 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297788841 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297798867
2014-07-02 03:43:27,917 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:43:27,918 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 257.1m
2014-07-02 03:43:28,095 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:43:29,945 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1284ms
GC pool 'ParNew' had collection(s): count=1 time=1351ms
2014-07-02 03:43:31,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:43:31,322 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297798867 with entries=87, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297811264
2014-07-02 03:43:32,301 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3410, memsize=258.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/a288c9d5ede64ef0afcc085c583b5fcc
2014-07-02 03:43:32,311 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/a288c9d5ede64ef0afcc085c583b5fcc as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/a288c9d5ede64ef0afcc085c583b5fcc
2014-07-02 03:43:32,323 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/a288c9d5ede64ef0afcc085c583b5fcc, entries=941910, sequenceid=3410, filesize=140.4m
2014-07-02 03:43:32,324 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.7m/271263040, currentsize=10.9m/11433200 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 4407ms, sequenceid=3410, compaction requested=true
2014-07-02 03:43:32,324 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:43:40,324 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:43:40,324 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., current region memstore size 256.5m
2014-07-02 03:43:40,683 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:43:40,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:43:40,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297811264 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297820751
2014-07-02 03:43:43,001 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1375ms
GC pool 'ParNew' had collection(s): count=1 time=1423ms
2014-07-02 03:43:44,862 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3418, memsize=248.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/f6da0269cb4946159ac1a1311488fe63
2014-07-02 03:43:44,873 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/f6da0269cb4946159ac1a1311488fe63 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/f6da0269cb4946159ac1a1311488fe63
2014-07-02 03:43:44,884 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/f6da0269cb4946159ac1a1311488fe63, entries=906390, sequenceid=3418, filesize=134.9m
2014-07-02 03:43:44,884 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268943520, currentsize=5.1m/5312960 for region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. in 4560ms, sequenceid=3418, compaction requested=false
2014-07-02 03:43:49,789 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1786ms
GC pool 'ParNew' had collection(s): count=1 time=1822ms
2014-07-02 03:43:51,682 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:43:51,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297820751 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297831683
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297181006
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297207813
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297231276
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297257235
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297278614
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297306546
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297347318
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297384781
2014-07-02 03:43:51,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297412589
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297444667
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297476633
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297514675
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297542778
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297581834
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297625253
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297678152
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297682099
2014-07-02 03:43:51,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297691530
2014-07-02 03:43:51,905 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297699536
2014-07-02 03:43:51,905 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297711197
2014-07-02 03:43:58,465 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1156ms
GC pool 'ParNew' had collection(s): count=1 time=1438ms
2014-07-02 03:43:59,999 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:44:00,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297831683 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297840000
2014-07-02 03:44:02,757 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/399a3415871948cb96365b8efaf45a2a as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/399a3415871948cb96365b8efaf45a2a
2014-07-02 03:44:02,954 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:44:03,061 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/555f8b1ce42e4a73810a038c22435a9c, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/555f8b1ce42e4a73810a038c22435a9c
2014-07-02 03:44:03,064 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2398de3c68c7409e8f53ab77d9f92dbb, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/2398de3c68c7409e8f53ab77d9f92dbb
2014-07-02 03:44:03,067 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6efbde87ad48449c97b109fe7003ac1e, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/6efbde87ad48449c97b109fe7003ac1e
2014-07-02 03:44:03,067 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 399a3415871948cb96365b8efaf45a2a(size=891.7m), total size for store is 891.7m. This selection was in queue for 0sec, and took 1mins, 42sec to execute.
2014-07-02 03:44:03,067 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=1.4g, priority=17, time=15954862652497; duration=1mins, 42sec
2014-07-02 03:44:03,067 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:44:03,067 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:44:03,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 439757762 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:44:03,068 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating minor compaction
2014-07-02 03:44:03,068 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:44:03,068 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=419.4m
2014-07-02 03:44:03,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7751c7a8e1fc4be8873d339b87c006cf, keycount=93654, bloomtype=ROW, size=139.6m, encoding=NONE, seqNum=3068
2014-07-02 03:44:03,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/5f73bd6b3057424d85e202c0d0ac6cf2, keycount=93511, bloomtype=ROW, size=139.4m, encoding=NONE, seqNum=3242
2014-07-02 03:44:03,068 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/a288c9d5ede64ef0afcc085c583b5fcc, keycount=94191, bloomtype=ROW, size=140.4m, encoding=NONE, seqNum=3410
2014-07-02 03:44:03,070 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:44:07,801 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:44:07,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297840000 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297847801
2014-07-02 03:44:10,152 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:44:10,153 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.0m
2014-07-02 03:44:10,338 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:44:11,895 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1062ms
GC pool 'ParNew' had collection(s): count=1 time=1041ms
2014-07-02 03:44:13,749 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3506, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/18227bfd2bbe4855b532ee33209bc08e
2014-07-02 03:44:13,763 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/18227bfd2bbe4855b532ee33209bc08e as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/18227bfd2bbe4855b532ee33209bc08e
2014-07-02 03:44:13,776 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/18227bfd2bbe4855b532ee33209bc08e, entries=935670, sequenceid=3506, filesize=139.5m
2014-07-02 03:44:13,776 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.0m/269466000, currentsize=9.5m/9938320 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 3623ms, sequenceid=3506, compaction requested=true
2014-07-02 03:44:13,776 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:44:18,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:44:18,449 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14011 synced till here 14010
2014-07-02 03:44:18,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297847801 with entries=87, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297858405
2014-07-02 03:44:18,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297722904
2014-07-02 03:44:18,691 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:44:18,691 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.1m
2014-07-02 03:44:18,875 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:44:21,085 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1011ms
GC pool 'ParNew' had collection(s): count=1 time=1115ms
2014-07-02 03:44:22,216 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3529, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/532e790648f24edc839b845c490a98ff
2014-07-02 03:44:22,226 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/532e790648f24edc839b845c490a98ff as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/532e790648f24edc839b845c490a98ff
2014-07-02 03:44:22,237 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/532e790648f24edc839b845c490a98ff, entries=932580, sequenceid=3529, filesize=139.0m
2014-07-02 03:44:22,237 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.1m/268576480, currentsize=6.3m/6600960 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3546ms, sequenceid=3529, compaction requested=false
2014-07-02 03:44:23,537 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/350d7c8503e14f9a8c3c79d80569c1d8 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/350d7c8503e14f9a8c3c79d80569c1d8
2014-07-02 03:44:23,559 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:44:23,591 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7751c7a8e1fc4be8873d339b87c006cf, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/7751c7a8e1fc4be8873d339b87c006cf
2014-07-02 03:44:23,595 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/5f73bd6b3057424d85e202c0d0ac6cf2, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/5f73bd6b3057424d85e202c0d0ac6cf2
2014-07-02 03:44:23,599 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/a288c9d5ede64ef0afcc085c583b5fcc, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/a288c9d5ede64ef0afcc085c583b5fcc
2014-07-02 03:44:23,599 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into 350d7c8503e14f9a8c3c79d80569c1d8(size=416.7m), total size for store is 1.3g. This selection was in queue for 0sec, and took 20sec to execute.
2014-07-02 03:44:23,599 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=3, fileSize=419.4m, priority=16, time=16057466680755; duration=20sec
2014-07-02 03:44:23,599 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:44:23,599 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:44:23,599 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 439002780 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:44:23,600 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating minor compaction
2014-07-02 03:44:23,600 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:44:23,600 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=418.7m
2014-07-02 03:44:23,600 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9a6adad168ac4be1ab4ce82119890f05, keycount=93728, bloomtype=ROW, size=139.7m, encoding=NONE, seqNum=3166
2014-07-02 03:44:23,600 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c0bf71f0865e4b0ea5860ae5ae047ae5, keycount=93578, bloomtype=ROW, size=139.5m, encoding=NONE, seqNum=3340
2014-07-02 03:44:23,600 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/18227bfd2bbe4855b532ee33209bc08e, keycount=93567, bloomtype=ROW, size=139.5m, encoding=NONE, seqNum=3506
2014-07-02 03:44:23,621 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:44:27,454 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1367ms
GC pool 'ParNew' had collection(s): count=1 time=1656ms
2014-07-02 03:44:29,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:44:29,985 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297858405 with entries=88, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297869923
2014-07-02 03:44:29,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297733381
2014-07-02 03:44:29,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297788841
2014-07-02 03:44:37,954 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1801ms
GC pool 'ParNew' had collection(s): count=1 time=1696ms
2014-07-02 03:44:39,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:44:39,798 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297869923 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297879717
2014-07-02 03:44:40,608 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/b55ef8808be14e77a194ef631a7e2e45 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/b55ef8808be14e77a194ef631a7e2e45
2014-07-02 03:44:40,638 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:44:40,661 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9a6adad168ac4be1ab4ce82119890f05, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/9a6adad168ac4be1ab4ce82119890f05
2014-07-02 03:44:40,665 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c0bf71f0865e4b0ea5860ae5ae047ae5, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/c0bf71f0865e4b0ea5860ae5ae047ae5
2014-07-02 03:44:40,667 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/18227bfd2bbe4855b532ee33209bc08e, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/18227bfd2bbe4855b532ee33209bc08e
2014-07-02 03:44:40,667 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into b55ef8808be14e77a194ef631a7e2e45(size=416.0m), total size for store is 1.3g. This selection was in queue for 0sec, and took 17sec to execute.
2014-07-02 03:44:40,667 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=3, fileSize=418.7m, priority=16, time=16077998574453; duration=17sec
2014-07-02 03:44:40,668 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:44:43,772 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:44:43,772 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.7m
2014-07-02 03:44:43,926 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:44:46,579 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3577, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/8c6c2e202f4a4f7f8a372286a484640c
2014-07-02 03:44:46,671 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/8c6c2e202f4a4f7f8a372286a484640c as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8c6c2e202f4a4f7f8a372286a484640c
2014-07-02 03:44:46,689 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8c6c2e202f4a4f7f8a372286a484640c, entries=934640, sequenceid=3577, filesize=139.3m
2014-07-02 03:44:46,725 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269168400, currentsize=9.3m/9803280 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2952ms, sequenceid=3577, compaction requested=true
2014-07-02 03:44:46,727 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:44:46,728 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:44:46,728 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:44:46,728 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:44:46,728 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. because compaction request was cancelled
2014-07-02 03:44:49,923 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1205ms
GC pool 'ParNew' had collection(s): count=1 time=1333ms
2014-07-02 03:44:50,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:44:50,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297879717 with entries=88, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297890437
2014-07-02 03:44:50,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297798867
2014-07-02 03:44:50,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297811264
2014-07-02 03:44:59,448 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1521ms
GC pool 'ParNew' had collection(s): count=1 time=1621ms
2014-07-02 03:45:00,499 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:45:00,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14362 synced till here 14361
2014-07-02 03:45:00,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297890437 with entries=88, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297900514
2014-07-02 03:45:09,308 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2356ms
GC pool 'ParNew' had collection(s): count=1 time=2522ms
2014-07-02 03:45:10,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:45:10,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14453 synced till here 14452
2014-07-02 03:45:10,420 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297900514 with entries=91, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297910235
2014-07-02 03:45:19,825 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:45:19,879 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297910235 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297919826
2014-07-02 03:45:25,653 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:45:25,654 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.5m
2014-07-02 03:45:25,880 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:45:28,474 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3674, memsize=257.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/039a3f11df924cb1b91975a524eab4a4
2014-07-02 03:45:28,485 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/039a3f11df924cb1b91975a524eab4a4 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/039a3f11df924cb1b91975a524eab4a4
2014-07-02 03:45:28,497 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/039a3f11df924cb1b91975a524eab4a4, entries=937560, sequenceid=3674, filesize=139.8m
2014-07-02 03:45:28,497 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.5m/270009360, currentsize=6.1m/6448080 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 2844ms, sequenceid=3674, compaction requested=true
2014-07-02 03:45:28,498 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:45:28,498 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:45:28,498 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:45:28,498 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:45:28,498 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. because compaction request was cancelled
2014-07-02 03:45:28,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:45:28,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14632 synced till here 14631
2014-07-02 03:45:29,005 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297919826 with entries=92, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297928847
2014-07-02 03:45:34,559 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:45:34,559 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.9m
2014-07-02 03:45:34,752 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:45:37,423 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3695, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/db2488d50f2b4156b25f522d9d682533
2014-07-02 03:45:37,436 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/db2488d50f2b4156b25f522d9d682533 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/db2488d50f2b4156b25f522d9d682533
2014-07-02 03:45:37,447 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/db2488d50f2b4156b25f522d9d682533, entries=935440, sequenceid=3695, filesize=139.4m
2014-07-02 03:45:37,447 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.9m/269400080, currentsize=10.8m/11306720 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 2888ms, sequenceid=3695, compaction requested=true
2014-07-02 03:45:37,448 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:45:37,448 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:45:37,448 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:45:37,448 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:45:37,448 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. because compaction request was cancelled
2014-07-02 03:45:41,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:45:41,054 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297928847 with entries=88, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297941030
2014-07-02 03:45:49,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:45:49,644 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14809 synced till here 14808
2014-07-02 03:45:49,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297941030 with entries=89, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297949074
2014-07-02 03:45:56,129 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:45:56,129 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.9m
2014-07-02 03:45:56,333 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:45:58,584 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:45:58,723 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297949074 with entries=88, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297958622
2014-07-02 03:45:59,662 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3744, memsize=258.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/fa2a07d7799144b883efa1abc780a051
2014-07-02 03:45:59,774 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/fa2a07d7799144b883efa1abc780a051 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/fa2a07d7799144b883efa1abc780a051
2014-07-02 03:45:59,784 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/fa2a07d7799144b883efa1abc780a051, entries=941070, sequenceid=3744, filesize=140.3m
2014-07-02 03:45:59,968 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.5m/271019360, currentsize=9.4m/9872400 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 3753ms, sequenceid=3744, compaction requested=true
2014-07-02 03:45:59,979 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:45:59,979 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:45:59,980 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 3 permutations with 0 in ratio
2014-07-02 03:45:59,980 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:45:59,980 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. because compaction request was cancelled
2014-07-02 03:46:05,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:46:05,998 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14985 synced till here 14984
2014-07-02 03:46:06,022 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297958622 with entries=88, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297965964
2014-07-02 03:46:13,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:46:13,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297965964 with entries=88, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297973452
2014-07-02 03:46:19,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:46:19,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297973452 with entries=87, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297979913
2014-07-02 03:46:28,815 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:46:29,187 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297979913 with entries=87, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297988816
2014-07-02 03:46:31,276 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:46:31,276 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 256.7m
2014-07-02 03:46:31,439 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:46:34,541 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3840, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/e5f326053050419c88667e4a267e3315
2014-07-02 03:46:34,654 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/e5f326053050419c88667e4a267e3315 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e5f326053050419c88667e4a267e3315
2014-07-02 03:46:34,673 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e5f326053050419c88667e4a267e3315, entries=934560, sequenceid=3840, filesize=139.3m
2014-07-02 03:46:34,776 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269147120, currentsize=13.7m/14382480 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 3467ms, sequenceid=3840, compaction requested=true
2014-07-02 03:46:34,776 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:46:34,776 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:46:34,776 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 3 permutations with 0 in ratio
2014-07-02 03:46:34,776 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:46:34,777 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. because compaction request was cancelled
2014-07-02 03:46:37,629 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:46:37,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297988816 with entries=88, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297997629
2014-07-02 03:46:38,207 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:46:38,208 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 257.0m
2014-07-02 03:46:38,378 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:46:41,482 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3862, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/9a1107d8e8d54ea4904656ee47ac823d
2014-07-02 03:46:41,507 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/9a1107d8e8d54ea4904656ee47ac823d as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9a1107d8e8d54ea4904656ee47ac823d
2014-07-02 03:46:41,537 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9a1107d8e8d54ea4904656ee47ac823d, entries=935890, sequenceid=3862, filesize=139.5m
2014-07-02 03:46:41,615 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.0m/269526720, currentsize=14.1m/14747920 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 3408ms, sequenceid=3862, compaction requested=true
2014-07-02 03:46:41,626 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:46:41,626 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 03:46:41,626 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 438252497 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-02 03:46:41,626 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 4fd5002bd7e150c46650daf5ebb5e2b8 - family: Initiating minor compaction
2014-07-02 03:46:41,627 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:46:41,627 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp, totalSize=418.0m
2014-07-02 03:46:41,628 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/532e790648f24edc839b845c490a98ff, keycount=93258, bloomtype=ROW, size=139.0m, encoding=NONE, seqNum=3529
2014-07-02 03:46:41,628 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/db2488d50f2b4156b25f522d9d682533, keycount=93544, bloomtype=ROW, size=139.4m, encoding=NONE, seqNum=3695
2014-07-02 03:46:41,628 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9a1107d8e8d54ea4904656ee47ac823d, keycount=93589, bloomtype=ROW, size=139.5m, encoding=NONE, seqNum=3862
2014-07-02 03:46:41,632 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:46:48,170 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:46:48,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15423 synced till here 15422
2014-07-02 03:46:48,327 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297997629 with entries=88, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298008171
2014-07-02 03:46:51,704 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/68ce553525d14e228de90212429cc663 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/68ce553525d14e228de90212429cc663
2014-07-02 03:46:51,818 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:46:51,867 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/532e790648f24edc839b845c490a98ff, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/532e790648f24edc839b845c490a98ff
2014-07-02 03:46:51,888 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/db2488d50f2b4156b25f522d9d682533, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/db2488d50f2b4156b25f522d9d682533
2014-07-02 03:46:51,903 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9a1107d8e8d54ea4904656ee47ac823d, to hdfs://master:54310/hbase/archive/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/9a1107d8e8d54ea4904656ee47ac823d
2014-07-02 03:46:51,903 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. into 68ce553525d14e228de90212429cc663(size=415.3m), total size for store is 1.3g. This selection was in queue for 0sec, and took 10sec to execute.
2014-07-02 03:46:51,903 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., storeName=family, fileCount=3, fileSize=418.0m, priority=16, time=16216025386372; duration=10sec
2014-07-02 03:46:51,904 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:46:58,724 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:46:58,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298008171 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298018724
2014-07-02 03:47:00,790 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:47:00,791 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.1m
2014-07-02 03:47:00,963 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:47:03,333 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3910, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/3243c850991a4020963ba8b220551fa8
2014-07-02 03:47:03,344 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/3243c850991a4020963ba8b220551fa8 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/3243c850991a4020963ba8b220551fa8
2014-07-02 03:47:03,353 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/3243c850991a4020963ba8b220551fa8, entries=932550, sequenceid=3910, filesize=139.0m
2014-07-02 03:47:03,539 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268565440, currentsize=6.2m/6520160 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 2733ms, sequenceid=3910, compaction requested=true
2014-07-02 03:47:03,540 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:47:03,541 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-02 03:47:03,541 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 1810917476 starting at candidate #0 after considering 6 permutations with 3 in ratio
2014-07-02 03:47:03,541 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5469e92a8a85cbc117b35a3d69349c81 - family: Initiating major compaction
2014-07-02 03:47:03,541 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:47:03,542 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp, totalSize=1.7g
2014-07-02 03:47:03,542 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/99cee5f5d1b248b8b0f997e68a020f84, keycount=602141, bloomtype=ROW, size=891.7m, encoding=NONE, seqNum=2901, earliestPutTs=1404295763928
2014-07-02 03:47:03,542 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/350d7c8503e14f9a8c3c79d80569c1d8, keycount=281356, bloomtype=ROW, size=416.7m, encoding=NONE, seqNum=3410, earliestPutTs=1404297221281
2014-07-02 03:47:03,542 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8c6c2e202f4a4f7f8a372286a484640c, keycount=93464, bloomtype=ROW, size=139.3m, encoding=NONE, seqNum=3577, earliestPutTs=1404297808243
2014-07-02 03:47:03,543 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/fa2a07d7799144b883efa1abc780a051, keycount=94107, bloomtype=ROW, size=140.3m, encoding=NONE, seqNum=3744, earliestPutTs=1404297884045
2014-07-02 03:47:03,543 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/3243c850991a4020963ba8b220551fa8, keycount=93255, bloomtype=ROW, size=139.0m, encoding=NONE, seqNum=3910, earliestPutTs=1404297956411
2014-07-02 03:47:03,762 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:47:07,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:47:07,345 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298018724 with entries=87, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298027297
2014-07-02 03:47:14,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:47:15,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298027297 with entries=90, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298034759
2014-07-02 03:47:25,715 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:47:25,989 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298034759 with entries=88, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298045721
2014-07-02 03:47:32,872 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:47:32,873 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., current region memstore size 256.2m
2014-07-02 03:47:33,090 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:47:34,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:47:34,942 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298045721 with entries=92, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298054495
2014-07-02 03:47:35,890 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3967, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/03f062ec9a6b436a96493fcc887a1d69
2014-07-02 03:47:35,904 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/03f062ec9a6b436a96493fcc887a1d69 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/03f062ec9a6b436a96493fcc887a1d69
2014-07-02 03:47:36,033 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/03f062ec9a6b436a96493fcc887a1d69, entries=932810, sequenceid=3967, filesize=138.8m
2014-07-02 03:47:36,061 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268625280, currentsize=2.8m/2954400 for region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. in 3188ms, sequenceid=3967, compaction requested=true
2014-07-02 03:47:36,061 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 03:47:41,528 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:47:41,529 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., current region memstore size 257.4m
2014-07-02 03:47:41,723 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:47:44,819 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:47:44,872 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4007, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/d5e8c70d679f47bfaf51379b49731e42
2014-07-02 03:47:45,004 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/d5e8c70d679f47bfaf51379b49731e42 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d5e8c70d679f47bfaf51379b49731e42
2014-07-02 03:47:45,086 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15963 synced till here 15962
2014-07-02 03:47:45,091 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d5e8c70d679f47bfaf51379b49731e42, entries=937270, sequenceid=4007, filesize=139.7m
2014-07-02 03:47:45,098 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298054495 with entries=95, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298064841
2014-07-02 03:47:45,098 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297820751
2014-07-02 03:47:45,098 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297831683
2014-07-02 03:47:45,098 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297840000
2014-07-02 03:47:45,098 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297847801
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297858405
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297869923
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297879717
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297890437
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297900514
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297910235
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297919826
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297928847
2014-07-02 03:47:45,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297941030
2014-07-02 03:47:45,100 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297949074
2014-07-02 03:47:45,100 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297958622
2014-07-02 03:47:45,100 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297965964
2014-07-02 03:47:45,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297973452
2014-07-02 03:47:45,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297979913
2014-07-02 03:47:45,180 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.4m/269926480, currentsize=12.5m/13112480 for region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. in 3652ms, sequenceid=4007, compaction requested=true
2014-07-02 03:47:45,187 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:47:50,145 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8.
2014-07-02 03:47:50,146 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8., current region memstore size 256.9m
2014-07-02 03:47:50,291 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:47:52,528 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4029, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/179a8385ecb142278841ec3f8d0cea26
2014-07-02 03:47:52,565 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/.tmp/179a8385ecb142278841ec3f8d0cea26 as hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/179a8385ecb142278841ec3f8d0cea26
2014-07-02 03:47:52,575 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/4fd5002bd7e150c46650daf5ebb5e2b8/family/179a8385ecb142278841ec3f8d0cea26, entries=935390, sequenceid=4029, filesize=139.4m
2014-07-02 03:47:52,804 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.9m/269383200, currentsize=9.4m/9903920 for region usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. in 2529ms, sequenceid=4029, compaction requested=true
2014-07-02 03:47:52,806 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-02 03:47:55,148 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1018ms
GC pool 'ParNew' had collection(s): count=1 time=1230ms
2014-07-02 03:47:56,192 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:47:56,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298064841 with entries=91, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298076193
2014-07-02 03:47:56,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297988816
2014-07-02 03:47:56,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404297997629
2014-07-02 03:47:56,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298008171
2014-07-02 03:48:03,766 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:48:03,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16143 synced till here 16141
2014-07-02 03:48:03,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298076193 with entries=89, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298083797
2014-07-02 03:48:09,469 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81.
2014-07-02 03:48:09,470 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., current region memstore size 256.9m
2014-07-02 03:48:09,610 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:48:12,808 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4076, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/c348b704fc054a238e1e9fa631573cf4
2014-07-02 03:48:12,823 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/c348b704fc054a238e1e9fa631573cf4 as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/c348b704fc054a238e1e9fa631573cf4
2014-07-02 03:48:12,834 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/c348b704fc054a238e1e9fa631573cf4, entries=935190, sequenceid=4076, filesize=139.4m
2014-07-02 03:48:12,836 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.9m/269327200, currentsize=6.2m/6482880 for region usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. in 3366ms, sequenceid=4076, compaction requested=false
2014-07-02 03:48:13,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:48:13,231 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298083797 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298093084
2014-07-02 03:48:13,232 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298018724
2014-07-02 03:48:13,232 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298027297
2014-07-02 03:48:13,232 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298034759
2014-07-02 03:48:16,597 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.8 GB, free=163.79 MB, max=3.96 GB, blocks=61419, accesses=23836294, hits=23549128, hitRatio=98.79%, , cachingAccesses=23610862, cachingHits=23446030, cachingHitsRatio=99.30%, evictions=4, evicted=102866, evictedPerRun=25716.5
2014-07-02 03:48:23,336 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:48:23,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16318 synced till here 16317
2014-07-02 03:48:23,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298093084 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298103337
2014-07-02 03:48:32,083 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1086ms
GC pool 'ParNew' had collection(s): count=1 time=1500ms
2014-07-02 03:48:32,625 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/.tmp/f8e008c59bc2417386ef2af48fc2cbdf as hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/f8e008c59bc2417386ef2af48fc2cbdf
2014-07-02 03:48:32,679 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:48:32,722 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/99cee5f5d1b248b8b0f997e68a020f84, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/99cee5f5d1b248b8b0f997e68a020f84
2014-07-02 03:48:32,726 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/350d7c8503e14f9a8c3c79d80569c1d8, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/350d7c8503e14f9a8c3c79d80569c1d8
2014-07-02 03:48:32,729 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8c6c2e202f4a4f7f8a372286a484640c, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/8c6c2e202f4a4f7f8a372286a484640c
2014-07-02 03:48:32,731 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/fa2a07d7799144b883efa1abc780a051, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/fa2a07d7799144b883efa1abc780a051
2014-07-02 03:48:32,739 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/3243c850991a4020963ba8b220551fa8, to hdfs://master:54310/hbase/archive/data/default/usertable/5469e92a8a85cbc117b35a3d69349c81/family/3243c850991a4020963ba8b220551fa8
2014-07-02 03:48:32,739 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81. into f8e008c59bc2417386ef2af48fc2cbdf(size=891.7m), total size for store is 1.0g. This selection was in queue for 0sec, and took 1mins, 29sec to execute.
2014-07-02 03:48:32,740 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1404295742993.5469e92a8a85cbc117b35a3d69349c81., storeName=family, fileCount=5, fileSize=1.7g, priority=15, time=16237939865639; duration=1mins, 29sec
2014-07-02 03:48:32,740 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-02 03:48:32,740 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-02 03:48:32,740 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 1810998419 starting at candidate #0 after considering 6 permutations with 3 in ratio
2014-07-02 03:48:32,740 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: b77d45ebabc849ed2a34dcd31b167abf - family: Initiating major compaction
2014-07-02 03:48:32,740 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf.
2014-07-02 03:48:32,740 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp, totalSize=1.7g
2014-07-02 03:48:32,741 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ac7a3426c56b4a1d83fc7f132480e13b, keycount=602555, bloomtype=ROW, size=892.3m, encoding=NONE, seqNum=2998, earliestPutTs=1404295762713
2014-07-02 03:48:32,741 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/b55ef8808be14e77a194ef631a7e2e45, keycount=280873, bloomtype=ROW, size=416.0m, encoding=NONE, seqNum=3506, earliestPutTs=1404297325007
2014-07-02 03:48:32,741 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/039a3f11df924cb1b91975a524eab4a4, keycount=93756, bloomtype=ROW, size=139.8m, encoding=NONE, seqNum=3674, earliestPutTs=1404297850756
2014-07-02 03:48:32,741 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e5f326053050419c88667e4a267e3315, keycount=93456, bloomtype=ROW, size=139.3m, encoding=NONE, seqNum=3840, earliestPutTs=1404297926745
2014-07-02 03:48:32,741 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d5e8c70d679f47bfaf51379b49731e42, keycount=93727, bloomtype=ROW, size=139.7m, encoding=NONE, seqNum=4007, earliestPutTs=1404297991473
2014-07-02 03:48:32,763 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:48:34,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:48:34,331 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298103337 with entries=88, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298114289
2014-07-02 03:48:38,738 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1150ms
GC pool 'ParNew' had collection(s): count=1 time=1495ms
2014-07-02 03:48:43,521 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 03:48:43,558 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298114289 with entries=88, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1404295396492/slave1%2C60020%2C1404295396492.1404298123521
2014-07-02 03:49:30,457 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/.tmp/4f4f3a65e7464a519b1985acfdef5e14 as hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/4f4f3a65e7464a519b1985acfdef5e14
2014-07-02 03:49:30,729 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:49:30,786 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ac7a3426c56b4a1d83fc7f132480e13b, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/ac7a3426c56b4a1d83fc7f132480e13b
2014-07-02 03:49:30,790 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/b55ef8808be14e77a194ef631a7e2e45, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/b55ef8808be14e77a194ef631a7e2e45
2014-07-02 03:49:30,793 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/039a3f11df924cb1b91975a524eab4a4, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/039a3f11df924cb1b91975a524eab4a4
2014-07-02 03:49:30,796 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e5f326053050419c88667e4a267e3315, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/e5f326053050419c88667e4a267e3315
2014-07-02 03:49:30,799 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d5e8c70d679f47bfaf51379b49731e42, to hdfs://master:54310/hbase/archive/data/default/usertable/b77d45ebabc849ed2a34dcd31b167abf/family/d5e8c70d679f47bfaf51379b49731e42
2014-07-02 03:49:30,799 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf. into 4f4f3a65e7464a519b1985acfdef5e14(size=892.3m), total size for store is 892.3m. This selection was in queue for 0sec, and took 58sec to execute.
2014-07-02 03:49:30,799 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1404295742993.b77d45ebabc849ed2a34dcd31b167abf., storeName=family, fileCount=5, fileSize=1.7g, priority=15, time=16327139134781; duration=58sec
2014-07-02 03:49:30,799 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-02 03:49:30,800 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:49:30,800 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-02 03:49:30,800 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 03:49:30,800 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Not compacting usertable,user7,1404295742993.4fd5002bd7e150c46650daf5ebb5e2b8. because compaction request was cancelled
2014-07-02 03:49:30,800 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 03:49:30,800 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 568143474 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-02 03:49:30,800 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: 5f58b71b81e6d85caf1b01aa1abb7cf9 - family: Initiating major compaction
2014-07-02 03:49:30,801 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HRegion: Starting compaction on family in region usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9.
2014-07-02 03:49:30,801 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp, totalSize=541.8m
2014-07-02 03:49:30,801 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/80f88a9b633948dead05d496fa643caf, keycount=181338, bloomtype=ROW, size=268.1m, encoding=NONE, seqNum=2860, earliestPutTs=1404295764376
2014-07-02 03:49:30,801 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/f6da0269cb4946159ac1a1311488fe63, keycount=90639, bloomtype=ROW, size=134.9m, encoding=NONE, seqNum=3418, earliestPutTs=1404297186211
2014-07-02 03:49:30,801 DEBUG [regionserver60020-smallCompactions-1404295830350] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/03f062ec9a6b436a96493fcc887a1d69, keycount=93281, bloomtype=ROW, size=138.8m, encoding=NONE, seqNum=3967, earliestPutTs=1404297820895
2014-07-02 03:49:30,822 DEBUG [regionserver60020-smallCompactions-1404295830350] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 03:49:46,357 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/.tmp/fa964505831e4a9489d9fd1be70eb515 as hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/fa964505831e4a9489d9fd1be70eb515
2014-07-02 03:49:46,378 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Removing store files after compaction...
2014-07-02 03:49:46,416 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/80f88a9b633948dead05d496fa643caf, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/80f88a9b633948dead05d496fa643caf
2014-07-02 03:49:46,418 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/f6da0269cb4946159ac1a1311488fe63, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/f6da0269cb4946159ac1a1311488fe63
2014-07-02 03:49:46,429 DEBUG [regionserver60020-smallCompactions-1404295830350] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/03f062ec9a6b436a96493fcc887a1d69, to hdfs://master:54310/hbase/archive/data/default/usertable/5f58b71b81e6d85caf1b01aa1abb7cf9/family/03f062ec9a6b436a96493fcc887a1d69
2014-07-02 03:49:46,430 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9. into fa964505831e4a9489d9fd1be70eb515(size=268.1m), total size for store is 268.1m. This selection was in queue for 0sec, and took 15sec to execute.
2014-07-02 03:49:46,430 INFO  [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user9,1404295742993.5f58b71b81e6d85caf1b01aa1abb7cf9., storeName=family, fileCount=3, fileSize=541.8m, priority=17, time=16385199266212; duration=15sec
2014-07-02 03:49:46,430 DEBUG [regionserver60020-smallCompactions-1404295830350] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 03:53:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 03:58:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:03:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:08:16,575 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:13:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:18:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:23:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:28:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:33:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:38:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
2014-07-02 04:43:16,569 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.09 GB, free=2.87 GB, max=3.96 GB, blocks=17495, accesses=24013014, hits=23706544, hitRatio=98.72%, , cachingAccesses=23745570, cachingHits=23574734, cachingHitsRatio=99.28%, evictions=5, evicted=152798, evictedPerRun=30559.599609375
