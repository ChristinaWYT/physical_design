Wed Aug 13 05:25:51 PDT 2014 Starting master on sceplus-vm48
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-08-13 05:25:52,310 INFO  [main] util.VersionInfo: HBase 2.0.0-SNAPSHOT
2014-08-13 05:25:52,311 INFO  [main] util.VersionInfo: Subversion git://sceplus-vm48/home/hadoop/hbase-2.0.0-SNAPSHOT -r 50ac59fa8530bbd35c21cd61cfd64d2bd7d3eb57
2014-08-13 05:25:52,311 INFO  [main] util.VersionInfo: Compiled by hadoop on Sun Aug  3 14:37:33 PDT 2014
2014-08-13 05:25:52,579 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64/
2014-08-13 05:25:52,579 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2014-08-13 05:25:52,579 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-08-13 05:25:52,579 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-08-13 05:25:52,579 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Dhbase.security.logger=INFO,RFAS
2014-08-13 05:25:52,579 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.53 46854 22
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=12288
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-master.znode
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.53 46854 9.1.143.58 22
2014-08-13 05:25:52,580 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-08-13 05:25:52,581 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-08-13 05:25:52,581 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-08-13 05:25:52,585 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.7.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/../hbase-server/target:/home/hadoop/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/com/lmax/disruptor/3.2.0/disruptor-3.2.0.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.19.Final/netty-all-4.0.19.Final.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/../lib/tools.jar:/home/hadoop/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.0/hadoop-annotations-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.0/hadoop-auth-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.4.0/hadoop-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.0/hadoop-mapreduce-client-app-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.0/hadoop-mapreduce-client-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.0/hadoop-mapreduce-client-core-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/2.4.0/hadoop-mapreduce-client-hs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.0/hadoop-mapreduce-client-shuffle-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-minicluster/2.4.0/hadoop-minicluster-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.0/hadoop-yarn-api-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.0/hadoop-yarn-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.0/hadoop-yarn-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.4.0/hadoop-yarn-server-applicationhistoryservice-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.0/hadoop-yarn-server-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.4.0/hadoop-yarn-server-nodemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.4.0/hadoop-yarn-server-resourcemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/2.4.0/hadoop-yarn-server-tests-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.4.0/hadoop-yarn-server-web-proxy-2.4.0.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-client/target/hbase-client-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-it/target/hbase-it-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-prefix-tree/target/hbase-prefix-tree-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-protocol/target/hbase-protocol-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-shell/target/hbase-shell-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-testing-util/target/hbase-testing-util-2.0.0-SNAPSHOT.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jettison/jettison/1.3.1/jettison-1.3.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/hadoop/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/home/hadoop/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/.m2/repository/org/jboss/netty/netty/3.2.4.Final/netty-3.2.4.Final.jar:/home/hadoop/.m2/repository/org/jruby/jruby-complete/1.6.8/jruby-complete-1.6.8.jar:/home/hadoop/.m2/repository/org/mockito/mockito-all/1.9.0/mockito-all-1.9.0.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/*.jar:::/home/hadoop/hbase/selfdapql.jar
2014-08-13 05:25:52,585 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-08-13 05:25:52,585 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-08-13 05:25:52,585 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-08-13 05:25:52,585 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-08-13 05:25:52,585 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=:/home/hadoop/hbase/selfdapql.jar
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-master.autorestart
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=7686
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-sceplus-vm48.log
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-sceplus-vm48
2014-08-13 05:25:52,586 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-08-13 05:25:52,589 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.51-b03
2014-08-13 05:25:52,590 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx12288m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Dhbase.security.logger=INFO,RFAS]
2014-08-13 05:25:52,987 INFO  [main] regionserver.RSRpcServices: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020 server-side HConnection retries=350
2014-08-13 05:25:53,198 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=5
2014-08-13 05:25:53,226 INFO  [main] ipc.RpcServer: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020: started 10 reader(s).
2014-08-13 05:25:53,370 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-08-13 05:25:53,387 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-08-13 05:25:53,481 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-08-13 05:25:53,481 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-08-13 05:25:53,736 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-08-13 05:25:53,741 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache size=4.76 GB, blockSize=64 KB
2014-08-13 05:25:53,760 INFO  [main] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:25:54,496 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-08-13 05:25:54,511 WARN  [main] trace.SpanReceiverHost: Class org.cloudera.htrace.impl.LocalFileSpanReceiver cannot be found. org.cloudera.htrace.impl.LocalFileSpanReceiver
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm48.almaden.ibm.com
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_55
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.7.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/../hbase-server/target:/home/hadoop/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/com/lmax/disruptor/3.2.0/disruptor-3.2.0.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.19.Final/netty-all-4.0.19.Final.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/../lib/tools.jar:/home/hadoop/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.0/hadoop-annotations-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.0/hadoop-auth-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.4.0/hadoop-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.0/hadoop-mapreduce-client-app-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.0/hadoop-mapreduce-client-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.0/hadoop-mapreduce-client-core-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/2.4.0/hadoop-mapreduce-client-hs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.0/hadoop-mapreduce-client-shuffle-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-minicluster/2.4.0/hadoop-minicluster-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.0/hadoop-yarn-api-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.0/hadoop-yarn-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.0/hadoop-yarn-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.4.0/hadoop-yarn-server-applicationhistoryservice-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.0/hadoop-yarn-server-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.4.0/hadoop-yarn-server-nodemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.4.0/hadoop-yarn-server-resourcemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/2.4.0/hadoop-yarn-server-tests-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.4.0/hadoop-yarn-server-web-proxy-2.4.0.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-client/target/hbase-client-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-it/target/hbase-it-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-prefix-tree/target/hbase-prefix-tree-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-protocol/target/hbase-protocol-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-shell/target/hbase-shell-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-testing-util/target/hbase-testing-util-2.0.0-SNAPSHOT.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jettison/jettison/1.3.1/jettison-1.3.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/hadoop/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/home/hadoop/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/.m2/repository/org/jboss/netty/netty/3.2.4.Final/netty-3.2.4.Final.jar:/home/hadoop/.m2/repository/org/jruby/jruby-complete/1.6.8/jruby-complete-1.6.8.jar:/home/hadoop/.m2/repository/org/mockito/mockito-all/1.9.0/mockito-all-1.9.0.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/*.jar:::/home/hadoop/hbase/selfdapql.jar
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-08-13 05:25:54,535 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-08-13 05:25:54,536 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop
2014-08-13 05:25:54,537 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=master:16020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:25:54,558 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:25:54,560 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:25:54,568 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-13 05:25:54,608 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147cf54dfb30000, negotiated timeout = 90000
2014-08-13 05:25:54,686 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-08-13 05:25:54,686 INFO  [RpcServer.listener,port=16020] ipc.RpcServer: RpcServer.listener,port=16020: starting
2014-08-13 05:25:54,769 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-08-13 05:25:54,774 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2014-08-13 05:25:54,788 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2014-08-13 05:25:54,792 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-08-13 05:25:54,792 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-08-13 05:25:54,792 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-08-13 05:25:54,814 INFO  [main] http.HttpServer: Jetty bound to port 16030
2014-08-13 05:25:54,814 INFO  [main] mortbay.log: jetty-6.1.26
2014-08-13 05:25:55,197 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16030
2014-08-13 05:25:55,198 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:54310/hbase, hbase.cluster.distributed=true
2014-08-13 05:25:55,213 INFO  [main] master.HMaster: Adding ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,16020,1407932753555 in backup master directory
2014-08-13 05:25:55,333 INFO  [main] mortbay.log: jetty-6.1.26
2014-08-13 05:25:55,335 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2014-08-13 05:25:55,360 INFO  [ActiveMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,16020,1407932753555 from backup master directory
2014-08-13 05:25:55,370 INFO  [ActiveMasterManager] master.ActiveMasterManager: Registered Active Master=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:25:55,519 INFO  [ActiveMasterManager] util.FSUtils: Waiting for dfs to exit safe mode...
2014-08-13 05:26:05,527 INFO  [ActiveMasterManager] util.FSUtils: Waiting for dfs to exit safe mode...
2014-08-13 05:26:16,105 INFO  [ActiveMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-08-13 05:26:16,122 INFO  [ActiveMasterManager] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=true
2014-08-13 05:26:16,124 INFO  [ActiveMasterManager] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-08-13 05:26:16,198 INFO  [ActiveMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x1660de94, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:26:16,199 INFO  [ActiveMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x1660de94 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:26:16,200 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:26:16,202 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-13 05:26:16,206 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47cf54e2bc0001, negotiated timeout = 90000
2014-08-13 05:26:16,318 INFO  [ActiveMasterManager] master.HMaster: Server active/primary master=sceplus-vm48.almaden.ibm.com,16020,1407932753555, sessionid=0x147cf54dfb30000, setting cluster-up flag (Was=false)
2014-08-13 05:26:16,322 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: ClusterId : e1269f5c-c7d1-4768-9543-f3056232703b
2014-08-13 05:26:16,344 INFO  [ActiveMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2014-08-13 05:26:16,351 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.8 G, globalMemStoreLimitLowMark=4.5 G, maxHeap=11.9 G
2014-08-13 05:26:16,356 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-08-13 05:26:16,381 INFO  [ActiveMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2014-08-13 05:26:16,388 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,16020,1407932753555 with port=16020, startcode=1407932753555
2014-08-13 05:26:16,393 WARN  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2014-08-13 05:26:16,394 INFO  [ActiveMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=replicationLogCleaner, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:26:16,395 INFO  [ActiveMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:26:16,396 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:26:16,397 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-13 05:26:16,400 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47cf54e2bc0002, negotiated timeout = 90000
2014-08-13 05:26:16,421 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,16020,1407932753555 with port=16020, startcode=1407932753555
2014-08-13 05:26:16,421 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn false
2014-08-13 05:26:16,430 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] master.ServerManager: Registering server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:16,475 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 54 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-13 05:26:16,502 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true, prefix=sceplus-vm48.almaden.ibm.com%2C16020%2C1407932753555, logDir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407932753555, oldLogDir=hdfs://master:54310/hbase/oldWALs
2014-08-13 05:26:16,800 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: Slow sync cost: 233 ms, current pipeline: []
2014-08-13 05:26:16,800 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407932753555/sceplus-vm48.almaden.ibm.com%2C16020%2C1407932753555.1407932776511
2014-08-13 05:26:16,846 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-08-13 05:26:16,860 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,16020,1407932753555] other RSs: [sceplus-vm48.almaden.ibm.com,16020,1407932753555, sceplus-vm49.almaden.ibm.com,16020,1407932754742]
2014-08-13 05:26:16,897 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x16514a37, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:26:16,898 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x16514a37 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:26:16,898 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:26:16,900 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-13 05:26:16,904 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47cf54e2bc0004, negotiated timeout = 90000
2014-08-13 05:26:16,942 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: SplitLogWorker sceplus-vm48.almaden.ibm.com,16020,1407932753555 starting
2014-08-13 05:26:16,944 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HeapMemoryManager: Starting HeapMemoryTuner chore.
2014-08-13 05:26:16,950 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: Serving as sceplus-vm48.almaden.ibm.com,16020,1407932753555, RpcServer on sceplus-vm48.almaden.ibm.com/9.1.143.58:16020, sessionid=0x147cf54dfb30000
2014-08-13 05:26:16,950 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x3abe110a, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:26:16,951 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x3abe110a connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:26:16,952 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:26:16,952 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-13 05:26:16,957 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147cf54dfb30001, negotiated timeout = 90000
2014-08-13 05:26:17,124 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.ServerManager: Registering server=slave1,16020,1407932754742
2014-08-13 05:26:17,127 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 706 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-13 05:26:18,632 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 2211 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-13 05:26:20,138 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 3717 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-13 05:26:20,941 INFO  [ActiveMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 2, slept for 4520 ms, expecting minimum of 2, maximum of 2147483647, master is running, selfCheckedIn true
2014-08-13 05:26:20,941 INFO  [ActiveMasterManager] master.ServerManager: Registering server=sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:20,941 INFO  [ActiveMasterManager] master.HMaster: Registered server found up in zk but who has not yet reported in: sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:20,951 INFO  [ActiveMasterManager] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407932753555 belongs to an existing region server
2014-08-13 05:26:20,952 INFO  [ActiveMasterManager] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742 belongs to an existing region server
2014-08-13 05:26:21,080 INFO  [ActiveMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=sceplus-vm48.almaden.ibm.com,16020,1407931593639, exception=org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on sceplus-vm48.almaden.ibm.com,16020,1407932753555
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2605)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:795)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1067)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:20158)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2013)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
	at java.lang.Thread.run(Thread.java:744)

2014-08-13 05:26:21,108 INFO  [ActiveMasterManager] zookeeper.MetaTableLocator: Unsetting hbase:meta region location in ZooKeeper
2014-08-13 05:26:21,149 INFO  [ActiveMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:21,150 INFO  [ActiveMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1407932780971, server=null} to {1588230740 state=PENDING_OPEN, ts=1407932781150, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:26:21,162 INFO  [ActiveMasterManager] regionserver.RSRpcServices: Open hbase:meta,,1.1588230740
2014-08-13 05:26:21,168 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true, prefix=sceplus-vm48.almaden.ibm.com%2C16020%2C1407932753555, logDir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407932753555, oldLogDir=hdfs://master:54310/hbase/oldWALs
2014-08-13 05:26:21,174 INFO  [ActiveMasterManager] master.MasterFileSystem: Log dir for server sceplus-vm48.almaden.ibm.com,16020,1407931593639 does not exist
2014-08-13 05:26:21,174 INFO  [ActiveMasterManager] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,16020,1407931593639]
2014-08-13 05:26:21,174 INFO  [ActiveMasterManager] master.SplitLogManager: started splitting 0 logs in []
2014-08-13 05:26:21,185 INFO  [main-EventThread] zookeeper.RecoveringRegionWatcher: /hbase/recovering-regions/1588230740 znode deleted. Region: 1588230740 completes recovery.
2014-08-13 05:26:21,185 INFO  [ActiveMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 11ms
2014-08-13 05:26:21,185 INFO  [ActiveMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-08-13 05:26:21,206 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: Slow sync cost: 22 ms, current pipeline: []
2014-08-13 05:26:21,206 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407932753555/sceplus-vm48.almaden.ibm.com%2C16020%2C1407932753555.1407932781176.meta
2014-08-13 05:26:21,244 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-08-13 05:26:21,314 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:26:21,325 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:26:21,454 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=182
2014-08-13 05:26:21,455 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for hbase:meta,,1.1588230740
2014-08-13 05:26:21,456 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaTableLocator: Setting hbase:meta region location in ZooKeeper as sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:21,479 INFO  [PostOpenDeployTasks:1588230740] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1407932781150, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {1588230740 state=OPEN, ts=1407932781479, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:26:21,479 INFO  [PostOpenDeployTasks:1588230740] master.RegionStates: Onlined 1588230740 on sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:21,481 INFO  [ActiveMasterManager] master.HMaster: hbase:meta assigned=1, rit=false, location=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:21,599 INFO  [ActiveMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-08-13 05:26:21,660 INFO  [ActiveMasterManager] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2014-08-13 05:26:21,660 WARN  [ActiveMasterManager] master.ServerManager: Expiration of slave1,16020,1407932445757 but server not online
2014-08-13 05:26:21,663 WARN  [ActiveMasterManager] master.ServerManager: Expiration of sceplus-vm48.almaden.ibm.com,16020,1407931593639 but server not online
2014-08-13 05:26:21,671 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407932445757 before assignment.
2014-08-13 05:26:21,671 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-13 05:26:21,671 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Splitting logs for sceplus-vm48.almaden.ibm.com,16020,1407931593639 before assignment.
2014-08-13 05:26:21,672 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-13 05:26:21,682 INFO  [ActiveMasterManager] master.AssignmentManager: Joined the cluster in 82ms, failover=true
2014-08-13 05:26:21,782 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=OPEN, ts=1407932781652, server=slave1,16020,1407932445757} to {b4897f073e60e8bc63a6f8d119db34bb state=OFFLINE, ts=1407932781782, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,783 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=OFFLINE
2014-08-13 05:26:21,815 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=OPEN, ts=1407932781654, server=slave1,16020,1407932445757} to {1e1eb564c9225f75a48fcbea8b612775 state=OFFLINE, ts=1407932781815, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,815 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=OFFLINE
2014-08-13 05:26:21,818 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {afc8a0671e30be06e10dcf4187e202de state=OPEN, ts=1407932781656, server=slave1,16020,1407932445757} to {afc8a0671e30be06e10dcf4187e202de state=OFFLINE, ts=1407932781818, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,818 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de. with state=OFFLINE
2014-08-13 05:26:21,821 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=OPEN, ts=1407932781656, server=slave1,16020,1407932445757} to {97e3f5dae1052ab6f8c8c95d648d22ee state=OFFLINE, ts=1407932781821, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,821 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=OFFLINE
2014-08-13 05:26:21,824 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {ee08c27660ca7f31ba19c03b35631d5a state=OPEN, ts=1407932781657, server=slave1,16020,1407932445757} to {ee08c27660ca7f31ba19c03b35631d5a state=OFFLINE, ts=1407932781824, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,824 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a. with state=OFFLINE
2014-08-13 05:26:21,827 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=OPEN, ts=1407932781653, server=slave1,16020,1407932445757} to {7620ecf4f35847960d5a5ac255c36750 state=OFFLINE, ts=1407932781827, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,827 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=OFFLINE
2014-08-13 05:26:21,831 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {42fbdcf382e2db1e95e5166bd67a2a96 state=OPEN, ts=1407932781659, server=slave1,16020,1407932445757} to {42fbdcf382e2db1e95e5166bd67a2a96 state=OFFLINE, ts=1407932781831, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,831 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96. with state=OFFLINE
2014-08-13 05:26:21,835 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=OPEN, ts=1407932781655, server=slave1,16020,1407932445757} to {8df07d02d8b56c1fa06b11867df8e19d state=OFFLINE, ts=1407932781835, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,835 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=OFFLINE
2014-08-13 05:26:21,840 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {ddeef26cf0d47188f4271d7ea65eefe0 state=OPEN, ts=1407932781651, server=slave1,16020,1407932445757} to {ddeef26cf0d47188f4271d7ea65eefe0 state=OFFLINE, ts=1407932781840, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,840 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0. with state=OFFLINE
2014-08-13 05:26:21,844 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=OPEN, ts=1407932781658, server=slave1,16020,1407932445757} to {a61c032ae7202dd4d9377544ae61f766 state=OFFLINE, ts=1407932781844, server=slave1,16020,1407932445757}
2014-08-13 05:26:21,844 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=OFFLINE
2014-08-13 05:26:21,848 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Reassigning 10 region(s) that slave1,16020,1407932445757 was carrying (and 0 regions(s) that were opening on this server)
2014-08-13 05:26:21,848 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407932781650, server=sceplus-vm48.almaden.ibm.com,16020,1407931593639} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OFFLINE, ts=1407932781848, server=sceplus-vm48.almaden.ibm.com,16020,1407931593639}
2014-08-13 05:26:21,849 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OFFLINE
2014-08-13 05:26:21,854 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Reassigning 1 region(s) that sceplus-vm48.almaden.ibm.com,16020,1407931593639 was carrying (and 0 regions(s) that were opening on this server)
2014-08-13 05:26:21,891 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2014-08-13 05:26:21,894 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 1 region(s) to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:21,900 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OFFLINE, ts=1407932781848, server=sceplus-vm48.almaden.ibm.com,16020,1407931593639} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407932781900, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:26:21,900 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN&sn=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:21,905 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:26:21,910 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Bulk assigning done
2014-08-13 05:26:21,910 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for 2eb418e3c70ddeb740c21f06d8d0f905 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:26:21,919 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:26:21,920 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:26:21,958 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=40000008
2014-08-13 05:26:21,959 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:26:21,984 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407932781900, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407932781984, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:26:21,985 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=40000008&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:21,989 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Onlined 2eb418e3c70ddeb740c21f06d8d0f905 on sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:26:22,000 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.MasterFileSystem: Log dir for server sceplus-vm48.almaden.ibm.com,16020,1407931593639 does not exist
2014-08-13 05:26:22,000 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,16020,1407931593639]
2014-08-13 05:26:22,001 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: started splitting 0 logs in []
2014-08-13 05:26:22,014 INFO  [main-EventThread] zookeeper.RecoveringRegionWatcher: /hbase/recovering-regions/2eb418e3c70ddeb740c21f06d8d0f905 znode deleted. Region: 2eb418e3c70ddeb740c21f06d8d0f905 completes recovery.
2014-08-13 05:26:22,022 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 21ms
2014-08-13 05:26:22,022 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.LogReplayHandler: Finished processing shutdown of sceplus-vm48.almaden.ibm.com,16020,1407931593639
2014-08-13 05:26:22,131 INFO  [ActiveMasterManager] master.HMaster: Master has completed initialization
2014-08-13 05:26:22,165 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Bulk assigning 10 region(s) across 3 server(s), round-robin=true
2014-08-13 05:26:22,166 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 5 region(s) to sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:22,167 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.AssignmentManager: Assigning 5 region(s) to slave1,16020,1407932754742
2014-08-13 05:26:22,167 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=OFFLINE, ts=1407932781815, server=slave1,16020,1407932445757} to {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932782167, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:22,167 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:22,167 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=OFFLINE, ts=1407932781782, server=slave1,16020,1407932445757} to {b4897f073e60e8bc63a6f8d119db34bb state=PENDING_OPEN, ts=1407932782167, server=slave1,16020,1407932754742}
2014-08-13 05:26:22,168 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:22,178 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=OFFLINE, ts=1407932781821, server=slave1,16020,1407932445757} to {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932782178, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:22,178 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:22,179 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStates: Transition {afc8a0671e30be06e10dcf4187e202de state=OFFLINE, ts=1407932781818, server=slave1,16020,1407932445757} to {afc8a0671e30be06e10dcf4187e202de state=PENDING_OPEN, ts=1407932782179, server=slave1,16020,1407932754742}
2014-08-13 05:26:22,180 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:22,182 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=OFFLINE, ts=1407932781827, server=slave1,16020,1407932445757} to {7620ecf4f35847960d5a5ac255c36750 state=PENDING_OPEN, ts=1407932782182, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:22,183 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:22,184 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStates: Transition {ee08c27660ca7f31ba19c03b35631d5a state=OFFLINE, ts=1407932781824, server=slave1,16020,1407932445757} to {ee08c27660ca7f31ba19c03b35631d5a state=PENDING_OPEN, ts=1407932782184, server=slave1,16020,1407932754742}
2014-08-13 05:26:22,184 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:22,187 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=OFFLINE, ts=1407932781835, server=slave1,16020,1407932445757} to {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_OPEN, ts=1407932782187, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:22,187 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:22,189 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStates: Transition {42fbdcf382e2db1e95e5166bd67a2a96 state=OFFLINE, ts=1407932781831, server=slave1,16020,1407932445757} to {42fbdcf382e2db1e95e5166bd67a2a96 state=PENDING_OPEN, ts=1407932782189, server=slave1,16020,1407932754742}
2014-08-13 05:26:22,189 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:22,192 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=OFFLINE, ts=1407932781844, server=slave1,16020,1407932445757} to {a61c032ae7202dd4d9377544ae61f766 state=PENDING_OPEN, ts=1407932782192, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:22,192 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:22,194 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStates: Transition {ddeef26cf0d47188f4271d7ea65eefe0 state=OFFLINE, ts=1407932781840, server=slave1,16020,1407932445757} to {ddeef26cf0d47188f4271d7ea65eefe0 state=PENDING_OPEN, ts=1407932782193, server=slave1,16020,1407932754742}
2014-08-13 05:26:22,194 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:22,584 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Bulk assigning done
2014-08-13 05:26:22,584 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Waiting for b4897f073e60e8bc63a6f8d119db34bb to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:26:23,018 INFO  [defaultRpcServer.handler=8,queue=3,port=16020] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=PENDING_OPEN, ts=1407932782167, server=slave1,16020,1407932754742} to {b4897f073e60e8bc63a6f8d119db34bb state=OPEN, ts=1407932783018, server=slave1,16020,1407932754742}
2014-08-13 05:26:23,018 INFO  [defaultRpcServer.handler=8,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=OPEN&openSeqNum=80002448&server=slave1,16020,1407932754742
2014-08-13 05:26:23,020 ERROR [defaultRpcServer.handler=1,queue=1,port=16020] master.AssignmentManager: Failed to transtion region from {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932782178, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to OPENED by slave1,16020,1407932754742: 97e3f5dae1052ab6f8c8c95d648d22ee is not pending open on slave1,16020,1407932754742
2014-08-13 05:26:23,020 ERROR [defaultRpcServer.handler=4,queue=4,port=16020] master.AssignmentManager: Failed to transtion region from {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932782167, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to OPENED by slave1,16020,1407932754742: 1e1eb564c9225f75a48fcbea8b612775 is not pending open on slave1,16020,1407932754742
2014-08-13 05:26:23,022 INFO  [defaultRpcServer.handler=8,queue=3,port=16020] master.RegionStates: Onlined b4897f073e60e8bc63a6f8d119db34bb on slave1,16020,1407932754742
2014-08-13 05:26:23,022 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Waiting for 1e1eb564c9225f75a48fcbea8b612775 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:26:23,043 ERROR [defaultRpcServer.handler=6,queue=1,port=16020] master.MasterRpcServices: Region server slave1,16020,1407932754742 reported a fatal error:
ABORTING region server slave1,16020,1407932754742: Exception running postOpenDeployTasks; region=97e3f5dae1052ab6f8c8c95d648d22ee
Cause:
java.io.IOException: Failed to report opened region to master: usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1730)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:321)

2014-08-13 05:26:23,043 ERROR [defaultRpcServer.handler=11,queue=1,port=16020] master.MasterRpcServices: Region server slave1,16020,1407932754742 reported a fatal error:
ABORTING region server slave1,16020,1407932754742: Exception running postOpenDeployTasks; region=1e1eb564c9225f75a48fcbea8b612775
Cause:
java.io.IOException: Failed to report opened region to master: usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1730)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:321)

2014-08-13 05:26:27,740 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sceplus-vm49.almaden.ibm.com,16020,1407932754742]
2014-08-13 05:26:27,747 INFO  [main-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/sceplus-vm49.almaden.ibm.com,16020,1407932754742 znode expired, triggering replicatorRemoved event
2014-08-13 05:26:27,748 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Splitting logs for sceplus-vm49.almaden.ibm.com,16020,1407932754742 before assignment.
2014-08-13 05:26:27,748 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-13 05:26:27,748 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {a61c032ae7202dd4d9377544ae61f766 state=PENDING_OPEN, ts=1407932782192, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:27,748 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932782178, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:27,748 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932782167, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:27,749 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_OPEN, ts=1407932782187, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:27,749 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {7620ecf4f35847960d5a5ac255c36750 state=PENDING_OPEN, ts=1407932782182, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:26:27,751 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/a61c032ae7202dd4d9377544ae61f766 already deleted, retry=false
2014-08-13 05:26:27,751 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=PENDING_OPEN, ts=1407932782192, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {a61c032ae7202dd4d9377544ae61f766 state=OFFLINE, ts=1407932787751, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:27,751 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=OFFLINE
2014-08-13 05:26:27,767 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/97e3f5dae1052ab6f8c8c95d648d22ee already deleted, retry=false
2014-08-13 05:26:27,767 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932782178, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {97e3f5dae1052ab6f8c8c95d648d22ee state=OFFLINE, ts=1407932787767, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:27,767 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=OFFLINE
2014-08-13 05:26:27,773 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/1e1eb564c9225f75a48fcbea8b612775 already deleted, retry=false
2014-08-13 05:26:27,773 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932782167, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {1e1eb564c9225f75a48fcbea8b612775 state=OFFLINE, ts=1407932787773, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:27,774 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=OFFLINE
2014-08-13 05:26:27,785 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/8df07d02d8b56c1fa06b11867df8e19d already deleted, retry=false
2014-08-13 05:26:27,786 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_OPEN, ts=1407932782187, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {8df07d02d8b56c1fa06b11867df8e19d state=OFFLINE, ts=1407932787786, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:27,786 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=OFFLINE
2014-08-13 05:26:27,798 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/7620ecf4f35847960d5a5ac255c36750 already deleted, retry=false
2014-08-13 05:26:27,798 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=PENDING_OPEN, ts=1407932782182, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {7620ecf4f35847960d5a5ac255c36750 state=OFFLINE, ts=1407932787798, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742}
2014-08-13 05:26:27,798 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=OFFLINE
2014-08-13 05:26:27,802 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Reassigning 0 region(s) that sceplus-vm49.almaden.ibm.com,16020,1407932754742 was carrying (and 5 regions(s) that were opening on this server)
2014-08-13 05:26:27,804 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Assigning 5 region(s) to slave1,16020,1407932754742
2014-08-13 05:26:27,805 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=OFFLINE, ts=1407932787751, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {a61c032ae7202dd4d9377544ae61f766 state=PENDING_OPEN, ts=1407932787805, server=slave1,16020,1407932754742}
2014-08-13 05:26:27,805 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:27,810 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=OFFLINE, ts=1407932787767, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932787810, server=slave1,16020,1407932754742}
2014-08-13 05:26:27,810 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:27,814 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=OFFLINE, ts=1407932787773, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932787814, server=slave1,16020,1407932754742}
2014-08-13 05:26:27,815 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:27,819 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=OFFLINE, ts=1407932787786, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_OPEN, ts=1407932787819, server=slave1,16020,1407932754742}
2014-08-13 05:26:27,819 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:27,824 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=OFFLINE, ts=1407932787798, server=sceplus-vm49.almaden.ibm.com,16020,1407932754742} to {7620ecf4f35847960d5a5ac255c36750 state=PENDING_OPEN, ts=1407932787824, server=slave1,16020,1407932754742}
2014-08-13 05:26:27,824 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=PENDING_OPEN&sn=slave1,16020,1407932754742
2014-08-13 05:26:27,832 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Unable to communicate with slave1,16020,1407932754742 in order to assign regions, 
java.io.IOException: Call to slave1/9.1.143.59:16020 failed on local exception: java.io.IOException: Connection to sceplus-vm49.almaden.ibm.com/9.1.143.59:16020 is closing. Call id=14, waitTime=1
	at org.apache.hadoop.hbase.ipc.RpcClient.wrapException(RpcClient.java:1571)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1542)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.openRegion(AdminProtos.java:20964)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionOpen(ServerManager.java:766)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1679)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2653)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2634)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:291)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.io.IOException: Connection to sceplus-vm49.almaden.ibm.com/9.1.143.59:16020 is closing. Call id=14, waitTime=1
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.cleanupCalls(RpcClient.java:1265)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.close(RpcClient.java:1059)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.run(RpcClient.java:792)
2014-08-13 05:26:27,837 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for a61c032ae7202dd4d9377544ae61f766 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:26:27,842 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=1 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:27,843 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:27,843 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:27,843 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:27,843 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:29,845 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:29,847 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:29,847 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=3 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:29,847 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:29,850 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:29,849 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:30,734 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving sceplus-vm49.almaden.ibm.com,16020,1407932754742's hlogs to my queue
2014-08-13 05:26:30,746 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Won't transfer the queue, another RS took care of it because of: KeeperErrorCode = NoNode for /hbase/replication/rs/sceplus-vm49.almaden.ibm.com,16020,1407932754742/lock
2014-08-13 05:26:31,850 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:31,851 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:31,852 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:31,854 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:31,854 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=5 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:31,854 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=4 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:31,854 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:33,857 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:33,860 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=5 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:33,861 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:33,860 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:33,862 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:33,863 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:35,863 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:35,864 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:35,865 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:35,867 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=8 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:35,866 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=7 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:35,866 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:35,866 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,868 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,869 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,871 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,872 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775., try=10 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,872 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=7 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,874 WARN  [AM.-pool1-t3] master.RegionStates: Failed to open/close 1e1eb564c9225f75a48fcbea8b612775 on slave1,16020,1407932754742, set to FAILED_CLOSE
2014-08-13 05:26:37,874 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,875 INFO  [AM.-pool1-t3] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932787814, server=slave1,16020,1407932754742} to {1e1eb564c9225f75a48fcbea8b612775 state=FAILED_CLOSE, ts=1407932797875, server=slave1,16020,1407932754742}
2014-08-13 05:26:37,875 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:37,876 INFO  [AM.-pool1-t3] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=FAILED_CLOSE
2014-08-13 05:26:37,889 INFO  [AM.-pool1-t3] master.AssignmentManager: Skip assigning {ENCODED => 1e1eb564c9225f75a48fcbea8b612775, NAME => 'usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775.', STARTKEY => 'user3', ENDKEY => 'user4'}, we couldn't close it: {1e1eb564c9225f75a48fcbea8b612775 state=FAILED_CLOSE, ts=1407932797875, server=slave1,16020,1407932754742}
2014-08-13 05:26:38,089 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Timed out on waiting for 1e1eb564c9225f75a48fcbea8b612775 to be assigned.
2014-08-13 05:26:38,089 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Region 1e1eb564c9225f75a48fcbea8b612775 didn't complete assignment in time
2014-08-13 05:26:38,089 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Waiting for afc8a0671e30be06e10dcf4187e202de to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:26:39,874 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:39,877 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:39,878 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:39,877 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d., try=10 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:39,880 WARN  [AM.-pool1-t4] master.RegionStates: Failed to open/close 8df07d02d8b56c1fa06b11867df8e19d on slave1,16020,1407932754742, set to FAILED_CLOSE
2014-08-13 05:26:39,880 INFO  [AM.-pool1-t4] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_OPEN, ts=1407932787819, server=slave1,16020,1407932754742} to {8df07d02d8b56c1fa06b11867df8e19d state=FAILED_CLOSE, ts=1407932799880, server=slave1,16020,1407932754742}
2014-08-13 05:26:39,880 INFO  [AM.-pool1-t4] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=FAILED_CLOSE
2014-08-13 05:26:39,882 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:39,888 INFO  [AM.-pool1-t4] master.AssignmentManager: Skip assigning {ENCODED => 8df07d02d8b56c1fa06b11867df8e19d, NAME => 'usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d.', STARTKEY => 'user4', ENDKEY => 'user5'}, we couldn't close it: {8df07d02d8b56c1fa06b11867df8e19d state=FAILED_CLOSE, ts=1407932799880, server=slave1,16020,1407932754742}
2014-08-13 05:26:41,880 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:41,881 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:41,883 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.net.ConnectException: Connection refused for usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766., try=10 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:41,884 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:41,883 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned java.io.IOException: This connection is closing for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=9 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:41,884 WARN  [AM.-pool1-t1] master.RegionStates: Failed to open/close a61c032ae7202dd4d9377544ae61f766 on slave1,16020,1407932754742, set to FAILED_CLOSE
2014-08-13 05:26:41,886 INFO  [AM.-pool1-t1] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=PENDING_OPEN, ts=1407932787805, server=slave1,16020,1407932754742} to {a61c032ae7202dd4d9377544ae61f766 state=FAILED_CLOSE, ts=1407932801886, server=slave1,16020,1407932754742}
2014-08-13 05:26:41,887 INFO  [AM.-pool1-t1] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=FAILED_CLOSE
2014-08-13 05:26:41,893 INFO  [AM.-pool1-t1] master.AssignmentManager: Skip assigning {ENCODED => a61c032ae7202dd4d9377544ae61f766, NAME => 'usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766.', STARTKEY => 'user8', ENDKEY => 'user9'}, we couldn't close it: {a61c032ae7202dd4d9377544ae61f766 state=FAILED_CLOSE, ts=1407932801886, server=slave1,16020,1407932754742}
2014-08-13 05:26:42,894 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Timed out on waiting for a61c032ae7202dd4d9377544ae61f766 to be assigned.
2014-08-13 05:26:42,895 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Region a61c032ae7202dd4d9377544ae61f766 didn't complete assignment in time
2014-08-13 05:26:42,895 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for 97e3f5dae1052ab6f8c8c95d648d22ee to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:26:43,887 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750., try=10 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:43,888 WARN  [AM.-pool1-t5] master.RegionStates: Failed to open/close 7620ecf4f35847960d5a5ac255c36750 on slave1,16020,1407932754742, set to FAILED_CLOSE
2014-08-13 05:26:43,888 INFO  [AM.-pool1-t5] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=PENDING_OPEN, ts=1407932787824, server=slave1,16020,1407932754742} to {7620ecf4f35847960d5a5ac255c36750 state=FAILED_CLOSE, ts=1407932803888, server=slave1,16020,1407932754742}
2014-08-13 05:26:43,888 INFO  [AM.-pool1-t5] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=FAILED_CLOSE
2014-08-13 05:26:43,888 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407932754742 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee., try=10 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-13 05:26:43,889 WARN  [AM.-pool1-t2] master.RegionStates: Failed to open/close 97e3f5dae1052ab6f8c8c95d648d22ee on slave1,16020,1407932754742, set to FAILED_CLOSE
2014-08-13 05:26:43,890 INFO  [AM.-pool1-t2] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932787810, server=slave1,16020,1407932754742} to {97e3f5dae1052ab6f8c8c95d648d22ee state=FAILED_CLOSE, ts=1407932803890, server=slave1,16020,1407932754742}
2014-08-13 05:26:43,890 INFO  [AM.-pool1-t2] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=FAILED_CLOSE
2014-08-13 05:26:43,895 INFO  [AM.-pool1-t5] master.AssignmentManager: Skip assigning {ENCODED => 7620ecf4f35847960d5a5ac255c36750, NAME => 'usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750.', STARTKEY => 'user2', ENDKEY => 'user3'}, we couldn't close it: {7620ecf4f35847960d5a5ac255c36750 state=FAILED_CLOSE, ts=1407932803888, server=slave1,16020,1407932754742}
2014-08-13 05:26:43,896 INFO  [AM.-pool1-t2] master.AssignmentManager: Skip assigning {ENCODED => 97e3f5dae1052ab6f8c8c95d648d22ee, NAME => 'usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee.', STARTKEY => 'user5', ENDKEY => 'user6'}, we couldn't close it: {97e3f5dae1052ab6f8c8c95d648d22ee state=FAILED_CLOSE, ts=1407932803890, server=slave1,16020,1407932754742}
2014-08-13 05:26:53,110 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Timed out on waiting for afc8a0671e30be06e10dcf4187e202de to be assigned.
2014-08-13 05:26:53,110 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Region afc8a0671e30be06e10dcf4187e202de didn't complete assignment in time
2014-08-13 05:26:53,110 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Waiting for 97e3f5dae1052ab6f8c8c95d648d22ee to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:26:57,916 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Timed out on waiting for 97e3f5dae1052ab6f8c8c95d648d22ee to be assigned.
2014-08-13 05:26:57,916 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Region 97e3f5dae1052ab6f8c8c95d648d22ee didn't complete assignment in time
2014-08-13 05:26:57,916 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for 1e1eb564c9225f75a48fcbea8b612775 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:05,771 INFO  [defaultRpcServer.handler=9,queue=4,port=16020] master.ServerManager: Registering server=slave1,16020,1407932822898
2014-08-13 05:27:05,771 INFO  [defaultRpcServer.handler=9,queue=4,port=16020] master.ServerManager: Triggering server recovery; existingServer slave1,16020,1407932754742 looks stale, new server:slave1,16020,1407932822898
2014-08-13 05:27:05,776 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407932754742 before assignment.
2014-08-13 05:27:05,776 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-13 05:27:05,783 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=OPEN, ts=1407932783018, server=slave1,16020,1407932754742} to {b4897f073e60e8bc63a6f8d119db34bb state=OFFLINE, ts=1407932825783, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,783 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=OFFLINE
2014-08-13 05:27:05,790 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {a61c032ae7202dd4d9377544ae61f766 state=FAILED_CLOSE, ts=1407932801886, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,790 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {ee08c27660ca7f31ba19c03b35631d5a state=PENDING_OPEN, ts=1407932782184, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,790 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {afc8a0671e30be06e10dcf4187e202de state=PENDING_OPEN, ts=1407932782179, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,790 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {42fbdcf382e2db1e95e5166bd67a2a96 state=PENDING_OPEN, ts=1407932782189, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,790 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {97e3f5dae1052ab6f8c8c95d648d22ee state=FAILED_CLOSE, ts=1407932803890, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,791 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {1e1eb564c9225f75a48fcbea8b612775 state=FAILED_CLOSE, ts=1407932797875, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,791 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {8df07d02d8b56c1fa06b11867df8e19d state=FAILED_CLOSE, ts=1407932799880, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,791 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {7620ecf4f35847960d5a5ac255c36750 state=FAILED_CLOSE, ts=1407932803888, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,791 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Found region in {ddeef26cf0d47188f4271d7ea65eefe0 state=PENDING_OPEN, ts=1407932782193, server=slave1,16020,1407932754742} to be reassigned by SSH for slave1,16020,1407932754742
2014-08-13 05:27:05,793 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/a61c032ae7202dd4d9377544ae61f766 already deleted, retry=false
2014-08-13 05:27:05,793 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=FAILED_CLOSE, ts=1407932801886, server=slave1,16020,1407932754742} to {a61c032ae7202dd4d9377544ae61f766 state=OFFLINE, ts=1407932825793, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,793 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=OFFLINE
2014-08-13 05:27:05,798 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/ee08c27660ca7f31ba19c03b35631d5a already deleted, retry=false
2014-08-13 05:27:05,798 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {ee08c27660ca7f31ba19c03b35631d5a state=PENDING_OPEN, ts=1407932782184, server=slave1,16020,1407932754742} to {ee08c27660ca7f31ba19c03b35631d5a state=OFFLINE, ts=1407932825798, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,798 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a. with state=OFFLINE
2014-08-13 05:27:05,803 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/afc8a0671e30be06e10dcf4187e202de already deleted, retry=false
2014-08-13 05:27:05,803 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {afc8a0671e30be06e10dcf4187e202de state=PENDING_OPEN, ts=1407932782179, server=slave1,16020,1407932754742} to {afc8a0671e30be06e10dcf4187e202de state=OFFLINE, ts=1407932825803, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,803 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de. with state=OFFLINE
2014-08-13 05:27:05,807 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/42fbdcf382e2db1e95e5166bd67a2a96 already deleted, retry=false
2014-08-13 05:27:05,807 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {42fbdcf382e2db1e95e5166bd67a2a96 state=PENDING_OPEN, ts=1407932782189, server=slave1,16020,1407932754742} to {42fbdcf382e2db1e95e5166bd67a2a96 state=OFFLINE, ts=1407932825807, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,807 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96. with state=OFFLINE
2014-08-13 05:27:05,812 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/97e3f5dae1052ab6f8c8c95d648d22ee already deleted, retry=false
2014-08-13 05:27:05,812 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=FAILED_CLOSE, ts=1407932803890, server=slave1,16020,1407932754742} to {97e3f5dae1052ab6f8c8c95d648d22ee state=OFFLINE, ts=1407932825812, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,812 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=OFFLINE
2014-08-13 05:27:05,816 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/1e1eb564c9225f75a48fcbea8b612775 already deleted, retry=false
2014-08-13 05:27:05,817 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=FAILED_CLOSE, ts=1407932797875, server=slave1,16020,1407932754742} to {1e1eb564c9225f75a48fcbea8b612775 state=OFFLINE, ts=1407932825817, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,817 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=OFFLINE
2014-08-13 05:27:05,825 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/8df07d02d8b56c1fa06b11867df8e19d already deleted, retry=false
2014-08-13 05:27:05,825 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=FAILED_CLOSE, ts=1407932799880, server=slave1,16020,1407932754742} to {8df07d02d8b56c1fa06b11867df8e19d state=OFFLINE, ts=1407932825825, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,825 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=OFFLINE
2014-08-13 05:27:05,830 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/7620ecf4f35847960d5a5ac255c36750 already deleted, retry=false
2014-08-13 05:27:05,830 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=FAILED_CLOSE, ts=1407932803888, server=slave1,16020,1407932754742} to {7620ecf4f35847960d5a5ac255c36750 state=OFFLINE, ts=1407932825830, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,830 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=OFFLINE
2014-08-13 05:27:05,837 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/ddeef26cf0d47188f4271d7ea65eefe0 already deleted, retry=false
2014-08-13 05:27:05,837 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {ddeef26cf0d47188f4271d7ea65eefe0 state=PENDING_OPEN, ts=1407932782193, server=slave1,16020,1407932754742} to {ddeef26cf0d47188f4271d7ea65eefe0 state=OFFLINE, ts=1407932825837, server=slave1,16020,1407932754742}
2014-08-13 05:27:05,837 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0. with state=OFFLINE
2014-08-13 05:27:05,839 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] handler.ServerShutdownHandler: Reassigning 1 region(s) that slave1,16020,1407932754742 was carrying (and 9 regions(s) that were opening on this server)
2014-08-13 05:27:05,841 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Assigning 10 region(s) to slave1,16020,1407932822898
2014-08-13 05:27:05,841 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=OFFLINE, ts=1407932825793, server=slave1,16020,1407932754742} to {a61c032ae7202dd4d9377544ae61f766 state=PENDING_OPEN, ts=1407932825841, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,841 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,844 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {ee08c27660ca7f31ba19c03b35631d5a state=OFFLINE, ts=1407932825798, server=slave1,16020,1407932754742} to {ee08c27660ca7f31ba19c03b35631d5a state=PENDING_OPEN, ts=1407932825844, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,844 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,846 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {afc8a0671e30be06e10dcf4187e202de state=OFFLINE, ts=1407932825803, server=slave1,16020,1407932754742} to {afc8a0671e30be06e10dcf4187e202de state=PENDING_OPEN, ts=1407932825846, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,846 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,849 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {42fbdcf382e2db1e95e5166bd67a2a96 state=OFFLINE, ts=1407932825807, server=slave1,16020,1407932754742} to {42fbdcf382e2db1e95e5166bd67a2a96 state=PENDING_OPEN, ts=1407932825849, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,849 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,851 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=OFFLINE, ts=1407932825812, server=slave1,16020,1407932754742} to {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932825851, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,851 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,853 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=OFFLINE, ts=1407932825817, server=slave1,16020,1407932754742} to {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932825853, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,853 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,856 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=OFFLINE, ts=1407932825825, server=slave1,16020,1407932754742} to {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_OPEN, ts=1407932825856, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,856 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,858 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=OFFLINE, ts=1407932825830, server=slave1,16020,1407932754742} to {7620ecf4f35847960d5a5ac255c36750 state=PENDING_OPEN, ts=1407932825858, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,858 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,860 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {ddeef26cf0d47188f4271d7ea65eefe0 state=OFFLINE, ts=1407932825837, server=slave1,16020,1407932754742} to {ddeef26cf0d47188f4271d7ea65eefe0 state=PENDING_OPEN, ts=1407932825860, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,860 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:05,863 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=OFFLINE, ts=1407932825783, server=slave1,16020,1407932754742} to {b4897f073e60e8bc63a6f8d119db34bb state=PENDING_OPEN, ts=1407932825863, server=slave1,16020,1407932822898}
2014-08-13 05:27:05,863 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:27:06,697 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Waiting for a61c032ae7202dd4d9377544ae61f766 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,128 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStates: Transition {afc8a0671e30be06e10dcf4187e202de state=PENDING_OPEN, ts=1407932825846, server=slave1,16020,1407932822898} to {afc8a0671e30be06e10dcf4187e202de state=OPEN, ts=1407932827128, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,128 INFO  [defaultRpcServer.handler=17,queue=2,port=16020] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=PENDING_OPEN, ts=1407932825841, server=slave1,16020,1407932822898} to {a61c032ae7202dd4d9377544ae61f766 state=OPEN, ts=1407932827128, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,128 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de. with state=OPEN&openSeqNum=80002356&server=slave1,16020,1407932822898
2014-08-13 05:27:07,128 INFO  [defaultRpcServer.handler=17,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=OPEN&openSeqNum=80002382&server=slave1,16020,1407932822898
2014-08-13 05:27:07,134 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStates: Onlined afc8a0671e30be06e10dcf4187e202de on slave1,16020,1407932822898
2014-08-13 05:27:07,134 INFO  [defaultRpcServer.handler=17,queue=2,port=16020] master.RegionStates: Onlined a61c032ae7202dd4d9377544ae61f766 on slave1,16020,1407932822898
2014-08-13 05:27:07,134 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Waiting for ee08c27660ca7f31ba19c03b35631d5a to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,157 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStates: Transition {ee08c27660ca7f31ba19c03b35631d5a state=PENDING_OPEN, ts=1407932825844, server=slave1,16020,1407932822898} to {ee08c27660ca7f31ba19c03b35631d5a state=OPEN, ts=1407932827157, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,157 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a. with state=OPEN&openSeqNum=80002254&server=slave1,16020,1407932822898
2014-08-13 05:27:07,161 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStates: Onlined ee08c27660ca7f31ba19c03b35631d5a on slave1,16020,1407932822898
2014-08-13 05:27:07,161 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Waiting for 42fbdcf382e2db1e95e5166bd67a2a96 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,251 INFO  [defaultRpcServer.handler=25,queue=0,port=16020] master.RegionStates: Transition {42fbdcf382e2db1e95e5166bd67a2a96 state=PENDING_OPEN, ts=1407932825849, server=slave1,16020,1407932822898} to {42fbdcf382e2db1e95e5166bd67a2a96 state=OPEN, ts=1407932827251, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,251 INFO  [defaultRpcServer.handler=25,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96. with state=OPEN&openSeqNum=80002292&server=slave1,16020,1407932822898
2014-08-13 05:27:07,255 INFO  [defaultRpcServer.handler=25,queue=0,port=16020] master.RegionStates: Onlined 42fbdcf382e2db1e95e5166bd67a2a96 on slave1,16020,1407932822898
2014-08-13 05:27:07,255 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Waiting for 97e3f5dae1052ab6f8c8c95d648d22ee to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,284 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_OPEN, ts=1407932825851, server=slave1,16020,1407932822898} to {97e3f5dae1052ab6f8c8c95d648d22ee state=OPEN, ts=1407932827284, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,284 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=OPEN&openSeqNum=80002204&server=slave1,16020,1407932822898
2014-08-13 05:27:07,288 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] master.RegionStates: Onlined 97e3f5dae1052ab6f8c8c95d648d22ee on slave1,16020,1407932822898
2014-08-13 05:27:07,288 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Waiting for 7620ecf4f35847960d5a5ac255c36750 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,288 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Waiting for 1e1eb564c9225f75a48fcbea8b612775 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,347 INFO  [defaultRpcServer.handler=22,queue=2,port=16020] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_OPEN, ts=1407932825853, server=slave1,16020,1407932822898} to {1e1eb564c9225f75a48fcbea8b612775 state=OPEN, ts=1407932827346, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,347 INFO  [defaultRpcServer.handler=22,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=OPEN&openSeqNum=80002105&server=slave1,16020,1407932822898
2014-08-13 05:27:07,355 INFO  [defaultRpcServer.handler=22,queue=2,port=16020] master.RegionStates: Onlined 1e1eb564c9225f75a48fcbea8b612775 on slave1,16020,1407932822898
2014-08-13 05:27:07,356 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Waiting for 8df07d02d8b56c1fa06b11867df8e19d to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,356 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for 8df07d02d8b56c1fa06b11867df8e19d to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,400 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_OPEN, ts=1407932825856, server=slave1,16020,1407932822898} to {8df07d02d8b56c1fa06b11867df8e19d state=OPEN, ts=1407932827400, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,400 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=OPEN&openSeqNum=80002140&server=slave1,16020,1407932822898
2014-08-13 05:27:07,404 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Onlined 8df07d02d8b56c1fa06b11867df8e19d on slave1,16020,1407932822898
2014-08-13 05:27:07,405 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.AssignmentManager: Waiting for 7620ecf4f35847960d5a5ac255c36750 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,405 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Waiting for 7620ecf4f35847960d5a5ac255c36750 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:27:07,418 INFO  [defaultRpcServer.handler=16,queue=1,port=16020] master.RegionStates: Transition {ddeef26cf0d47188f4271d7ea65eefe0 state=PENDING_OPEN, ts=1407932825860, server=slave1,16020,1407932822898} to {ddeef26cf0d47188f4271d7ea65eefe0 state=OPEN, ts=1407932827418, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,418 INFO  [defaultRpcServer.handler=16,queue=1,port=16020] master.RegionStateStore: Updating row usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0. with state=OPEN&openSeqNum=40000002&server=slave1,16020,1407932822898
2014-08-13 05:27:07,421 INFO  [defaultRpcServer.handler=16,queue=1,port=16020] master.RegionStates: Onlined ddeef26cf0d47188f4271d7ea65eefe0 on slave1,16020,1407932822898
2014-08-13 05:27:07,503 INFO  [defaultRpcServer.handler=19,queue=4,port=16020] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=PENDING_OPEN, ts=1407932825863, server=slave1,16020,1407932822898} to {b4897f073e60e8bc63a6f8d119db34bb state=OPEN, ts=1407932827503, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,504 INFO  [defaultRpcServer.handler=19,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=OPEN&openSeqNum=80002448&server=slave1,16020,1407932822898
2014-08-13 05:27:07,507 INFO  [defaultRpcServer.handler=19,queue=4,port=16020] master.RegionStates: Onlined b4897f073e60e8bc63a6f8d119db34bb on slave1,16020,1407932822898
2014-08-13 05:27:07,509 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=PENDING_OPEN, ts=1407932825858, server=slave1,16020,1407932822898} to {7620ecf4f35847960d5a5ac255c36750 state=OPEN, ts=1407932827509, server=slave1,16020,1407932822898}
2014-08-13 05:27:07,509 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=OPEN&openSeqNum=80002484&server=slave1,16020,1407932822898
2014-08-13 05:27:07,511 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStates: Onlined 7620ecf4f35847960d5a5ac255c36750 on slave1,16020,1407932822898
2014-08-13 05:27:07,523 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.MasterFileSystem: Log dir for server slave1,16020,1407932445757 does not exist
2014-08-13 05:27:07,523 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: dead splitlog workers [slave1,16020,1407932445757]
2014-08-13 05:27:07,523 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: started splitting 0 logs in []
2014-08-13 05:27:07,524 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.MasterFileSystem: Log dir for server sceplus-vm49.almaden.ibm.com,16020,1407932754742 does not exist
2014-08-13 05:27:07,524 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: dead splitlog workers [sceplus-vm49.almaden.ibm.com,16020,1407932754742]
2014-08-13 05:27:07,524 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: started splitting 0 logs in []
2014-08-13 05:27:07,565 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: dead splitlog workers [slave1,16020,1407932754742]
2014-08-13 05:27:07,570 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: started splitting 1 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742-splitting]
2014-08-13 05:27:07,588 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932754742-splitting%2Fslave1%252C16020%252C1407932754742.1407932776560
2014-08-13 05:27:07,589 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932754742-splitting%2Fslave1%252C16020%252C1407932754742.1407932776560 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:27:07,617 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 94ms
2014-08-13 05:27:07,618 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407932445757
2014-08-13 05:27:07,620 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 96ms
2014-08-13 05:27:07,620 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.LogReplayHandler: Finished processing shutdown of sceplus-vm49.almaden.ibm.com,16020,1407932754742
2014-08-13 05:27:07,634 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742-splitting/slave1%2C16020%2C1407932754742.1407932776560, length=17
2014-08-13 05:27:07,634 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:27:07,638 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742-splitting/slave1%2C16020%2C1407932754742.1407932776560
2014-08-13 05:27:07,651 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742-splitting/slave1%2C16020%2C1407932754742.1407932776560 after 13ms
2014-08-13 05:27:07,672 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:27:07,672 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742-splitting/slave1%2C16020%2C1407932754742.1407932776560 is corrupted = false progress failed = false
2014-08-13 05:27:07,676 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932754742-splitting%2Fslave1%252C16020%252C1407932754742.1407932776560 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:27:07,677 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932754742-splitting%2Fslave1%252C16020%252C1407932754742.1407932776560 in 84ms
2014-08-13 05:27:07,677 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932754742-splitting%2Fslave1%252C16020%252C1407932754742.1407932776560 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:27:07,705 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742-splitting/slave1%2C16020%2C1407932754742.1407932776560 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932754742.1407932776560
2014-08-13 05:27:07,709 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932754742-splitting%2Fslave1%252C16020%252C1407932754742.1407932776560
2014-08-13 05:27:07,731 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: finished splitting (more than or equal to) 17 bytes in 1 log files in [hdfs://master:54310/hbase/WALs/slave1,16020,1407932754742-splitting] in 161ms
2014-08-13 05:27:07,732 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407932754742
2014-08-13 05:27:10,472 INFO  [defaultRpcServer.handler=35,queue=0,port=16020] master.HMaster: Client=hadoop//9.1.143.58 disable usertable
2014-08-13 05:27:10,519 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.DisableTableHandler: Attempting to disable table usertable
2014-08-13 05:27:10,520 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from DISABLING to DISABLING
2014-08-13 05:27:10,526 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.DisableTableHandler: Offlining 10 regions.
2014-08-13 05:27:10,533 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transition {ddeef26cf0d47188f4271d7ea65eefe0 state=OPEN, ts=1407932827418, server=slave1,16020,1407932822898} to {ddeef26cf0d47188f4271d7ea65eefe0 state=PENDING_CLOSE, ts=1407932830533, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,533 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStateStore: Updating row usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0. with state=PENDING_CLOSE
2014-08-13 05:27:10,534 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-1] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=OPEN, ts=1407932827503, server=slave1,16020,1407932822898} to {b4897f073e60e8bc63a6f8d119db34bb state=PENDING_CLOSE, ts=1407932830534, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,536 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-2] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=OPEN, ts=1407932827509, server=slave1,16020,1407932822898} to {7620ecf4f35847960d5a5ac255c36750 state=PENDING_CLOSE, ts=1407932830536, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,536 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-1] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=PENDING_CLOSE
2014-08-13 05:27:10,536 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-2] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=PENDING_CLOSE
2014-08-13 05:27:10,537 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-3] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=OPEN, ts=1407932827346, server=slave1,16020,1407932822898} to {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_CLOSE, ts=1407932830537, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,540 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-3] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=PENDING_CLOSE
2014-08-13 05:27:10,540 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-4] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=OPEN, ts=1407932827400, server=slave1,16020,1407932822898} to {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_CLOSE, ts=1407932830540, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,540 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-4] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=PENDING_CLOSE
2014-08-13 05:27:10,542 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-5] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=OPEN, ts=1407932827284, server=slave1,16020,1407932822898} to {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_CLOSE, ts=1407932830542, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,543 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-5] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=PENDING_CLOSE
2014-08-13 05:27:10,546 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-6] master.RegionStates: Transition {afc8a0671e30be06e10dcf4187e202de state=OPEN, ts=1407932827128, server=slave1,16020,1407932822898} to {afc8a0671e30be06e10dcf4187e202de state=PENDING_CLOSE, ts=1407932830546, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,546 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-6] master.RegionStateStore: Updating row usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de. with state=PENDING_CLOSE
2014-08-13 05:27:10,549 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-7] master.RegionStates: Transition {ee08c27660ca7f31ba19c03b35631d5a state=OPEN, ts=1407932827157, server=slave1,16020,1407932822898} to {ee08c27660ca7f31ba19c03b35631d5a state=PENDING_CLOSE, ts=1407932830549, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,549 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-9] master.RegionStates: Transition {42fbdcf382e2db1e95e5166bd67a2a96 state=OPEN, ts=1407932827251, server=slave1,16020,1407932822898} to {42fbdcf382e2db1e95e5166bd67a2a96 state=PENDING_CLOSE, ts=1407932830549, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,549 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-8] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=OPEN, ts=1407932827128, server=slave1,16020,1407932822898} to {a61c032ae7202dd4d9377544ae61f766 state=PENDING_CLOSE, ts=1407932830549, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,550 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-9] master.RegionStateStore: Updating row usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96. with state=PENDING_CLOSE
2014-08-13 05:27:10,550 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-7] master.RegionStateStore: Updating row usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a. with state=PENDING_CLOSE
2014-08-13 05:27:10,551 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-8] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=PENDING_CLOSE
2014-08-13 05:27:10,649 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStates: Transition {afc8a0671e30be06e10dcf4187e202de state=PENDING_CLOSE, ts=1407932830546, server=slave1,16020,1407932822898} to {afc8a0671e30be06e10dcf4187e202de state=OFFLINE, ts=1407932830649, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,650 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStates: Transition {97e3f5dae1052ab6f8c8c95d648d22ee state=PENDING_CLOSE, ts=1407932830542, server=slave1,16020,1407932822898} to {97e3f5dae1052ab6f8c8c95d648d22ee state=OFFLINE, ts=1407932830649, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,650 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de. with state=OFFLINE
2014-08-13 05:27:10,650 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee. with state=OFFLINE
2014-08-13 05:27:10,650 INFO  [defaultRpcServer.handler=36,queue=1,port=16020] master.RegionStates: Transition {8df07d02d8b56c1fa06b11867df8e19d state=PENDING_CLOSE, ts=1407932830540, server=slave1,16020,1407932822898} to {8df07d02d8b56c1fa06b11867df8e19d state=OFFLINE, ts=1407932830650, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,650 INFO  [defaultRpcServer.handler=36,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d. with state=OFFLINE
2014-08-13 05:27:10,653 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStates: Offlined afc8a0671e30be06e10dcf4187e202de from slave1,16020,1407932822898
2014-08-13 05:27:10,654 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStates: Offlined 97e3f5dae1052ab6f8c8c95d648d22ee from slave1,16020,1407932822898
2014-08-13 05:27:10,655 INFO  [defaultRpcServer.handler=36,queue=1,port=16020] master.RegionStates: Offlined 8df07d02d8b56c1fa06b11867df8e19d from slave1,16020,1407932822898
2014-08-13 05:27:10,663 INFO  [defaultRpcServer.handler=41,queue=1,port=16020] master.RegionStates: Transition {ddeef26cf0d47188f4271d7ea65eefe0 state=PENDING_CLOSE, ts=1407932830533, server=slave1,16020,1407932822898} to {ddeef26cf0d47188f4271d7ea65eefe0 state=OFFLINE, ts=1407932830663, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,663 INFO  [defaultRpcServer.handler=41,queue=1,port=16020] master.RegionStateStore: Updating row usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0. with state=OFFLINE
2014-08-13 05:27:10,663 INFO  [defaultRpcServer.handler=18,queue=3,port=16020] master.RegionStates: Transition {b4897f073e60e8bc63a6f8d119db34bb state=PENDING_CLOSE, ts=1407932830534, server=slave1,16020,1407932822898} to {b4897f073e60e8bc63a6f8d119db34bb state=OFFLINE, ts=1407932830663, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,664 INFO  [defaultRpcServer.handler=18,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb. with state=OFFLINE
2014-08-13 05:27:10,666 INFO  [defaultRpcServer.handler=41,queue=1,port=16020] master.RegionStates: Offlined ddeef26cf0d47188f4271d7ea65eefe0 from slave1,16020,1407932822898
2014-08-13 05:27:10,668 INFO  [defaultRpcServer.handler=18,queue=3,port=16020] master.RegionStates: Offlined b4897f073e60e8bc63a6f8d119db34bb from slave1,16020,1407932822898
2014-08-13 05:27:10,670 INFO  [defaultRpcServer.handler=24,queue=4,port=16020] master.RegionStates: Transition {42fbdcf382e2db1e95e5166bd67a2a96 state=PENDING_CLOSE, ts=1407932830549, server=slave1,16020,1407932822898} to {42fbdcf382e2db1e95e5166bd67a2a96 state=OFFLINE, ts=1407932830670, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,670 INFO  [defaultRpcServer.handler=24,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96. with state=OFFLINE
2014-08-13 05:27:10,673 INFO  [defaultRpcServer.handler=37,queue=2,port=16020] master.RegionStates: Transition {7620ecf4f35847960d5a5ac255c36750 state=PENDING_CLOSE, ts=1407932830536, server=slave1,16020,1407932822898} to {7620ecf4f35847960d5a5ac255c36750 state=OFFLINE, ts=1407932830673, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,673 INFO  [defaultRpcServer.handler=37,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750. with state=OFFLINE
2014-08-13 05:27:10,675 INFO  [defaultRpcServer.handler=24,queue=4,port=16020] master.RegionStates: Offlined 42fbdcf382e2db1e95e5166bd67a2a96 from slave1,16020,1407932822898
2014-08-13 05:27:10,676 INFO  [defaultRpcServer.handler=40,queue=0,port=16020] master.RegionStates: Transition {ee08c27660ca7f31ba19c03b35631d5a state=PENDING_CLOSE, ts=1407932830549, server=slave1,16020,1407932822898} to {ee08c27660ca7f31ba19c03b35631d5a state=OFFLINE, ts=1407932830676, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,676 INFO  [defaultRpcServer.handler=40,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a. with state=OFFLINE
2014-08-13 05:27:10,677 INFO  [defaultRpcServer.handler=37,queue=2,port=16020] master.RegionStates: Offlined 7620ecf4f35847960d5a5ac255c36750 from slave1,16020,1407932822898
2014-08-13 05:27:10,679 INFO  [defaultRpcServer.handler=40,queue=0,port=16020] master.RegionStates: Offlined ee08c27660ca7f31ba19c03b35631d5a from slave1,16020,1407932822898
2014-08-13 05:27:10,682 INFO  [defaultRpcServer.handler=45,queue=0,port=16020] master.RegionStates: Transition {1e1eb564c9225f75a48fcbea8b612775 state=PENDING_CLOSE, ts=1407932830537, server=slave1,16020,1407932822898} to {1e1eb564c9225f75a48fcbea8b612775 state=OFFLINE, ts=1407932830682, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,682 INFO  [defaultRpcServer.handler=45,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775. with state=OFFLINE
2014-08-13 05:27:10,685 INFO  [defaultRpcServer.handler=45,queue=0,port=16020] master.RegionStates: Offlined 1e1eb564c9225f75a48fcbea8b612775 from slave1,16020,1407932822898
2014-08-13 05:27:10,910 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStates: Transition {a61c032ae7202dd4d9377544ae61f766 state=PENDING_CLOSE, ts=1407932830549, server=slave1,16020,1407932822898} to {a61c032ae7202dd4d9377544ae61f766 state=OFFLINE, ts=1407932830910, server=slave1,16020,1407932822898}
2014-08-13 05:27:10,910 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766. with state=OFFLINE
2014-08-13 05:27:10,913 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStates: Offlined a61c032ae7202dd4d9377544ae61f766 from slave1,16020,1407932822898
2014-08-13 05:27:11,549 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from DISABLING to DISABLED
2014-08-13 05:27:11,553 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.DisableTableHandler: Disabled table, usertable, is done=true
2014-08-13 05:27:11,847 INFO  [defaultRpcServer.handler=23,queue=3,port=16020] master.HMaster: Client=hadoop//9.1.143.58 delete usertable
2014-08-13 05:27:11,872 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table usertable
2014-08-13 05:27:11,951 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] hbase.MetaTableAccessor: Deleted [{ENCODED => ddeef26cf0d47188f4271d7ea65eefe0, NAME => 'usertable,,1407931738075.ddeef26cf0d47188f4271d7ea65eefe0.', STARTKEY => '', ENDKEY => 'user1'}, {ENCODED => b4897f073e60e8bc63a6f8d119db34bb, NAME => 'usertable,user1,1407931738075.b4897f073e60e8bc63a6f8d119db34bb.', STARTKEY => 'user1', ENDKEY => 'user2'}, {ENCODED => 7620ecf4f35847960d5a5ac255c36750, NAME => 'usertable,user2,1407931738075.7620ecf4f35847960d5a5ac255c36750.', STARTKEY => 'user2', ENDKEY => 'user3'}, {ENCODED => 1e1eb564c9225f75a48fcbea8b612775, NAME => 'usertable,user3,1407931738075.1e1eb564c9225f75a48fcbea8b612775.', STARTKEY => 'user3', ENDKEY => 'user4'}, {ENCODED => 8df07d02d8b56c1fa06b11867df8e19d, NAME => 'usertable,user4,1407931738075.8df07d02d8b56c1fa06b11867df8e19d.', STARTKEY => 'user4', ENDKEY => 'user5'}, {ENCODED => 97e3f5dae1052ab6f8c8c95d648d22ee, NAME => 'usertable,user5,1407931738075.97e3f5dae1052ab6f8c8c95d648d22ee.', STARTKEY => 'user5', ENDKEY => 'user6'}, {ENCODED => afc8a0671e30be06e10dcf4187e202de, NAME => 'usertable,user6,1407931738075.afc8a0671e30be06e10dcf4187e202de.', STARTKEY => 'user6', ENDKEY => 'user7'}, {ENCODED => ee08c27660ca7f31ba19c03b35631d5a, NAME => 'usertable,user7,1407931738075.ee08c27660ca7f31ba19c03b35631d5a.', STARTKEY => 'user7', ENDKEY => 'user8'}, {ENCODED => a61c032ae7202dd4d9377544ae61f766, NAME => 'usertable,user8,1407931738075.a61c032ae7202dd4d9377544ae61f766.', STARTKEY => 'user8', ENDKEY => 'user9'}, {ENCODED => 42fbdcf382e2db1e95e5166bd67a2a96, NAME => 'usertable,user9,1407931738075.42fbdcf382e2db1e95e5166bd67a2a96.', STARTKEY => 'user9', ENDKEY => ''}]
2014-08-13 05:27:12,629 INFO  [PriorityRpcServer.handler=2,queue=0,port=16020] regionserver.RSRpcServices: Compacting hbase:meta,,1.1588230740
2014-08-13 05:27:12,635 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407932832634] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-08-13 05:27:12,637 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407932832634] regionserver.HStore: Starting compaction of 1 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=26.5 K
2014-08-13 05:27:12,640 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407932832634] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:27:12,836 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407932832634] regionserver.HStore: Completed major compaction of 1 (all) file(s) in info of hbase:meta,,1.1588230740 into cfc7097b017c4ace891171612f35b3ce(size=25.8 K), total size for store is 25.8 K. This selection was in queue for 0sec, and took 0sec to execute.
2014-08-13 05:27:12,841 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407932832634] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=1, fileSize=26.5 K, priority=1, time=1591239996128816; duration=0sec
2014-08-13 05:28:21,305 INFO  [defaultRpcServer.handler=10,queue=0,port=16020] compress.CodecPool: Got brand-new compressor [.gz]
2014-08-13 05:28:21,306 INFO  [defaultRpcServer.handler=10,queue=0,port=16020] master.HMaster: Client=hadoop//9.1.143.58 create 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-08-13 05:28:21,361 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.CreateTableHandler: Create table usertable
2014-08-13 05:28:21,414 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,414 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,415 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,415 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,415 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,416 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,417 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,417 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,417 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,418 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-13 05:28:21,469 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: Closed usertable,,1407932901296.c2381157c28448b5d8ebe79568d1ec12.
2014-08-13 05:28:21,473 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: Closed usertable,user4,1407932901296.13c70b99a242fd3f20739a3f1d8efd82.
2014-08-13 05:28:21,474 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: Closed usertable,user3,1407932901296.02a81f884b512b228f14ed6e340777e2.
2014-08-13 05:28:21,478 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: Closed usertable,user7,1407932901296.d343b193952e1d75f5f6046a051771d8.
2014-08-13 05:28:21,485 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: Closed usertable,user8,1407932901296.5c41fa17f4b842ff55849d85aa55d5f4.
2014-08-13 05:28:21,486 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: Closed usertable,user1,1407932901296.c640592e3f14a007ce12a364cfe69273.
2014-08-13 05:28:21,487 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: Closed usertable,user5,1407932901296.f5a391c3d60cfddbd50b21629d534258.
2014-08-13 05:28:21,488 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: Closed usertable,user6,1407932901296.cdbad283e1c8378f2a3266a7ed0ced3f.
2014-08-13 05:28:21,488 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: Closed usertable,user9,1407932901296.32ea3b7cd0d8b4e9f0c318aa71dd29ad.
2014-08-13 05:28:21,526 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: Closed usertable,user2,1407932901296.7e3dbba374f40008ae52e34ad3e4fef1.
2014-08-13 05:28:21,548 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] hbase.MetaTableAccessor: Added 10
2014-08-13 05:28:21,601 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Assigning 10 region(s) to slave1,16020,1407932822898
2014-08-13 05:28:21,602 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {c2381157c28448b5d8ebe79568d1ec12 state=OFFLINE, ts=1407932901549, server=null} to {c2381157c28448b5d8ebe79568d1ec12 state=PENDING_OPEN, ts=1407932901602, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,602 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,,1407932901296.c2381157c28448b5d8ebe79568d1ec12. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,606 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {13c70b99a242fd3f20739a3f1d8efd82 state=OFFLINE, ts=1407932901549, server=null} to {13c70b99a242fd3f20739a3f1d8efd82 state=PENDING_OPEN, ts=1407932901606, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,606 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user4,1407932901296.13c70b99a242fd3f20739a3f1d8efd82. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,610 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {02a81f884b512b228f14ed6e340777e2 state=OFFLINE, ts=1407932901549, server=null} to {02a81f884b512b228f14ed6e340777e2 state=PENDING_OPEN, ts=1407932901610, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,610 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user3,1407932901296.02a81f884b512b228f14ed6e340777e2. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,614 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {d343b193952e1d75f5f6046a051771d8 state=OFFLINE, ts=1407932901550, server=null} to {d343b193952e1d75f5f6046a051771d8 state=PENDING_OPEN, ts=1407932901614, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,614 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user7,1407932901296.d343b193952e1d75f5f6046a051771d8. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,617 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {5c41fa17f4b842ff55849d85aa55d5f4 state=OFFLINE, ts=1407932901550, server=null} to {5c41fa17f4b842ff55849d85aa55d5f4 state=PENDING_OPEN, ts=1407932901617, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,617 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user8,1407932901296.5c41fa17f4b842ff55849d85aa55d5f4. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,619 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {c640592e3f14a007ce12a364cfe69273 state=OFFLINE, ts=1407932901551, server=null} to {c640592e3f14a007ce12a364cfe69273 state=PENDING_OPEN, ts=1407932901619, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,620 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user1,1407932901296.c640592e3f14a007ce12a364cfe69273. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,622 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {f5a391c3d60cfddbd50b21629d534258 state=OFFLINE, ts=1407932901551, server=null} to {f5a391c3d60cfddbd50b21629d534258 state=PENDING_OPEN, ts=1407932901622, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,622 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user5,1407932901296.f5a391c3d60cfddbd50b21629d534258. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,624 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {cdbad283e1c8378f2a3266a7ed0ced3f state=OFFLINE, ts=1407932901551, server=null} to {cdbad283e1c8378f2a3266a7ed0ced3f state=PENDING_OPEN, ts=1407932901624, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,625 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user6,1407932901296.cdbad283e1c8378f2a3266a7ed0ced3f. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,628 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=OFFLINE, ts=1407932901552, server=null} to {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=PENDING_OPEN, ts=1407932901628, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,629 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user9,1407932901296.32ea3b7cd0d8b4e9f0c318aa71dd29ad. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,632 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {7e3dbba374f40008ae52e34ad3e4fef1 state=OFFLINE, ts=1407932901552, server=null} to {7e3dbba374f40008ae52e34ad3e4fef1 state=PENDING_OPEN, ts=1407932901632, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,633 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user2,1407932901296.7e3dbba374f40008ae52e34ad3e4fef1. with state=PENDING_OPEN&sn=slave1,16020,1407932822898
2014-08-13 05:28:21,686 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from ENABLING to ENABLED
2014-08-13 05:28:21,696 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.CreateTableHandler: failed. null
2014-08-13 05:28:21,698 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStates: Transition {c2381157c28448b5d8ebe79568d1ec12 state=PENDING_OPEN, ts=1407932901602, server=slave1,16020,1407932822898} to {c2381157c28448b5d8ebe79568d1ec12 state=OPEN, ts=1407932901698, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,699 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStateStore: Updating row usertable,,1407932901296.c2381157c28448b5d8ebe79568d1ec12. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,699 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStates: Transition {13c70b99a242fd3f20739a3f1d8efd82 state=PENDING_OPEN, ts=1407932901606, server=slave1,16020,1407932822898} to {13c70b99a242fd3f20739a3f1d8efd82 state=OPEN, ts=1407932901699, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,699 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user4,1407932901296.13c70b99a242fd3f20739a3f1d8efd82. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,703 INFO  [defaultRpcServer.handler=14,queue=4,port=16020] master.RegionStates: Onlined c2381157c28448b5d8ebe79568d1ec12 on slave1,16020,1407932822898
2014-08-13 05:28:21,704 INFO  [defaultRpcServer.handler=32,queue=2,port=16020] master.RegionStates: Onlined 13c70b99a242fd3f20739a3f1d8efd82 on slave1,16020,1407932822898
2014-08-13 05:28:21,716 INFO  [defaultRpcServer.handler=16,queue=1,port=16020] master.RegionStates: Transition {02a81f884b512b228f14ed6e340777e2 state=PENDING_OPEN, ts=1407932901610, server=slave1,16020,1407932822898} to {02a81f884b512b228f14ed6e340777e2 state=OPEN, ts=1407932901716, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,716 INFO  [defaultRpcServer.handler=16,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user3,1407932901296.02a81f884b512b228f14ed6e340777e2. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,719 INFO  [defaultRpcServer.handler=16,queue=1,port=16020] master.RegionStates: Onlined 02a81f884b512b228f14ed6e340777e2 on slave1,16020,1407932822898
2014-08-13 05:28:21,732 INFO  [defaultRpcServer.handler=38,queue=3,port=16020] master.RegionStates: Transition {d343b193952e1d75f5f6046a051771d8 state=PENDING_OPEN, ts=1407932901614, server=slave1,16020,1407932822898} to {d343b193952e1d75f5f6046a051771d8 state=OPEN, ts=1407932901732, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,733 INFO  [defaultRpcServer.handler=38,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user7,1407932901296.d343b193952e1d75f5f6046a051771d8. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,736 INFO  [defaultRpcServer.handler=38,queue=3,port=16020] master.RegionStates: Onlined d343b193952e1d75f5f6046a051771d8 on slave1,16020,1407932822898
2014-08-13 05:28:21,742 INFO  [defaultRpcServer.handler=43,queue=3,port=16020] master.RegionStates: Transition {5c41fa17f4b842ff55849d85aa55d5f4 state=PENDING_OPEN, ts=1407932901617, server=slave1,16020,1407932822898} to {5c41fa17f4b842ff55849d85aa55d5f4 state=OPEN, ts=1407932901742, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,742 INFO  [defaultRpcServer.handler=43,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user8,1407932901296.5c41fa17f4b842ff55849d85aa55d5f4. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,747 INFO  [defaultRpcServer.handler=43,queue=3,port=16020] master.RegionStates: Onlined 5c41fa17f4b842ff55849d85aa55d5f4 on slave1,16020,1407932822898
2014-08-13 05:28:21,758 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStates: Transition {c640592e3f14a007ce12a364cfe69273 state=PENDING_OPEN, ts=1407932901619, server=slave1,16020,1407932822898} to {c640592e3f14a007ce12a364cfe69273 state=OPEN, ts=1407932901758, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,758 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user1,1407932901296.c640592e3f14a007ce12a364cfe69273. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,763 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStates: Onlined c640592e3f14a007ce12a364cfe69273 on slave1,16020,1407932822898
2014-08-13 05:28:21,772 INFO  [defaultRpcServer.handler=19,queue=4,port=16020] master.RegionStates: Transition {f5a391c3d60cfddbd50b21629d534258 state=PENDING_OPEN, ts=1407932901622, server=slave1,16020,1407932822898} to {f5a391c3d60cfddbd50b21629d534258 state=OPEN, ts=1407932901772, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,772 INFO  [defaultRpcServer.handler=19,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user5,1407932901296.f5a391c3d60cfddbd50b21629d534258. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,776 INFO  [defaultRpcServer.handler=19,queue=4,port=16020] master.RegionStates: Onlined f5a391c3d60cfddbd50b21629d534258 on slave1,16020,1407932822898
2014-08-13 05:28:21,793 INFO  [defaultRpcServer.handler=24,queue=4,port=16020] master.RegionStates: Transition {cdbad283e1c8378f2a3266a7ed0ced3f state=PENDING_OPEN, ts=1407932901624, server=slave1,16020,1407932822898} to {cdbad283e1c8378f2a3266a7ed0ced3f state=OPEN, ts=1407932901793, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,793 INFO  [defaultRpcServer.handler=24,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user6,1407932901296.cdbad283e1c8378f2a3266a7ed0ced3f. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,797 INFO  [defaultRpcServer.handler=24,queue=4,port=16020] master.RegionStates: Onlined cdbad283e1c8378f2a3266a7ed0ced3f on slave1,16020,1407932822898
2014-08-13 05:28:21,804 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStates: Transition {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=PENDING_OPEN, ts=1407932901628, server=slave1,16020,1407932822898} to {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=OPEN, ts=1407932901804, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,805 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user9,1407932901296.32ea3b7cd0d8b4e9f0c318aa71dd29ad. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,809 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStates: Onlined 32ea3b7cd0d8b4e9f0c318aa71dd29ad on slave1,16020,1407932822898
2014-08-13 05:28:21,852 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStates: Transition {7e3dbba374f40008ae52e34ad3e4fef1 state=PENDING_OPEN, ts=1407932901632, server=slave1,16020,1407932822898} to {7e3dbba374f40008ae52e34ad3e4fef1 state=OPEN, ts=1407932901852, server=slave1,16020,1407932822898}
2014-08-13 05:28:21,852 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user2,1407932901296.7e3dbba374f40008ae52e34ad3e4fef1. with state=OPEN&openSeqNum=2&server=slave1,16020,1407932822898
2014-08-13 05:28:21,856 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStates: Onlined 7e3dbba374f40008ae52e34ad3e4fef1 on slave1,16020,1407932822898
2014-08-13 05:29:17,875 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-HeapMemoryTunerChore] regionserver.HeapMemoryManager: Setting block cache heap size to 5747186176 and memstore heap size to 4470033408
2014-08-13 05:30:53,760 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.35 GB, max=5.35 GB, accesses=103, hits=95, hitRatio=92.23%, , cachingAccesses=100, cachingHits=92, cachingHitsRatio=92.00%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-08-13 05:31:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905., src=sceplus-vm48.almaden.ibm.com,16020,1407931593639, dest=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:31:21,692 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407932781984, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933081692, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:31:21,692 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_CLOSE
2014-08-13 05:31:21,697 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] regionserver.RSRpcServices: Close 2eb418e3c70ddeb740c21f06d8d0f905, moving to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:31:21,712 INFO  [StoreCloserThread-hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.-1] regionserver.HStore: Closed info
2014-08-13 05:31:21,715 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:31:21,715 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: 2eb418e3c70ddeb740c21f06d8d0f905 to self.
2014-08-13 05:31:21,717 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933081692, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933081717, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:31:21,717 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=CLOSED
2014-08-13 05:31:21,721 INFO  [AM.-pool1-t6] master.AssignmentManager: Assigning hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:31:21,721 INFO  [AM.-pool1-t6] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933081717, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933081721, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:31:21,721 INFO  [AM.-pool1-t6] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN
2014-08-13 05:31:21,725 INFO  [AM.-pool1-t6] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:31:21,739 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:31:21,740 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:31:21,777 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=8
2014-08-13 05:31:21,778 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:31:21,778 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933081721, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933081778, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:31:21,778 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:32:17,350 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-HeapMemoryTunerChore] regionserver.HeapMemoryManager: Setting block cache heap size to 6385762304 and memstore heap size to 3831457280
2014-08-13 05:35:53,760 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.94 GB, max=5.95 GB, accesses=151, hits=143, hitRatio=94.70%, , cachingAccesses=148, cachingHits=140, cachingHitsRatio=94.59%, evictions=0, evicted=5, evictedPerRun=Infinity
2014-08-13 05:36:21,693 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905., src=sceplus-vm48.almaden.ibm.com,16020,1407931593639, dest=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:36:21,695 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933081778, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933381695, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:36:21,695 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_CLOSE
2014-08-13 05:36:21,701 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] regionserver.RSRpcServices: Close 2eb418e3c70ddeb740c21f06d8d0f905, moving to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:36:21,711 INFO  [StoreCloserThread-hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.-1] regionserver.HStore: Closed info
2014-08-13 05:36:21,713 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:36:21,714 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: 2eb418e3c70ddeb740c21f06d8d0f905 to self.
2014-08-13 05:36:21,714 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933381695, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933381714, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:36:21,715 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=CLOSED
2014-08-13 05:36:21,721 INFO  [AM.-pool1-t7] master.AssignmentManager: Assigning hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:36:21,721 INFO  [AM.-pool1-t7] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933381714, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933381721, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:36:21,721 INFO  [AM.-pool1-t7] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN
2014-08-13 05:36:21,728 INFO  [AM.-pool1-t7] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:36:21,749 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:36:21,750 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:36:21,771 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=8
2014-08-13 05:36:21,772 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:36:21,773 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933381721, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933381773, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:36:21,773 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:38:18,814 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sceplus-vm49.almaden.ibm.com,16020,1407932822898]
2014-08-13 05:38:18,814 WARN  [main-EventThread] zookeeper.RegionServerTracker: sceplus-vm49.almaden.ibm.com,16020,1407932822898 is not online or isn't known to the master.The latter could be caused by a DNS misconfiguration.
2014-08-13 05:38:18,849 INFO  [main-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/sceplus-vm49.almaden.ibm.com,16020,1407932822898 znode expired, triggering replicatorRemoved event
2014-08-13 05:38:22,308 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving sceplus-vm49.almaden.ibm.com,16020,1407932822898's hlogs to my queue
2014-08-13 05:38:22,314 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Won't transfer the queue, another RS took care of it because of: KeeperErrorCode = NoNode for /hbase/replication/rs/sceplus-vm49.almaden.ibm.com,16020,1407932822898/lock
2014-08-13 05:40:07,695 ERROR [defaultRpcServer.handler=16,queue=1,port=16020] master.MasterRpcServices: Region server slave1,16020,1407932822898 reported a fatal error:
ABORTING region server slave1,16020,1407932822898: regionserver:16020-0x47cf54e2bc0006-0x47cf54e2bc0006, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase regionserver:16020-0x47cf54e2bc0006-0x47cf54e2bc0006 received expired from ZooKeeper, aborting
Cause:
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:409)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:320)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)

2014-08-13 05:40:53,760 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.94 GB, max=5.95 GB, accesses=929, hits=921, hitRatio=99.14%, , cachingAccesses=926, cachingHits=918, cachingHitsRatio=99.14%, evictions=0, evicted=5, evictedPerRun=Infinity
2014-08-13 05:41:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905., src=sceplus-vm48.almaden.ibm.com,16020,1407931593639, dest=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:21,693 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933381773, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933681693, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:41:21,694 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_CLOSE
2014-08-13 05:41:21,700 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] regionserver.RSRpcServices: Close 2eb418e3c70ddeb740c21f06d8d0f905, moving to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:21,707 INFO  [StoreCloserThread-hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.-1] regionserver.HStore: Closed info
2014-08-13 05:41:21,708 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:41:21,709 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: 2eb418e3c70ddeb740c21f06d8d0f905 to self.
2014-08-13 05:41:21,710 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933681693, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933681710, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:41:21,710 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=CLOSED
2014-08-13 05:41:21,716 INFO  [AM.-pool1-t8] master.AssignmentManager: Assigning hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:21,716 INFO  [AM.-pool1-t8] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933681710, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933681716, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:41:21,717 INFO  [AM.-pool1-t8] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN
2014-08-13 05:41:21,726 INFO  [AM.-pool1-t8] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:41:21,738 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:41:21,739 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:41:21,770 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=8
2014-08-13 05:41:21,770 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:41:21,771 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933681716, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933681771, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:41:21,771 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:54,125 INFO  [defaultRpcServer.handler=2,queue=2,port=16020] master.ServerManager: Registering server=slave1,16020,1407933710998
2014-08-13 05:41:54,125 INFO  [defaultRpcServer.handler=2,queue=2,port=16020] master.ServerManager: Triggering server recovery; existingServer slave1,16020,1407932822898 looks stale, new server:slave1,16020,1407933710998
2014-08-13 05:41:54,130 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407932822898 before assignment.
2014-08-13 05:41:54,130 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-13 05:41:54,256 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {c2381157c28448b5d8ebe79568d1ec12 state=OPEN, ts=1407932901698, server=slave1,16020,1407932822898} to {c2381157c28448b5d8ebe79568d1ec12 state=OFFLINE, ts=1407933714255, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,256 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,,1407932901296.c2381157c28448b5d8ebe79568d1ec12. with state=OFFLINE
2014-08-13 05:41:54,259 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {d343b193952e1d75f5f6046a051771d8 state=OPEN, ts=1407932901732, server=slave1,16020,1407932822898} to {d343b193952e1d75f5f6046a051771d8 state=OFFLINE, ts=1407933714259, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,259 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user7,1407932901296.d343b193952e1d75f5f6046a051771d8. with state=OFFLINE
2014-08-13 05:41:54,261 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {cdbad283e1c8378f2a3266a7ed0ced3f state=OPEN, ts=1407932901793, server=slave1,16020,1407932822898} to {cdbad283e1c8378f2a3266a7ed0ced3f state=OFFLINE, ts=1407933714261, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,262 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user6,1407932901296.cdbad283e1c8378f2a3266a7ed0ced3f. with state=OFFLINE
2014-08-13 05:41:54,264 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=OPEN, ts=1407932901804, server=slave1,16020,1407932822898} to {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=OFFLINE, ts=1407933714264, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,264 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user9,1407932901296.32ea3b7cd0d8b4e9f0c318aa71dd29ad. with state=OFFLINE
2014-08-13 05:41:54,266 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {7e3dbba374f40008ae52e34ad3e4fef1 state=OPEN, ts=1407932901852, server=slave1,16020,1407932822898} to {7e3dbba374f40008ae52e34ad3e4fef1 state=OFFLINE, ts=1407933714266, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,266 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user2,1407932901296.7e3dbba374f40008ae52e34ad3e4fef1. with state=OFFLINE
2014-08-13 05:41:54,268 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {13c70b99a242fd3f20739a3f1d8efd82 state=OPEN, ts=1407932901699, server=slave1,16020,1407932822898} to {13c70b99a242fd3f20739a3f1d8efd82 state=OFFLINE, ts=1407933714268, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,268 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user4,1407932901296.13c70b99a242fd3f20739a3f1d8efd82. with state=OFFLINE
2014-08-13 05:41:54,270 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {5c41fa17f4b842ff55849d85aa55d5f4 state=OPEN, ts=1407932901742, server=slave1,16020,1407932822898} to {5c41fa17f4b842ff55849d85aa55d5f4 state=OFFLINE, ts=1407933714270, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,270 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user8,1407932901296.5c41fa17f4b842ff55849d85aa55d5f4. with state=OFFLINE
2014-08-13 05:41:54,272 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {f5a391c3d60cfddbd50b21629d534258 state=OPEN, ts=1407932901772, server=slave1,16020,1407932822898} to {f5a391c3d60cfddbd50b21629d534258 state=OFFLINE, ts=1407933714272, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,272 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user5,1407932901296.f5a391c3d60cfddbd50b21629d534258. with state=OFFLINE
2014-08-13 05:41:54,274 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {02a81f884b512b228f14ed6e340777e2 state=OPEN, ts=1407932901716, server=slave1,16020,1407932822898} to {02a81f884b512b228f14ed6e340777e2 state=OFFLINE, ts=1407933714274, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,274 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user3,1407932901296.02a81f884b512b228f14ed6e340777e2. with state=OFFLINE
2014-08-13 05:41:54,276 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {c640592e3f14a007ce12a364cfe69273 state=OPEN, ts=1407932901758, server=slave1,16020,1407932822898} to {c640592e3f14a007ce12a364cfe69273 state=OFFLINE, ts=1407933714276, server=slave1,16020,1407932822898}
2014-08-13 05:41:54,276 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user1,1407932901296.c640592e3f14a007ce12a364cfe69273. with state=OFFLINE
2014-08-13 05:41:54,278 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Reassigning 10 region(s) that slave1,16020,1407932822898 was carrying (and 0 regions(s) that were opening on this server)
2014-08-13 05:41:54,279 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Assigning 10 region(s) to slave1,16020,1407933710998
2014-08-13 05:41:54,279 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {c2381157c28448b5d8ebe79568d1ec12 state=OFFLINE, ts=1407933714255, server=slave1,16020,1407932822898} to {c2381157c28448b5d8ebe79568d1ec12 state=PENDING_OPEN, ts=1407933714279, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,280 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,,1407932901296.c2381157c28448b5d8ebe79568d1ec12. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,282 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {d343b193952e1d75f5f6046a051771d8 state=OFFLINE, ts=1407933714259, server=slave1,16020,1407932822898} to {d343b193952e1d75f5f6046a051771d8 state=PENDING_OPEN, ts=1407933714282, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,282 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user7,1407932901296.d343b193952e1d75f5f6046a051771d8. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,284 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {cdbad283e1c8378f2a3266a7ed0ced3f state=OFFLINE, ts=1407933714261, server=slave1,16020,1407932822898} to {cdbad283e1c8378f2a3266a7ed0ced3f state=PENDING_OPEN, ts=1407933714284, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,284 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user6,1407932901296.cdbad283e1c8378f2a3266a7ed0ced3f. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,286 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=OFFLINE, ts=1407933714264, server=slave1,16020,1407932822898} to {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=PENDING_OPEN, ts=1407933714286, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,286 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user9,1407932901296.32ea3b7cd0d8b4e9f0c318aa71dd29ad. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,288 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {7e3dbba374f40008ae52e34ad3e4fef1 state=OFFLINE, ts=1407933714266, server=slave1,16020,1407932822898} to {7e3dbba374f40008ae52e34ad3e4fef1 state=PENDING_OPEN, ts=1407933714288, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,288 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user2,1407932901296.7e3dbba374f40008ae52e34ad3e4fef1. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,290 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {13c70b99a242fd3f20739a3f1d8efd82 state=OFFLINE, ts=1407933714268, server=slave1,16020,1407932822898} to {13c70b99a242fd3f20739a3f1d8efd82 state=PENDING_OPEN, ts=1407933714290, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,290 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user4,1407932901296.13c70b99a242fd3f20739a3f1d8efd82. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,292 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {5c41fa17f4b842ff55849d85aa55d5f4 state=OFFLINE, ts=1407933714270, server=slave1,16020,1407932822898} to {5c41fa17f4b842ff55849d85aa55d5f4 state=PENDING_OPEN, ts=1407933714292, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,292 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user8,1407932901296.5c41fa17f4b842ff55849d85aa55d5f4. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,294 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {f5a391c3d60cfddbd50b21629d534258 state=OFFLINE, ts=1407933714272, server=slave1,16020,1407932822898} to {f5a391c3d60cfddbd50b21629d534258 state=PENDING_OPEN, ts=1407933714294, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,294 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user5,1407932901296.f5a391c3d60cfddbd50b21629d534258. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,296 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {02a81f884b512b228f14ed6e340777e2 state=OFFLINE, ts=1407933714274, server=slave1,16020,1407932822898} to {02a81f884b512b228f14ed6e340777e2 state=PENDING_OPEN, ts=1407933714296, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,296 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user3,1407932901296.02a81f884b512b228f14ed6e340777e2. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:54,298 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {c640592e3f14a007ce12a364cfe69273 state=OFFLINE, ts=1407933714276, server=slave1,16020,1407932822898} to {c640592e3f14a007ce12a364cfe69273 state=PENDING_OPEN, ts=1407933714298, server=slave1,16020,1407933710998}
2014-08-13 05:41:54,298 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user1,1407932901296.c640592e3f14a007ce12a364cfe69273. with state=PENDING_OPEN&sn=slave1,16020,1407933710998
2014-08-13 05:41:55,126 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for c2381157c28448b5d8ebe79568d1ec12 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:41:55,390 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStates: Transition {c2381157c28448b5d8ebe79568d1ec12 state=PENDING_OPEN, ts=1407933714279, server=slave1,16020,1407933710998} to {c2381157c28448b5d8ebe79568d1ec12 state=OPEN, ts=1407933715390, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,391 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStateStore: Updating row usertable,,1407932901296.c2381157c28448b5d8ebe79568d1ec12. with state=OPEN&openSeqNum=40000002&server=slave1,16020,1407933710998
2014-08-13 05:41:55,394 INFO  [defaultRpcServer.handler=20,queue=0,port=16020] master.RegionStates: Onlined c2381157c28448b5d8ebe79568d1ec12 on slave1,16020,1407933710998
2014-08-13 05:41:55,394 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for d343b193952e1d75f5f6046a051771d8 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:41:55,480 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStates: Transition {d343b193952e1d75f5f6046a051771d8 state=PENDING_OPEN, ts=1407933714282, server=slave1,16020,1407933710998} to {d343b193952e1d75f5f6046a051771d8 state=OPEN, ts=1407933715479, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,481 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user7,1407932901296.d343b193952e1d75f5f6046a051771d8. with state=OPEN&openSeqNum=40002498&server=slave1,16020,1407933710998
2014-08-13 05:41:55,483 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Transition {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=PENDING_OPEN, ts=1407933714286, server=slave1,16020,1407933710998} to {32ea3b7cd0d8b4e9f0c318aa71dd29ad state=OPEN, ts=1407933715482, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,484 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user9,1407932901296.32ea3b7cd0d8b4e9f0c318aa71dd29ad. with state=OPEN&openSeqNum=40001688&server=slave1,16020,1407933710998
2014-08-13 05:41:55,484 INFO  [defaultRpcServer.handler=21,queue=1,port=16020] master.RegionStates: Onlined d343b193952e1d75f5f6046a051771d8 on slave1,16020,1407933710998
2014-08-13 05:41:55,484 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for cdbad283e1c8378f2a3266a7ed0ced3f to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:41:55,486 INFO  [defaultRpcServer.handler=13,queue=3,port=16020] master.RegionStates: Onlined 32ea3b7cd0d8b4e9f0c318aa71dd29ad on slave1,16020,1407933710998
2014-08-13 05:41:55,508 INFO  [defaultRpcServer.handler=18,queue=3,port=16020] master.RegionStates: Transition {cdbad283e1c8378f2a3266a7ed0ced3f state=PENDING_OPEN, ts=1407933714284, server=slave1,16020,1407933710998} to {cdbad283e1c8378f2a3266a7ed0ced3f state=OPEN, ts=1407933715508, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,509 INFO  [defaultRpcServer.handler=18,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user6,1407932901296.cdbad283e1c8378f2a3266a7ed0ced3f. with state=OPEN&openSeqNum=40002416&server=slave1,16020,1407933710998
2014-08-13 05:41:55,512 INFO  [defaultRpcServer.handler=18,queue=3,port=16020] master.RegionStates: Onlined cdbad283e1c8378f2a3266a7ed0ced3f on slave1,16020,1407933710998
2014-08-13 05:41:55,512 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 7e3dbba374f40008ae52e34ad3e4fef1 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:41:55,616 INFO  [defaultRpcServer.handler=25,queue=0,port=16020] master.RegionStates: Transition {13c70b99a242fd3f20739a3f1d8efd82 state=PENDING_OPEN, ts=1407933714290, server=slave1,16020,1407933710998} to {13c70b99a242fd3f20739a3f1d8efd82 state=OPEN, ts=1407933715615, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,616 INFO  [defaultRpcServer.handler=25,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user4,1407932901296.13c70b99a242fd3f20739a3f1d8efd82. with state=OPEN&openSeqNum=40002110&server=slave1,16020,1407933710998
2014-08-13 05:41:55,618 INFO  [defaultRpcServer.handler=25,queue=0,port=16020] master.RegionStates: Onlined 13c70b99a242fd3f20739a3f1d8efd82 on slave1,16020,1407933710998
2014-08-13 05:41:55,627 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStates: Transition {5c41fa17f4b842ff55849d85aa55d5f4 state=PENDING_OPEN, ts=1407933714292, server=slave1,16020,1407933710998} to {5c41fa17f4b842ff55849d85aa55d5f4 state=OPEN, ts=1407933715627, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,627 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user8,1407932901296.5c41fa17f4b842ff55849d85aa55d5f4. with state=OPEN&openSeqNum=40001555&server=slave1,16020,1407933710998
2014-08-13 05:41:55,628 INFO  [defaultRpcServer.handler=7,queue=2,port=16020] master.RegionStates: Transition {7e3dbba374f40008ae52e34ad3e4fef1 state=PENDING_OPEN, ts=1407933714288, server=slave1,16020,1407933710998} to {7e3dbba374f40008ae52e34ad3e4fef1 state=OPEN, ts=1407933715628, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,628 INFO  [defaultRpcServer.handler=7,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user2,1407932901296.7e3dbba374f40008ae52e34ad3e4fef1. with state=OPEN&openSeqNum=40001880&server=slave1,16020,1407933710998
2014-08-13 05:41:55,630 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStates: Onlined 5c41fa17f4b842ff55849d85aa55d5f4 on slave1,16020,1407933710998
2014-08-13 05:41:55,631 INFO  [defaultRpcServer.handler=7,queue=2,port=16020] master.RegionStates: Onlined 7e3dbba374f40008ae52e34ad3e4fef1 on slave1,16020,1407933710998
2014-08-13 05:41:55,631 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for f5a391c3d60cfddbd50b21629d534258 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:41:55,703 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStates: Transition {c640592e3f14a007ce12a364cfe69273 state=PENDING_OPEN, ts=1407933714298, server=slave1,16020,1407933710998} to {c640592e3f14a007ce12a364cfe69273 state=OPEN, ts=1407933715702, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,703 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user1,1407932901296.c640592e3f14a007ce12a364cfe69273. with state=OPEN&openSeqNum=40001774&server=slave1,16020,1407933710998
2014-08-13 05:41:55,707 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStates: Onlined c640592e3f14a007ce12a364cfe69273 on slave1,16020,1407933710998
2014-08-13 05:41:55,744 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] master.RegionStates: Transition {f5a391c3d60cfddbd50b21629d534258 state=PENDING_OPEN, ts=1407933714294, server=slave1,16020,1407933710998} to {f5a391c3d60cfddbd50b21629d534258 state=OPEN, ts=1407933715743, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,744 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user5,1407932901296.f5a391c3d60cfddbd50b21629d534258. with state=OPEN&openSeqNum=40002208&server=slave1,16020,1407933710998
2014-08-13 05:41:55,747 INFO  [defaultRpcServer.handler=30,queue=0,port=16020] master.RegionStates: Onlined f5a391c3d60cfddbd50b21629d534258 on slave1,16020,1407933710998
2014-08-13 05:41:55,747 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 02a81f884b512b228f14ed6e340777e2 to leave regions-in-transition, timeOut=15000 ms.
2014-08-13 05:41:55,755 INFO  [defaultRpcServer.handler=36,queue=1,port=16020] master.RegionStates: Transition {02a81f884b512b228f14ed6e340777e2 state=PENDING_OPEN, ts=1407933714296, server=slave1,16020,1407933710998} to {02a81f884b512b228f14ed6e340777e2 state=OPEN, ts=1407933715754, server=slave1,16020,1407933710998}
2014-08-13 05:41:55,755 INFO  [defaultRpcServer.handler=36,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user3,1407932901296.02a81f884b512b228f14ed6e340777e2. with state=OPEN&openSeqNum=40001992&server=slave1,16020,1407933710998
2014-08-13 05:41:55,758 INFO  [defaultRpcServer.handler=36,queue=1,port=16020] master.RegionStates: Onlined 02a81f884b512b228f14ed6e340777e2 on slave1,16020,1407933710998
2014-08-13 05:41:55,772 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: dead splitlog workers [slave1,16020,1407932822898]
2014-08-13 05:41:55,780 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: started splitting 36 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting]
2014-08-13 05:41:55,829 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933104362 acquired by slave1,16020,1407933710998
2014-08-13 05:41:55,834 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702
2014-08-13 05:41:55,836 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:55,872 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933376702, length=130371721
2014-08-13 05:41:55,872 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:41:55,876 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933376702
2014-08-13 05:41:55,878 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933376702 after 1ms
2014-08-13 05:41:56,004 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x76859984, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:41:56,005 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x76859984 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:41:56,005 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:41:56,006 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-13 05:41:56,010 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47cf54e2bc000e, negotiated timeout = 90000
2014-08-13 05:41:56,272 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 36 unassigned = 34 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702=last_update = 1407933715877 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933361507=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933113643=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933151359=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933224319=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933236798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933211569=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933104362=last_update = 1407933715889 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 0 error = 0}
2014-08-13 05:41:56,468 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933211569 acquired by slave1,16020,1407933710998
2014-08-13 05:41:56,514 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933113643
2014-08-13 05:41:56,516 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933113643 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:56,585 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933113643, length=130396310
2014-08-13 05:41:56,585 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:41:56,594 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933113643
2014-08-13 05:41:56,596 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933113643 after 2ms
2014-08-13 05:41:57,894 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:41:57,894 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933113643 is corrupted = false progress failed = false
2014-08-13 05:41:57,899 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933113643 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:57,899 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933113643 in 1383ms
2014-08-13 05:41:57,900 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933113643 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:57,911 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933113643 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933113643
2014-08-13 05:41:57,912 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933113643
2014-08-13 05:41:57,935 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716
2014-08-13 05:41:57,935 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:41:57,966 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933406716, length=120359471
2014-08-13 05:41:57,966 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:41:57,971 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933406716
2014-08-13 05:41:57,973 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933406716 after 2ms
2014-08-13 05:41:57,979 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933104362 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:41:57,990 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933104362 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933104362
2014-08-13 05:41:57,991 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933104362
2014-08-13 05:41:58,020 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933224319 acquired by slave1,16020,1407933710998
2014-08-13 05:42:02,270 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 34 unassigned = 30 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702=last_update = 1407933715877 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933361507=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933151359=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933224319=last_update = 1407933718127 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933236798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933211569=last_update = 1407933716562 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716=last_update = 1407933717973 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 2 error = 0}
2014-08-13 05:42:05,003 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:05,005 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 117 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933376702 is corrupted = false progress failed = false
2014-08-13 05:42:05,011 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:05,012 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702 in 9176ms
2014-08-13 05:42:05,013 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:05,031 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933376702 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933376702
2014-08-13 05:42:05,033 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933376702
2014-08-13 05:42:05,052 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866
2014-08-13 05:42:05,054 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:05,091 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933108866, length=130266821
2014-08-13 05:42:05,091 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:05,096 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933108866
2014-08-13 05:42:05,098 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933108866 after 2ms
2014-08-13 05:42:05,279 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933211569 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:05,288 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933211569 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933211569
2014-08-13 05:42:05,289 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933211569
2014-08-13 05:42:05,494 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933151359 acquired by slave1,16020,1407933710998
2014-08-13 05:42:05,974 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933224319 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:05,983 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933224319 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933224319
2014-08-13 05:42:05,984 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933224319
2014-08-13 05:42:06,225 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:06,232 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x47cf54e2bc000e
2014-08-13 05:42:06,242 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:06,242 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933108866 is corrupted = false progress failed = false
2014-08-13 05:42:06,243 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] zookeeper.ZooKeeper: Session: 0x47cf54e2bc000e closed
2014-08-13 05:42:06,244 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-13 05:42:06,245 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:06,245 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866 in 1193ms
2014-08-13 05:42:06,246 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:06,254 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933108866 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933108866
2014-08-13 05:42:06,255 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933108866
2014-08-13 05:42:06,265 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766
2014-08-13 05:42:06,268 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:06,295 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933156766, length=134026850
2014-08-13 05:42:06,295 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:06,302 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933156766
2014-08-13 05:42:06,303 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933156766 after 1ms
2014-08-13 05:42:06,344 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 146 edits across 9 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933406716 is corrupted = false progress failed = false
2014-08-13 05:42:06,346 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x2b900ac3, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:42:06,347 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2b900ac3 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:42:06,347 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:42:06,348 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:06,348 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716 in 8413ms
2014-08-13 05:42:06,348 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-13 05:42:06,350 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:06,354 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147cf54dfb30009, negotiated timeout = 90000
2014-08-13 05:42:06,364 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933406716 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933406716
2014-08-13 05:42:06,366 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933406716
2014-08-13 05:42:06,397 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933361507 acquired by slave1,16020,1407933710998
2014-08-13 05:42:06,894 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192
2014-08-13 05:42:06,895 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:06,925 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933345192, length=135376583
2014-08-13 05:42:06,925 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:06,936 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933345192
2014-08-13 05:42:06,938 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933345192 after 2ms
2014-08-13 05:42:08,270 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 29 unassigned = 25 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933361507=last_update = 1407933726439 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933151359=last_update = 1407933725573 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192=last_update = 1407933726937 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933236798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766=last_update = 1407933726307 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 7 error = 0}
2014-08-13 05:42:09,359 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:09,360 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 17 edits across 2 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933156766 is corrupted = false progress failed = false
2014-08-13 05:42:09,364 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:09,364 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766 in 3099ms
2014-08-13 05:42:09,365 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:09,379 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933156766 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933156766
2014-08-13 05:42:09,382 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933156766
2014-08-13 05:42:09,402 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559
2014-08-13 05:42:09,404 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:09,439 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933242559, length=127956800
2014-08-13 05:42:09,440 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:09,447 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933242559
2014-08-13 05:42:09,450 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933242559 after 3ms
2014-08-13 05:42:09,602 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933151359 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:09,612 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933151359 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933151359
2014-08-13 05:42:09,613 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933151359
2014-08-13 05:42:09,628 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933236798 acquired by slave1,16020,1407933710998
2014-08-13 05:42:13,271 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 27 unassigned = 23 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933361507=last_update = 1407933726439 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192=last_update = 1407933726937 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933236798=last_update = 1407933729670 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559=last_update = 1407933729449 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 9 error = 0}
2014-08-13 05:42:14,422 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933361507 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:14,436 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933361507 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933361507
2014-08-13 05:42:14,438 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933361507
2014-08-13 05:42:14,518 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348 acquired by slave1,16020,1407933710998
2014-08-13 05:42:17,521 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933236798 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:17,531 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933236798 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933236798
2014-08-13 05:42:17,532 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933236798
2014-08-13 05:42:17,584 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076 acquired by slave1,16020,1407933710998
2014-08-13 05:42:18,272 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 25 unassigned = 21 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192=last_update = 1407933726937 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348=last_update = 1407933734570 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076=last_update = 1407933737645 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559=last_update = 1407933729449 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 11 error = 0}
2014-08-13 05:42:18,785 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:18,786 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 110 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933345192 is corrupted = false progress failed = false
2014-08-13 05:42:18,945 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:18,945 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192 in 12050ms
2014-08-13 05:42:18,947 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:19,217 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:19,223 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x147cf54dfb30009
2014-08-13 05:42:19,338 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933345192 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933345192
2014-08-13 05:42:19,339 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933345192
2014-08-13 05:42:19,340 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] zookeeper.ZooKeeper: Session: 0x147cf54dfb30009 closed
2014-08-13 05:42:19,340 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-13 05:42:19,440 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 112 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933242559 is corrupted = false progress failed = false
2014-08-13 05:42:19,442 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184
2014-08-13 05:42:19,445 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:19,445 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559 in 10042ms
2014-08-13 05:42:19,445 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:19,447 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:19,454 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933242559 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933242559
2014-08-13 05:42:19,455 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933242559
2014-08-13 05:42:19,472 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933398184, length=129971810
2014-08-13 05:42:19,473 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:19,479 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933398184
2014-08-13 05:42:19,480 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933398184 after 1ms
2014-08-13 05:42:19,530 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x11e9e7b5, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:42:19,530 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x11e9e7b5 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:42:19,531 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:42:19,532 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-13 05:42:19,537 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47cf54e2bc0010, negotiated timeout = 90000
2014-08-13 05:42:20,335 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871
2014-08-13 05:42:20,336 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:20,365 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933217871, length=128182551
2014-08-13 05:42:20,365 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:20,371 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933217871
2014-08-13 05:42:20,374 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:20,375 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933217871 after 3ms
2014-08-13 05:42:20,386 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933206348 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933206348
2014-08-13 05:42:20,387 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933206348
2014-08-13 05:42:20,404 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510 acquired by slave1,16020,1407933710998
2014-08-13 05:42:21,119 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:21,130 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933136076 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933136076
2014-08-13 05:42:21,131 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933136076
2014-08-13 05:42:21,158 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458 acquired by slave1,16020,1407933710998
2014-08-13 05:42:23,337 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 21 unassigned = 17 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510=last_update = 1407933740493 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184=last_update = 1407933739480 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458=last_update = 1407933741256 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871=last_update = 1407933740373 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0}
2014-08-13 05:42:28,339 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 21 unassigned = 17 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510=last_update = 1407933740493 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184=last_update = 1407933739480 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458=last_update = 1407933741256 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871=last_update = 1407933740373 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 15 error = 0}
2014-08-13 05:42:31,033 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:31,038 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 87 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933217871 is corrupted = false progress failed = false
2014-08-13 05:42:31,043 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:31,043 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871 in 10708ms
2014-08-13 05:42:31,047 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:31,061 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933217871 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933217871
2014-08-13 05:42:31,063 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933217871
2014-08-13 05:42:31,074 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228
2014-08-13 05:42:31,076 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:31,110 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933133228, length=130142518
2014-08-13 05:42:31,110 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:31,118 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933133228
2014-08-13 05:42:31,121 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933133228 after 3ms
2014-08-13 05:42:31,199 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:31,203 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x47cf54e2bc0010
2014-08-13 05:42:31,213 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] zookeeper.ZooKeeper: Session: 0x47cf54e2bc0010 closed
2014-08-13 05:42:31,213 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-13 05:42:31,313 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 157 edits across 9 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933398184 is corrupted = false progress failed = false
2014-08-13 05:42:31,320 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:31,321 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184 in 11879ms
2014-08-13 05:42:31,322 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:31,331 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933398184 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933398184
2014-08-13 05:42:31,332 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933398184
2014-08-13 05:42:31,664 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:31,673 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933254510 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933254510
2014-08-13 05:42:31,674 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933254510
2014-08-13 05:42:31,733 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742 acquired by slave1,16020,1407933710998
2014-08-13 05:42:31,900 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049
2014-08-13 05:42:31,901 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:31,927 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933183049, length=131033120
2014-08-13 05:42:31,928 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:31,931 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933183049
2014-08-13 05:42:31,933 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933183049 after 2ms
2014-08-13 05:42:31,974 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x2fc11ac1, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-13 05:42:31,975 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2fc11ac1 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-13 05:42:31,975 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-13 05:42:31,976 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-13 05:42:31,981 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47cf54e2bc0011, negotiated timeout = 90000
2014-08-13 05:42:32,257 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:32,267 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933248458 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933248458
2014-08-13 05:42:32,268 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933248458
2014-08-13 05:42:32,474 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697 acquired by slave1,16020,1407933710998
2014-08-13 05:42:32,893 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:32,893 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933133228 is corrupted = false progress failed = false
2014-08-13 05:42:32,901 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:32,901 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228 in 1826ms
2014-08-13 05:42:32,903 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:32,913 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933133228 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933133228
2014-08-13 05:42:32,914 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933133228
2014-08-13 05:42:32,928 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127
2014-08-13 05:42:32,929 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:32,956 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933606127, length=35003976
2014-08-13 05:42:32,956 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:32,962 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933606127
2014-08-13 05:42:32,964 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933606127 after 2ms
2014-08-13 05:42:34,339 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 16 unassigned = 12 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049=last_update = 1407933751932 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742=last_update = 1407933751788 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = 1407933752531 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = 1407933752964 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 20 error = 0}
2014-08-13 05:42:36,501 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:36,515 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933145742 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933145742
2014-08-13 05:42:36,517 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933145742
2014-08-13 05:42:36,536 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528 acquired by slave1,16020,1407933710998
2014-08-13 05:42:38,620 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:38,623 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 51 edits across 3 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933183049 is corrupted = false progress failed = false
2014-08-13 05:42:38,627 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:38,627 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049 in 6726ms
2014-08-13 05:42:38,628 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:38,641 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933183049 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933183049
2014-08-13 05:42:38,642 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933183049
2014-08-13 05:42:38,661 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846
2014-08-13 05:42:38,667 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:38,694 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933230846, length=130839849
2014-08-13 05:42:38,694 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:38,698 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933230846
2014-08-13 05:42:38,700 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933230846 after 2ms
2014-08-13 05:42:39,340 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 14 unassigned = 10 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = 1407933758702 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = 1407933756681 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697=last_update = 1407933752531 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127=last_update = 1407933752964 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 22 error = 0}
2014-08-13 05:42:39,375 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:39,376 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 45 edits across 9 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933606127 is corrupted = false progress failed = false
2014-08-13 05:42:39,383 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:39,383 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127 in 6455ms
2014-08-13 05:42:39,384 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:39,401 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933606127 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933606127
2014-08-13 05:42:39,403 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933606127
2014-08-13 05:42:39,414 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510
2014-08-13 05:42:39,415 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:39,444 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933171510, length=131809615
2014-08-13 05:42:39,444 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:39,482 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933171510
2014-08-13 05:42:39,484 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933171510 after 2ms
2014-08-13 05:42:40,059 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:40,070 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933188697 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933188697
2014-08-13 05:42:40,071 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933188697
2014-08-13 05:42:40,090 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059 acquired by slave1,16020,1407933710998
2014-08-13 05:42:44,341 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 12 unassigned = 8 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846=last_update = 1407933758702 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059=last_update = 1407933760181 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528=last_update = 1407933756681 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510=last_update = 1407933759484 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 24 error = 0}
2014-08-13 05:42:45,398 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:45,414 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933392528 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933392528
2014-08-13 05:42:45,415 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933392528
2014-08-13 05:42:45,636 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248 acquired by slave1,16020,1407933710998
2014-08-13 05:42:45,797 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:45,810 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933140059 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933140059
2014-08-13 05:42:45,812 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933140059
2014-08-13 05:42:46,525 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222 acquired by slave1,16020,1407933710998
2014-08-13 05:42:46,897 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:46,899 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 58 edits across 3 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933171510 is corrupted = false progress failed = false
2014-08-13 05:42:46,904 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:46,904 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510 in 7489ms
2014-08-13 05:42:46,905 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:46,920 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933171510 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933171510
2014-08-13 05:42:46,922 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933171510
2014-08-13 05:42:46,942 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994
2014-08-13 05:42:46,942 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:46,974 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933176994, length=128719440
2014-08-13 05:42:46,974 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:46,981 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933176994
2014-08-13 05:42:46,982 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933176994 after 1ms
2014-08-13 05:42:47,691 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:47,692 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 107 edits across 6 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933230846 is corrupted = false progress failed = false
2014-08-13 05:42:47,743 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:47,743 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846 in 9081ms
2014-08-13 05:42:47,744 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:47,766 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933230846 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933230846
2014-08-13 05:42:47,769 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933230846
2014-08-13 05:42:47,896 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078
2014-08-13 05:42:47,899 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:47,924 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:47,926 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933194078, length=128828692
2014-08-13 05:42:47,926 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:47,932 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933194078
2014-08-13 05:42:47,934 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933119248 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933119248
2014-08-13 05:42:47,935 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933194078 after 3ms
2014-08-13 05:42:47,936 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933119248
2014-08-13 05:42:47,957 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876 acquired by slave1,16020,1407933710998
2014-08-13 05:42:49,342 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 7 unassigned = 3 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994=last_update = 1407933766980 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 29 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 29 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 29 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 29 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = 1407933767941 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 29 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = 1407933768017 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 29 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = 1407933766570 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 29 error = 0}
2014-08-13 05:42:52,638 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:52,639 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 55 edits across 3 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933176994 is corrupted = false progress failed = false
2014-08-13 05:42:52,986 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:52,987 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:53,110 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994 in 6168ms
2014-08-13 05:42:53,321 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933176994 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933176994
2014-08-13 05:42:53,324 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933176994
2014-08-13 05:42:53,952 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228
2014-08-13 05:42:53,954 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:53,985 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933262228, length=13159501
2014-08-13 05:42:53,985 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:54,323 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933262228
2014-08-13 05:42:54,325 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933262228 after 2ms
2014-08-13 05:42:55,341 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 6 unassigned = 2 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228=last_update = 1407933774324 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078=last_update = 1407933767941 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876=last_update = 1407933768017 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 30 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222=last_update = 1407933766570 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 30 error = 0}
2014-08-13 05:42:55,986 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:55,996 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933199876 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933199876
2014-08-13 05:42:55,997 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933199876
2014-08-13 05:42:56,016 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520 acquired by slave1,16020,1407933710998
2014-08-13 05:42:56,317 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:56,319 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 12 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933262228 is corrupted = false progress failed = false
2014-08-13 05:42:56,325 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:56,325 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228 in 2372ms
2014-08-13 05:42:56,327 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:56,342 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933262228 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933262228
2014-08-13 05:42:56,344 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933262228
2014-08-13 05:42:56,356 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407932753555] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919
2014-08-13 05:42:56,357 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919 acquired by sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:56,383 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933386919, length=128050072
2014-08-13 05:42:56,383 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-13 05:42:56,388 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933386919
2014-08-13 05:42:56,389 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933386919 after 1ms
2014-08-13 05:42:56,708 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:42:56,719 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933380222 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933380222
2014-08-13 05:42:56,720 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933380222
2014-08-13 05:42:56,984 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-13 05:42:56,985 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 70 edits across 4 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933194078 is corrupted = false progress failed = false
2014-08-13 05:42:56,992 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:56,992 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078 in 9095ms
2014-08-13 05:42:56,994 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:42:57,004 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933194078 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933194078
2014-08-13 05:42:57,005 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933194078
2014-08-13 05:43:00,342 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 2 unassigned = 0 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919=last_update = 1407933776388 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407932753555 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 34 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520=last_update = 1407933776061 last_version = 2 cur_worker_name = slave1,16020,1407933710998 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 36 done = 34 error = 0}
2014-08-13 05:43:00,652 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520 entered state: DONE slave1,16020,1407933710998
2014-08-13 05:43:00,665 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933167520 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933167520
2014-08-13 05:43:00,667 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933167520
2014-08-13 05:43:02,649 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-13 05:43:02,656 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x47cf54e2bc0011
2014-08-13 05:43:02,660 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] zookeeper.ZooKeeper: Session: 0x47cf54e2bc0011 closed
2014-08-13 05:43:02,660 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-13 05:43:02,761 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 138 edits across 8 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933386919 is corrupted = false progress failed = false
2014-08-13 05:43:02,765 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:43:02,765 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407932753555 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919 in 6409ms
2014-08-13 05:43:02,767 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:43:02,777 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting/slave1%2C16020%2C1407932822898.1407933386919 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407932822898.1407933386919
2014-08-13 05:43:02,779 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407932822898-splitting%2Fslave1%252C16020%252C1407932822898.1407933386919
2014-08-13 05:43:02,905 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: finished splitting (more than or equal to) 4487060213 bytes in 36 log files in [hdfs://master:54310/hbase/WALs/slave1,16020,1407932822898-splitting] in 67125ms
2014-08-13 05:43:02,905 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407932822898
2014-08-13 05:45:53,759 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1482, hits=1474, hitRatio=99.46%, , cachingAccesses=1479, cachingHits=1471, cachingHitsRatio=99.46%, evictions=0, evicted=5, evictedPerRun=Infinity
2014-08-13 05:46:21,690 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905., src=sceplus-vm48.almaden.ibm.com,16020,1407931593639, dest=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:46:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933681771, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933981691, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:46:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_CLOSE
2014-08-13 05:46:21,723 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] regionserver.RSRpcServices: Close 2eb418e3c70ddeb740c21f06d8d0f905, moving to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:46:21,728 INFO  [StoreCloserThread-hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.-1] regionserver.HStore: Closed info
2014-08-13 05:46:21,729 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:46:21,731 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: 2eb418e3c70ddeb740c21f06d8d0f905 to self.
2014-08-13 05:46:21,731 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407933981691, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933981731, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:46:21,731 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=CLOSED
2014-08-13 05:46:21,735 INFO  [AM.-pool1-t9] master.AssignmentManager: Assigning hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:46:21,735 INFO  [AM.-pool1-t9] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407933981731, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933981735, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:46:21,736 INFO  [AM.-pool1-t9] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN
2014-08-13 05:46:21,741 INFO  [AM.-pool1-t9] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:46:21,756 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:46:21,757 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:46:21,787 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=8
2014-08-13 05:46:21,788 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:46:21,788 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407933981735, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933981788, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:46:21,788 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:50:53,760 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1485, hits=1477, hitRatio=99.46%, , cachingAccesses=1482, cachingHits=1474, cachingHitsRatio=99.46%, evictions=0, evicted=5, evictedPerRun=Infinity
2014-08-13 05:51:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905., src=sceplus-vm48.almaden.ibm.com,16020,1407931593639, dest=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:51:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407933981788, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407934281691, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:51:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_CLOSE
2014-08-13 05:51:21,699 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] regionserver.RSRpcServices: Close 2eb418e3c70ddeb740c21f06d8d0f905, moving to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:51:21,709 INFO  [StoreCloserThread-hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.-1] regionserver.HStore: Closed info
2014-08-13 05:51:21,710 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:51:21,710 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: 2eb418e3c70ddeb740c21f06d8d0f905 to self.
2014-08-13 05:51:21,711 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407934281691, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407934281711, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:51:21,711 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=CLOSED
2014-08-13 05:51:21,715 INFO  [AM.-pool1-t10] master.AssignmentManager: Assigning hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:51:21,716 INFO  [AM.-pool1-t10] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407934281711, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407934281716, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:51:21,716 INFO  [AM.-pool1-t10] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN
2014-08-13 05:51:21,720 INFO  [AM.-pool1-t10] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:51:21,735 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:51:21,736 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:51:21,768 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=8
2014-08-13 05:51:21,768 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:51:21,769 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407934281716, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407934281769, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:51:21,769 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:55:53,759 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1488, hits=1480, hitRatio=99.46%, , cachingAccesses=1485, cachingHits=1477, cachingHitsRatio=99.46%, evictions=0, evicted=5, evictedPerRun=Infinity
2014-08-13 05:56:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905., src=sceplus-vm48.almaden.ibm.com,16020,1407931593639, dest=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:56:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407934281769, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407934581691, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:56:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_CLOSE
2014-08-13 05:56:21,696 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] regionserver.RSRpcServices: Close 2eb418e3c70ddeb740c21f06d8d0f905, moving to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:56:21,703 INFO  [StoreCloserThread-hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.-1] regionserver.HStore: Closed info
2014-08-13 05:56:21,703 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:56:21,704 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: 2eb418e3c70ddeb740c21f06d8d0f905 to self.
2014-08-13 05:56:21,705 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407934581691, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407934581705, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:56:21,705 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=CLOSED
2014-08-13 05:56:21,709 INFO  [AM.-pool1-t11] master.AssignmentManager: Assigning hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 05:56:21,709 INFO  [AM.-pool1-t11] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407934581705, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407934581709, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:56:21,709 INFO  [AM.-pool1-t11] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN
2014-08-13 05:56:21,712 INFO  [AM.-pool1-t11] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:56:21,722 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 05:56:21,724 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 05:56:21,746 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=8
2014-08-13 05:56:21,747 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 05:56:21,747 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407934581709, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407934581747, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 05:56:21,747 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 06:00:53,759 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1491, hits=1483, hitRatio=99.46%, , cachingAccesses=1488, cachingHits=1480, cachingHitsRatio=99.46%, evictions=0, evicted=5, evictedPerRun=Infinity
2014-08-13 06:01:21,691 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905., src=sceplus-vm48.almaden.ibm.com,16020,1407931593639, dest=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 06:01:21,692 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407934581747, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407934881692, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 06:01:21,692 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_CLOSE
2014-08-13 06:01:21,703 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407932753555-BalancerChore] regionserver.RSRpcServices: Close 2eb418e3c70ddeb740c21f06d8d0f905, moving to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 06:01:21,708 INFO  [StoreCloserThread-hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.-1] regionserver.HStore: Closed info
2014-08-13 06:01:21,708 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 06:01:21,708 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: 2eb418e3c70ddeb740c21f06d8d0f905 to self.
2014-08-13 06:01:21,708 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_CLOSE, ts=1407934881692, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407934881708, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 06:01:21,709 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=CLOSED
2014-08-13 06:01:21,713 INFO  [AM.-pool1-t12] master.AssignmentManager: Assigning hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. to sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 06:01:21,713 INFO  [AM.-pool1-t12] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=CLOSED, ts=1407934881708, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407934881713, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 06:01:21,714 INFO  [AM.-pool1-t12] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=PENDING_OPEN
2014-08-13 06:01:21,718 INFO  [AM.-pool1-t12] regionserver.RSRpcServices: Open hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 06:01:21,730 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@2c1cc003, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-13 06:01:21,731 INFO  [StoreOpener-2eb418e3c70ddeb740c21f06d8d0f905-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-13 06:01:21,757 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined 2eb418e3c70ddeb740c21f06d8d0f905; next sequenceid=8
2014-08-13 06:01:21,758 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905.
2014-08-13 06:01:21,758 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStates: Transition {2eb418e3c70ddeb740c21f06d8d0f905 state=PENDING_OPEN, ts=1407934881713, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555} to {2eb418e3c70ddeb740c21f06d8d0f905 state=OPEN, ts=1407934881758, server=sceplus-vm48.almaden.ibm.com,16020,1407932753555}
2014-08-13 06:01:21,759 INFO  [PostOpenDeployTasks:2eb418e3c70ddeb740c21f06d8d0f905] master.RegionStateStore: Updating row hbase:namespace,,1407931602983.2eb418e3c70ddeb740c21f06d8d0f905. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407932753555
2014-08-13 06:05:53,760 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.02 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1494, hits=1486, hitRatio=99.46%, , cachingAccesses=1491, cachingHits=1483, cachingHitsRatio=99.46%, evictions=0, evicted=5, evictedPerRun=Infinity
