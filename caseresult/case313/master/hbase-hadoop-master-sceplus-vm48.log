Wed Aug  6 03:27:30 PDT 2014 Starting master on sceplus-vm48
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-08-06 03:27:31,014 INFO  [main] util.VersionInfo: HBase 2.0.0-SNAPSHOT
2014-08-06 03:27:31,015 INFO  [main] util.VersionInfo: Subversion git://sceplus-vm48/home/hadoop/hbase-2.0.0-SNAPSHOT -r 50ac59fa8530bbd35c21cd61cfd64d2bd7d3eb57
2014-08-06 03:27:31,015 INFO  [main] util.VersionInfo: Compiled by hadoop on Sun Aug  3 14:37:33 PDT 2014
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64/
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Dhbase.security.logger=INFO,RFAS
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.53 39014 22
2014-08-06 03:27:31,294 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=12288
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-master.znode
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.53 39014 9.1.143.58 22
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-08-06 03:27:31,295 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-08-06 03:27:31,299 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.7.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/../hbase-server/target:/home/hadoop/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/com/lmax/disruptor/3.2.0/disruptor-3.2.0.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.19.Final/netty-all-4.0.19.Final.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/../lib/tools.jar:/home/hadoop/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.0/hadoop-annotations-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.0/hadoop-auth-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.4.0/hadoop-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.0/hadoop-mapreduce-client-app-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.0/hadoop-mapreduce-client-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.0/hadoop-mapreduce-client-core-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/2.4.0/hadoop-mapreduce-client-hs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.0/hadoop-mapreduce-client-shuffle-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-minicluster/2.4.0/hadoop-minicluster-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.0/hadoop-yarn-api-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.0/hadoop-yarn-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.0/hadoop-yarn-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.4.0/hadoop-yarn-server-applicationhistoryservice-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.0/hadoop-yarn-server-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.4.0/hadoop-yarn-server-nodemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.4.0/hadoop-yarn-server-resourcemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/2.4.0/hadoop-yarn-server-tests-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.4.0/hadoop-yarn-server-web-proxy-2.4.0.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-client/target/hbase-client-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-it/target/hbase-it-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-prefix-tree/target/hbase-prefix-tree-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-protocol/target/hbase-protocol-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-shell/target/hbase-shell-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-testing-util/target/hbase-testing-util-2.0.0-SNAPSHOT.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jettison/jettison/1.3.1/jettison-1.3.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/hadoop/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/home/hadoop/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/.m2/repository/org/jboss/netty/netty/3.2.4.Final/netty-3.2.4.Final.jar:/home/hadoop/.m2/repository/org/jruby/jruby-complete/1.6.8/jruby-complete-1.6.8.jar:/home/hadoop/.m2/repository/org/mockito/mockito-all/1.9.0/mockito-all-1.9.0.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/*.jar:::/home/hadoop/hbase/selfdapql.jar
2014-08-06 03:27:31,299 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-08-06 03:27:31,299 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-08-06 03:27:31,299 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=:/home/hadoop/hbase/selfdapql.jar
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-master.autorestart
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=3551
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-sceplus-vm48.log
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-sceplus-vm48
2014-08-06 03:27:31,300 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-08-06 03:27:31,303 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.51-b03
2014-08-06 03:27:31,304 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx12288m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Dhbase.security.logger=INFO,RFAS]
2014-08-06 03:27:31,709 INFO  [main] regionserver.RSRpcServices: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020 server-side HConnection retries=350
2014-08-06 03:27:31,918 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=5
2014-08-06 03:27:31,959 INFO  [main] ipc.RpcServer: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020: started 10 reader(s).
2014-08-06 03:27:32,083 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-08-06 03:27:32,101 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-08-06 03:27:32,197 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-08-06 03:27:32,197 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-08-06 03:27:32,442 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-08-06 03:27:32,447 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache size=4.76 GB, blockSize=64 KB
2014-08-06 03:27:32,465 INFO  [main] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:27:33,189 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-08-06 03:27:33,204 WARN  [main] trace.SpanReceiverHost: Class org.cloudera.htrace.impl.LocalFileSpanReceiver cannot be found. org.cloudera.htrace.impl.LocalFileSpanReceiver
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm48.almaden.ibm.com
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_55
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.7.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/../hbase-server/target:/home/hadoop/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/home/hadoop/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/com/lmax/disruptor/3.2.0/disruptor-3.2.0.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.7/commons-codec-1.7.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.19.Final/netty-all-4.0.19.Final.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/hadoop/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/../lib/tools.jar:/home/hadoop/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.0/hadoop-annotations-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.0/hadoop-auth-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.4.0/hadoop-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.0/hadoop-mapreduce-client-app-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.0/hadoop-mapreduce-client-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.0/hadoop-mapreduce-client-core-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-hs/2.4.0/hadoop-mapreduce-client-hs-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.0/hadoop-mapreduce-client-shuffle-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-minicluster/2.4.0/hadoop-minicluster-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.0/hadoop-yarn-api-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.0/hadoop-yarn-client-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.0/hadoop-yarn-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.4.0/hadoop-yarn-server-applicationhistoryservice-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.0/hadoop-yarn-server-common-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.4.0/hadoop-yarn-server-nodemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.4.0/hadoop-yarn-server-resourcemanager-2.4.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-tests/2.4.0/hadoop-yarn-server-tests-2.4.0-tests.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.4.0/hadoop-yarn-server-web-proxy-2.4.0.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-client/target/hbase-client-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-common/target/hbase-common-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop-compat/target/hbase-hadoop-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-hadoop2-compat/target/hbase-hadoop2-compat-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-it/target/hbase-it-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-prefix-tree/target/hbase-prefix-tree-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-protocol/target/hbase-protocol-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-server/target/hbase-server-2.0.0-SNAPSHOT-tests.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-shell/target/hbase-shell-2.0.0-SNAPSHOT.jar:/home/hadoop/hbase-2.0.0-SNAPSHOT/hbase-testing-util/target/hbase-testing-util-2.0.0-SNAPSHOT.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/home/hadoop/.m2/repository/org/codehaus/jettison/jettison/1.3.1/jettison-1.3.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/hadoop/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/home/hadoop/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/home/hadoop/.m2/repository/org/jboss/netty/netty/3.2.4.Final/netty-3.2.4.Final.jar:/home/hadoop/.m2/repository/org/jruby/jruby-complete/1.6.8/jruby-complete-1.6.8.jar:/home/hadoop/.m2/repository/org/mockito/mockito-all/1.9.0/mockito-all-1.9.0.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/home/hadoop/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/*.jar:::/home/hadoop/hbase/selfdapql.jar
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-08-06 03:27:33,229 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-08-06 03:27:33,230 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-08-06 03:27:33,230 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-08-06 03:27:33,230 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-08-06 03:27:33,230 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-08-06 03:27:33,230 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop
2014-08-06 03:27:33,231 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=master:16020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:27:33,250 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:16020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:27:33,254 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:27:33,263 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-06 03:27:33,290 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147aadc06860000, negotiated timeout = 90000
2014-08-06 03:27:33,363 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-08-06 03:27:33,363 INFO  [RpcServer.listener,port=16020] ipc.RpcServer: RpcServer.listener,port=16020: starting
2014-08-06 03:27:33,452 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-08-06 03:27:33,459 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
2014-08-06 03:27:33,475 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
2014-08-06 03:27:33,479 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-08-06 03:27:33,479 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-08-06 03:27:33,479 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-08-06 03:27:33,504 INFO  [main] http.HttpServer: Jetty bound to port 16030
2014-08-06 03:27:33,504 INFO  [main] mortbay.log: jetty-6.1.26
2014-08-06 03:27:33,881 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16030
2014-08-06 03:27:33,882 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:54310/hbase, hbase.cluster.distributed=true
2014-08-06 03:27:33,897 INFO  [main] master.HMaster: Adding ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,16020,1407320852266 in backup master directory
2014-08-06 03:27:34,017 INFO  [main] mortbay.log: jetty-6.1.26
2014-08-06 03:27:34,018 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
2014-08-06 03:27:34,062 INFO  [ActiveMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,16020,1407320852266 from backup master directory
2014-08-06 03:27:34,068 INFO  [ActiveMasterManager] master.ActiveMasterManager: Registered Active Master=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:27:34,196 INFO  [ActiveMasterManager] util.FSUtils: Waiting for dfs to exit safe mode...
2014-08-06 03:27:44,203 INFO  [ActiveMasterManager] util.FSUtils: Waiting for dfs to exit safe mode...
2014-08-06 03:27:54,738 INFO  [ActiveMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-08-06 03:27:54,759 INFO  [ActiveMasterManager] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=true
2014-08-06 03:27:54,762 INFO  [ActiveMasterManager] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-08-06 03:27:54,839 INFO  [ActiveMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x40f93dfb, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:27:54,841 INFO  [ActiveMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x40f93dfb connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:27:54,841 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:27:54,843 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-06 03:27:54,847 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47aadc098f0001, negotiated timeout = 90000
2014-08-06 03:27:55,033 INFO  [ActiveMasterManager] master.HMaster: Server active/primary master=sceplus-vm48.almaden.ibm.com,16020,1407320852266, sessionid=0x147aadc06860000, setting cluster-up flag (Was=false)
2014-08-06 03:27:55,037 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: ClusterId : 78c9dafc-f226-435b-aae6-e472cfc131f9
2014-08-06 03:27:55,097 INFO  [ActiveMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2014-08-06 03:27:55,103 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.8 G, globalMemStoreLimitLowMark=4.5 G, maxHeap=11.9 G
2014-08-06 03:27:55,108 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-08-06 03:27:55,110 INFO  [ActiveMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
2014-08-06 03:27:55,131 INFO  [ActiveMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=replicationLogCleaner, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:27:55,132 INFO  [ActiveMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:27:55,132 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:27:55,133 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-06 03:27:55,136 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,16020,1407320852266 with port=16020, startcode=1407320852266
2014-08-06 03:27:55,138 INFO  [ActiveMasterManager-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47aadc098f0002, negotiated timeout = 90000
2014-08-06 03:27:55,141 WARN  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2014-08-06 03:27:55,165 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn false
2014-08-06 03:27:55,165 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,16020,1407320852266 with port=16020, startcode=1407320852266
2014-08-06 03:27:55,177 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] master.ServerManager: Registering server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:27:55,216 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 51 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-06 03:27:55,226 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true, prefix=sceplus-vm48.almaden.ibm.com%2C16020%2C1407320852266, logDir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407320852266, oldLogDir=hdfs://master:54310/hbase/oldWALs
2014-08-06 03:27:55,548 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: Slow sync cost: 267 ms, current pipeline: []
2014-08-06 03:27:55,549 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407320852266/sceplus-vm48.almaden.ibm.com%2C16020%2C1407320852266.1407320875232
2014-08-06 03:27:55,593 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-08-06 03:27:55,606 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,16020,1407320852266, slave1,16020,1407319321553] other RSs: [sceplus-vm48.almaden.ibm.com,16020,1407320852266, sceplus-vm49.almaden.ibm.com,16020,1407320853379]
2014-08-06 03:27:55,636 INFO  [defaultRpcServer.handler=7,queue=2,port=16020] master.ServerManager: Registering server=slave1,16020,1407320853379
2014-08-06 03:27:55,646 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x316dcbde, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:27:55,647 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x316dcbde connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:27:55,648 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:27:55,649 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-06 03:27:55,653 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147aadc06860004, negotiated timeout = 90000
2014-08-06 03:27:55,667 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 502 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-06 03:27:55,690 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: SplitLogWorker sceplus-vm48.almaden.ibm.com,16020,1407320852266 starting
2014-08-06 03:27:55,692 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HeapMemoryManager: Starting HeapMemoryTuner chore.
2014-08-06 03:27:55,698 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020] regionserver.HRegionServer: Serving as sceplus-vm48.almaden.ibm.com,16020,1407320852266, RpcServer on sceplus-vm48.almaden.ibm.com/9.1.143.58:16020, sessionid=0x147aadc06860000
2014-08-06 03:27:55,698 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x511f45ff, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:27:55,699 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x511f45ff connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:27:55,700 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:27:55,702 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-06 03:27:55,706 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147aadc06860005, negotiated timeout = 90000
2014-08-06 03:27:57,173 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 2008 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-06 03:27:58,678 INFO  [ActiveMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 3513 ms, expecting minimum of 2, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms, selfCheckedIn true
2014-08-06 03:27:59,075 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving slave1,16020,1407319321553's hlogs to my queue
2014-08-06 03:27:59,087 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Won't transfer the queue, another RS took care of it because of: KeeperErrorCode = NoNode for /hbase/replication/rs/slave1,16020,1407319321553/lock
2014-08-06 03:27:59,681 INFO  [ActiveMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 2, slept for 4516 ms, expecting minimum of 2, maximum of 2147483647, master is running, selfCheckedIn true
2014-08-06 03:27:59,682 INFO  [ActiveMasterManager] master.ServerManager: Registering server=sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:27:59,682 INFO  [ActiveMasterManager] master.HMaster: Registered server found up in zk but who has not yet reported in: sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:27:59,691 INFO  [ActiveMasterManager] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407320852266 belongs to an existing region server
2014-08-06 03:27:59,691 INFO  [ActiveMasterManager] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553 doesn't belong to a known region server, splitting
2014-08-06 03:27:59,692 INFO  [ActiveMasterManager] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379 belongs to an existing region server
2014-08-06 03:27:59,788 INFO  [ActiveMasterManager] zookeeper.MetaTableLocator: Failed verification of hbase:meta,,1 at address=sceplus-vm48.almaden.ibm.com,16020,1407319285032, exception=org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on sceplus-vm48.almaden.ibm.com,16020,1407320852266
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2605)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:795)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegionInfo(RSRpcServices.java:1067)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:20158)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2013)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
	at java.lang.Thread.run(Thread.java:744)

2014-08-06 03:27:59,818 INFO  [ActiveMasterManager] zookeeper.MetaTableLocator: Unsetting hbase:meta region location in ZooKeeper
2014-08-06 03:27:59,872 INFO  [ActiveMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:27:59,872 INFO  [ActiveMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1407320879711, server=null} to {1588230740 state=PENDING_OPEN, ts=1407320879872, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:27:59,885 INFO  [ActiveMasterManager] regionserver.RSRpcServices: Open hbase:meta,,1.1588230740
2014-08-06 03:27:59,891 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true, prefix=sceplus-vm48.almaden.ibm.com%2C16020%2C1407320852266, logDir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407320852266, oldLogDir=hdfs://master:54310/hbase/oldWALs
2014-08-06 03:27:59,918 INFO  [ActiveMasterManager] master.MasterFileSystem: Log dir for server sceplus-vm48.almaden.ibm.com,16020,1407319285032 does not exist
2014-08-06 03:27:59,919 INFO  [ActiveMasterManager] master.SplitLogManager: dead splitlog workers [slave1,16020,1407319321553, sceplus-vm48.almaden.ibm.com,16020,1407319285032]
2014-08-06 03:27:59,938 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: Slow sync cost: 21 ms, current pipeline: []
2014-08-06 03:27:59,939 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,16020,1407320852266/sceplus-vm48.almaden.ibm.com%2C16020%2C1407320852266.1407320879899.meta
2014-08-06 03:27:59,947 INFO  [ActiveMasterManager] master.SplitLogManager: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting is empty dir, no logs to split
2014-08-06 03:27:59,947 INFO  [ActiveMasterManager] master.SplitLogManager: started splitting 0 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting]
2014-08-06 03:27:59,960 INFO  [main-EventThread] zookeeper.RecoveringRegionWatcher: /hbase/recovering-regions/1588230740 znode deleted. Region: 1588230740 completes recovery.
2014-08-06 03:27:59,984 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-08-06 03:27:59,987 WARN  [ActiveMasterManager] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting
2014-08-06 03:27:59,987 INFO  [ActiveMasterManager] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting] in 40ms
2014-08-06 03:27:59,987 INFO  [ActiveMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-08-06 03:28:00,059 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:28:00,091 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:28:00,171 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for b74bce3b0d88427391bd384d1e8e461b
2014-08-06 03:28:00,218 INFO  [RS_OPEN_META-sceplus-vm48:16020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=9790
2014-08-06 03:28:00,220 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for hbase:meta,,1.1588230740
2014-08-06 03:28:00,221 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaTableLocator: Setting hbase:meta region location in ZooKeeper as sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:28:00,238 INFO  [PostOpenDeployTasks:1588230740] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1407320879872, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {1588230740 state=OPEN, ts=1407320880238, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:28:00,239 INFO  [PostOpenDeployTasks:1588230740] master.RegionStates: Onlined 1588230740 on sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:28:00,241 INFO  [ActiveMasterManager] master.HMaster: hbase:meta assigned=1, rit=false, location=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:28:00,368 INFO  [ActiveMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-08-06 03:28:00,429 INFO  [ActiveMasterManager] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2014-08-06 03:28:00,429 WARN  [ActiveMasterManager] master.ServerManager: Expiration of sceplus-vm48.almaden.ibm.com,16020,1407319285032 but server not online
2014-08-06 03:28:00,438 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Splitting logs for sceplus-vm48.almaden.ibm.com,16020,1407319285032 before assignment.
2014-08-06 03:28:00,438 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-06 03:28:00,438 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407319321553 before assignment.
2014-08-06 03:28:00,439 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-06 03:28:00,451 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407320880420, server=sceplus-vm48.almaden.ibm.com,16020,1407319285032} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OFFLINE, ts=1407320880451, server=sceplus-vm48.almaden.ibm.com,16020,1407319285032}
2014-08-06 03:28:00,452 INFO  [ActiveMasterManager] master.AssignmentManager: Joined the cluster in 84ms, failover=true
2014-08-06 03:28:00,453 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OFFLINE
2014-08-06 03:28:00,481 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] handler.ServerShutdownHandler: Reassigning 1 region(s) that sceplus-vm48.almaden.ibm.com,16020,1407319285032 was carrying (and 0 regions(s) that were opening on this server)
2014-08-06 03:28:00,509 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Bulk assigning 1 region(s) across 3 server(s), round-robin=true
2014-08-06 03:28:00,512 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 1 region(s) to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:28:00,516 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OFFLINE, ts=1407320880451, server=sceplus-vm48.almaden.ibm.com,16020,1407319285032} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407320880516, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:28:00,516 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN&sn=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:28:00,521 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:28:00,528 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Bulk assigning done
2014-08-06 03:28:00,528 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-2] master.AssignmentManager: Waiting for fe1c441ecb6e3789e0fdd62314d7b06a to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:00,536 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:28:00,537 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:28:00,564 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=40000008
2014-08-06 03:28:00,565 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:28:00,574 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {cce6d814539276fd22b26867b43c998d state=OPEN, ts=1407320880425, server=slave1,16020,1407319321553} to {cce6d814539276fd22b26867b43c998d state=OFFLINE, ts=1407320880574, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,574 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user5,1407319358584.cce6d814539276fd22b26867b43c998d. with state=OFFLINE
2014-08-06 03:28:00,577 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {c1131055f4f6d48d5e6ad78c4c97663a state=OPEN, ts=1407320880427, server=slave1,16020,1407319321553} to {c1131055f4f6d48d5e6ad78c4c97663a state=OFFLINE, ts=1407320880577, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,577 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a. with state=OFFLINE
2014-08-06 03:28:00,580 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {8f7167cd426af8a818920e7a047649ae state=OPEN, ts=1407320880426, server=slave1,16020,1407319321553} to {8f7167cd426af8a818920e7a047649ae state=OFFLINE, ts=1407320880580, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,580 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user7,1407319358584.8f7167cd426af8a818920e7a047649ae. with state=OFFLINE
2014-08-06 03:28:00,582 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {f4880f1fe753a7bc9cece08fdf998430 state=OPEN, ts=1407320880422, server=slave1,16020,1407319321553} to {f4880f1fe753a7bc9cece08fdf998430 state=OFFLINE, ts=1407320880582, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,582 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430. with state=OFFLINE
2014-08-06 03:28:00,585 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {5c8404c1d7d86635c92a35d7de11d407 state=OPEN, ts=1407320880424, server=slave1,16020,1407319321553} to {5c8404c1d7d86635c92a35d7de11d407 state=OFFLINE, ts=1407320880585, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,585 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user4,1407319358584.5c8404c1d7d86635c92a35d7de11d407. with state=OFFLINE
2014-08-06 03:28:00,587 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {027f02bdfa065ce4a6a97ca2f269b28b state=OPEN, ts=1407320880422, server=slave1,16020,1407319321553} to {027f02bdfa065ce4a6a97ca2f269b28b state=OFFLINE, ts=1407320880587, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,587 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b. with state=OFFLINE
2014-08-06 03:28:00,589 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {6da652800f7aa3a98ca1822845f2b600 state=OPEN, ts=1407320880428, server=slave1,16020,1407319321553} to {6da652800f7aa3a98ca1822845f2b600 state=OFFLINE, ts=1407320880589, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,589 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user9,1407319358584.6da652800f7aa3a98ca1822845f2b600. with state=OFFLINE
2014-08-06 03:28:00,592 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {c75a847add084fca666d04bac8c5b88f state=OPEN, ts=1407320880425, server=slave1,16020,1407319321553} to {c75a847add084fca666d04bac8c5b88f state=OFFLINE, ts=1407320880592, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,592 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f. with state=OFFLINE
2014-08-06 03:28:00,594 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {100c3ad1432410b7d2b1166d58ed979d state=OPEN, ts=1407320880423, server=slave1,16020,1407319321553} to {100c3ad1432410b7d2b1166d58ed979d state=OFFLINE, ts=1407320880594, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,594 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,user3,1407319358584.100c3ad1432410b7d2b1166d58ed979d. with state=OFFLINE
2014-08-06 03:28:00,597 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStates: Transition {955f3e36325a0ec2428b432a1d5aaffe state=OPEN, ts=1407320880421, server=slave1,16020,1407319321553} to {955f3e36325a0ec2428b432a1d5aaffe state=OFFLINE, ts=1407320880597, server=slave1,16020,1407319321553}
2014-08-06 03:28:00,597 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.RegionStateStore: Updating row usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe. with state=OFFLINE
2014-08-06 03:28:00,599 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Reassigning 10 region(s) that slave1,16020,1407319321553 was carrying (and 0 regions(s) that were opening on this server)
2014-08-06 03:28:00,599 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407320880516, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407320880599, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:28:00,599 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=40000008&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:28:00,602 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Onlined fe1c441ecb6e3789e0fdd62314d7b06a on sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:28:00,607 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.MasterFileSystem: Log dir for server sceplus-vm48.almaden.ibm.com,16020,1407319285032 does not exist
2014-08-06 03:28:00,607 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,16020,1407319285032]
2014-08-06 03:28:00,607 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: started splitting 0 logs in []
2014-08-06 03:28:00,619 INFO  [main-EventThread] zookeeper.RecoveringRegionWatcher: /hbase/recovering-regions/fe1c441ecb6e3789e0fdd62314d7b06a znode deleted. Region: fe1c441ecb6e3789e0fdd62314d7b06a completes recovery.
2014-08-06 03:28:00,625 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 18ms
2014-08-06 03:28:00,625 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.LogReplayHandler: Finished processing shutdown of sceplus-vm48.almaden.ibm.com,16020,1407319285032
2014-08-06 03:28:00,693 INFO  [ActiveMasterManager] master.HMaster: Master has completed initialization
2014-08-06 03:28:00,780 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Bulk assigning 10 region(s) across 3 server(s), round-robin=true
2014-08-06 03:28:00,781 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 5 region(s) to sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:00,781 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.AssignmentManager: Assigning 5 region(s) to slave1,16020,1407320853379
2014-08-06 03:28:00,781 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStates: Transition {c1131055f4f6d48d5e6ad78c4c97663a state=OFFLINE, ts=1407320880577, server=slave1,16020,1407319321553} to {c1131055f4f6d48d5e6ad78c4c97663a state=PENDING_OPEN, ts=1407320880781, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:00,782 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:00,782 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStates: Transition {cce6d814539276fd22b26867b43c998d state=OFFLINE, ts=1407320880574, server=slave1,16020,1407319321553} to {cce6d814539276fd22b26867b43c998d state=PENDING_OPEN, ts=1407320880782, server=slave1,16020,1407320853379}
2014-08-06 03:28:00,782 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user5,1407319358584.cce6d814539276fd22b26867b43c998d. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:00,787 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStates: Transition {f4880f1fe753a7bc9cece08fdf998430 state=OFFLINE, ts=1407320880582, server=slave1,16020,1407319321553} to {f4880f1fe753a7bc9cece08fdf998430 state=PENDING_OPEN, ts=1407320880787, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:00,787 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:00,788 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStates: Transition {8f7167cd426af8a818920e7a047649ae state=OFFLINE, ts=1407320880580, server=slave1,16020,1407319321553} to {8f7167cd426af8a818920e7a047649ae state=PENDING_OPEN, ts=1407320880788, server=slave1,16020,1407320853379}
2014-08-06 03:28:00,788 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user7,1407319358584.8f7167cd426af8a818920e7a047649ae. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:00,789 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStates: Transition {027f02bdfa065ce4a6a97ca2f269b28b state=OFFLINE, ts=1407320880587, server=slave1,16020,1407319321553} to {027f02bdfa065ce4a6a97ca2f269b28b state=PENDING_OPEN, ts=1407320880789, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:00,789 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:00,790 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStates: Transition {5c8404c1d7d86635c92a35d7de11d407 state=OFFLINE, ts=1407320880585, server=slave1,16020,1407319321553} to {5c8404c1d7d86635c92a35d7de11d407 state=PENDING_OPEN, ts=1407320880790, server=slave1,16020,1407320853379}
2014-08-06 03:28:00,790 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user4,1407319358584.5c8404c1d7d86635c92a35d7de11d407. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:00,792 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStates: Transition {c75a847add084fca666d04bac8c5b88f state=OFFLINE, ts=1407320880592, server=slave1,16020,1407319321553} to {c75a847add084fca666d04bac8c5b88f state=PENDING_OPEN, ts=1407320880792, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:00,792 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:00,793 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStates: Transition {6da652800f7aa3a98ca1822845f2b600 state=OFFLINE, ts=1407320880589, server=slave1,16020,1407319321553} to {6da652800f7aa3a98ca1822845f2b600 state=PENDING_OPEN, ts=1407320880793, server=slave1,16020,1407320853379}
2014-08-06 03:28:00,793 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user9,1407319358584.6da652800f7aa3a98ca1822845f2b600. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:00,794 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStates: Transition {955f3e36325a0ec2428b432a1d5aaffe state=OFFLINE, ts=1407320880597, server=slave1,16020,1407319321553} to {955f3e36325a0ec2428b432a1d5aaffe state=PENDING_OPEN, ts=1407320880794, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:00,795 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-0] master.RegionStateStore: Updating row usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe. with state=PENDING_OPEN&sn=sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:00,795 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStates: Transition {100c3ad1432410b7d2b1166d58ed979d state=OFFLINE, ts=1407320880594, server=slave1,16020,1407319321553} to {100c3ad1432410b7d2b1166d58ed979d state=PENDING_OPEN, ts=1407320880795, server=slave1,16020,1407320853379}
2014-08-06 03:28:00,795 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-GeneralBulkAssigner-1] master.RegionStateStore: Updating row usertable,user3,1407319358584.100c3ad1432410b7d2b1166d58ed979d. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:01,142 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Bulk assigning done
2014-08-06 03:28:01,142 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for cce6d814539276fd22b26867b43c998d to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:01,521 ERROR [defaultRpcServer.handler=23,queue=3,port=16020] master.AssignmentManager: Failed to transtion region from {f4880f1fe753a7bc9cece08fdf998430 state=PENDING_OPEN, ts=1407320880787, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to OPENED by slave1,16020,1407320853379: f4880f1fe753a7bc9cece08fdf998430 is not pending open on slave1,16020,1407320853379
2014-08-06 03:28:01,521 ERROR [defaultRpcServer.handler=1,queue=1,port=16020] master.AssignmentManager: Failed to transtion region from {c1131055f4f6d48d5e6ad78c4c97663a state=PENDING_OPEN, ts=1407320880781, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to OPENED by slave1,16020,1407320853379: c1131055f4f6d48d5e6ad78c4c97663a is not pending open on slave1,16020,1407320853379
2014-08-06 03:28:01,541 ERROR [defaultRpcServer.handler=17,queue=2,port=16020] master.MasterRpcServices: Region server slave1,16020,1407320853379 reported a fatal error:
ABORTING region server slave1,16020,1407320853379: Exception running postOpenDeployTasks; region=c1131055f4f6d48d5e6ad78c4c97663a
Cause:
java.io.IOException: Failed to report opened region to master: usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1730)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:321)

2014-08-06 03:28:01,541 ERROR [defaultRpcServer.handler=19,queue=4,port=16020] master.MasterRpcServices: Region server slave1,16020,1407320853379 reported a fatal error:
ABORTING region server slave1,16020,1407320853379: Exception running postOpenDeployTasks; region=f4880f1fe753a7bc9cece08fdf998430
Cause:
java.io.IOException: Failed to report opened region to master: usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430.
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1730)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:321)

2014-08-06 03:28:01,548 ERROR [defaultRpcServer.handler=6,queue=1,port=16020] master.MasterRpcServices: Region server slave1,16020,1407320853379 reported a fatal error:
ABORTING region server slave1,16020,1407320853379: Exception running postOpenDeployTasks; region=cce6d814539276fd22b26867b43c998d
Cause:
org.apache.hadoop.hbase.regionserver.RegionServerStoppedException: Server slave1,16020,1407320853379 not running, aborting
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.checkOpen(RSRpcServices.java:823)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.postOpenDeployTasks(HRegionServer.java:1703)
	at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler$PostOpenDeployTasksThread.run(OpenRegionHandler.java:321)

2014-08-06 03:28:06,196 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sceplus-vm49.almaden.ibm.com,16020,1407320853379]
2014-08-06 03:28:06,201 INFO  [main-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/sceplus-vm49.almaden.ibm.com,16020,1407320853379 znode expired, triggering replicatorRemoved event
2014-08-06 03:28:06,202 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Splitting logs for sceplus-vm49.almaden.ibm.com,16020,1407320853379 before assignment.
2014-08-06 03:28:06,203 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-06 03:28:06,203 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Found region in {f4880f1fe753a7bc9cece08fdf998430 state=PENDING_OPEN, ts=1407320880787, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:06,203 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Found region in {c75a847add084fca666d04bac8c5b88f state=PENDING_OPEN, ts=1407320880792, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:06,203 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Found region in {955f3e36325a0ec2428b432a1d5aaffe state=PENDING_OPEN, ts=1407320880794, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:06,203 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Found region in {027f02bdfa065ce4a6a97ca2f269b28b state=PENDING_OPEN, ts=1407320880789, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:06,203 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Found region in {c1131055f4f6d48d5e6ad78c4c97663a state=PENDING_OPEN, ts=1407320880781, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to be reassigned by SSH for sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:28:06,207 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/f4880f1fe753a7bc9cece08fdf998430 already deleted, retry=false
2014-08-06 03:28:06,207 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {f4880f1fe753a7bc9cece08fdf998430 state=PENDING_OPEN, ts=1407320880787, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {f4880f1fe753a7bc9cece08fdf998430 state=OFFLINE, ts=1407320886207, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:06,207 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430. with state=OFFLINE
2014-08-06 03:28:06,216 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/c75a847add084fca666d04bac8c5b88f already deleted, retry=false
2014-08-06 03:28:06,216 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {c75a847add084fca666d04bac8c5b88f state=PENDING_OPEN, ts=1407320880792, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {c75a847add084fca666d04bac8c5b88f state=OFFLINE, ts=1407320886216, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:06,216 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f. with state=OFFLINE
2014-08-06 03:28:06,224 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/955f3e36325a0ec2428b432a1d5aaffe already deleted, retry=false
2014-08-06 03:28:06,224 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {955f3e36325a0ec2428b432a1d5aaffe state=PENDING_OPEN, ts=1407320880794, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {955f3e36325a0ec2428b432a1d5aaffe state=OFFLINE, ts=1407320886224, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:06,224 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe. with state=OFFLINE
2014-08-06 03:28:06,232 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/027f02bdfa065ce4a6a97ca2f269b28b already deleted, retry=false
2014-08-06 03:28:06,233 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {027f02bdfa065ce4a6a97ca2f269b28b state=PENDING_OPEN, ts=1407320880789, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {027f02bdfa065ce4a6a97ca2f269b28b state=OFFLINE, ts=1407320886233, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:06,233 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b. with state=OFFLINE
2014-08-06 03:28:06,244 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/c1131055f4f6d48d5e6ad78c4c97663a already deleted, retry=false
2014-08-06 03:28:06,244 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {c1131055f4f6d48d5e6ad78c4c97663a state=PENDING_OPEN, ts=1407320880781, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {c1131055f4f6d48d5e6ad78c4c97663a state=OFFLINE, ts=1407320886244, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379}
2014-08-06 03:28:06,244 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a. with state=OFFLINE
2014-08-06 03:28:06,249 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Reassigning 0 region(s) that sceplus-vm49.almaden.ibm.com,16020,1407320853379 was carrying (and 5 regions(s) that were opening on this server)
2014-08-06 03:28:06,251 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Assigning 5 region(s) to slave1,16020,1407320853379
2014-08-06 03:28:06,251 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {f4880f1fe753a7bc9cece08fdf998430 state=OFFLINE, ts=1407320886207, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {f4880f1fe753a7bc9cece08fdf998430 state=PENDING_OPEN, ts=1407320886251, server=slave1,16020,1407320853379}
2014-08-06 03:28:06,251 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:06,256 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {c75a847add084fca666d04bac8c5b88f state=OFFLINE, ts=1407320886216, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {c75a847add084fca666d04bac8c5b88f state=PENDING_OPEN, ts=1407320886256, server=slave1,16020,1407320853379}
2014-08-06 03:28:06,256 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:06,261 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {955f3e36325a0ec2428b432a1d5aaffe state=OFFLINE, ts=1407320886224, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {955f3e36325a0ec2428b432a1d5aaffe state=PENDING_OPEN, ts=1407320886261, server=slave1,16020,1407320853379}
2014-08-06 03:28:06,261 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:06,265 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {027f02bdfa065ce4a6a97ca2f269b28b state=OFFLINE, ts=1407320886233, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {027f02bdfa065ce4a6a97ca2f269b28b state=PENDING_OPEN, ts=1407320886265, server=slave1,16020,1407320853379}
2014-08-06 03:28:06,265 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:06,269 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStates: Transition {c1131055f4f6d48d5e6ad78c4c97663a state=OFFLINE, ts=1407320886244, server=sceplus-vm49.almaden.ibm.com,16020,1407320853379} to {c1131055f4f6d48d5e6ad78c4c97663a state=PENDING_OPEN, ts=1407320886269, server=slave1,16020,1407320853379}
2014-08-06 03:28:06,270 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.RegionStateStore: Updating row usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a. with state=PENDING_OPEN&sn=slave1,16020,1407320853379
2014-08-06 03:28:06,278 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Unable to communicate with slave1,16020,1407320853379 in order to assign regions, 
java.io.IOException: Call to slave1/9.1.143.59:16020 failed on local exception: java.io.IOException: Connection to sceplus-vm49.almaden.ibm.com/9.1.143.59:16020 is closing. Call id=12, waitTime=2
	at org.apache.hadoop.hbase.ipc.RpcClient.wrapException(RpcClient.java:1571)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1542)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.openRegion(AdminProtos.java:20964)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionOpen(ServerManager.java:766)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1679)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2653)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:2634)
	at org.apache.hadoop.hbase.master.handler.ServerShutdownHandler.process(ServerShutdownHandler.java:291)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.io.IOException: Connection to sceplus-vm49.almaden.ibm.com/9.1.143.59:16020 is closing. Call id=12, waitTime=2
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.cleanupCalls(RpcClient.java:1265)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.close(RpcClient.java:1059)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.run(RpcClient.java:792)
2014-08-06 03:28:06,284 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for f4880f1fe753a7bc9cece08fdf998430 to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:06,289 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=1 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:06,290 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:06,289 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:06,290 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:06,289 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=1 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:06,623 INFO  [defaultRpcServer.handler=24,queue=4,port=16020] master.HMaster: Client=hadoop//9.1.143.58 disable usertable
2014-08-06 03:28:06,680 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.DisableTableHandler: Attempting to disable table usertable
2014-08-06 03:28:06,681 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from DISABLING to DISABLING
2014-08-06 03:28:06,687 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from DISABLING to DISABLED
2014-08-06 03:28:06,693 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.DisableTableHandler: Disabled table, usertable, is done=true
2014-08-06 03:28:06,795 INFO  [defaultRpcServer.handler=22,queue=2,port=16020] master.HMaster: Client=hadoop//9.1.143.58 delete usertable
2014-08-06 03:28:06,832 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table usertable
2014-08-06 03:28:08,292 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:08,294 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:08,295 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:08,295 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:08,295 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=3 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:08,296 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=2 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:08,617 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving sceplus-vm49.almaden.ibm.com,16020,1407320853379's hlogs to my queue
2014-08-06 03:28:08,622 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Won't transfer the queue, another RS took care of it because of: KeeperErrorCode = NoNode for /hbase/replication/rs/sceplus-vm49.almaden.ibm.com,16020,1407320853379/lock
2014-08-06 03:28:10,297 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:10,298 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:10,299 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=4 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:10,299 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:10,299 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=4 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:10,302 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=3 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:10,300 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,304 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,305 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,305 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=4 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,305 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,308 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=5 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,308 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=6 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,305 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:12,310 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=6 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:14,311 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=5 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:14,312 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:14,311 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:14,316 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=8 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:14,315 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=6 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:14,315 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:14,314 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=6 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,188 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Timed out on waiting for cce6d814539276fd22b26867b43c998d to be assigned.
2014-08-06 03:28:16,188 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Region cce6d814539276fd22b26867b43c998d didn't complete assignment in time
2014-08-06 03:28:16,188 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for c1131055f4f6d48d5e6ad78c4c97663a to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:16,319 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,320 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,322 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,323 INFO  [AM.-pool1-t1] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.io.IOException: This connection is closing for usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430., try=10 of 10
java.io.IOException: This connection is closing
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:908)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,323 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=8 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,326 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=7 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,326 WARN  [AM.-pool1-t1] master.RegionStates: Failed to open/close f4880f1fe753a7bc9cece08fdf998430 on slave1,16020,1407320853379, set to FAILED_CLOSE
2014-08-06 03:28:16,325 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:16,328 INFO  [AM.-pool1-t1] master.RegionStates: Transition {f4880f1fe753a7bc9cece08fdf998430 state=PENDING_OPEN, ts=1407320886251, server=slave1,16020,1407320853379} to {f4880f1fe753a7bc9cece08fdf998430 state=FAILED_CLOSE, ts=1407320896328, server=slave1,16020,1407320853379}
2014-08-06 03:28:16,332 INFO  [AM.-pool1-t1] master.RegionStateStore: Updating row usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430. with state=FAILED_CLOSE
2014-08-06 03:28:16,343 INFO  [AM.-pool1-t1] master.AssignmentManager: Skip assigning {ENCODED => f4880f1fe753a7bc9cece08fdf998430, NAME => 'usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430.', STARTKEY => 'user1', ENDKEY => 'user2'}, we couldn't close it: {f4880f1fe753a7bc9cece08fdf998430 state=FAILED_CLOSE, ts=1407320896328, server=slave1,16020,1407320853379}
2014-08-06 03:28:18,325 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:18,328 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=9 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:18,329 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:18,333 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=8 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:18,334 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:20,331 INFO  [AM.-pool1-t2] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f., try=10 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:20,332 WARN  [AM.-pool1-t2] master.RegionStates: Failed to open/close c75a847add084fca666d04bac8c5b88f on slave1,16020,1407320853379, set to FAILED_CLOSE
2014-08-06 03:28:20,332 INFO  [AM.-pool1-t3] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe., try=10 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:20,332 INFO  [AM.-pool1-t2] master.RegionStates: Transition {c75a847add084fca666d04bac8c5b88f state=PENDING_OPEN, ts=1407320886256, server=slave1,16020,1407320853379} to {c75a847add084fca666d04bac8c5b88f state=FAILED_CLOSE, ts=1407320900332, server=slave1,16020,1407320853379}
2014-08-06 03:28:20,333 WARN  [AM.-pool1-t3] master.RegionStates: Failed to open/close 955f3e36325a0ec2428b432a1d5aaffe on slave1,16020,1407320853379, set to FAILED_CLOSE
2014-08-06 03:28:20,333 INFO  [AM.-pool1-t2] master.RegionStateStore: Updating row usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f. with state=FAILED_CLOSE
2014-08-06 03:28:20,333 INFO  [AM.-pool1-t3] master.RegionStates: Transition {955f3e36325a0ec2428b432a1d5aaffe state=PENDING_OPEN, ts=1407320886261, server=slave1,16020,1407320853379} to {955f3e36325a0ec2428b432a1d5aaffe state=FAILED_CLOSE, ts=1407320900333, server=slave1,16020,1407320853379}
2014-08-06 03:28:20,335 INFO  [AM.-pool1-t3] master.RegionStateStore: Updating row usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe. with state=FAILED_CLOSE
2014-08-06 03:28:20,335 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=9 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:20,336 INFO  [AM.-pool1-t4] master.AssignmentManager: Server slave1,16020,1407320853379 returned org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020 for usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b., try=10 of 10
org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: slave1/9.1.143.59:16020
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:916)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:20,337 WARN  [AM.-pool1-t4] master.RegionStates: Failed to open/close 027f02bdfa065ce4a6a97ca2f269b28b on slave1,16020,1407320853379, set to FAILED_CLOSE
2014-08-06 03:28:20,337 INFO  [AM.-pool1-t4] master.RegionStates: Transition {027f02bdfa065ce4a6a97ca2f269b28b state=PENDING_OPEN, ts=1407320886265, server=slave1,16020,1407320853379} to {027f02bdfa065ce4a6a97ca2f269b28b state=FAILED_CLOSE, ts=1407320900337, server=slave1,16020,1407320853379}
2014-08-06 03:28:20,338 INFO  [AM.-pool1-t4] master.RegionStateStore: Updating row usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b. with state=FAILED_CLOSE
2014-08-06 03:28:20,338 INFO  [AM.-pool1-t5] master.AssignmentManager: Server slave1,16020,1407320853379 returned java.net.ConnectException: Connection refused for usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a., try=10 of 10
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:631)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:931)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.writeRequest(RpcClient.java:1100)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.tracedWriteRequest(RpcClient.java:1069)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1512)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1700)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1765)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.closeRegion(AdminProtos.java:20976)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.closeRegion(ProtobufUtil.java:1652)
	at org.apache.hadoop.hbase.master.ServerManager.sendRegionClose(ServerManager.java:797)
	at org.apache.hadoop.hbase.master.AssignmentManager.unassign(AssignmentManager.java:1802)
	at org.apache.hadoop.hbase.master.AssignmentManager.forceRegionStateToOffline(AssignmentManager.java:1919)
	at org.apache.hadoop.hbase.master.AssignmentManager.assign(AssignmentManager.java:1548)
	at org.apache.hadoop.hbase.master.AssignCallable.call(AssignCallable.java:48)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:28:20,339 WARN  [AM.-pool1-t5] master.RegionStates: Failed to open/close c1131055f4f6d48d5e6ad78c4c97663a on slave1,16020,1407320853379, set to FAILED_CLOSE
2014-08-06 03:28:20,340 INFO  [AM.-pool1-t5] master.RegionStates: Transition {c1131055f4f6d48d5e6ad78c4c97663a state=PENDING_OPEN, ts=1407320886269, server=slave1,16020,1407320853379} to {c1131055f4f6d48d5e6ad78c4c97663a state=FAILED_CLOSE, ts=1407320900340, server=slave1,16020,1407320853379}
2014-08-06 03:28:20,340 INFO  [AM.-pool1-t5] master.RegionStateStore: Updating row usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a. with state=FAILED_CLOSE
2014-08-06 03:28:20,341 INFO  [AM.-pool1-t2] master.AssignmentManager: Skip assigning {ENCODED => c75a847add084fca666d04bac8c5b88f, NAME => 'usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f.', STARTKEY => 'user6', ENDKEY => 'user7'}, we couldn't close it: {c75a847add084fca666d04bac8c5b88f state=FAILED_CLOSE, ts=1407320900332, server=slave1,16020,1407320853379}
2014-08-06 03:28:20,342 INFO  [AM.-pool1-t3] master.AssignmentManager: Skip assigning {ENCODED => 955f3e36325a0ec2428b432a1d5aaffe, NAME => 'usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe.', STARTKEY => '', ENDKEY => 'user1'}, we couldn't close it: {955f3e36325a0ec2428b432a1d5aaffe state=FAILED_CLOSE, ts=1407320900333, server=slave1,16020,1407320853379}
2014-08-06 03:28:20,344 INFO  [AM.-pool1-t4] master.AssignmentManager: Skip assigning {ENCODED => 027f02bdfa065ce4a6a97ca2f269b28b, NAME => 'usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b.', STARTKEY => 'user2', ENDKEY => 'user3'}, we couldn't close it: {027f02bdfa065ce4a6a97ca2f269b28b state=FAILED_CLOSE, ts=1407320900337, server=slave1,16020,1407320853379}
2014-08-06 03:28:20,346 INFO  [AM.-pool1-t5] master.AssignmentManager: Skip assigning {ENCODED => c1131055f4f6d48d5e6ad78c4c97663a, NAME => 'usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a.', STARTKEY => 'user8', ENDKEY => 'user9'}, we couldn't close it: {c1131055f4f6d48d5e6ad78c4c97663a state=FAILED_CLOSE, ts=1407320900340, server=slave1,16020,1407320853379}
2014-08-06 03:28:21,347 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Timed out on waiting for f4880f1fe753a7bc9cece08fdf998430 to be assigned.
2014-08-06 03:28:21,347 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Region f4880f1fe753a7bc9cece08fdf998430 didn't complete assignment in time
2014-08-06 03:28:21,347 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for c75a847add084fca666d04bac8c5b88f to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:31,261 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Timed out on waiting for c1131055f4f6d48d5e6ad78c4c97663a to be assigned.
2014-08-06 03:28:31,261 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Region c1131055f4f6d48d5e6ad78c4c97663a didn't complete assignment in time
2014-08-06 03:28:31,262 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 8f7167cd426af8a818920e7a047649ae to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:36,368 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Timed out on waiting for c75a847add084fca666d04bac8c5b88f to be assigned.
2014-08-06 03:28:36,368 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Region c75a847add084fca666d04bac8c5b88f didn't complete assignment in time
2014-08-06 03:28:36,369 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for 955f3e36325a0ec2428b432a1d5aaffe to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:46,284 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Timed out on waiting for 8f7167cd426af8a818920e7a047649ae to be assigned.
2014-08-06 03:28:46,285 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Region 8f7167cd426af8a818920e7a047649ae didn't complete assignment in time
2014-08-06 03:28:46,285 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for f4880f1fe753a7bc9cece08fdf998430 to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:28:51,390 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Timed out on waiting for 955f3e36325a0ec2428b432a1d5aaffe to be assigned.
2014-08-06 03:28:51,391 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] handler.ServerShutdownHandler: Region 955f3e36325a0ec2428b432a1d5aaffe didn't complete assignment in time
2014-08-06 03:28:51,391 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for 027f02bdfa065ce4a6a97ca2f269b28b to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:29:01,305 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Timed out on waiting for f4880f1fe753a7bc9cece08fdf998430 to be assigned.
2014-08-06 03:29:01,305 WARN  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] handler.ServerShutdownHandler: Region f4880f1fe753a7bc9cece08fdf998430 didn't complete assignment in time
2014-08-06 03:29:01,306 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 5c8404c1d7d86635c92a35d7de11d407 to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:29:04,513 INFO  [defaultRpcServer.handler=27,queue=2,port=16020] master.ServerManager: Registering server=slave1,16020,1407320941557
2014-08-06 03:29:04,513 INFO  [defaultRpcServer.handler=27,queue=2,port=16020] master.ServerManager: Triggering server recovery; existingServer slave1,16020,1407320853379 looks stale, new server:slave1,16020,1407320941557
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Splitting logs for slave1,16020,1407320853379 before assignment.
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Mark regions in recovery before assignment.
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {f4880f1fe753a7bc9cece08fdf998430 state=FAILED_CLOSE, ts=1407320896328, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {5c8404c1d7d86635c92a35d7de11d407 state=PENDING_OPEN, ts=1407320880790, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {c75a847add084fca666d04bac8c5b88f state=FAILED_CLOSE, ts=1407320900332, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {8f7167cd426af8a818920e7a047649ae state=PENDING_OPEN, ts=1407320880788, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {955f3e36325a0ec2428b432a1d5aaffe state=FAILED_CLOSE, ts=1407320900333, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {027f02bdfa065ce4a6a97ca2f269b28b state=FAILED_CLOSE, ts=1407320900337, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,519 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {c1131055f4f6d48d5e6ad78c4c97663a state=FAILED_CLOSE, ts=1407320900340, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,520 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {6da652800f7aa3a98ca1822845f2b600 state=PENDING_OPEN, ts=1407320880793, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,520 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {100c3ad1432410b7d2b1166d58ed979d state=PENDING_OPEN, ts=1407320880795, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,520 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Found region in {cce6d814539276fd22b26867b43c998d state=PENDING_OPEN, ts=1407320880782, server=slave1,16020,1407320853379} to be reassigned by SSH for slave1,16020,1407320853379
2014-08-06 03:29:04,522 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/f4880f1fe753a7bc9cece08fdf998430 already deleted, retry=false
2014-08-06 03:29:04,522 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {f4880f1fe753a7bc9cece08fdf998430 state=FAILED_CLOSE, ts=1407320896328, server=slave1,16020,1407320853379} to {f4880f1fe753a7bc9cece08fdf998430 state=OFFLINE, ts=1407320944522, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,523 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430. with state=OFFLINE
2014-08-06 03:29:04,534 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/5c8404c1d7d86635c92a35d7de11d407 already deleted, retry=false
2014-08-06 03:29:04,534 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {5c8404c1d7d86635c92a35d7de11d407 state=PENDING_OPEN, ts=1407320880790, server=slave1,16020,1407320853379} to {5c8404c1d7d86635c92a35d7de11d407 state=OFFLINE, ts=1407320944534, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,534 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user4,1407319358584.5c8404c1d7d86635c92a35d7de11d407. with state=OFFLINE
2014-08-06 03:29:04,539 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 027f02bdfa065ce4a6a97ca2f269b28b to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:29:04,542 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/c75a847add084fca666d04bac8c5b88f already deleted, retry=false
2014-08-06 03:29:04,542 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {c75a847add084fca666d04bac8c5b88f state=FAILED_CLOSE, ts=1407320900332, server=slave1,16020,1407320853379} to {c75a847add084fca666d04bac8c5b88f state=OFFLINE, ts=1407320944542, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,542 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f. with state=OFFLINE
2014-08-06 03:29:04,554 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/8f7167cd426af8a818920e7a047649ae already deleted, retry=false
2014-08-06 03:29:04,554 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {8f7167cd426af8a818920e7a047649ae state=PENDING_OPEN, ts=1407320880788, server=slave1,16020,1407320853379} to {8f7167cd426af8a818920e7a047649ae state=OFFLINE, ts=1407320944554, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,554 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user7,1407319358584.8f7167cd426af8a818920e7a047649ae. with state=OFFLINE
2014-08-06 03:29:04,560 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/955f3e36325a0ec2428b432a1d5aaffe already deleted, retry=false
2014-08-06 03:29:04,560 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {955f3e36325a0ec2428b432a1d5aaffe state=FAILED_CLOSE, ts=1407320900333, server=slave1,16020,1407320853379} to {955f3e36325a0ec2428b432a1d5aaffe state=OFFLINE, ts=1407320944560, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,560 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe. with state=OFFLINE
2014-08-06 03:29:04,566 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/027f02bdfa065ce4a6a97ca2f269b28b already deleted, retry=false
2014-08-06 03:29:04,566 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {027f02bdfa065ce4a6a97ca2f269b28b state=FAILED_CLOSE, ts=1407320900337, server=slave1,16020,1407320853379} to {027f02bdfa065ce4a6a97ca2f269b28b state=OFFLINE, ts=1407320944566, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,566 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b. with state=OFFLINE
2014-08-06 03:29:04,569 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-3] master.AssignmentManager: Waiting for c1131055f4f6d48d5e6ad78c4c97663a to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:29:04,570 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 6da652800f7aa3a98ca1822845f2b600 to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:29:04,572 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/c1131055f4f6d48d5e6ad78c4c97663a already deleted, retry=false
2014-08-06 03:29:04,572 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {c1131055f4f6d48d5e6ad78c4c97663a state=FAILED_CLOSE, ts=1407320900340, server=slave1,16020,1407320853379} to {c1131055f4f6d48d5e6ad78c4c97663a state=OFFLINE, ts=1407320944572, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,572 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a. with state=OFFLINE
2014-08-06 03:29:04,577 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/6da652800f7aa3a98ca1822845f2b600 already deleted, retry=false
2014-08-06 03:29:04,578 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {6da652800f7aa3a98ca1822845f2b600 state=PENDING_OPEN, ts=1407320880793, server=slave1,16020,1407320853379} to {6da652800f7aa3a98ca1822845f2b600 state=OFFLINE, ts=1407320944578, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,578 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user9,1407319358584.6da652800f7aa3a98ca1822845f2b600. with state=OFFLINE
2014-08-06 03:29:04,580 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.MasterFileSystem: Log dir for server sceplus-vm49.almaden.ibm.com,16020,1407320853379 does not exist
2014-08-06 03:29:04,581 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: dead splitlog workers [sceplus-vm49.almaden.ibm.com,16020,1407320853379]
2014-08-06 03:29:04,581 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-1] master.AssignmentManager: Waiting for 100c3ad1432410b7d2b1166d58ed979d to leave regions-in-transition, timeOut=15000 ms.
2014-08-06 03:29:04,581 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: started splitting 0 logs in []
2014-08-06 03:29:04,583 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/100c3ad1432410b7d2b1166d58ed979d already deleted, retry=false
2014-08-06 03:29:04,583 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {100c3ad1432410b7d2b1166d58ed979d state=PENDING_OPEN, ts=1407320880795, server=slave1,16020,1407320853379} to {100c3ad1432410b7d2b1166d58ed979d state=OFFLINE, ts=1407320944583, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,583 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user3,1407319358584.100c3ad1432410b7d2b1166d58ed979d. with state=OFFLINE
2014-08-06 03:29:04,589 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] zookeeper.RecoverableZooKeeper: Node /hbase/region-in-transition/cce6d814539276fd22b26867b43c998d already deleted, retry=false
2014-08-06 03:29:04,589 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStates: Transition {cce6d814539276fd22b26867b43c998d state=PENDING_OPEN, ts=1407320880782, server=slave1,16020,1407320853379} to {cce6d814539276fd22b26867b43c998d state=OFFLINE, ts=1407320944589, server=slave1,16020,1407320853379}
2014-08-06 03:29:04,589 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] master.RegionStateStore: Updating row usertable,user5,1407319358584.cce6d814539276fd22b26867b43c998d. with state=OFFLINE
2014-08-06 03:29:04,592 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:16020-4] handler.ServerShutdownHandler: Reassigning 0 region(s) that slave1,16020,1407320853379 was carrying (and 0 regions(s) that were opening on this server)
2014-08-06 03:29:04,593 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: dead splitlog workers [slave1,16020,1407319321553]
2014-08-06 03:29:04,596 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 15ms
2014-08-06 03:29:04,596 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.LogReplayHandler: Finished processing shutdown of sceplus-vm49.almaden.ibm.com,16020,1407320853379
2014-08-06 03:29:04,604 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: dead splitlog workers [slave1,16020,1407320853379]
2014-08-06 03:29:04,607 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: started splitting 37 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting]
2014-08-06 03:29:04,607 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: started splitting 1 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379-splitting]
2014-08-06 03:29:04,646 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586
2014-08-06 03:29:04,647 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:04,736 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319928586, length=130952688
2014-08-06 03:29:04,736 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:04,742 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319928586
2014-08-06 03:29:04,755 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319928586 after 13ms
2014-08-06 03:29:04,778 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 38 unassigned = 37 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319993318=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320055409=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320045882=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319924922=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319953556=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320096498=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320108972=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319917313=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320016103=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320035086=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320008140=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319997848=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319972675=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319934193=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320031390=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320002854=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319938226=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319962847=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319957464=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319968477=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320065079=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320102730=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586=last_update = 1407320944741 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407320852266 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320094164=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 0 error = 0}
2014-08-06 03:29:04,935 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/c75a847add084fca666d04bac8c5b88f/recovered.edits/0000000000000003581.temp region=c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:04,941 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] hbase.MetaTableAccessor: Deleted [{ENCODED => 955f3e36325a0ec2428b432a1d5aaffe, NAME => 'usertable,,1407319358584.955f3e36325a0ec2428b432a1d5aaffe.', STARTKEY => '', ENDKEY => 'user1'}, {ENCODED => f4880f1fe753a7bc9cece08fdf998430, NAME => 'usertable,user1,1407319358584.f4880f1fe753a7bc9cece08fdf998430.', STARTKEY => 'user1', ENDKEY => 'user2'}, {ENCODED => 027f02bdfa065ce4a6a97ca2f269b28b, NAME => 'usertable,user2,1407319358584.027f02bdfa065ce4a6a97ca2f269b28b.', STARTKEY => 'user2', ENDKEY => 'user3'}, {ENCODED => 100c3ad1432410b7d2b1166d58ed979d, NAME => 'usertable,user3,1407319358584.100c3ad1432410b7d2b1166d58ed979d.', STARTKEY => 'user3', ENDKEY => 'user4'}, {ENCODED => 5c8404c1d7d86635c92a35d7de11d407, NAME => 'usertable,user4,1407319358584.5c8404c1d7d86635c92a35d7de11d407.', STARTKEY => 'user4', ENDKEY => 'user5'}, {ENCODED => cce6d814539276fd22b26867b43c998d, NAME => 'usertable,user5,1407319358584.cce6d814539276fd22b26867b43c998d.', STARTKEY => 'user5', ENDKEY => 'user6'}, {ENCODED => c75a847add084fca666d04bac8c5b88f, NAME => 'usertable,user6,1407319358584.c75a847add084fca666d04bac8c5b88f.', STARTKEY => 'user6', ENDKEY => 'user7'}, {ENCODED => 8f7167cd426af8a818920e7a047649ae, NAME => 'usertable,user7,1407319358584.8f7167cd426af8a818920e7a047649ae.', STARTKEY => 'user7', ENDKEY => 'user8'}, {ENCODED => c1131055f4f6d48d5e6ad78c4c97663a, NAME => 'usertable,user8,1407319358584.c1131055f4f6d48d5e6ad78c4c97663a.', STARTKEY => 'user8', ENDKEY => 'user9'}, {ENCODED => 6da652800f7aa3a98ca1822845f2b600, NAME => 'usertable,user9,1407319358584.6da652800f7aa3a98ca1822845f2b600.', STARTKEY => 'user9', ENDKEY => ''}]
2014-08-06 03:29:04,994 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: This region's directory doesn't exist: hdfs://master:54310/hbase/data/default/usertable/5c8404c1d7d86635c92a35d7de11d407. It is very likely that it was already split so it's safe to discard those edits.
2014-08-06 03:29:05,020 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: This region's directory doesn't exist: hdfs://master:54310/hbase/data/default/usertable/cce6d814539276fd22b26867b43c998d. It is very likely that it was already split so it's safe to discard those edits.
2014-08-06 03:29:05,032 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: This region's directory doesn't exist: hdfs://master:54310/hbase/data/default/usertable/8f7167cd426af8a818920e7a047649ae. It is very likely that it was already split so it's safe to discard those edits.
2014-08-06 03:29:05,064 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: This region's directory doesn't exist: hdfs://master:54310/hbase/data/default/usertable/100c3ad1432410b7d2b1166d58ed979d. It is very likely that it was already split so it's safe to discard those edits.
2014-08-06 03:29:05,066 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: This region's directory doesn't exist: hdfs://master:54310/hbase/data/default/usertable/027f02bdfa065ce4a6a97ca2f269b28b. It is very likely that it was already split so it's safe to discard those edits.
2014-08-06 03:29:05,069 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: This region's directory doesn't exist: hdfs://master:54310/hbase/data/default/usertable/6da652800f7aa3a98ca1822845f2b600. It is very likely that it was already split so it's safe to discard those edits.
2014-08-06 03:29:05,139 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320094164 acquired by slave1,16020,1407320941557
2014-08-06 03:29:05,520 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319953556
2014-08-06 03:29:05,521 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319953556 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:05,554 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319953556, length=136216203
2014-08-06 03:29:05,554 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:05,557 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319953556
2014-08-06 03:29:05,559 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319953556 after 2ms
2014-08-06 03:29:05,614 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x76d51962, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:29:05,615 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x76d51962 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:29:05,616 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:29:05,616 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-06 03:29:05,621 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47aadc098f0007, negotiated timeout = 90000
2014-08-06 03:29:05,654 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:05,666 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:05,699 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:05,720 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:05,758 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:05,820 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:05,838 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:05,999 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320102730 acquired by slave1,16020,1407320941557
2014-08-06 03:29:06,625 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:06,625 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:06,647 ERROR [split-log-closeStream-1] wal.HLogSplitter: Couldn't close log at hdfs://master:54310/hbase/data/default/usertable/c75a847add084fca666d04bac8c5b88f/recovered.edits/0000000000000003581.temp
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /hbase/data/default/usertable/c75a847add084fca666d04bac8c5b88f/recovered.edits/0000000000000003581.temp: File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_1341177960_1, pendingcreates: 3]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2934)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2978)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy18.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:190)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)
	at com.sun.proxy.$Proxy18.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:404)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy19.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy19.complete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.close(ProtobufLogWriter.java:120)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink$2.call(HLogSplitter.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink$2.call(HLogSplitter.java:1075)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:29:06,650 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 123 edits across 7 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319928586 is corrupted = false progress failed = true
2014-08-06 03:29:06,650 WARN  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] regionserver.SplitLogWorker: log splitting of WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319928586 failed, returning error
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /hbase/data/default/usertable/c75a847add084fca666d04bac8c5b88f/recovered.edits/0000000000000003581.temp: File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_1341177960_1, pendingcreates: 3]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2934)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2978)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:641)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:484)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy18.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:190)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)
	at com.sun.proxy.$Proxy18.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:404)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy19.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
	at com.sun.proxy.$Proxy19.complete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2116)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2100)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:70)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:103)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.close(ProtobufLogWriter.java:120)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink$2.call(HLogSplitter.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.HLogSplitter$LogRecoveredEditsOutputSink$2.call(HLogSplitter.java:1075)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
2014-08-06 03:29:06,661 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586 to final state ERR sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:06,661 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586 in 2007ms
2014-08-06 03:29:06,662 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586 entered state: ERR sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:06,662 WARN  [main-EventThread] master.SplitLogManager: Error splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586
2014-08-06 03:29:06,675 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319957464
2014-08-06 03:29:06,676 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319957464 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:06,714 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319957464, length=127783080
2014-08-06 03:29:06,714 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:06,720 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319957464
2014-08-06 03:29:06,721 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320094164 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:06,722 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319957464 after 2ms
2014-08-06 03:29:06,738 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320094164 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320094164
2014-08-06 03:29:06,741 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320094164
2014-08-06 03:29:06,791 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:06,799 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:06,828 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:06,843 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:06,858 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:06,911 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:06,914 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319972675 acquired by slave1,16020,1407320941557
2014-08-06 03:29:07,007 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:07,018 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:07,120 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:07,120 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 7 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319953556 is corrupted = false progress failed = false
2014-08-06 03:29:07,123 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319953556 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:07,124 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319953556 in 1602ms
2014-08-06 03:29:07,125 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319953556 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:07,137 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319953556 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319953556
2014-08-06 03:29:07,138 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319953556
2014-08-06 03:29:07,155 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:07,314 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320002854
2014-08-06 03:29:07,316 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320002854 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:07,345 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320002854, length=127740513
2014-08-06 03:29:07,345 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:07,353 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320002854
2014-08-06 03:29:07,355 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320002854 after 2ms
2014-08-06 03:29:07,397 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:07,415 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:07,436 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:07,448 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:07,460 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:07,506 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:07,518 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320102730 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:07,530 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320102730 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320102730
2014-08-06 03:29:07,531 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320102730
2014-08-06 03:29:07,535 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:07,559 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:07,633 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319934193 acquired by slave1,16020,1407320941557
2014-08-06 03:29:08,434 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:08,434 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 9 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319957464 is corrupted = false progress failed = false
2014-08-06 03:29:08,443 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319957464 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:08,443 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319957464 in 1767ms
2014-08-06 03:29:08,444 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319957464 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:08,459 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319957464 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319957464
2014-08-06 03:29:08,461 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319957464
2014-08-06 03:29:08,478 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320045882
2014-08-06 03:29:08,479 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320045882 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:08,513 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320045882, length=133613148
2014-08-06 03:29:08,513 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:08,515 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320045882
2014-08-06 03:29:08,516 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320045882 after 1ms
2014-08-06 03:29:08,570 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:08,600 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:08,603 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:08,608 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:08,616 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:08,631 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:08,639 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:08,663 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:08,749 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319972675 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:08,760 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319972675 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319972675
2014-08-06 03:29:08,761 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319972675
2014-08-06 03:29:08,771 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319993318 acquired by slave1,16020,1407320941557
2014-08-06 03:29:09,415 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:09,415 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320002854 is corrupted = false progress failed = false
2014-08-06 03:29:09,420 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320002854 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:09,420 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320002854 in 2106ms
2014-08-06 03:29:09,422 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320002854 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:09,436 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320002854 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320002854
2014-08-06 03:29:09,438 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320002854
2014-08-06 03:29:09,447 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341
2014-08-06 03:29:09,448 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:09,475 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319987341, length=128197022
2014-08-06 03:29:09,475 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:09,478 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319987341
2014-08-06 03:29:09,480 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319987341 after 2ms
2014-08-06 03:29:09,554 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:09,567 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:09,737 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:09,749 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:09,806 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319934193 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:09,822 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319934193 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319934193
2014-08-06 03:29:09,831 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319934193
2014-08-06 03:29:09,849 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320096498 acquired by slave1,16020,1407320941557
2014-08-06 03:29:09,946 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:09,986 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:09,995 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:10,081 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:10,451 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:10,451 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320045882 is corrupted = false progress failed = false
2014-08-06 03:29:10,455 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320045882 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:10,455 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320045882 in 1977ms
2014-08-06 03:29:10,456 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320045882 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:10,472 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320045882 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320045882
2014-08-06 03:29:10,474 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320045882
2014-08-06 03:29:10,483 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534
2014-08-06 03:29:10,484 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:10,513 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320059534, length=129639059
2014-08-06 03:29:10,513 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:10,517 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320059534
2014-08-06 03:29:10,518 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320059534 after 1ms
2014-08-06 03:29:10,555 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:10,561 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:10,567 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:10,569 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:10,575 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:10,581 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:10,586 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:10,596 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319993318 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:10,604 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:10,605 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319993318 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319993318
2014-08-06 03:29:10,607 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319993318
2014-08-06 03:29:10,609 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:10,616 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320065079 acquired by slave1,16020,1407320941557
2014-08-06 03:29:10,775 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 28 unassigned = 24 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320055409=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341=last_update = 1407320949479 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407320852266 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319924922=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320096498=last_update = 1407320949891 last_version = 2 cur_worker_name = slave1,16020,1407320941557 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320108972=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319917313=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320016103=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320035086=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320008140=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319997848=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534=last_update = 1407320950518 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407320852266 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320031390=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319938226=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319962847=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319968477=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320065079=last_update = 1407320950670 last_version = 2 cur_worker_name = slave1,16020,1407320941557 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 9 error = 1}
2014-08-06 03:29:10,809 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320096498 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:10,826 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320096498 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320096498
2014-08-06 03:29:10,828 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320096498
2014-08-06 03:29:11,141 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:11,142 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 9 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320059534 is corrupted = false progress failed = false
2014-08-06 03:29:11,145 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:11,145 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534 in 662ms
2014-08-06 03:29:11,145 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:11,158 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320059534 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320059534
2014-08-06 03:29:11,160 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320059534
2014-08-06 03:29:11,163 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319917313 acquired by slave1,16020,1407320941557
2014-08-06 03:29:11,168 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340
2014-08-06 03:29:11,169 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:11,171 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:11,184 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x47aadc098f0007
2014-08-06 03:29:11,189 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] zookeeper.ZooKeeper: Session: 0x47aadc098f0007 closed
2014-08-06 03:29:11,189 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-06 03:29:11,215 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319978340, length=129021630
2014-08-06 03:29:11,215 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:11,218 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319978340
2014-08-06 03:29:11,220 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319978340 after 2ms
2014-08-06 03:29:11,290 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319987341 is corrupted = false progress failed = false
2014-08-06 03:29:11,293 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x207bf926, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:29:11,293 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:11,294 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341 in 1847ms
2014-08-06 03:29:11,294 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x207bf926 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:29:11,294 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:29:11,295 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-06 03:29:11,295 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:11,298 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147aadc06860008, negotiated timeout = 90000
2014-08-06 03:29:11,308 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319987341 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319987341
2014-08-06 03:29:11,310 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319987341
2014-08-06 03:29:11,315 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:11,315 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:11,316 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:11,325 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:11,326 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:11,345 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:11,434 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:11,444 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:11,841 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566
2014-08-06 03:29:11,843 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:11,871 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319982566, length=143501454
2014-08-06 03:29:11,871 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:11,875 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319982566
2014-08-06 03:29:11,878 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319982566 after 3ms
2014-08-06 03:29:11,922 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:11,923 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:11,930 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:11,941 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320065079 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:11,948 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:11,952 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320065079 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320065079
2014-08-06 03:29:11,953 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320065079
2014-08-06 03:29:11,956 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:11,956 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:11,961 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:11,961 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319997848 acquired by slave1,16020,1407320941557
2014-08-06 03:29:12,707 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:12,708 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 11 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319978340 is corrupted = false progress failed = false
2014-08-06 03:29:12,711 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:12,711 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340 in 1543ms
2014-08-06 03:29:12,712 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:12,777 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319978340 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319978340
2014-08-06 03:29:12,779 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319978340
2014-08-06 03:29:12,792 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959
2014-08-06 03:29:12,793 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:12,822 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320025959, length=130749507
2014-08-06 03:29:12,822 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:12,826 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320025959
2014-08-06 03:29:12,828 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320025959 after 1ms
2014-08-06 03:29:12,864 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:12,867 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:12,873 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:12,876 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:12,882 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:12,893 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:12,905 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:12,907 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:13,054 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319917313 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:13,066 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319917313 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319917313
2014-08-06 03:29:13,068 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319917313
2014-08-06 03:29:13,078 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319924922 acquired by slave1,16020,1407320941557
2014-08-06 03:29:13,391 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:13,391 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 7 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319982566 is corrupted = false progress failed = false
2014-08-06 03:29:13,395 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:13,395 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566 in 1554ms
2014-08-06 03:29:13,396 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:13,409 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319982566 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319982566
2014-08-06 03:29:13,410 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319982566
2014-08-06 03:29:13,751 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491
2014-08-06 03:29:13,752 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:13,784 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319943491, length=130647386
2014-08-06 03:29:13,784 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:13,787 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319943491
2014-08-06 03:29:13,789 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319943491 after 2ms
2014-08-06 03:29:13,832 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:13,865 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:13,869 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:13,872 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:13,875 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:13,893 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:13,942 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:13,950 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319997848 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:13,962 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319997848 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319997848
2014-08-06 03:29:13,964 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319997848
2014-08-06 03:29:13,975 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320055409 acquired by slave1,16020,1407320941557
2014-08-06 03:29:14,550 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:14,551 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320025959 is corrupted = false progress failed = false
2014-08-06 03:29:14,554 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:14,554 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959 in 1762ms
2014-08-06 03:29:14,555 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:14,570 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320025959 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320025959
2014-08-06 03:29:14,571 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320025959
2014-08-06 03:29:14,582 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844
2014-08-06 03:29:14,583 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:14,613 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319947844, length=128956381
2014-08-06 03:29:14,613 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:14,618 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319947844
2014-08-06 03:29:14,620 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319947844 after 2ms
2014-08-06 03:29:14,652 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:14,661 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:14,664 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:14,667 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:14,671 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:14,682 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:14,700 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:14,789 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319924922 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:14,801 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319924922 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319924922
2014-08-06 03:29:14,802 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319924922
2014-08-06 03:29:14,809 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320008140 acquired by slave1,16020,1407320941557
2014-08-06 03:29:15,115 INFO  [PriorityRpcServer.handler=7,queue=0,port=16020] regionserver.RSRpcServices: Compacting hbase:meta,,1.1588230740
2014-08-06 03:29:15,121 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407320955120] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-08-06 03:29:15,122 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407320955120] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=35.2 K
2014-08-06 03:29:15,124 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407320955120] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:29:15,323 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407320955120] regionserver.HStore: Completed major compaction of 2 (all) file(s) in info of hbase:meta,,1.1588230740 into 3a88ead8ecc64aeeb07f000f1339b02b(size=18.3 K), total size for store is 18.3 K. This selection was in queue for 0sec, and took 0sec to execute.
2014-08-06 03:29:15,328 INFO  [master/sceplus-vm48.almaden.ibm.com/9.1.143.58:16020-shortCompactions-1407320955120] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=35.2 K, priority=1, time=979362482605083; duration=0sec
2014-08-06 03:29:15,860 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320055409 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:15,887 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320055409 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320055409
2014-08-06 03:29:15,889 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320055409
2014-08-06 03:29:15,912 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319962847 acquired by slave1,16020,1407320941557
2014-08-06 03:29:15,926 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:15,926 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 7 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319943491 is corrupted = false progress failed = false
2014-08-06 03:29:15,930 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:15,930 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491 in 2179ms
2014-08-06 03:29:15,930 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:15,943 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319943491 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319943491
2014-08-06 03:29:15,944 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319943491
2014-08-06 03:29:15,958 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244
2014-08-06 03:29:15,958 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:15,985 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320020244, length=128958490
2014-08-06 03:29:15,985 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:15,988 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320020244
2014-08-06 03:29:15,989 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320020244 after 1ms
2014-08-06 03:29:16,032 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:16,032 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 7 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319947844 is corrupted = false progress failed = false
2014-08-06 03:29:16,034 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:16,034 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844 in 1452ms
2014-08-06 03:29:16,035 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:16,039 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:16,045 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:16,046 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319947844 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319947844
2014-08-06 03:29:16,047 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319947844
2014-08-06 03:29:16,048 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:16,058 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:16,068 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:16,079 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:16,082 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:16,096 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:16,776 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 15 unassigned = 12 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320108972=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320016103=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320035086=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244=last_update = 1407320955989 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407320852266 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320008140=last_update = 1407320954831 last_version = 2 cur_worker_name = slave1,16020,1407320941557 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320031390=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319938226=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319962847=last_update = 1407320955951 last_version = 2 cur_worker_name = slave1,16020,1407320941557 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319968477=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 22 error = 1}
2014-08-06 03:29:16,825 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796
2014-08-06 03:29:16,826 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:16,851 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320069796, length=130060221
2014-08-06 03:29:16,852 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:16,858 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320069796
2014-08-06 03:29:16,859 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320069796 after 1ms
2014-08-06 03:29:16,890 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:16,893 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:16,899 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:16,903 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:16,908 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:16,922 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:16,924 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:16,932 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:16,949 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320008140 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:16,959 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320008140 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320008140
2014-08-06 03:29:16,961 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320008140
2014-08-06 03:29:16,974 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319968477 acquired by slave1,16020,1407320941557
2014-08-06 03:29:17,477 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:17,477 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320069796 is corrupted = false progress failed = false
2014-08-06 03:29:17,480 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:17,480 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796 in 654ms
2014-08-06 03:29:17,481 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:17,493 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320069796 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320069796
2014-08-06 03:29:17,494 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320069796
2014-08-06 03:29:17,517 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319962847 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:17,527 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319962847 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319962847
2014-08-06 03:29:17,529 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319962847
2014-08-06 03:29:17,599 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:17,610 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x147aadc06860008
2014-08-06 03:29:17,612 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] zookeeper.ZooKeeper: Session: 0x147aadc06860008 closed
2014-08-06 03:29:17,612 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-06 03:29:17,664 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838
2014-08-06 03:29:17,665 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:17,690 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320084838, length=136139293
2014-08-06 03:29:17,690 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:17,693 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320084838
2014-08-06 03:29:17,694 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320084838 after 1ms
2014-08-06 03:29:17,713 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320020244 is corrupted = false progress failed = false
2014-08-06 03:29:17,715 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:17,715 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244 in 1757ms
2014-08-06 03:29:17,731 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:17,739 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x2eb65e9f, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:29:17,739 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2eb65e9f connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:29:17,740 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:29:17,741 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-06 03:29:17,741 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320020244 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320020244
2014-08-06 03:29:17,743 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320020244
2014-08-06 03:29:17,745 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47aadc098f000a, negotiated timeout = 90000
2014-08-06 03:29:17,755 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:17,756 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:17,758 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:17,760 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:17,762 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:17,767 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:17,776 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:17,791 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319938226 acquired by slave1,16020,1407320941557
2014-08-06 03:29:17,792 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:18,226 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319968477 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:18,237 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319968477 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319968477
2014-08-06 03:29:18,238 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319968477
2014-08-06 03:29:18,355 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:18,359 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x47aadc098f000a
2014-08-06 03:29:18,363 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] zookeeper.ZooKeeper: Session: 0x47aadc098f000a closed
2014-08-06 03:29:18,363 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-06 03:29:18,463 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320084838 is corrupted = false progress failed = false
2014-08-06 03:29:18,469 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:18,469 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838 in 805ms
2014-08-06 03:29:18,471 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:18,487 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320084838 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320084838
2014-08-06 03:29:18,488 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320084838
2014-08-06 03:29:18,543 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320035086 acquired by slave1,16020,1407320941557
2014-08-06 03:29:18,548 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027
2014-08-06 03:29:18,550 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:18,577 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379-splitting/slave1%2C16020%2C1407320853379.1407320875027, length=17
2014-08-06 03:29:18,577 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:18,581 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379-splitting/slave1%2C16020%2C1407320853379.1407320875027
2014-08-06 03:29:18,583 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379-splitting/slave1%2C16020%2C1407320853379.1407320875027 after 2ms
2014-08-06 03:29:18,596 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:18,597 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379-splitting/slave1%2C16020%2C1407320853379.1407320875027 is corrupted = false progress failed = false
2014-08-06 03:29:18,599 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:18,599 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027 in 50ms
2014-08-06 03:29:18,599 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:18,610 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379-splitting/slave1%2C16020%2C1407320853379.1407320875027 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407320853379.1407320875027
2014-08-06 03:29:18,611 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407320853379-splitting%2Fslave1%252C16020%252C1407320853379.1407320875027
2014-08-06 03:29:18,631 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] master.SplitLogManager: finished splitting (more than or equal to) 17 bytes in 1 log files in [hdfs://master:54310/hbase/WALs/slave1,16020,1407320853379-splitting] in 14024ms
2014-08-06 03:29:18,631 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-3] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407320853379
2014-08-06 03:29:18,889 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319938226 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:18,902 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319938226 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319938226
2014-08-06 03:29:18,905 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319938226
2014-08-06 03:29:19,231 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129
2014-08-06 03:29:19,233 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:19,256 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320080129, length=127721043
2014-08-06 03:29:19,256 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:19,258 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320080129
2014-08-06 03:29:19,260 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320080129 after 2ms
2014-08-06 03:29:19,289 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x24ce9acc, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:29:19,290 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x24ce9acc connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:29:19,290 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:29:19,291 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-08-06 03:29:19,295 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x147aadc06860009, negotiated timeout = 90000
2014-08-06 03:29:19,307 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:19,307 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:19,307 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:19,312 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:19,317 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:19,323 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:19,331 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:19,340 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:19,371 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320108972 acquired by slave1,16020,1407320941557
2014-08-06 03:29:19,883 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:19,887 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x147aadc06860009
2014-08-06 03:29:19,890 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] zookeeper.ZooKeeper: Session: 0x147aadc06860009 closed
2014-08-06 03:29:19,890 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-06 03:29:19,906 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635
2014-08-06 03:29:19,907 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:19,932 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320074635, length=130933638
2014-08-06 03:29:19,932 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:19,937 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320074635
2014-08-06 03:29:19,939 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320074635 after 2ms
2014-08-06 03:29:19,953 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320035086 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:19,963 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320035086 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320035086
2014-08-06 03:29:19,964 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320035086
2014-08-06 03:29:19,990 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320080129 is corrupted = false progress failed = false
2014-08-06 03:29:19,993 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x2bbad06f, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-08-06 03:29:19,994 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2bbad06f connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-08-06 03:29:19,994 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-08-06 03:29:19,995 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-08-06 03:29:19,997 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:19,997 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129 in 765ms
2014-08-06 03:29:20,002 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:20,003 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x47aadc098f000b, negotiated timeout = 90000
2014-08-06 03:29:20,014 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320080129 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320080129
2014-08-06 03:29:20,015 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:20,015 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:20,015 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:20,016 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320080129
2014-08-06 03:29:20,020 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:20,020 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:20,020 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:20,024 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:20,025 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:20,026 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:20,031 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:20,036 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:20,301 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320016103 acquired by slave1,16020,1407320941557
2014-08-06 03:29:20,436 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,16020,1407320852266] regionserver.SplitLogWorker: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 acquired task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342
2014-08-06 03:29:20,437 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342 acquired by sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:20,457 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320108972 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:20,463 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320040342, length=151567246
2014-08-06 03:29:20,463 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: DistributedLogReplay = true
2014-08-06 03:29:20,465 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320040342
2014-08-06 03:29:20,467 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320040342 after 2ms
2014-08-06 03:29:20,468 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320108972 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320108972
2014-08-06 03:29:20,470 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320108972
2014-08-06 03:29:20,504 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 8f7167cd426af8a818920e7a047649ae
2014-08-06 03:29:20,514 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 027f02bdfa065ce4a6a97ca2f269b28b
2014-08-06 03:29:20,549 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region f4880f1fe753a7bc9cece08fdf998430
2014-08-06 03:29:20,553 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 100c3ad1432410b7d2b1166d58ed979d
2014-08-06 03:29:20,557 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 6da652800f7aa3a98ca1822845f2b600
2014-08-06 03:29:20,563 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-2] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region 5c8404c1d7d86635c92a35d7de11d407
2014-08-06 03:29:20,571 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-1] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region cce6d814539276fd22b26867b43c998d
2014-08-06 03:29:20,579 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0-Writer-0] wal.HLogSplitter: Table usertable doesn't exist. Skip log replay for region c75a847add084fca666d04bac8c5b88f
2014-08-06 03:29:20,607 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:20,607 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] wal.HLogSplitter: Processed 14 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320074635 is corrupted = false progress failed = false
2014-08-06 03:29:20,610 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:20,610 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635 in 704ms
2014-08-06 03:29:20,611 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:20,621 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320074635 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320074635
2014-08-06 03:29:20,622 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320074635
2014-08-06 03:29:21,062 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320031390 acquired by slave1,16020,1407320941557
2014-08-06 03:29:21,776 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 3 unassigned = 0 tasks={/hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342=last_update = 1407320960473 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,16020,1407320852266 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 33 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320016103=last_update = 1407320960360 last_version = 2 cur_worker_name = slave1,16020,1407320941557 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 33 error = 1, /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320031390=last_update = 1407320961114 last_version = 2 cur_worker_name = slave1,16020,1407320941557 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 37 done = 33 error = 1}
2014-08-06 03:29:21,847 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320016103 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:21,860 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320016103 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320016103
2014-08-06 03:29:21,861 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320016103
2014-08-06 03:29:22,008 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Split writers finished
2014-08-06 03:29:22,014 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x47aadc098f000b
2014-08-06 03:29:22,018 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] zookeeper.ZooKeeper: Session: 0x47aadc098f000b closed
2014-08-06 03:29:22,018 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-1-Writer-2-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-08-06 03:29:22,118 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] wal.HLogSplitter: Processed 8 edits across 0 regions; log file=hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320040342 is corrupted = false progress failed = false
2014-08-06 03:29:22,122 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342 to final state DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:22,122 INFO  [RS_LOG_REPLAY_OPS-sceplus-vm48:16020-0] handler.HLogSplitterHandler: worker sceplus-vm48.almaden.ibm.com,16020,1407320852266 done with task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342 in 1685ms
2014-08-06 03:29:22,123 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342 entered state: DONE sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:29:22,134 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320040342 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320040342
2014-08-06 03:29:22,136 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320040342
2014-08-06 03:29:22,589 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320031390 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:22,599 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407320031390 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407320031390
2014-08-06 03:29:22,601 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407320031390
2014-08-06 03:29:22,712 WARN  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] master.SplitLogManager: error while splitting logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting] installed = 37 but only 36 done
2014-08-06 03:29:22,713 ERROR [M_LOG_REPLAY_OPS-sceplus-vm48:16020-2] executor.EventHandler: Caught throwable while processing event M_LOG_REPLAY
java.io.IOException: failed log replay for slave1,16020,1407319321553, will retry
	at org.apache.hadoop.hbase.master.handler.LogReplayHandler.process(LogReplayHandler.java:78)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.io.IOException: error or interrupted while splitting logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting] Task = installed = 37 done = 36 error = 1
	at org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(SplitLogManager.java:350)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:387)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:361)
	at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:283)
	at org.apache.hadoop.hbase.master.handler.LogReplayHandler.process(LogReplayHandler.java:72)
	... 4 more
2014-08-06 03:29:22,715 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: dead splitlog workers [slave1,16020,1407319321553]
2014-08-06 03:29:22,719 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: started splitting 1 logs in [hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting]
2014-08-06 03:29:22,727 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586 acquired by slave1,16020,1407320941557
2014-08-06 03:29:24,215 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586 entered state: DONE slave1,16020,1407320941557
2014-08-06 03:29:24,225 INFO  [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting/slave1%2C16020%2C1407319321553.1407319928586 to hdfs://master:54310/hbase/oldWALs/slave1%2C16020%2C1407319321553.1407319928586
2014-08-06 03:29:24,226 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C16020%2C1407319321553-splitting%2Fslave1%252C16020%252C1407319321553.1407319928586
2014-08-06 03:29:24,233 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] master.SplitLogManager: finished splitting (more than or equal to) 130952688 bytes in 1 log files in [hdfs://master:54310/hbase/WALs/slave1,16020,1407319321553-splitting] in 1514ms
2014-08-06 03:29:24,233 INFO  [M_LOG_REPLAY_OPS-sceplus-vm48:16020-4] handler.LogReplayHandler: Finished processing shutdown of slave1,16020,1407319321553
2014-08-06 03:29:43,835 INFO  [defaultRpcServer.handler=44,queue=4,port=16020] compress.CodecPool: Got brand-new compressor [.gz]
2014-08-06 03:29:43,836 INFO  [defaultRpcServer.handler=44,queue=4,port=16020] master.HMaster: Client=hadoop//9.1.143.58 create 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-08-06 03:29:43,859 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.CreateTableHandler: Create table usertable
2014-08-06 03:29:43,939 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,939 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,940 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,939 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,940 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,940 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,939 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,941 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,941 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:43,941 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'GZ', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-08-06 03:29:44,003 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: Closed usertable,user3,1407320983827.1d9932d591b7c2474981d15851efd33e.
2014-08-06 03:29:44,005 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: Closed usertable,user1,1407320983827.ddee78e9198b31770a8a4d174fbbcd79.
2014-08-06 03:29:44,007 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: Closed usertable,user6,1407320983827.2f2aab284fdb8db96b9703a46178fab7.
2014-08-06 03:29:44,007 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: Closed usertable,user7,1407320983827.084755abb8eed2518c15a77a26b3b2b8.
2014-08-06 03:29:44,010 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: Closed usertable,,1407320983827.a2694381176b05d10296a4454830e44c.
2014-08-06 03:29:44,012 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: Closed usertable,user9,1407320983827.11e533d9d143676ff2bc58f1a40da24b.
2014-08-06 03:29:44,013 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: Closed usertable,user4,1407320983827.0a3334b8520545d3a50190b5f6cccdcf.
2014-08-06 03:29:44,014 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: Closed usertable,user5,1407320983827.9185e3c380fe6542bea6618f94e63142.
2014-08-06 03:29:44,053 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: Closed usertable,user8,1407320983827.2e12b9686e556714c2c9bd198840ce9b.
2014-08-06 03:29:44,405 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: Closed usertable,user2,1407320983827.461b0a35a3093ee843aa62f15b3ae820.
2014-08-06 03:29:44,422 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] hbase.MetaTableAccessor: Added 10
2014-08-06 03:29:44,478 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.AssignmentManager: Assigning 10 region(s) to slave1,16020,1407320941557
2014-08-06 03:29:44,478 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {1d9932d591b7c2474981d15851efd33e state=OFFLINE, ts=1407320984422, server=null} to {1d9932d591b7c2474981d15851efd33e state=PENDING_OPEN, ts=1407320984478, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,478 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user3,1407320983827.1d9932d591b7c2474981d15851efd33e. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,481 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {ddee78e9198b31770a8a4d174fbbcd79 state=OFFLINE, ts=1407320984423, server=null} to {ddee78e9198b31770a8a4d174fbbcd79 state=PENDING_OPEN, ts=1407320984481, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,481 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user1,1407320983827.ddee78e9198b31770a8a4d174fbbcd79. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,483 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {2f2aab284fdb8db96b9703a46178fab7 state=OFFLINE, ts=1407320984423, server=null} to {2f2aab284fdb8db96b9703a46178fab7 state=PENDING_OPEN, ts=1407320984483, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,483 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user6,1407320983827.2f2aab284fdb8db96b9703a46178fab7. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,486 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {084755abb8eed2518c15a77a26b3b2b8 state=OFFLINE, ts=1407320984423, server=null} to {084755abb8eed2518c15a77a26b3b2b8 state=PENDING_OPEN, ts=1407320984486, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,486 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user7,1407320983827.084755abb8eed2518c15a77a26b3b2b8. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,488 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {a2694381176b05d10296a4454830e44c state=OFFLINE, ts=1407320984424, server=null} to {a2694381176b05d10296a4454830e44c state=PENDING_OPEN, ts=1407320984488, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,488 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,,1407320983827.a2694381176b05d10296a4454830e44c. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,491 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {11e533d9d143676ff2bc58f1a40da24b state=OFFLINE, ts=1407320984424, server=null} to {11e533d9d143676ff2bc58f1a40da24b state=PENDING_OPEN, ts=1407320984491, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,491 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user9,1407320983827.11e533d9d143676ff2bc58f1a40da24b. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,493 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {0a3334b8520545d3a50190b5f6cccdcf state=OFFLINE, ts=1407320984425, server=null} to {0a3334b8520545d3a50190b5f6cccdcf state=PENDING_OPEN, ts=1407320984493, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,493 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user4,1407320983827.0a3334b8520545d3a50190b5f6cccdcf. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,495 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {9185e3c380fe6542bea6618f94e63142 state=OFFLINE, ts=1407320984426, server=null} to {9185e3c380fe6542bea6618f94e63142 state=PENDING_OPEN, ts=1407320984495, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,495 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user5,1407320983827.9185e3c380fe6542bea6618f94e63142. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,498 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {2e12b9686e556714c2c9bd198840ce9b state=OFFLINE, ts=1407320984426, server=null} to {2e12b9686e556714c2c9bd198840ce9b state=PENDING_OPEN, ts=1407320984498, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,498 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user8,1407320983827.2e12b9686e556714c2c9bd198840ce9b. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,500 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStates: Transition {461b0a35a3093ee843aa62f15b3ae820 state=OFFLINE, ts=1407320984426, server=null} to {461b0a35a3093ee843aa62f15b3ae820 state=PENDING_OPEN, ts=1407320984500, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,500 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] master.RegionStateStore: Updating row usertable,user2,1407320983827.461b0a35a3093ee843aa62f15b3ae820. with state=PENDING_OPEN&sn=slave1,16020,1407320941557
2014-08-06 03:29:44,730 WARN  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] zookeeper.ZKTableStateManager: Moving table usertable state from ENABLING to ENABLED
2014-08-06 03:29:44,736 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:16020-0] handler.CreateTableHandler: failed. null
2014-08-06 03:29:44,872 INFO  [defaultRpcServer.handler=43,queue=3,port=16020] master.RegionStates: Transition {2f2aab284fdb8db96b9703a46178fab7 state=PENDING_OPEN, ts=1407320984483, server=slave1,16020,1407320941557} to {2f2aab284fdb8db96b9703a46178fab7 state=OPEN, ts=1407320984872, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,872 INFO  [defaultRpcServer.handler=49,queue=4,port=16020] master.RegionStates: Transition {1d9932d591b7c2474981d15851efd33e state=PENDING_OPEN, ts=1407320984478, server=slave1,16020,1407320941557} to {1d9932d591b7c2474981d15851efd33e state=OPEN, ts=1407320984872, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,872 INFO  [defaultRpcServer.handler=43,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user6,1407320983827.2f2aab284fdb8db96b9703a46178fab7. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,872 INFO  [defaultRpcServer.handler=49,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user3,1407320983827.1d9932d591b7c2474981d15851efd33e. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,876 INFO  [defaultRpcServer.handler=43,queue=3,port=16020] master.RegionStates: Onlined 2f2aab284fdb8db96b9703a46178fab7 on slave1,16020,1407320941557
2014-08-06 03:29:44,876 INFO  [defaultRpcServer.handler=49,queue=4,port=16020] master.RegionStates: Onlined 1d9932d591b7c2474981d15851efd33e on slave1,16020,1407320941557
2014-08-06 03:29:44,883 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStates: Transition {ddee78e9198b31770a8a4d174fbbcd79 state=PENDING_OPEN, ts=1407320984481, server=slave1,16020,1407320941557} to {ddee78e9198b31770a8a4d174fbbcd79 state=OPEN, ts=1407320984883, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,883 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user1,1407320983827.ddee78e9198b31770a8a4d174fbbcd79. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,888 INFO  [defaultRpcServer.handler=48,queue=3,port=16020] master.RegionStates: Onlined ddee78e9198b31770a8a4d174fbbcd79 on slave1,16020,1407320941557
2014-08-06 03:29:44,901 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStates: Transition {084755abb8eed2518c15a77a26b3b2b8 state=PENDING_OPEN, ts=1407320984486, server=slave1,16020,1407320941557} to {084755abb8eed2518c15a77a26b3b2b8 state=OPEN, ts=1407320984901, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,901 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStateStore: Updating row usertable,user7,1407320983827.084755abb8eed2518c15a77a26b3b2b8. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,903 INFO  [defaultRpcServer.handler=0,queue=0,port=16020] master.RegionStates: Onlined 084755abb8eed2518c15a77a26b3b2b8 on slave1,16020,1407320941557
2014-08-06 03:29:44,906 INFO  [defaultRpcServer.handler=5,queue=0,port=16020] master.RegionStates: Transition {a2694381176b05d10296a4454830e44c state=PENDING_OPEN, ts=1407320984488, server=slave1,16020,1407320941557} to {a2694381176b05d10296a4454830e44c state=OPEN, ts=1407320984906, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,906 INFO  [defaultRpcServer.handler=5,queue=0,port=16020] master.RegionStateStore: Updating row usertable,,1407320983827.a2694381176b05d10296a4454830e44c. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,908 INFO  [defaultRpcServer.handler=5,queue=0,port=16020] master.RegionStates: Onlined a2694381176b05d10296a4454830e44c on slave1,16020,1407320941557
2014-08-06 03:29:44,920 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStates: Transition {11e533d9d143676ff2bc58f1a40da24b state=PENDING_OPEN, ts=1407320984491, server=slave1,16020,1407320941557} to {11e533d9d143676ff2bc58f1a40da24b state=OPEN, ts=1407320984920, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,921 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user9,1407320983827.11e533d9d143676ff2bc58f1a40da24b. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,923 INFO  [defaultRpcServer.handler=26,queue=1,port=16020] master.RegionStates: Onlined 11e533d9d143676ff2bc58f1a40da24b on slave1,16020,1407320941557
2014-08-06 03:29:44,934 INFO  [defaultRpcServer.handler=42,queue=2,port=16020] master.RegionStates: Transition {0a3334b8520545d3a50190b5f6cccdcf state=PENDING_OPEN, ts=1407320984493, server=slave1,16020,1407320941557} to {0a3334b8520545d3a50190b5f6cccdcf state=OPEN, ts=1407320984933, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,934 INFO  [defaultRpcServer.handler=42,queue=2,port=16020] master.RegionStateStore: Updating row usertable,user4,1407320983827.0a3334b8520545d3a50190b5f6cccdcf. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,936 INFO  [defaultRpcServer.handler=42,queue=2,port=16020] master.RegionStates: Onlined 0a3334b8520545d3a50190b5f6cccdcf on slave1,16020,1407320941557
2014-08-06 03:29:44,941 INFO  [defaultRpcServer.handler=3,queue=3,port=16020] master.RegionStates: Transition {9185e3c380fe6542bea6618f94e63142 state=PENDING_OPEN, ts=1407320984495, server=slave1,16020,1407320941557} to {9185e3c380fe6542bea6618f94e63142 state=OPEN, ts=1407320984941, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,941 INFO  [defaultRpcServer.handler=3,queue=3,port=16020] master.RegionStateStore: Updating row usertable,user5,1407320983827.9185e3c380fe6542bea6618f94e63142. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,944 INFO  [defaultRpcServer.handler=3,queue=3,port=16020] master.RegionStates: Onlined 9185e3c380fe6542bea6618f94e63142 on slave1,16020,1407320941557
2014-08-06 03:29:44,945 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStates: Transition {2e12b9686e556714c2c9bd198840ce9b state=PENDING_OPEN, ts=1407320984498, server=slave1,16020,1407320941557} to {2e12b9686e556714c2c9bd198840ce9b state=OPEN, ts=1407320984945, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,946 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStateStore: Updating row usertable,user8,1407320983827.2e12b9686e556714c2c9bd198840ce9b. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,948 INFO  [defaultRpcServer.handler=31,queue=1,port=16020] master.RegionStates: Onlined 2e12b9686e556714c2c9bd198840ce9b on slave1,16020,1407320941557
2014-08-06 03:29:44,994 INFO  [defaultRpcServer.handler=4,queue=4,port=16020] master.RegionStates: Transition {461b0a35a3093ee843aa62f15b3ae820 state=PENDING_OPEN, ts=1407320984500, server=slave1,16020,1407320941557} to {461b0a35a3093ee843aa62f15b3ae820 state=OPEN, ts=1407320984994, server=slave1,16020,1407320941557}
2014-08-06 03:29:44,994 INFO  [defaultRpcServer.handler=4,queue=4,port=16020] master.RegionStateStore: Updating row usertable,user2,1407320983827.461b0a35a3093ee843aa62f15b3ae820. with state=OPEN&openSeqNum=2&server=slave1,16020,1407320941557
2014-08-06 03:29:44,997 INFO  [defaultRpcServer.handler=4,queue=4,port=16020] master.RegionStates: Onlined 461b0a35a3093ee843aa62f15b3ae820 on slave1,16020,1407320941557
2014-08-06 03:30:56,864 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-HeapMemoryTunerChore] regionserver.HeapMemoryManager: Setting block cache heap size to 5747186176 and memstore heap size to 4470033408
2014-08-06 03:32:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.35 GB, max=5.35 GB, accesses=1822, hits=1814, hitRatio=99.56%, , cachingAccesses=1818, cachingHits=1810, cachingHitsRatio=99.56%, evictions=0, evicted=4, evictedPerRun=Infinity
2014-08-06 03:33:00,492 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:33:00,492 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407320880599, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407321180492, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:33:00,492 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 03:33:00,502 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:33:00,514 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 03:33:00,517 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:33:00,517 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 03:33:00,518 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407321180492, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407321180518, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:33:00,518 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 03:33:00,524 INFO  [AM.-pool1-t6] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:33:00,524 INFO  [AM.-pool1-t6] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407321180518, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407321180524, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:33:00,524 INFO  [AM.-pool1-t6] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 03:33:00,528 INFO  [AM.-pool1-t6] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:33:00,541 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:33:00,542 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:33:00,569 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 03:33:00,569 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:33:00,570 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407321180524, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407321180570, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:33:00,570 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:33:56,093 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-HeapMemoryTunerChore] regionserver.HeapMemoryManager: Setting block cache heap size to 6385762304 and memstore heap size to 3831457280
2014-08-06 03:37:32,466 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1824, hits=1816, hitRatio=99.56%, , cachingAccesses=1820, cachingHits=1812, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 03:38:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:38:00,491 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407321180570, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407321480491, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:38:00,492 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 03:38:00,525 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:38:00,530 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 03:38:00,531 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:38:00,531 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 03:38:00,531 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407321480491, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407321480531, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:38:00,531 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 03:38:00,538 INFO  [AM.-pool1-t7] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:38:00,539 INFO  [AM.-pool1-t7] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407321480531, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407321480538, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:38:00,539 INFO  [AM.-pool1-t7] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 03:38:00,543 INFO  [AM.-pool1-t7] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:38:00,555 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:38:00,556 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:38:00,586 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 03:38:00,586 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:38:00,587 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407321480538, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407321480587, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:38:00,587 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:42:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1826, hits=1818, hitRatio=99.56%, , cachingAccesses=1822, cachingHits=1814, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 03:43:00,492 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:43:00,494 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407321480587, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407321780494, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:43:00,495 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 03:43:00,636 INFO  [sync.3] wal.FSHLog: Slow sync cost: 137 ms, current pipeline: [9.1.143.58:50010, 9.1.143.59:50010]
2014-08-06 03:43:00,636 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:43:00,639 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 03:43:00,640 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:43:00,640 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 03:43:00,640 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407321780494, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407321780640, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:43:00,640 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 03:43:00,644 INFO  [AM.-pool1-t8] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:43:00,644 INFO  [AM.-pool1-t8] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407321780640, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407321780644, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:43:00,644 INFO  [AM.-pool1-t8] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 03:43:00,648 INFO  [AM.-pool1-t8] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:43:00,661 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:43:00,662 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:43:00,684 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 03:43:00,685 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:43:00,685 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407321780644, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407321780685, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:43:00,686 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:47:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1828, hits=1820, hitRatio=99.56%, , cachingAccesses=1824, cachingHits=1816, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 03:48:00,488 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:48:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407321780685, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322080490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:48:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 03:48:00,494 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:48:00,501 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 03:48:00,501 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:48:00,504 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 03:48:00,505 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322080490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322080505, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:48:00,505 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 03:48:00,509 INFO  [AM.-pool1-t9] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:48:00,510 INFO  [AM.-pool1-t9] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322080505, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322080510, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:48:00,510 INFO  [AM.-pool1-t9] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 03:48:00,514 INFO  [AM.-pool1-t9] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:48:00,529 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:48:00,530 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:48:00,558 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 03:48:00,559 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:48:00,559 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322080510, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322080559, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:48:00,559 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:52:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1830, hits=1822, hitRatio=99.56%, , cachingAccesses=1826, cachingHits=1818, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 03:53:00,488 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:53:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322080559, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322380489, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:53:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 03:53:00,509 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:53:00,514 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 03:53:00,514 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:53:00,514 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 03:53:00,515 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322380489, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322380515, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:53:00,516 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 03:53:00,520 INFO  [AM.-pool1-t10] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:53:00,520 INFO  [AM.-pool1-t10] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322380515, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322380520, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:53:00,520 INFO  [AM.-pool1-t10] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 03:53:00,524 INFO  [AM.-pool1-t10] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:53:00,539 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:53:00,541 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:53:00,569 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 03:53:00,570 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:53:00,571 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322380520, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322380571, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:53:00,571 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:57:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1832, hits=1824, hitRatio=99.56%, , cachingAccesses=1828, cachingHits=1820, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 03:58:00,488 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:58:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322380571, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322680489, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:58:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 03:58:00,493 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:58:00,499 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 03:58:00,499 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:58:00,499 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 03:58:00,500 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322680489, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322680500, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:58:00,500 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 03:58:00,505 INFO  [AM.-pool1-t11] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 03:58:00,505 INFO  [AM.-pool1-t11] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322680500, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322680505, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:58:00,505 INFO  [AM.-pool1-t11] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 03:58:00,510 INFO  [AM.-pool1-t11] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:58:00,522 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 03:58:00,523 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 03:58:00,547 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 03:58:00,547 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 03:58:00,547 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322680505, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322680547, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 03:58:00,548 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:02:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1834, hits=1826, hitRatio=99.56%, , cachingAccesses=1830, cachingHits=1822, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 04:03:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:03:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322680547, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322980490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:03:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 04:03:00,514 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:03:00,519 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 04:03:00,519 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:03:00,519 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 04:03:00,520 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407322980490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322980520, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:03:00,520 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 04:03:00,524 INFO  [AM.-pool1-t12] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:03:00,524 INFO  [AM.-pool1-t12] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407322980520, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322980524, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:03:00,525 INFO  [AM.-pool1-t12] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 04:03:00,528 INFO  [AM.-pool1-t12] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:03:00,544 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 04:03:00,545 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 04:03:00,575 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 04:03:00,575 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:03:00,576 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407322980524, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322980576, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:03:00,576 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:07:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1836, hits=1828, hitRatio=99.56%, , cachingAccesses=1832, cachingHits=1824, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 04:08:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:08:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407322980576, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407323280490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:08:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 04:08:00,496 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:08:00,502 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 04:08:00,502 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:08:00,502 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 04:08:00,503 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407323280490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407323280503, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:08:00,503 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 04:08:00,511 INFO  [AM.-pool1-t13] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:08:00,511 INFO  [AM.-pool1-t13] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407323280503, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407323280511, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:08:00,511 INFO  [AM.-pool1-t13] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 04:08:00,514 INFO  [AM.-pool1-t13] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:08:00,527 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 04:08:00,528 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 04:08:00,553 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 04:08:00,553 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:08:00,554 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407323280511, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407323280554, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:08:00,554 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:12:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1838, hits=1830, hitRatio=99.56%, , cachingAccesses=1834, cachingHits=1826, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 04:13:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:13:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407323280554, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407323580490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:13:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 04:13:00,513 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:13:00,516 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 04:13:00,517 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:13:00,517 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-2] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 04:13:00,518 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407323580490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407323580517, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:13:00,518 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-2] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 04:13:00,522 INFO  [AM.-pool1-t14] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:13:00,522 INFO  [AM.-pool1-t14] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407323580517, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407323580522, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:13:00,523 INFO  [AM.-pool1-t14] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 04:13:00,526 INFO  [AM.-pool1-t14] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:13:00,537 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 04:13:00,538 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 04:13:00,567 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 04:13:00,568 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:13:00,568 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407323580522, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407323580568, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:13:00,568 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:17:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1840, hits=1832, hitRatio=99.57%, , cachingAccesses=1836, cachingHits=1828, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 04:18:00,489 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:18:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407323580568, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407323880490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:18:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 04:18:00,495 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:18:00,501 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 04:18:00,501 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:18:00,501 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-0] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 04:18:00,502 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407323880490, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407323880502, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:18:00,502 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-0] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 04:18:00,509 INFO  [AM.-pool1-t15] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:18:00,509 INFO  [AM.-pool1-t15] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407323880502, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407323880509, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:18:00,509 INFO  [AM.-pool1-t15] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 04:18:00,512 INFO  [AM.-pool1-t15] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:18:00,545 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 04:18:00,546 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 04:18:00,571 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 04:18:00,571 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:18:00,572 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407323880509, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407323880572, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:18:00,572 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:22:32,465 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=5.01 MB, freeSize=5.94 GB, max=5.95 GB, accesses=1842, hits=1834, hitRatio=99.57%, , cachingAccesses=1838, cachingHits=1830, cachingHitsRatio=99.56%, evictions=0, evicted=6, evictedPerRun=Infinity
2014-08-06 04:23:00,490 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.HMaster: balance hri=hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a., src=sceplus-vm48.almaden.ibm.com,16020,1407319285032, dest=sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:23:00,491 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407323880572, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407324180491, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:23:00,491 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_CLOSE
2014-08-06 04:23:00,519 INFO  [sceplus-vm48.almaden.ibm.com,16020,1407320852266-BalancerChore] regionserver.RSRpcServices: Close fe1c441ecb6e3789e0fdd62314d7b06a, moving to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:23:00,522 INFO  [StoreCloserThread-hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.-1] regionserver.HStore: Closed info
2014-08-06 04:23:00,523 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegion: Closed hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:23:00,523 WARN  [RS_CLOSE_REGION-sceplus-vm48:16020-1] regionserver.HRegionServer: Not adding moved region record: fe1c441ecb6e3789e0fdd62314d7b06a to self.
2014-08-06 04:23:00,523 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_CLOSE, ts=1407324180491, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407324180523, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:23:00,523 INFO  [RS_CLOSE_REGION-sceplus-vm48:16020-1] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=CLOSED
2014-08-06 04:23:00,528 INFO  [AM.-pool1-t16] master.AssignmentManager: Assigning hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. to sceplus-vm48.almaden.ibm.com,16020,1407320852266
2014-08-06 04:23:00,528 INFO  [AM.-pool1-t16] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=CLOSED, ts=1407324180523, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407324180528, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:23:00,529 INFO  [AM.-pool1-t16] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=PENDING_OPEN
2014-08-06 04:23:00,533 INFO  [AM.-pool1-t16] regionserver.RSRpcServices: Open hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:23:00,542 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] hfile.CacheConfig: blockCache=org.apache.hadoop.hbase.io.hfile.LruBlockCache@473479e9, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheCompressed=false, prefetchOnOpen=false
2014-08-06 04:23:00,543 INFO  [StoreOpener-fe1c441ecb6e3789e0fdd62314d7b06a-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2560; major period 604800000, major jitter 0.500000
2014-08-06 04:23:00,562 INFO  [RS_OPEN_REGION-sceplus-vm48:16020-2] regionserver.HRegion: Onlined fe1c441ecb6e3789e0fdd62314d7b06a; next sequenceid=8
2014-08-06 04:23:00,562 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a.
2014-08-06 04:23:00,563 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStates: Transition {fe1c441ecb6e3789e0fdd62314d7b06a state=PENDING_OPEN, ts=1407324180528, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266} to {fe1c441ecb6e3789e0fdd62314d7b06a state=OPEN, ts=1407324180563, server=sceplus-vm48.almaden.ibm.com,16020,1407320852266}
2014-08-06 04:23:00,563 INFO  [PostOpenDeployTasks:fe1c441ecb6e3789e0fdd62314d7b06a] master.RegionStateStore: Updating row hbase:namespace,,1406986075482.fe1c441ecb6e3789e0fdd62314d7b06a. with state=OPEN&openSeqNum=8&server=sceplus-vm48.almaden.ibm.com,16020,1407320852266
